{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2375a36c-99ae-4852-91f3-8dbec09b1f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 03:07:24.106469: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 03:07:24.817039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cuda_nvrtc/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cublas/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/:/usr/local/cudnn-112-81133/lib64:/usr/local/cuda-11.2/lib64:/lib/x86_64-linux-gnu:/opt/anaconda-3-2020.02/lib\n",
      "2023-09-19 03:07:24.817111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cuda_nvrtc/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cublas/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/:/usr/local/cudnn-112-81133/lib64:/usr/local/cuda-11.2/lib64:/lib/x86_64-linux-gnu:/opt/anaconda-3-2020.02/lib\n",
      "2023-09-19 03:07:24.817117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5539747e-7bde-4cd5-b26c-08cdf8d23ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 17:36:47.332135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 17:36:48.078672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cuda_nvrtc/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cublas/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/:/usr/local/cudnn-112-81133/lib64:/usr/local/cuda-11.2/lib64:/lib/x86_64-linux-gnu:/opt/anaconda-3-2020.02/lib\n",
      "2023-09-22 17:36:48.078741: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cuda_nvrtc/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cublas/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/nvidia/cudnn/lib:/opt/anaconda-3-2020.02/envs/hskim/lib/:/usr/local/cudnn-112-81133/lib64:/usr/local/cuda-11.2/lib64:/lib/x86_64-linux-gnu:/opt/anaconda-3-2020.02/lib\n",
      "2023-09-22 17:36:48.078747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-22 17:36:49.462090\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./.local/lib/python3.8/site-packages')\n",
    "sys.path.append('/usr/lib/python3/dist-packages')\n",
    "\n",
    "from keras import losses, metrics\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, BatchNormalization, Dropout, Activation, Input\n",
    "from keras.layers import GlobalAveragePooling1D, Flatten, SeparableConv1D, concatenate, Add\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, f1_score, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats, interp\n",
    "import os, sys, pickle, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, datetime, time\n",
    "from sklearn.model_selection import KFold\n",
    "#from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "\n",
    "# tensorflow 사용 시 seed 고정\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "SEED = 98\n",
    "GPU = 2\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= f\"{GPU}\"\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada78df-cfa1-42dd-970d-94cded4648b2",
   "metadata": {},
   "source": [
    "# Input loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f99cfe-a6c1-4266-b34a-1ab7d0719383",
   "metadata": {},
   "source": [
    "## signal only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8cae03-8acf-4aa2-828a-c72efb0f5f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (7022, 5000, 12)\n",
      "x test shape: (1756, 5000, 12)\n"
     ]
    }
   ],
   "source": [
    "SRATE = 500\n",
    "ECG_FILT = 'bandpass'\n",
    "TRAIN = 'train'\n",
    "ADULT = 'child'\n",
    "NORM = 'z-norm'\n",
    "GENDER = 'female'\n",
    "\n",
    "hyper_path = f'SRATE{SRATE}_ECG-{ECG_FILT}_{NORM}_{ADULT}_{TRAIN}'\n",
    "input_path = f'dataset/{hyper_path}/'\n",
    "\n",
    "with np.load(input_path+'x.npz', allow_pickle=True) as f:\n",
    "    x_train = f['x_train']\n",
    "    x_test = f['x_test']\n",
    "        \n",
    "with np.load(input_path+'y.npz', allow_pickle=True) as f:\n",
    "    y_train = f['y_train']\n",
    "    y_test = f['y_test']\n",
    "    \n",
    "with np.load(input_path+'c.npz', allow_pickle=True) as f:\n",
    "    c_train = f['c_train']\n",
    "    c_test = f['c_test']  \n",
    "    \n",
    "with np.load(input_path+'g.npz', allow_pickle=True) as f:\n",
    "    g_train = f['g_train']\n",
    "    g_test = f['g_test']        \n",
    "    \n",
    "print(f'x train shape: {x_train.shape}')\n",
    "print(f'x test shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b642ace-b1dc-4ed8-b0be-7b651a6bc384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (3131, 5000, 12)\n",
      "x test shape: (793, 5000, 12)\n"
     ]
    }
   ],
   "source": [
    "hyper_path = f'SRATE{SRATE}_ECG-{ECG_FILT}_{NORM}_{ADULT}_{GENDER}_{TRAIN}'\n",
    "\n",
    "train_mask = (g_train == 1) if GENDER == 'male' else (g_train == 0)\n",
    "test_mask = (g_test == 1) if GENDER == 'male' else (g_test == 0)\n",
    "\n",
    "x_train = x_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "c_train = c_train[train_mask]\n",
    "g_train = g_train[train_mask]\n",
    "\n",
    "x_test = x_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "c_test = c_test[test_mask]\n",
    "g_test = g_test[test_mask]\n",
    "\n",
    "print(f'x train shape: {x_train.shape}')\n",
    "print(f'x test shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8905684-8b6c-4c2e-9e8e-77a744e376e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train / 20\n",
    "y_test = y_test / 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd83c6-dbe6-4da8-abcf-2ef2713f3f8d",
   "metadata": {},
   "source": [
    "## signal + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78ae5f6-65d8-466c-898a-1b6a8847085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (27824, 5000, 12)\n",
      "feat train shape: (27824, 55)\n",
      "x test shape: (6962, 5000, 12)\n",
      "feat test shape: (6962, 55)\n",
      "x train shape: (13358, 5000, 12)\n",
      "x test shape: (3387, 5000, 12)\n",
      "train: 0.6191248297691345, test: 0.6184705495834351\n"
     ]
    }
   ],
   "source": [
    "SRATE = 500\n",
    "ECG_FILT = 'bandpass'\n",
    "TRAIN = 'train'\n",
    "ADULT = 'adult'\n",
    "NORM = 'z-norm'\n",
    "GENDER = 'male'\n",
    "\n",
    "hyper_path = f'SRATE{SRATE}_ECG-{ECG_FILT}_{NORM}_{ADULT}_{TRAIN}'\n",
    "input_path = f'dataset/{hyper_path}/signal+features/'\n",
    "\n",
    "with np.load(input_path+'x.npz', allow_pickle=True) as f:\n",
    "    x_train = f['x_train']\n",
    "    x_test = f['x_test']\n",
    "     \n",
    "with np.load(input_path+'feats.npz', allow_pickle=True) as f:\n",
    "    feat_train = f['feat_train']\n",
    "    feat_test = f['feat_test']\n",
    "        \n",
    "with np.load(input_path+'y.npz', allow_pickle=True) as f:\n",
    "    y_train = f['y_train']\n",
    "    y_test = f['y_test']\n",
    "    \n",
    "with np.load(input_path+'c.npz', allow_pickle=True) as f:\n",
    "    c_train = f['c_train']\n",
    "    c_test = f['c_test']  \n",
    "    \n",
    "with np.load(input_path+'g.npz', allow_pickle=True) as f:\n",
    "    g_train = f['g_train']\n",
    "    g_test = f['g_test']        \n",
    "    \n",
    "print(f'x train shape: {x_train.shape}')\n",
    "print(f'feat train shape: {feat_train.shape}')\n",
    "print(f'x test shape: {x_test.shape}')\n",
    "print(f'feat test shape: {feat_test.shape}')\n",
    "\n",
    "hyper_path = f'SRATE{SRATE}_ECG-{ECG_FILT}_{NORM}_{ADULT}_{GENDER}_{TRAIN}'\n",
    "\n",
    "train_mask = (g_train == 1) if GENDER == 'male' else (g_train == 0)\n",
    "test_mask = (g_test == 1) if GENDER == 'male' else (g_test == 0)\n",
    "\n",
    "x_train = x_train[train_mask]\n",
    "feat_train = feat_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "c_train = c_train[train_mask]\n",
    "g_train = g_train[train_mask]\n",
    "\n",
    "x_test = x_test[test_mask]\n",
    "feat_test = feat_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "c_test = c_test[test_mask]\n",
    "g_test = g_test[test_mask]\n",
    "\n",
    "print(f'x train shape: {x_train.shape}')\n",
    "print(f'x test shape: {x_test.shape}')\n",
    "\n",
    "\n",
    "SCALE_Y = 100 if ADULT == 'adult' else 20\n",
    "y_train = y_train / SCALE_Y\n",
    "y_test = y_test / SCALE_Y\n",
    "\n",
    "print(f'train: {np.mean(y_train)}, test: {np.mean(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cac09-b6df-49b3-9e47-cf45c7ed6756",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.load(input_path+'x_train.npz', allow_pickle=True)['arr_0']\n",
    "x_test = np.load(input_path+'x_test.npz', allow_pickle=True)['arr_0']\n",
    "y_train = np.load(input_path+'y_train.npz')['arr_0']\n",
    "y_test = np.load(input_path+'y_test.npz')['arr_0']\n",
    "c_train = np.load(input_path+'c_train.npz')['arr_0']\n",
    "c_test = np.load(input_path+'c_test.npz')['arr_0']\n",
    "\n",
    "print(f'x train shape: {x_train.shape}')\n",
    "print(f'x test shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b46f07-0d89-462f-abdb-3dcfdb0a8779",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91c1c53-fb8c-46ad-b077-3902581121f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making test settings...done\n",
      "2023-09-21 15:18:47.064394\n"
     ]
    }
   ],
   "source": [
    "# folder\n",
    "nfold = 4  # 각각의 hyperparameter에 대해 k-fold 를 시행하고 평균을 구한다.\n",
    "ntest = 500\n",
    "rootdir = f\"randomSearch/{hyper_path}/CNN_4layers_kernel(9~19)_age%20(sigmoid)_{nfold}fold_test{ntest}\"\n",
    "\n",
    "if not os.path.exists(f\"randomSearch/{hyper_path}\"):\n",
    "    os.mkdir(f\"randomSearch/{hyper_path}\")\n",
    "\n",
    "if not os.path.exists(rootdir):\n",
    "    os.mkdir(rootdir)\n",
    "\n",
    "# 모델에 대한 정보 txt로 저장\n",
    "f = open(f'{rootdir}/README.txt', 'w')\n",
    "f.write(f'model: 1D CNN 4 layers, regression')\n",
    "f.write(f'input: ECG of 10 second, output: age')\n",
    "f.close()\n",
    "    \n",
    "\n",
    "# test_settings\n",
    "layer_settings, test_settings = [], []\n",
    "\n",
    "\n",
    "# hyperparamters\n",
    "globalpool_opts = ['max','ave']\n",
    "\n",
    "# hyperparamters pool\n",
    "filt_opts = [16, 32, 64, 128] # num of filters(kernel)\n",
    "stride_opts = [1,2,3]  # other opts: stride = (kernel-1)/2\n",
    "kernel_opts = range(7,19,2) # kernel size\n",
    "pool_size = 2\n",
    "dropout_opts  = [0, 0.1, 0.2, 0.3, 0.4, 0.5] # dropout rate\n",
    "dense_opts = [0, 8, 16, 32, 64]\n",
    "BATCH_SIZE = [32, 64, 128, 256, 512]\n",
    "lr_opts = [0.001, 0.002, 0.0005]\n",
    "\n",
    "print('start making test settings...', end='', flush=True)\n",
    "# test settings\n",
    "nfilt, kernels, strides = [], [], []\n",
    "for i in range(5):\n",
    "    nfilt.append(0)\n",
    "    kernels.append(0)\n",
    "    strides.append(0)\n",
    "\n",
    "for nfilter in filt_opts:\n",
    "    for kernel in kernel_opts:\n",
    "        for stride in stride_opts:\n",
    "        #layer_settings.append([nfilter, kernel, int((kernel-1)/2)])       \n",
    "            layer_settings.append([nfilter, kernel, stride])\n",
    "    \n",
    "for dense_node in dense_opts:\n",
    "    for dropout_cnn in dropout_opts:\n",
    "        for dropout_fc in dropout_opts:\n",
    "            for batch_size in BATCH_SIZE:\n",
    "                for learning_rate in lr_opts:\n",
    "                    test_settings.append([dense_node, dropout_cnn, dropout_fc, batch_size, learning_rate])                                   \n",
    "\n",
    "                        \n",
    "print('done')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65166b0-a99d-4065-ae82-44ffce10f2c3",
   "metadata": {},
   "source": [
    "## 1d-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc66dd-af29-42b2-b7cf-535f6d80f375",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random search 0/500\n",
      "Epoch 1/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.1266 - mean_squared_error: 0.0323\n",
      "Epoch 1: val_loss improved from inf to 0.10229, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 2s 12ms/step - loss: 0.1252 - mean_squared_error: 0.0314 - val_loss: 0.1023 - val_mean_squared_error: 0.0188\n",
      "Epoch 2/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0822 - mean_squared_error: 0.0136\n",
      "Epoch 2: val_loss did not improve from 0.10229\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0824 - mean_squared_error: 0.0137 - val_loss: 0.2890 - val_mean_squared_error: 0.1256\n",
      "Epoch 3/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.0103\n",
      "Epoch 3: val_loss improved from 0.10229 to 0.07661, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0705 - mean_squared_error: 0.0102 - val_loss: 0.0766 - val_mean_squared_error: 0.0124\n",
      "Epoch 4/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0614 - mean_squared_error: 0.0075\n",
      "Epoch 4: val_loss improved from 0.07661 to 0.07029, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0617 - mean_squared_error: 0.0076 - val_loss: 0.0703 - val_mean_squared_error: 0.0097\n",
      "Epoch 5/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0574 - mean_squared_error: 0.0066\n",
      "Epoch 5: val_loss improved from 0.07029 to 0.06671, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0573 - mean_squared_error: 0.0066 - val_loss: 0.0667 - val_mean_squared_error: 0.0085\n",
      "Epoch 6/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.0588 - mean_squared_error: 0.0071\n",
      "Epoch 6: val_loss improved from 0.06671 to 0.06242, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0580 - mean_squared_error: 0.0068 - val_loss: 0.0624 - val_mean_squared_error: 0.0072\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.0062\n",
      "Epoch 7: val_loss improved from 0.06242 to 0.05632, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0550 - mean_squared_error: 0.0062 - val_loss: 0.0563 - val_mean_squared_error: 0.0062\n",
      "Epoch 8/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0527 - mean_squared_error: 0.0059\n",
      "Epoch 8: val_loss improved from 0.05632 to 0.05181, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0528 - mean_squared_error: 0.0060 - val_loss: 0.0518 - val_mean_squared_error: 0.0056\n",
      "Epoch 9/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0547 - mean_squared_error: 0.0062\n",
      "Epoch 9: val_loss did not improve from 0.05181\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0544 - mean_squared_error: 0.0061 - val_loss: 0.0532 - val_mean_squared_error: 0.0056\n",
      "Epoch 10/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.0053\n",
      "Epoch 10: val_loss did not improve from 0.05181\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0499 - mean_squared_error: 0.0053 - val_loss: 0.0533 - val_mean_squared_error: 0.0056\n",
      "Epoch 11/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0495 - mean_squared_error: 0.0052\n",
      "Epoch 11: val_loss improved from 0.05181 to 0.05071, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0496 - mean_squared_error: 0.0052 - val_loss: 0.0507 - val_mean_squared_error: 0.0050\n",
      "Epoch 12/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0469 - mean_squared_error: 0.0047\n",
      "Epoch 12: val_loss did not improve from 0.05071\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0474 - mean_squared_error: 0.0048 - val_loss: 0.0822 - val_mean_squared_error: 0.0130\n",
      "Epoch 13/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0048\n",
      "Epoch 13: val_loss did not improve from 0.05071\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0479 - mean_squared_error: 0.0049 - val_loss: 0.0528 - val_mean_squared_error: 0.0061\n",
      "Epoch 14/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0048\n",
      "Epoch 14: val_loss did not improve from 0.05071\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0478 - mean_squared_error: 0.0048 - val_loss: 0.0602 - val_mean_squared_error: 0.0066\n",
      "25/25 [==============================] - 1s 4ms/step\n",
      " ###0 fold : val mae 0.05, val rmse 0.07###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.1220 - mean_squared_error: 0.0303\n",
      "Epoch 1: val_loss improved from inf to 0.10013, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_1.hdf5\n",
      "74/74 [==============================] - 3s 16ms/step - loss: 0.1217 - mean_squared_error: 0.0300 - val_loss: 0.1001 - val_mean_squared_error: 0.0213\n",
      "Epoch 2/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.0140\n",
      "Epoch 2: val_loss did not improve from 0.10013\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.0822 - mean_squared_error: 0.0139 - val_loss: 0.1614 - val_mean_squared_error: 0.0467\n",
      "Epoch 3/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0666 - mean_squared_error: 0.0089\n",
      "Epoch 3: val_loss improved from 0.10013 to 0.06246, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_1.hdf5\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0667 - mean_squared_error: 0.0089 - val_loss: 0.0625 - val_mean_squared_error: 0.0086\n",
      "Epoch 4/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0627 - mean_squared_error: 0.0082\n",
      "Epoch 4: val_loss did not improve from 0.06246\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0627 - mean_squared_error: 0.0082 - val_loss: 0.1056 - val_mean_squared_error: 0.0183\n",
      "Epoch 5/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0582 - mean_squared_error: 0.0070\n",
      "Epoch 5: val_loss did not improve from 0.06246\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0583 - mean_squared_error: 0.0070 - val_loss: 0.0718 - val_mean_squared_error: 0.0113\n",
      "Epoch 6/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0564 - mean_squared_error: 0.0066\n",
      "Epoch 6: val_loss improved from 0.06246 to 0.05737, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0562 - mean_squared_error: 0.0066 - val_loss: 0.0574 - val_mean_squared_error: 0.0069\n",
      "Epoch 7/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.0061\n",
      "Epoch 7: val_loss did not improve from 0.05737\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0540 - mean_squared_error: 0.0061 - val_loss: 0.0585 - val_mean_squared_error: 0.0072\n",
      "Epoch 8/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0532 - mean_squared_error: 0.0057\n",
      "Epoch 8: val_loss improved from 0.05737 to 0.04966, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0531 - mean_squared_error: 0.0057 - val_loss: 0.0497 - val_mean_squared_error: 0.0051\n",
      "Epoch 9/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0506 - mean_squared_error: 0.0055\n",
      "Epoch 9: val_loss improved from 0.04966 to 0.04873, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_1.hdf5\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0507 - mean_squared_error: 0.0055 - val_loss: 0.0487 - val_mean_squared_error: 0.0048\n",
      "Epoch 10/100\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.0055\n",
      "Epoch 10: val_loss did not improve from 0.04873\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0512 - mean_squared_error: 0.0054 - val_loss: 0.0516 - val_mean_squared_error: 0.0055\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0495 - mean_squared_error: 0.0052\n",
      "Epoch 11: val_loss did not improve from 0.04873\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0495 - mean_squared_error: 0.0052 - val_loss: 0.0837 - val_mean_squared_error: 0.0133\n",
      "Epoch 12/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0504 - mean_squared_error: 0.0054\n",
      "Epoch 12: val_loss improved from 0.04873 to 0.04654, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_1.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0504 - mean_squared_error: 0.0054 - val_loss: 0.0465 - val_mean_squared_error: 0.0042\n",
      "Epoch 13/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0050\n",
      "Epoch 13: val_loss did not improve from 0.04654\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0488 - mean_squared_error: 0.0051 - val_loss: 0.0487 - val_mean_squared_error: 0.0049\n",
      "Epoch 14/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.0466 - mean_squared_error: 0.0046\n",
      "Epoch 14: val_loss did not improve from 0.04654\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.0469 - mean_squared_error: 0.0046 - val_loss: 0.0527 - val_mean_squared_error: 0.0058\n",
      "Epoch 15/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0465 - mean_squared_error: 0.0046\n",
      "Epoch 15: val_loss did not improve from 0.04654\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0467 - mean_squared_error: 0.0046 - val_loss: 0.0626 - val_mean_squared_error: 0.0079\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      " ###1 fold : val mae 0.05, val rmse 0.07###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.1220 - mean_squared_error: 0.0317\n",
      "Epoch 1: val_loss improved from inf to 0.26634, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 2s 12ms/step - loss: 0.1213 - mean_squared_error: 0.0313 - val_loss: 0.2663 - val_mean_squared_error: 0.1029\n",
      "Epoch 2/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0766 - mean_squared_error: 0.0116\n",
      "Epoch 2: val_loss improved from 0.26634 to 0.11782, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0760 - mean_squared_error: 0.0113 - val_loss: 0.1178 - val_mean_squared_error: 0.0243\n",
      "Epoch 3/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0667 - mean_squared_error: 0.0089\n",
      "Epoch 3: val_loss improved from 0.11782 to 0.06382, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0672 - mean_squared_error: 0.0090 - val_loss: 0.0638 - val_mean_squared_error: 0.0080\n",
      "Epoch 4/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.0079\n",
      "Epoch 4: val_loss did not improve from 0.06382\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0621 - mean_squared_error: 0.0079 - val_loss: 0.0872 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0592 - mean_squared_error: 0.0071\n",
      "Epoch 5: val_loss improved from 0.06382 to 0.05177, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0592 - mean_squared_error: 0.0070 - val_loss: 0.0518 - val_mean_squared_error: 0.0055\n",
      "Epoch 6/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.0568 - mean_squared_error: 0.0065\n",
      "Epoch 6: val_loss did not improve from 0.05177\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0566 - mean_squared_error: 0.0064 - val_loss: 0.0518 - val_mean_squared_error: 0.0057\n",
      "Epoch 7/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0531 - mean_squared_error: 0.0058\n",
      "Epoch 7: val_loss did not improve from 0.05177\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0535 - mean_squared_error: 0.0059 - val_loss: 0.0592 - val_mean_squared_error: 0.0067\n",
      "Epoch 8/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.0055\n",
      "Epoch 8: val_loss improved from 0.05177 to 0.05045, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0520 - mean_squared_error: 0.0056 - val_loss: 0.0505 - val_mean_squared_error: 0.0059\n",
      "Epoch 9/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.0057\n",
      "Epoch 9: val_loss did not improve from 0.05045\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0525 - mean_squared_error: 0.0057 - val_loss: 0.0529 - val_mean_squared_error: 0.0060\n",
      "Epoch 10/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0524 - mean_squared_error: 0.0057\n",
      "Epoch 10: val_loss improved from 0.05045 to 0.04973, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0522 - mean_squared_error: 0.0057 - val_loss: 0.0497 - val_mean_squared_error: 0.0054\n",
      "Epoch 11/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.0047\n",
      "Epoch 11: val_loss did not improve from 0.04973\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0473 - mean_squared_error: 0.0048 - val_loss: 0.0931 - val_mean_squared_error: 0.0163\n",
      "Epoch 12/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.0051\n",
      "Epoch 12: val_loss did not improve from 0.04973\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0493 - mean_squared_error: 0.0051 - val_loss: 0.0591 - val_mean_squared_error: 0.0072\n",
      "Epoch 13/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0051\n",
      "Epoch 13: val_loss improved from 0.04973 to 0.04742, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0493 - mean_squared_error: 0.0051 - val_loss: 0.0474 - val_mean_squared_error: 0.0047\n",
      "Epoch 14/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0045\n",
      "Epoch 14: val_loss improved from 0.04742 to 0.04620, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_2.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0462 - mean_squared_error: 0.0045 - val_loss: 0.0462 - val_mean_squared_error: 0.0048\n",
      "Epoch 15/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0482 - mean_squared_error: 0.0048\n",
      "Epoch 15: val_loss did not improve from 0.04620\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0481 - mean_squared_error: 0.0048 - val_loss: 0.0472 - val_mean_squared_error: 0.0048\n",
      "Epoch 16/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0042\n",
      "Epoch 16: val_loss did not improve from 0.04620\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0444 - mean_squared_error: 0.0042 - val_loss: 0.0640 - val_mean_squared_error: 0.0078\n",
      "Epoch 17/100\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.0474 - mean_squared_error: 0.0047\n",
      "Epoch 17: val_loss did not improve from 0.04620\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0469 - mean_squared_error: 0.0046 - val_loss: 0.0519 - val_mean_squared_error: 0.0059\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      " ###2 fold : val mae 0.05, val rmse 0.07###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1206 - mean_squared_error: 0.0320\n",
      "Epoch 1: val_loss improved from inf to 0.12947, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_3.hdf5\n",
      "74/74 [==============================] - 2s 13ms/step - loss: 0.1206 - mean_squared_error: 0.0320 - val_loss: 0.1295 - val_mean_squared_error: 0.0325\n",
      "Epoch 2/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0783 - mean_squared_error: 0.0119\n",
      "Epoch 2: val_loss improved from 0.12947 to 0.10281, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0782 - mean_squared_error: 0.0118 - val_loss: 0.1028 - val_mean_squared_error: 0.0199\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0681 - mean_squared_error: 0.0090\n",
      "Epoch 3: val_loss improved from 0.10281 to 0.05817, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0681 - mean_squared_error: 0.0090 - val_loss: 0.0582 - val_mean_squared_error: 0.0069\n",
      "Epoch 4/100\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.0631 - mean_squared_error: 0.0080\n",
      "Epoch 4: val_loss did not improve from 0.05817\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.0632 - mean_squared_error: 0.0080 - val_loss: 0.0796 - val_mean_squared_error: 0.0118\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0585 - mean_squared_error: 0.0068\n",
      "Epoch 5: val_loss did not improve from 0.05817\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0585 - mean_squared_error: 0.0068 - val_loss: 0.0630 - val_mean_squared_error: 0.0083\n",
      "Epoch 6/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0597 - mean_squared_error: 0.0071\n",
      "Epoch 6: val_loss improved from 0.05817 to 0.05544, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_3.hdf5\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0596 - mean_squared_error: 0.0071 - val_loss: 0.0554 - val_mean_squared_error: 0.0062\n",
      "Epoch 7/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.0065\n",
      "Epoch 7: val_loss improved from 0.05544 to 0.05055, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt9str3,layer2:c64filt13str1,layer3:c64filt17str3,1conv,dropout0.2,dnodes0,dropout0.4/weights_3.hdf5\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0566 - mean_squared_error: 0.0065 - val_loss: 0.0505 - val_mean_squared_error: 0.0055\n",
      "Epoch 8/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.0053\n",
      "Epoch 8: val_loss did not improve from 0.05055\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0514 - mean_squared_error: 0.0053 - val_loss: 0.0512 - val_mean_squared_error: 0.0056\n",
      "Epoch 9/100\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0529 - mean_squared_error: 0.0057\n",
      "Epoch 9: val_loss did not improve from 0.05055\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0530 - mean_squared_error: 0.0057 - val_loss: 0.0566 - val_mean_squared_error: 0.0071\n",
      "Epoch 10/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0537 - mean_squared_error: 0.0058\n",
      "Epoch 10: val_loss did not improve from 0.05055\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0536 - mean_squared_error: 0.0058 - val_loss: 0.0578 - val_mean_squared_error: 0.0068\n",
      "25/25 [==============================] - 1s 4ms/step\n",
      " ###3 fold : val mae 0.06, val rmse 0.08###\n",
      "mae1.02+-0.06_rmse1.44+-0.08\n",
      "random search 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0228\n",
      "Epoch 1: val_loss improved from inf to 0.25155, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_0.hdf5\n",
      "19/19 [==============================] - 3s 45ms/step - loss: 0.1114 - mean_squared_error: 0.0227 - val_loss: 0.2515 - val_mean_squared_error: 0.1251\n",
      "Epoch 2/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.0193\n",
      "Epoch 2: val_loss did not improve from 0.25155\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.1016 - mean_squared_error: 0.0193 - val_loss: 0.3637 - val_mean_squared_error: 0.2098\n",
      "Epoch 3/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0843 - mean_squared_error: 0.0142\n",
      "Epoch 3: val_loss improved from 0.25155 to 0.13684, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_0.hdf5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0833 - mean_squared_error: 0.0138 - val_loss: 0.1368 - val_mean_squared_error: 0.0320\n",
      "Epoch 4/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0658 - mean_squared_error: 0.0084\n",
      "Epoch 4: val_loss did not improve from 0.13684\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0656 - mean_squared_error: 0.0084 - val_loss: 0.2402 - val_mean_squared_error: 0.0876\n",
      "Epoch 5/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0553 - mean_squared_error: 0.0063\n",
      "Epoch 5: val_loss did not improve from 0.13684\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0550 - mean_squared_error: 0.0062 - val_loss: 0.2579 - val_mean_squared_error: 0.0974\n",
      "Epoch 6/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0052\n",
      "Epoch 6: val_loss did not improve from 0.13684\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0480 - mean_squared_error: 0.0051 - val_loss: 0.1647 - val_mean_squared_error: 0.0414\n",
      "25/25 [==============================] - 1s 4ms/step\n",
      " ###0 fold : val mae 0.13, val rmse 0.17###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1140 - mean_squared_error: 0.0235\n",
      "Epoch 1: val_loss improved from inf to 0.42985, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_1.hdf5\n",
      "19/19 [==============================] - 3s 52ms/step - loss: 0.1138 - mean_squared_error: 0.0235 - val_loss: 0.4298 - val_mean_squared_error: 0.2765\n",
      "Epoch 2/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0199\n",
      "Epoch 2: val_loss improved from 0.42985 to 0.35698, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_1.hdf5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0996 - mean_squared_error: 0.0193 - val_loss: 0.3570 - val_mean_squared_error: 0.1820\n",
      "Epoch 3/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0743 - mean_squared_error: 0.0105\n",
      "Epoch 3: val_loss improved from 0.35698 to 0.17226, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_1.hdf5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0742 - mean_squared_error: 0.0104 - val_loss: 0.1723 - val_mean_squared_error: 0.0441\n",
      "Epoch 4/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.0073\n",
      "Epoch 4: val_loss did not improve from 0.17226\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 0.0601 - mean_squared_error: 0.0072 - val_loss: 0.2430 - val_mean_squared_error: 0.0808\n",
      "Epoch 5/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0545 - mean_squared_error: 0.0061\n",
      "Epoch 5: val_loss did not improve from 0.17226\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0544 - mean_squared_error: 0.0061 - val_loss: 0.1881 - val_mean_squared_error: 0.0516\n",
      "Epoch 6/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.0053\n",
      "Epoch 6: val_loss did not improve from 0.17226\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0493 - mean_squared_error: 0.0052 - val_loss: 0.1737 - val_mean_squared_error: 0.0473\n",
      "25/25 [==============================] - 1s 3ms/step\n",
      " ###1 fold : val mae 0.17, val rmse 0.21###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1144 - mean_squared_error: 0.0241\n",
      "Epoch 1: val_loss improved from inf to 0.19189, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_2.hdf5\n",
      "19/19 [==============================] - 3s 38ms/step - loss: 0.1144 - mean_squared_error: 0.0241 - val_loss: 0.1919 - val_mean_squared_error: 0.0790\n",
      "Epoch 2/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0203\n",
      "Epoch 2: val_loss did not improve from 0.19189\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.1022 - mean_squared_error: 0.0200 - val_loss: 0.2717 - val_mean_squared_error: 0.1180\n",
      "Epoch 3/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0735 - mean_squared_error: 0.0105\n",
      "Epoch 3: val_loss improved from 0.19189 to 0.13874, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_2.hdf5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0732 - mean_squared_error: 0.0105 - val_loss: 0.1387 - val_mean_squared_error: 0.0350\n",
      "Epoch 4/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0586 - mean_squared_error: 0.0067\n",
      "Epoch 4: val_loss did not improve from 0.13874\n",
      "19/19 [==============================] - 1s 40ms/step - loss: 0.0584 - mean_squared_error: 0.0067 - val_loss: 0.2486 - val_mean_squared_error: 0.0895\n",
      "Epoch 5/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.0054\n",
      "Epoch 5: val_loss did not improve from 0.13874\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0514 - mean_squared_error: 0.0055 - val_loss: 0.1631 - val_mean_squared_error: 0.0413\n",
      "Epoch 6/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0484 - mean_squared_error: 0.0051\n",
      "Epoch 6: val_loss improved from 0.13874 to 0.11590, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_2.hdf5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0479 - mean_squared_error: 0.0050 - val_loss: 0.1159 - val_mean_squared_error: 0.0233\n",
      "Epoch 7/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0444 - mean_squared_error: 0.0043\n",
      "Epoch 7: val_loss did not improve from 0.11590\n",
      "19/19 [==============================] - 1s 48ms/step - loss: 0.0450 - mean_squared_error: 0.0044 - val_loss: 0.1394 - val_mean_squared_error: 0.0301\n",
      "Epoch 8/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0039\n",
      "Epoch 8: val_loss improved from 0.11590 to 0.07646, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_2.hdf5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0418 - mean_squared_error: 0.0039 - val_loss: 0.0765 - val_mean_squared_error: 0.0107\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0034\n",
      "Epoch 9: val_loss did not improve from 0.07646\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0382 - mean_squared_error: 0.0034 - val_loss: 0.0822 - val_mean_squared_error: 0.0118\n",
      "Epoch 10/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0033\n",
      "Epoch 10: val_loss improved from 0.07646 to 0.07147, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_2.hdf5\n",
      "19/19 [==============================] - 1s 45ms/step - loss: 0.0365 - mean_squared_error: 0.0032 - val_loss: 0.0715 - val_mean_squared_error: 0.0093\n",
      "Epoch 11/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0028\n",
      "Epoch 11: val_loss improved from 0.07147 to 0.06267, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_2.hdf5\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0343 - mean_squared_error: 0.0029 - val_loss: 0.0627 - val_mean_squared_error: 0.0073\n",
      "Epoch 12/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0336 - mean_squared_error: 0.0028\n",
      "Epoch 12: val_loss did not improve from 0.06267\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0334 - mean_squared_error: 0.0028 - val_loss: 0.0658 - val_mean_squared_error: 0.0081\n",
      "Epoch 13/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0025\n",
      "Epoch 13: val_loss did not improve from 0.06267\n",
      "19/19 [==============================] - 1s 46ms/step - loss: 0.0323 - mean_squared_error: 0.0026 - val_loss: 0.0704 - val_mean_squared_error: 0.0086\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0301 - mean_squared_error: 0.0024\n",
      "Epoch 14: val_loss did not improve from 0.06267\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0301 - mean_squared_error: 0.0024 - val_loss: 0.0640 - val_mean_squared_error: 0.0076\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      " ###2 fold : val mae 0.06, val rmse 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1176 - mean_squared_error: 0.0251\n",
      "Epoch 1: val_loss improved from inf to 0.13194, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch128,layer1:c128filt17str3,layer2:c16filt11str3,layer3:c128filt13str1,layer4:c32filt11str2,1conv,dropout0,dnodes32,dropout0/weights_3.hdf5\n",
      "19/19 [==============================] - 2s 37ms/step - loss: 0.1165 - mean_squared_error: 0.0247 - val_loss: 0.1319 - val_mean_squared_error: 0.0413\n",
      "Epoch 2/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.1096 - mean_squared_error: 0.0214\n",
      "Epoch 2: val_loss did not improve from 0.13194\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.1096 - mean_squared_error: 0.0213 - val_loss: 0.2077 - val_mean_squared_error: 0.0967\n",
      "Epoch 3/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0930 - mean_squared_error: 0.0162\n",
      "Epoch 3: val_loss did not improve from 0.13194\n",
      "19/19 [==============================] - 1s 47ms/step - loss: 0.0913 - mean_squared_error: 0.0157 - val_loss: 0.1380 - val_mean_squared_error: 0.0313\n",
      "Epoch 4/100\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0674 - mean_squared_error: 0.0087\n",
      "Epoch 4: val_loss did not improve from 0.13194\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0674 - mean_squared_error: 0.0087 - val_loss: 0.1359 - val_mean_squared_error: 0.0306\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      " ###3 fold : val mae 0.14, val rmse 0.21###\n",
      "mae2.49+-0.79_rmse3.33+-1.04\n",
      "random search 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.1494 - mean_squared_error: 0.0507\n",
      "Epoch 1: val_loss improved from inf to 0.11148, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt7str1,layer2:c16filt7str1,layer3:c64filt15str2,1conv,dropout0.1,dnodes16,dropout0.5/weights_0.hdf5\n",
      "74/74 [==============================] - 3s 14ms/step - loss: 0.1494 - mean_squared_error: 0.0507 - val_loss: 0.1115 - val_mean_squared_error: 0.0221\n",
      "Epoch 2/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss improved from 0.11148 to 0.09215, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt7str1,layer2:c16filt7str1,layer3:c64filt15str2,1conv,dropout0.1,dnodes16,dropout0.5/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1055 - mean_squared_error: 0.0205 - val_loss: 0.0922 - val_mean_squared_error: 0.0157\n",
      "Epoch 3/100\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0887 - mean_squared_error: 0.0150\n",
      "Epoch 3: val_loss improved from 0.09215 to 0.08099, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt7str1,layer2:c16filt7str1,layer3:c64filt15str2,1conv,dropout0.1,dnodes16,dropout0.5/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0896 - mean_squared_error: 0.0154 - val_loss: 0.0810 - val_mean_squared_error: 0.0126\n",
      "Epoch 4/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0836 - mean_squared_error: 0.0135\n",
      "Epoch 4: val_loss improved from 0.08099 to 0.06625, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt7str1,layer2:c16filt7str1,layer3:c64filt15str2,1conv,dropout0.1,dnodes16,dropout0.5/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0838 - mean_squared_error: 0.0135 - val_loss: 0.0662 - val_mean_squared_error: 0.0091\n",
      "Epoch 5/100\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0793 - mean_squared_error: 0.0123\n",
      "Epoch 5: val_loss improved from 0.06625 to 0.06434, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN_4layers_kernel(9~19)_age%20(sigmoid)_4fold_test500/batch32,layer1:c16filt7str1,layer2:c16filt7str1,layer3:c64filt15str2,1conv,dropout0.1,dnodes16,dropout0.5/weights_0.hdf5\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0792 - mean_squared_error: 0.0123 - val_loss: 0.0643 - val_mean_squared_error: 0.0084\n",
      "Epoch 6/100\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0742 - mean_squared_error: 0.0108"
     ]
    }
   ],
   "source": [
    "from keras import metrics\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# random search for hyperparameter\n",
    "ntrial = ntest\n",
    "train_errs, val_errs = [] ,[]\n",
    "test_acc, test_roc, test_prc = [], [], []\n",
    "#test_rmse, test_mae, test_auc = [], [], []\n",
    "random_settings = []\n",
    "\n",
    "\n",
    "for itrial in range(ntrial):\n",
    "    # grid search\n",
    "    # test_setting = test_settings[itrial]\n",
    "\n",
    "    # random search\n",
    "    print('random search {}/{}'.format(itrial, ntrial))\n",
    "    \n",
    "    # total conv layers of the model\n",
    "    n_conv = random.choice([2,3,4]) \n",
    "    # test settings\n",
    "    for i in range(n_conv):\n",
    "        nfilt[i], kernels[i], strides[i] = random.choice(layer_settings)\n",
    "    dense_node, dropout_cnn, dropout_fc, batch_size, learning_rate = random.choice(test_settings)\n",
    "    \n",
    "    if itrial < 0:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # 이번 옵션에 대한 결과 디렉토리\n",
    "    odir_f = f'batch{batch_size},'\n",
    "    for i in range(n_conv):\n",
    "        odir_f += f'layer{i+1}:c{nfilt[i]}filt{kernels[i]}str{strides[i]},'\n",
    "    odir_f += f'1conv,dropout{dropout_cnn},dnodes{dense_node},dropout{dropout_fc}'#,lr{learning_rate}'\n",
    "    random_settings.append(odir_f)\n",
    "    \n",
    "    odir = rootdir + '/' + odir_f\n",
    "    if not os.path.exists(odir):\n",
    "        os.mkdir(odir)\n",
    "\n",
    "        \n",
    "    # model validation (VGG)\n",
    "    out_shape = x_train.shape[1]\n",
    "    for i in range(n_conv):\n",
    "        out_shape = out_shape / pool_size / strides[i]\n",
    "    if out_shape < 1:\n",
    "        print('non-valid structure')\n",
    "        os.rmdir(odir)\n",
    "        itrial -= 1\n",
    "        continue\n",
    "        \n",
    "    #mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/GPU:0\",\"/GPU:1\",\"/GPU:2\",\"/GPU:3\"])\n",
    "    #with mirrored_strategy.scope(): \n",
    "    \n",
    "    with tf.device(f'/gpu:{GPU}'):\n",
    "        # build a model\n",
    "        inp = Input(shape=(x_train.shape[1],x_train.shape[2]))\n",
    "        out = inp\n",
    "\n",
    "\n",
    "        # VGC block\n",
    "        out = Conv1D(filters=nfilt[i], kernel_size=kernels[i], strides=strides[i], padding='same', activation=None)(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "        out = MaxPooling1D(pool_size)(out)\n",
    "\n",
    "\n",
    "        # globalpooling vs flattening vs 1x1 convolution\n",
    "        #elif globalpool_opt == 'ave':\n",
    "        #    out = GlobalAveragePooling1D()(out)\n",
    "        out = Conv1D(filters=1, kernel_size=1)(out)\n",
    "        out = Flatten() (out)\n",
    "\n",
    "\n",
    "\n",
    "        if dense_node != 0:\n",
    "            out = Dropout(dropout_cnn)(out)\n",
    "            out = Dense(dense_node, activation='relu')(out)\n",
    "        out = Dropout(dropout_fc)(out)\n",
    "        out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "\n",
    "        model = Model(inputs=[inp], outputs=[out])\n",
    "        model.save_weights(f'{odir}/initial_weights.hdf5')\n",
    "\n",
    "\n",
    "        # 4-fold cv\n",
    "        kfold = KFold(nfold)\n",
    "        tprs, aucs, prs = [], [], []\n",
    "        test_rmse, test_mae = [], []\n",
    "        f1_scores, thvals = [], []\n",
    "        mean_fpr = np.linspace(0,1,100)\n",
    "        mean_recall = np.linspace(0,1,100)\n",
    "\n",
    "        switch = 0\n",
    "        caseids_train = np.unique(c_train)\n",
    "        for fold, (c_cv_trains_mask, c_cv_test_mask) in enumerate(kfold.split(caseids_train)):\n",
    "            c_cv_trains = caseids_train[c_cv_trains_mask]\n",
    "            \n",
    "            cv_train_mask = np.isin(c_train, c_cv_trains)\n",
    "            cv_val_mask = ~cv_train_mask\n",
    "            \n",
    "            X_train = x_train[cv_train_mask]\n",
    "            X_val = x_train[cv_val_mask]\n",
    "\n",
    "            Y_train = y_train[cv_train_mask]\n",
    "            Y_val = y_train[cv_val_mask]\n",
    "\n",
    "\n",
    "            # model 학습\n",
    "            try:\n",
    "                # learning scheduler\n",
    "                def step_decay(epoch):\n",
    "                    start = 1e-3\n",
    "                    drop = 0.1\n",
    "                    epochs_drop = 10\n",
    "                    lr = start * (drop ** np.floor((epoch)/epochs_drop))\n",
    "                    return lr\n",
    "                lr_scheduler = LearningRateScheduler(step_decay, verbose=1)\n",
    "                \n",
    "                weightcache = f\"{odir}/weights_{fold}.hdf5\"\n",
    "                \n",
    "                model.compile(loss='mean_absolute_error', optimizer=Adam(lr=lr_scheduler, weight_decay=0), metrics=['mean_squared_error'])\n",
    "                hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3}, \n",
    "                                        callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weightcache, verbose=1, save_best_only=True),\n",
    "                                                    EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')])\n",
    "\n",
    "                model.load_weights(weightcache)\n",
    "                y_pred = model.predict(x_test).flatten()\n",
    "\n",
    "                # MAE 계산\n",
    "                model_err = metrics.MeanAbsoluteError()\n",
    "                model_err.update_state(y_test, y_pred)\n",
    "                mae_val = model_err.result().numpy()\n",
    "                test_mae.append(mae_val)\n",
    "\n",
    "                # RMSE 계산\n",
    "                model_err = metrics.RootMeanSquaredError() \n",
    "                model_err.update_state(y_test, y_pred)\n",
    "                rmse_val = model_err.result().numpy()\n",
    "                test_rmse.append(rmse_val)\n",
    "\n",
    "\n",
    "                print(f' ###{fold} fold : val mae {mae_val:.2f}, val rmse {rmse_val:.2f}###')\n",
    "                tf.keras.backend.clear_session()\n",
    "                model.load_weights(f'{odir}/initial_weights.hdf5')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                switch = 1\n",
    "                shutil.rmtree(odir)\n",
    "                itrial -= 1\n",
    "                break\n",
    "        ###\n",
    "        if switch:\n",
    "            switch = 0\n",
    "            tf.keras.backend.clear_session()\n",
    "            continue\n",
    "\n",
    "    # \n",
    "\n",
    "    # RMSE 계산\n",
    "    mean_rmse = np.mean(test_rmse)\n",
    "    std_rmse = np.std(test_rmse)\n",
    "    \n",
    "    mean_mae = np.mean(test_mae)\n",
    "    std_mae = np.std(test_mae)\n",
    "\n",
    "    max_idx = test_mae.index(min(test_mae))\n",
    "    \n",
    "\n",
    "    print(f'mae{mean_mae*20:.2f}+-{std_mae*20:.2f}_rmse{mean_rmse*20:.2f}+-{std_rmse*20:.2f}')\n",
    "    open(odir+\"/model.json\", \"wt\").write(model.to_json())\n",
    "\n",
    "    os.rename(odir, rootdir+f'/mae{mean_mae*20:.2f}+-{std_mae*20:.2f}_rmse{mean_rmse*20:.2f}+-{std_rmse*20:.2f}_max{max_idx}__{odir_f}')\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0431314-6f05-4312-a87e-27066ae28b6f",
   "metadata": {},
   "source": [
    "## cnn-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813310a-20a8-46b8-8994-2c78069c751b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 00:17:10.603307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 00:17:11.076687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21956 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 00:17:19.552360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8904\n",
      "2023-09-22 00:17:20.603293: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-22 00:17:20.679126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-22 00:17:20.773509: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2f1d2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-22 00:17:20.773544: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-09-22 00:17:20.779571: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-22 00:17:20.857025: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-22 00:17:20.910598: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.0214\n",
      "Epoch 1: val_loss improved from inf to 0.08347, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 27s 333ms/step - loss: 0.0982 - mean_squared_error: 0.0214 - val_loss: 0.0835 - val_mean_squared_error: 0.0094\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0808 - mean_squared_error: 0.0125\n",
      "Epoch 2: val_loss improved from 0.08347 to 0.07921, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.0807 - mean_squared_error: 0.0125 - val_loss: 0.0792 - val_mean_squared_error: 0.0093\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0766 - mean_squared_error: 0.0113\n",
      "Epoch 3: val_loss improved from 0.07921 to 0.05835, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 13s 301ms/step - loss: 0.0767 - mean_squared_error: 0.0113 - val_loss: 0.0583 - val_mean_squared_error: 0.0055\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.0068\n",
      "Epoch 4: val_loss improved from 0.05835 to 0.04529, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 13s 299ms/step - loss: 0.0572 - mean_squared_error: 0.0068 - val_loss: 0.0453 - val_mean_squared_error: 0.0043\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0518 - mean_squared_error: 0.0056\n",
      "Epoch 5: val_loss improved from 0.04529 to 0.04403, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 13s 300ms/step - loss: 0.0518 - mean_squared_error: 0.0056 - val_loss: 0.0440 - val_mean_squared_error: 0.0043\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0051\n",
      "Epoch 6: val_loss improved from 0.04403 to 0.04071, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 13s 300ms/step - loss: 0.0485 - mean_squared_error: 0.0051 - val_loss: 0.0407 - val_mean_squared_error: 0.0036\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0464 - mean_squared_error: 0.0046\n",
      "Epoch 7: val_loss did not improve from 0.04071\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 0.0465 - mean_squared_error: 0.0046 - val_loss: 0.0450 - val_mean_squared_error: 0.0036\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.0045\n",
      "Epoch 8: val_loss improved from 0.04071 to 0.04011, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 0.0448 - mean_squared_error: 0.0044 - val_loss: 0.0401 - val_mean_squared_error: 0.0033\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0040\n",
      "Epoch 9: val_loss did not improve from 0.04011\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 0.0422 - mean_squared_error: 0.0040 - val_loss: 0.0484 - val_mean_squared_error: 0.0051\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0038\n",
      "Epoch 10: val_loss did not improve from 0.04011\n",
      "42/42 [==============================] - 12s 298ms/step - loss: 0.0416 - mean_squared_error: 0.0038 - val_loss: 0.0480 - val_mean_squared_error: 0.0051\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0420 - mean_squared_error: 0.0039\n",
      "Epoch 11: val_loss did not improve from 0.04011\n",
      "42/42 [==============================] - 13s 299ms/step - loss: 0.0420 - mean_squared_error: 0.0039 - val_loss: 0.0463 - val_mean_squared_error: 0.0044\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###0 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0986 - mean_squared_error: 0.0214\n",
      "Epoch 1: val_loss improved from inf to 0.08147, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 25s 336ms/step - loss: 0.0986 - mean_squared_error: 0.0214 - val_loss: 0.0815 - val_mean_squared_error: 0.0092\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.0128\n",
      "Epoch 2: val_loss improved from 0.08147 to 0.07661, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.0823 - mean_squared_error: 0.0128 - val_loss: 0.0766 - val_mean_squared_error: 0.0095\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0771 - mean_squared_error: 0.0114\n",
      "Epoch 3: val_loss improved from 0.07661 to 0.05783, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.0771 - mean_squared_error: 0.0114 - val_loss: 0.0578 - val_mean_squared_error: 0.0067\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0607 - mean_squared_error: 0.0074\n",
      "Epoch 4: val_loss improved from 0.05783 to 0.05236, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 13s 303ms/step - loss: 0.0607 - mean_squared_error: 0.0074 - val_loss: 0.0524 - val_mean_squared_error: 0.0058\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.0060\n",
      "Epoch 5: val_loss did not improve from 0.05236\n",
      "42/42 [==============================] - 13s 301ms/step - loss: 0.0546 - mean_squared_error: 0.0060 - val_loss: 0.0530 - val_mean_squared_error: 0.0064\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0502 - mean_squared_error: 0.0053\n",
      "Epoch 6: val_loss improved from 0.05236 to 0.05102, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 13s 304ms/step - loss: 0.0502 - mean_squared_error: 0.0053 - val_loss: 0.0510 - val_mean_squared_error: 0.0057\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0481 - mean_squared_error: 0.0049\n",
      "Epoch 7: val_loss improved from 0.05102 to 0.04689, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 13s 303ms/step - loss: 0.0481 - mean_squared_error: 0.0049 - val_loss: 0.0469 - val_mean_squared_error: 0.0049\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0046\n",
      "Epoch 8: val_loss did not improve from 0.04689\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 0.0462 - mean_squared_error: 0.0046 - val_loss: 0.0537 - val_mean_squared_error: 0.0062\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0460 - mean_squared_error: 0.0045\n",
      "Epoch 9: val_loss did not improve from 0.04689\n",
      "42/42 [==============================] - 13s 301ms/step - loss: 0.0460 - mean_squared_error: 0.0045 - val_loss: 0.0577 - val_mean_squared_error: 0.0074\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0038\n",
      "Epoch 10: val_loss did not improve from 0.04689\n",
      "42/42 [==============================] - 13s 301ms/step - loss: 0.0421 - mean_squared_error: 0.0038 - val_loss: 0.0539 - val_mean_squared_error: 0.0064\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###1 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0975 - mean_squared_error: 0.0203\n",
      "Epoch 1: val_loss improved from inf to 0.08099, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 24s 327ms/step - loss: 0.0975 - mean_squared_error: 0.0203 - val_loss: 0.0810 - val_mean_squared_error: 0.0092\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.0128\n",
      "Epoch 2: val_loss improved from 0.08099 to 0.07502, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 13s 307ms/step - loss: 0.0823 - mean_squared_error: 0.0128 - val_loss: 0.0750 - val_mean_squared_error: 0.0096\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0777 - mean_squared_error: 0.0115\n",
      "Epoch 3: val_loss improved from 0.07502 to 0.05889, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 13s 301ms/step - loss: 0.0777 - mean_squared_error: 0.0115 - val_loss: 0.0589 - val_mean_squared_error: 0.0060\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0621 - mean_squared_error: 0.0078\n",
      "Epoch 4: val_loss improved from 0.05889 to 0.04714, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.0621 - mean_squared_error: 0.0078 - val_loss: 0.0471 - val_mean_squared_error: 0.0048\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.0063\n",
      "Epoch 5: val_loss did not improve from 0.04714\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.0550 - mean_squared_error: 0.0063 - val_loss: 0.0495 - val_mean_squared_error: 0.0051\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0522 - mean_squared_error: 0.0058\n",
      "Epoch 6: val_loss did not improve from 0.04714\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 0.0522 - mean_squared_error: 0.0058 - val_loss: 0.0514 - val_mean_squared_error: 0.0055\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0049\n",
      "Epoch 7: val_loss did not improve from 0.04714\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 0.0478 - mean_squared_error: 0.0049 - val_loss: 0.0531 - val_mean_squared_error: 0.0062\n",
      "55/55 [==============================] - 2s 31ms/step\n",
      " ###2 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0976 - mean_squared_error: 0.0206\n",
      "Epoch 1: val_loss improved from inf to 0.07956, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 24s 321ms/step - loss: 0.0976 - mean_squared_error: 0.0206 - val_loss: 0.0796 - val_mean_squared_error: 0.0095\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.0130\n",
      "Epoch 2: val_loss improved from 0.07956 to 0.07545, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.0832 - mean_squared_error: 0.0130 - val_loss: 0.0754 - val_mean_squared_error: 0.0101\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0748 - mean_squared_error: 0.0105\n",
      "Epoch 3: val_loss did not improve from 0.07545\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 0.0748 - mean_squared_error: 0.0105 - val_loss: 0.0771 - val_mean_squared_error: 0.0087\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0581 - mean_squared_error: 0.0069\n",
      "Epoch 4: val_loss improved from 0.07545 to 0.05966, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0581 - mean_squared_error: 0.0069 - val_loss: 0.0597 - val_mean_squared_error: 0.0054\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0524 - mean_squared_error: 0.0057\n",
      "Epoch 5: val_loss did not improve from 0.05966\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 0.0524 - mean_squared_error: 0.0057 - val_loss: 0.0622 - val_mean_squared_error: 0.0059\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0490 - mean_squared_error: 0.0051\n",
      "Epoch 6: val_loss improved from 0.05966 to 0.04697, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0490 - mean_squared_error: 0.0051 - val_loss: 0.0470 - val_mean_squared_error: 0.0048\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0046\n",
      "Epoch 7: val_loss improved from 0.04697 to 0.04674, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool2_do0.2_tra4_head8_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 0.0462 - mean_squared_error: 0.0046 - val_loss: 0.0467 - val_mean_squared_error: 0.0049\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0045\n",
      "Epoch 8: val_loss did not improve from 0.04674\n",
      "42/42 [==============================] - 13s 308ms/step - loss: 0.0456 - mean_squared_error: 0.0045 - val_loss: 0.0495 - val_mean_squared_error: 0.0055\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0452 - mean_squared_error: 0.0043\n",
      "Epoch 9: val_loss did not improve from 0.04674\n",
      "42/42 [==============================] - 13s 307ms/step - loss: 0.0451 - mean_squared_error: 0.0043 - val_loss: 0.0474 - val_mean_squared_error: 0.0051\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0040\n",
      "Epoch 10: val_loss did not improve from 0.04674\n",
      "42/42 [==============================] - 13s 301ms/step - loss: 0.0425 - mean_squared_error: 0.0040 - val_loss: 0.0548 - val_mean_squared_error: 0.0067\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###3 fold : val mae 0.05###\n",
      "mae0.95+-0.08\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1498 - mean_squared_error: 0.0601\n",
      "Epoch 1: val_loss improved from inf to 0.10978, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 15s 154ms/step - loss: 0.1498 - mean_squared_error: 0.0601 - val_loss: 0.1098 - val_mean_squared_error: 0.0216\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1052 - mean_squared_error: 0.0205\n",
      "Epoch 2: val_loss improved from 0.10978 to 0.10969, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 0.1052 - mean_squared_error: 0.0205 - val_loss: 0.1097 - val_mean_squared_error: 0.0216\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0205\n",
      "Epoch 3: val_loss improved from 0.10969 to 0.10954, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.1054 - mean_squared_error: 0.0205 - val_loss: 0.1095 - val_mean_squared_error: 0.0215\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0205\n",
      "Epoch 4: val_loss improved from 0.10954 to 0.10865, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1049 - mean_squared_error: 0.0205 - val_loss: 0.1086 - val_mean_squared_error: 0.0214\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0204\n",
      "Epoch 5: val_loss improved from 0.10865 to 0.10666, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 0.1036 - mean_squared_error: 0.0204 - val_loss: 0.1067 - val_mean_squared_error: 0.0209\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0199\n",
      "Epoch 6: val_loss improved from 0.10666 to 0.10034, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1030 - mean_squared_error: 0.0199 - val_loss: 0.1003 - val_mean_squared_error: 0.0195\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0196\n",
      "Epoch 7: val_loss improved from 0.10034 to 0.09794, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.1012 - mean_squared_error: 0.0196 - val_loss: 0.0979 - val_mean_squared_error: 0.0189\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0194\n",
      "Epoch 8: val_loss improved from 0.09794 to 0.09704, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 0.1007 - mean_squared_error: 0.0194 - val_loss: 0.0970 - val_mean_squared_error: 0.0187\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.0186\n",
      "Epoch 9: val_loss improved from 0.09704 to 0.08613, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0983 - mean_squared_error: 0.0186 - val_loss: 0.0861 - val_mean_squared_error: 0.0158\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0951 - mean_squared_error: 0.0174\n",
      "Epoch 10: val_loss improved from 0.08613 to 0.08148, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0951 - mean_squared_error: 0.0174 - val_loss: 0.0815 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.0162\n",
      "Epoch 11: val_loss improved from 0.08148 to 0.07202, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 0.0914 - mean_squared_error: 0.0162 - val_loss: 0.0720 - val_mean_squared_error: 0.0111\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0787 - mean_squared_error: 0.0126\n",
      "Epoch 12: val_loss did not improve from 0.07202\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0787 - mean_squared_error: 0.0126 - val_loss: 0.0811 - val_mean_squared_error: 0.0132\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0683 - mean_squared_error: 0.0096\n",
      "Epoch 13: val_loss improved from 0.07202 to 0.06920, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0683 - mean_squared_error: 0.0096 - val_loss: 0.0692 - val_mean_squared_error: 0.0113\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0610 - mean_squared_error: 0.0076\n",
      "Epoch 14: val_loss did not improve from 0.06920\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 0.0610 - mean_squared_error: 0.0076 - val_loss: 0.0800 - val_mean_squared_error: 0.0133\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0556 - mean_squared_error: 0.0063\n",
      "Epoch 15: val_loss did not improve from 0.06920\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0556 - mean_squared_error: 0.0063 - val_loss: 0.0960 - val_mean_squared_error: 0.0223\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0526 - mean_squared_error: 0.0058\n",
      "Epoch 16: val_loss did not improve from 0.06920\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0526 - mean_squared_error: 0.0058 - val_loss: 0.0722 - val_mean_squared_error: 0.0114\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###0 fold : val mae 0.07###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1528 - mean_squared_error: 0.0614\n",
      "Epoch 1: val_loss improved from inf to 0.10681, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 15s 168ms/step - loss: 0.1528 - mean_squared_error: 0.0614 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0208\n",
      "Epoch 2: val_loss improved from 0.10681 to 0.10666, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1064 - mean_squared_error: 0.0208 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.10666 to 0.10660, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 0.1061 - mean_squared_error: 0.0207 - val_loss: 0.1066 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss improved from 0.10660 to 0.10626, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.1060 - mean_squared_error: 0.0206 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss improved from 0.10626 to 0.10518, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.1054 - mean_squared_error: 0.0206 - val_loss: 0.1052 - val_mean_squared_error: 0.0204\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.0206\n",
      "Epoch 6: val_loss improved from 0.10518 to 0.10363, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 118ms/step - loss: 0.1044 - mean_squared_error: 0.0206 - val_loss: 0.1036 - val_mean_squared_error: 0.0201\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0204\n",
      "Epoch 7: val_loss improved from 0.10363 to 0.10215, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1040 - mean_squared_error: 0.0204 - val_loss: 0.1021 - val_mean_squared_error: 0.0198\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0200\n",
      "Epoch 8: val_loss improved from 0.10215 to 0.09703, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.1029 - mean_squared_error: 0.0200 - val_loss: 0.0970 - val_mean_squared_error: 0.0186\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.0193\n",
      "Epoch 9: val_loss improved from 0.09703 to 0.09217, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 118ms/step - loss: 0.1001 - mean_squared_error: 0.0193 - val_loss: 0.0922 - val_mean_squared_error: 0.0175\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0970 - mean_squared_error: 0.0182\n",
      "Epoch 10: val_loss improved from 0.09217 to 0.08390, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0970 - mean_squared_error: 0.0182 - val_loss: 0.0839 - val_mean_squared_error: 0.0152\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0944 - mean_squared_error: 0.0171\n",
      "Epoch 11: val_loss improved from 0.08390 to 0.07932, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 0.0944 - mean_squared_error: 0.0171 - val_loss: 0.0793 - val_mean_squared_error: 0.0137\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0923 - mean_squared_error: 0.0164\n",
      "Epoch 12: val_loss improved from 0.07932 to 0.07580, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 0.0923 - mean_squared_error: 0.0164 - val_loss: 0.0758 - val_mean_squared_error: 0.0122\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0891 - mean_squared_error: 0.0152\n",
      "Epoch 13: val_loss improved from 0.07580 to 0.07066, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 0.0891 - mean_squared_error: 0.0152 - val_loss: 0.0707 - val_mean_squared_error: 0.0107\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0770 - mean_squared_error: 0.0118\n",
      "Epoch 14: val_loss did not improve from 0.07066\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 0.0770 - mean_squared_error: 0.0118 - val_loss: 0.0846 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.0101\n",
      "Epoch 15: val_loss did not improve from 0.07066\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 0.0706 - mean_squared_error: 0.0101 - val_loss: 0.0812 - val_mean_squared_error: 0.0140\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0622 - mean_squared_error: 0.0078\n",
      "Epoch 16: val_loss improved from 0.07066 to 0.04820, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0622 - mean_squared_error: 0.0078 - val_loss: 0.0482 - val_mean_squared_error: 0.0058\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0576 - mean_squared_error: 0.0068\n",
      "Epoch 17: val_loss did not improve from 0.04820\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.0576 - mean_squared_error: 0.0068 - val_loss: 0.0592 - val_mean_squared_error: 0.0079\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.0060\n",
      "Epoch 18: val_loss did not improve from 0.04820\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 0.0542 - mean_squared_error: 0.0060 - val_loss: 0.0582 - val_mean_squared_error: 0.0075\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.0054\n",
      "Epoch 19: val_loss improved from 0.04820 to 0.04750, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 0.0511 - mean_squared_error: 0.0054 - val_loss: 0.0475 - val_mean_squared_error: 0.0052\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.0049\n",
      "Epoch 20: val_loss did not improve from 0.04750\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0491 - mean_squared_error: 0.0049 - val_loss: 0.0500 - val_mean_squared_error: 0.0041\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0475 - mean_squared_error: 0.0046\n",
      "Epoch 21: val_loss did not improve from 0.04750\n",
      "21/21 [==============================] - 2s 119ms/step - loss: 0.0475 - mean_squared_error: 0.0046 - val_loss: 0.0586 - val_mean_squared_error: 0.0053\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0458 - mean_squared_error: 0.0043\n",
      "Epoch 22: val_loss did not improve from 0.04750\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0458 - mean_squared_error: 0.0043 - val_loss: 0.0625 - val_mean_squared_error: 0.0061\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###1 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1500 - mean_squared_error: 0.0581\n",
      "Epoch 1: val_loss improved from inf to 0.10575, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 15s 143ms/step - loss: 0.1500 - mean_squared_error: 0.0581 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10575 to 0.10569, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 0.1071 - mean_squared_error: 0.0210 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0212\n",
      "Epoch 3: val_loss improved from 0.10569 to 0.10554, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1073 - mean_squared_error: 0.0212 - val_loss: 0.1055 - val_mean_squared_error: 0.0203\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10554 to 0.10513, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1066 - mean_squared_error: 0.0209 - val_loss: 0.1051 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10513 to 0.10377, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 0.1061 - mean_squared_error: 0.0209 - val_loss: 0.1038 - val_mean_squared_error: 0.0200\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0207\n",
      "Epoch 6: val_loss improved from 0.10377 to 0.10234, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1054 - mean_squared_error: 0.0207 - val_loss: 0.1023 - val_mean_squared_error: 0.0197\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1048 - mean_squared_error: 0.0206\n",
      "Epoch 7: val_loss improved from 0.10234 to 0.10137, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1048 - mean_squared_error: 0.0206 - val_loss: 0.1014 - val_mean_squared_error: 0.0195\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0204\n",
      "Epoch 8: val_loss improved from 0.10137 to 0.09203, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 0.1037 - mean_squared_error: 0.0204 - val_loss: 0.0920 - val_mean_squared_error: 0.0174\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0203\n",
      "Epoch 9: val_loss did not improve from 0.09203\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.1023 - mean_squared_error: 0.0203 - val_loss: 0.0943 - val_mean_squared_error: 0.0180\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0994 - mean_squared_error: 0.0190\n",
      "Epoch 10: val_loss improved from 0.09203 to 0.08816, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 0.0994 - mean_squared_error: 0.0190 - val_loss: 0.0882 - val_mean_squared_error: 0.0165\n",
      "Epoch 11/100\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.0190\n",
      "Epoch 11: val_loss improved from 0.08816 to 0.08400, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 0.0988 - mean_squared_error: 0.0189 - val_loss: 0.0840 - val_mean_squared_error: 0.0155\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0956 - mean_squared_error: 0.0175\n",
      "Epoch 12: val_loss improved from 0.08400 to 0.07266, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0956 - mean_squared_error: 0.0175 - val_loss: 0.0727 - val_mean_squared_error: 0.0118\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.0148\n",
      "Epoch 13: val_loss improved from 0.07266 to 0.05599, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.0859 - mean_squared_error: 0.0148 - val_loss: 0.0560 - val_mean_squared_error: 0.0064\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0736 - mean_squared_error: 0.0114\n",
      "Epoch 14: val_loss did not improve from 0.05599\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 0.0736 - mean_squared_error: 0.0114 - val_loss: 0.0621 - val_mean_squared_error: 0.0077\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0678 - mean_squared_error: 0.0094\n",
      "Epoch 15: val_loss improved from 0.05599 to 0.04702, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0678 - mean_squared_error: 0.0094 - val_loss: 0.0470 - val_mean_squared_error: 0.0047\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0615 - mean_squared_error: 0.0078\n",
      "Epoch 16: val_loss did not improve from 0.04702\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0615 - mean_squared_error: 0.0078 - val_loss: 0.0506 - val_mean_squared_error: 0.0054\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0571 - mean_squared_error: 0.0066\n",
      "Epoch 17: val_loss did not improve from 0.04702\n",
      "21/21 [==============================] - 3s 121ms/step - loss: 0.0571 - mean_squared_error: 0.0066 - val_loss: 0.0588 - val_mean_squared_error: 0.0072\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.0060\n",
      "Epoch 18: val_loss improved from 0.04702 to 0.04329, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0539 - mean_squared_error: 0.0060 - val_loss: 0.0433 - val_mean_squared_error: 0.0044\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0513 - mean_squared_error: 0.0053\n",
      "Epoch 19: val_loss did not improve from 0.04329\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0513 - mean_squared_error: 0.0053 - val_loss: 0.0709 - val_mean_squared_error: 0.0096\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0048\n",
      "Epoch 20: val_loss did not improve from 0.04329\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.0486 - mean_squared_error: 0.0048 - val_loss: 0.1004 - val_mean_squared_error: 0.0179\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0465 - mean_squared_error: 0.0044\n",
      "Epoch 21: val_loss did not improve from 0.04329\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 0.0465 - mean_squared_error: 0.0044 - val_loss: 0.1062 - val_mean_squared_error: 0.0178\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###2 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1469 - mean_squared_error: 0.0553\n",
      "Epoch 1: val_loss improved from inf to 0.10616, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 14s 160ms/step - loss: 0.1469 - mean_squared_error: 0.0553 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.10616 to 0.10584, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1070 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0206\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0208\n",
      "Epoch 3: val_loss did not improve from 0.10584\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 0.1065 - mean_squared_error: 0.0208 - val_loss: 0.1059 - val_mean_squared_error: 0.0206\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0208\n",
      "Epoch 4: val_loss improved from 0.10584 to 0.10439, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 0.1059 - mean_squared_error: 0.0208 - val_loss: 0.1044 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1051 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10439 to 0.10278, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 0.1051 - mean_squared_error: 0.0209 - val_loss: 0.1028 - val_mean_squared_error: 0.0200\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0201\n",
      "Epoch 6: val_loss did not improve from 0.10278\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.1040 - mean_squared_error: 0.0201 - val_loss: 0.1033 - val_mean_squared_error: 0.0201\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0203\n",
      "Epoch 7: val_loss improved from 0.10278 to 0.09620, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 0.1035 - mean_squared_error: 0.0203 - val_loss: 0.0962 - val_mean_squared_error: 0.0185\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0204\n",
      "Epoch 8: val_loss improved from 0.09620 to 0.09452, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1035 - mean_squared_error: 0.0204 - val_loss: 0.0945 - val_mean_squared_error: 0.0182\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0195\n",
      "Epoch 9: val_loss improved from 0.09452 to 0.09030, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.1014 - mean_squared_error: 0.0195 - val_loss: 0.0903 - val_mean_squared_error: 0.0172\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0989 - mean_squared_error: 0.0190\n",
      "Epoch 10: val_loss improved from 0.09030 to 0.08068, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 0.0989 - mean_squared_error: 0.0190 - val_loss: 0.0807 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0944 - mean_squared_error: 0.0170\n",
      "Epoch 11: val_loss improved from 0.08068 to 0.07679, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 0.0944 - mean_squared_error: 0.0170 - val_loss: 0.0768 - val_mean_squared_error: 0.0133\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0842 - mean_squared_error: 0.0143\n",
      "Epoch 12: val_loss did not improve from 0.07679\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0842 - mean_squared_error: 0.0143 - val_loss: 0.0775 - val_mean_squared_error: 0.0121\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0714 - mean_squared_error: 0.0104\n",
      "Epoch 13: val_loss improved from 0.07679 to 0.05377, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 0.0714 - mean_squared_error: 0.0104 - val_loss: 0.0538 - val_mean_squared_error: 0.0065\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0663 - mean_squared_error: 0.0089\n",
      "Epoch 14: val_loss did not improve from 0.05377\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.0663 - mean_squared_error: 0.0089 - val_loss: 0.0692 - val_mean_squared_error: 0.0098\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0596 - mean_squared_error: 0.0072\n",
      "Epoch 15: val_loss did not improve from 0.05377\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0596 - mean_squared_error: 0.0072 - val_loss: 0.0660 - val_mean_squared_error: 0.0089\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.0062\n",
      "Epoch 16: val_loss improved from 0.05377 to 0.04437, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size7_pool4_do0.5_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 0.0550 - mean_squared_error: 0.0062 - val_loss: 0.0444 - val_mean_squared_error: 0.0047\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.0056\n",
      "Epoch 17: val_loss did not improve from 0.04437\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 0.0519 - mean_squared_error: 0.0056 - val_loss: 0.0622 - val_mean_squared_error: 0.0083\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0505 - mean_squared_error: 0.0053\n",
      "Epoch 18: val_loss did not improve from 0.04437\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 0.0505 - mean_squared_error: 0.0053 - val_loss: 0.0995 - val_mean_squared_error: 0.0178\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0048\n",
      "Epoch 19: val_loss did not improve from 0.04437\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 0.0478 - mean_squared_error: 0.0048 - val_loss: 0.1229 - val_mean_squared_error: 0.0238\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###3 fold : val mae 0.05###\n",
      "mae1.04+-0.17\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size15_pool2_do0.1_tra5_head8_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 00:30:36.339364: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.96GiB (rounded to 6400000000)requested by op model/multi_head_attention/softmax/Softmax\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-22 00:30:36.339504: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-22 00:30:36.339523: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 567, Chunks in use: 567. 141.8KiB allocated for chunks. 141.8KiB in use in bin. 101.3KiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339536: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 95, Chunks in use: 94. 48.0KiB allocated for chunks. 47.5KiB in use in bin. 47.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339546: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 2.8KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339558: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 108, Chunks in use: 108. 229.0KiB allocated for chunks. 229.0KiB in use in bin. 216.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339569: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 45, Chunks in use: 45. 188.0KiB allocated for chunks. 188.0KiB in use in bin. 180.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339580: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 82, Chunks in use: 81. 707.5KiB allocated for chunks. 697.5KiB in use in bin. 648.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339591: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 23, Chunks in use: 22. 461.5KiB allocated for chunks. 438.5KiB in use in bin. 404.6KiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339601: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 40, Chunks in use: 39. 1.42MiB allocated for chunks. 1.38MiB in use in bin. 1.27MiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339612: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 19, Chunks in use: 19. 2.09MiB allocated for chunks. 2.09MiB in use in bin. 2.08MiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339623: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 152, Chunks in use: 152. 20.28MiB allocated for chunks. 20.28MiB in use in bin. 18.88MiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339633: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339645: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 60, Chunks in use: 60. 30.78MiB allocated for chunks. 30.78MiB in use in bin. 30.00MiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339654: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339663: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339673: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 0. 6.40MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339682: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339693: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 3. 84.78MiB allocated for chunks. 84.78MiB in use in bin. 68.36MiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339705: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 6, Chunks in use: 5. 313.77MiB allocated for chunks. 251.42MiB in use in bin. 195.31MiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339716: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 4, Chunks in use: 4. 334.64MiB allocated for chunks. 334.64MiB in use in bin. 312.50MiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339725: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339736: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 11, Chunks in use: 6. 20.66GiB allocated for chunks. 14.95GiB in use in bin. 14.93GiB client-requested in use in bin.\n",
      "2023-09-22 00:30:36.339746: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 5.96GiB was 256.00MiB, Chunk State: \n",
      "2023-09-22 00:30:36.339767: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 402.83MiB | Requested Size: 64B | in_use: 0 | bin_num: 20, prev:   Size: 625.00MiB | Requested Size: 625.00MiB | in_use: 1 | bin_num: -1, next:   Size: 112.0KiB | Requested Size: 112.0KiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 00:30:36.339782: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 431.01MiB | Requested Size: 123.44MiB | in_use: 0 | bin_num: 20, prev:   Size: 3.0KiB | Requested Size: 2.0KiB | in_use: 1 | bin_num: -1, next:   Size: 2.0KiB | Requested Size: 2.0KiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 00:30:36.339796: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 501.79MiB | Requested Size: 455.45MiB | in_use: 0 | bin_num: 20, prev:   Size: 224.5KiB | Requested Size: 128.0KiB | in_use: 1 | bin_num: -1, next:   Size: 256B | Requested Size: 256B | in_use: 1 | bin_num: -1\n",
      "2023-09-22 00:30:36.339813: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 1.22GiB | Requested Size: 625.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 5.96GiB | Requested Size: 5.96GiB | in_use: 1 | bin_num: -1, next:   Size: 5.96GiB | Requested Size: 5.96GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 00:30:36.339825: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 3.19GiB | Requested Size: 64B | in_use: 0 | bin_num: 20, prev:   Size: 5.96GiB | Requested Size: 5.96GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 00:30:36.339832: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 23023321088\n",
      "2023-09-22 00:30:36.339844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000000 of size 1280 next 1\n",
      "2023-09-22 00:30:36.339853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000500 of size 256 next 2\n",
      "2023-09-22 00:30:36.339860: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000600 of size 256 next 3\n",
      "2023-09-22 00:30:36.339868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000700 of size 256 next 5\n",
      "2023-09-22 00:30:36.339875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000800 of size 256 next 6\n",
      "2023-09-22 00:30:36.339883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000900 of size 256 next 4\n",
      "2023-09-22 00:30:36.339890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000a00 of size 256 next 890\n",
      "2023-09-22 00:30:36.339898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000b00 of size 256 next 624\n",
      "2023-09-22 00:30:36.339905: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000c00 of size 256 next 816\n",
      "2023-09-22 00:30:36.339913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000d00 of size 256 next 12\n",
      "2023-09-22 00:30:36.339920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000e00 of size 256 next 13\n",
      "2023-09-22 00:30:36.339927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000f00 of size 256 next 14\n",
      "2023-09-22 00:30:36.339935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001000 of size 12544 next 28\n",
      "2023-09-22 00:30:36.339946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004100 of size 256 next 29\n",
      "2023-09-22 00:30:36.339953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004200 of size 256 next 30\n",
      "2023-09-22 00:30:36.339961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004300 of size 256 next 61\n",
      "2023-09-22 00:30:36.339968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004400 of size 256 next 309\n",
      "2023-09-22 00:30:36.339976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004500 of size 256 next 254\n",
      "2023-09-22 00:30:36.339983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004600 of size 256 next 42\n",
      "2023-09-22 00:30:36.339991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004700 of size 256 next 37\n",
      "2023-09-22 00:30:36.339998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004800 of size 256 next 36\n",
      "2023-09-22 00:30:36.340006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004900 of size 2048 next 1334\n",
      "2023-09-22 00:30:36.340014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005100 of size 2048 next 787\n",
      "2023-09-22 00:30:36.340021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005900 of size 2048 next 32\n",
      "2023-09-22 00:30:36.340029: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006100 of size 256 next 31\n",
      "2023-09-22 00:30:36.340036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006200 of size 256 next 33\n",
      "2023-09-22 00:30:36.340061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006300 of size 256 next 1281\n",
      "2023-09-22 00:30:36.340069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006400 of size 256 next 1261\n",
      "2023-09-22 00:30:36.340076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006500 of size 256 next 578\n",
      "2023-09-22 00:30:36.340084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006600 of size 256 next 80\n",
      "2023-09-22 00:30:36.340091: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006700 of size 256 next 1288\n",
      "2023-09-22 00:30:36.340099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006800 of size 256 next 35\n",
      "2023-09-22 00:30:36.340116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006900 of size 256 next 45\n",
      "2023-09-22 00:30:36.340125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006a00 of size 256 next 48\n",
      "2023-09-22 00:30:36.340141: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006b00 of size 256 next 49\n",
      "2023-09-22 00:30:36.340152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006c00 of size 8192 next 1465\n",
      "2023-09-22 00:30:36.340163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de008c00 of size 10496 next 310\n",
      "2023-09-22 00:30:36.340175: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00b500 of size 2560 next 875\n",
      "2023-09-22 00:30:36.340187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00bf00 of size 2304 next 39\n",
      "2023-09-22 00:30:36.340201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00c800 of size 144128 next 105\n",
      "2023-09-22 00:30:36.340211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fb00 of size 256 next 103\n",
      "2023-09-22 00:30:36.340220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fc00 of size 256 next 104\n",
      "2023-09-22 00:30:36.340230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fd00 of size 256 next 107\n",
      "2023-09-22 00:30:36.340239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fe00 of size 256 next 110\n",
      "2023-09-22 00:30:36.340248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ff00 of size 256 next 115\n",
      "2023-09-22 00:30:36.340257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030000 of size 256 next 116\n",
      "2023-09-22 00:30:36.340266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030100 of size 256 next 117\n",
      "2023-09-22 00:30:36.340277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030200 of size 256 next 629\n",
      "2023-09-22 00:30:36.340286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030300 of size 256 next 153\n",
      "2023-09-22 00:30:36.340295: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030400 of size 256 next 359\n",
      "2023-09-22 00:30:36.340304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030500 of size 256 next 694\n",
      "2023-09-22 00:30:36.340314: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030600 of size 256 next 108\n",
      "2023-09-22 00:30:36.340323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030700 of size 256 next 109\n",
      "2023-09-22 00:30:36.340333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030800 of size 1263704320 next 1085\n",
      "2023-09-22 00:30:36.340342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a100 of size 256 next 601\n",
      "2023-09-22 00:30:36.340350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a200 of size 256 next 1035\n",
      "2023-09-22 00:30:36.340359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a300 of size 256 next 663\n",
      "2023-09-22 00:30:36.340368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a400 of size 256 next 882\n",
      "2023-09-22 00:30:36.340376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a500 of size 256 next 962\n",
      "2023-09-22 00:30:36.340385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a600 of size 256 next 1284\n",
      "2023-09-22 00:30:36.340394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a700 of size 256 next 295\n",
      "2023-09-22 00:30:36.340403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a800 of size 256 next 1257\n",
      "2023-09-22 00:30:36.340411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955a900 of size 256 next 1341\n",
      "2023-09-22 00:30:36.340420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955aa00 of size 256 next 1238\n",
      "2023-09-22 00:30:36.340429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955ab00 of size 256 next 1358\n",
      "2023-09-22 00:30:36.340438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955ac00 of size 256 next 1016\n",
      "2023-09-22 00:30:36.340447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955ad00 of size 256 next 1201\n",
      "2023-09-22 00:30:36.340456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955ae00 of size 256 next 1021\n",
      "2023-09-22 00:30:36.340466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955af00 of size 256 next 1022\n",
      "2023-09-22 00:30:36.340475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955b000 of size 256 next 631\n",
      "2023-09-22 00:30:36.340483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955b100 of size 256 next 1211\n",
      "2023-09-22 00:30:36.340492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955b200 of size 256 next 1210\n",
      "2023-09-22 00:30:36.340501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955b300 of size 256 next 22\n",
      "2023-09-22 00:30:36.340511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122955b400 of size 81920000 next 638\n",
      "2023-09-22 00:30:36.340521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122e37b400 of size 102847232 next 323\n",
      "2023-09-22 00:30:36.340530: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1234590700 of size 131072 next 1208\n",
      "2023-09-22 00:30:36.340539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12345b0700 of size 131072 next 1036\n",
      "2023-09-22 00:30:36.340548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12345d0700 of size 167424 next 1055\n",
      "2023-09-22 00:30:36.340558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12345f9500 of size 131072 next 1056\n",
      "2023-09-22 00:30:36.340567: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1234619500 of size 135168 next 1059\n",
      "2023-09-22 00:30:36.340576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123463a500 of size 131072 next 1062\n",
      "2023-09-22 00:30:36.340585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123465a500 of size 135168 next 1063\n",
      "2023-09-22 00:30:36.340594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123467b500 of size 131072 next 1230\n",
      "2023-09-22 00:30:36.340602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123469b500 of size 153088 next 1075\n",
      "2023-09-22 00:30:36.340614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c0b00 of size 8192 next 1080\n",
      "2023-09-22 00:30:36.340622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c2b00 of size 8704 next 1079\n",
      "2023-09-22 00:30:36.340630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c4d00 of size 2048 next 757\n",
      "2023-09-22 00:30:36.340637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c5500 of size 2048 next 968\n",
      "2023-09-22 00:30:36.340645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c5d00 of size 256 next 294\n",
      "2023-09-22 00:30:36.340652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c5e00 of size 256 next 1429\n",
      "2023-09-22 00:30:36.340661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c5f00 of size 256 next 462\n",
      "2023-09-22 00:30:36.340669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c6000 of size 256 next 1426\n",
      "2023-09-22 00:30:36.340679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c6100 of size 256 next 815\n",
      "2023-09-22 00:30:36.340688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c6200 of size 256 next 880\n",
      "2023-09-22 00:30:36.340698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c6300 of size 256 next 119\n",
      "2023-09-22 00:30:36.340708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c6400 of size 256 next 1344\n",
      "2023-09-22 00:30:36.340717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c6500 of size 2048 next 912\n",
      "2023-09-22 00:30:36.340727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c6d00 of size 10240 next 1089\n",
      "2023-09-22 00:30:36.340736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c9500 of size 256 next 1252\n",
      "2023-09-22 00:30:36.340746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c9600 of size 256 next 1246\n",
      "2023-09-22 00:30:36.340754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12346c9700 of size 81920000 next 589\n",
      "2023-09-22 00:30:36.340762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12394e9700 of size 84213760 next 129\n",
      "2023-09-22 00:30:36.340772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123e539700 of size 131072 next 1098\n",
      "2023-09-22 00:30:36.340782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123e559700 of size 196608 next 893\n",
      "2023-09-22 00:30:36.340791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f123e589700 of size 65380352 next 973\n",
      "2023-09-22 00:30:36.340801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12423e3700 of size 8192 next 729\n",
      "2023-09-22 00:30:36.340810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12423e5700 of size 8192 next 1032\n",
      "2023-09-22 00:30:36.340820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12423e7700 of size 8192 next 1385\n",
      "2023-09-22 00:30:36.340831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12423e9700 of size 8192 next 767\n",
      "2023-09-22 00:30:36.340840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12423eb700 of size 131072 next 1365\n",
      "2023-09-22 00:30:36.340849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124240b700 of size 237568 next 603\n",
      "2023-09-22 00:30:36.340859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445700 of size 256 next 953\n",
      "2023-09-22 00:30:36.340868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445800 of size 256 next 925\n",
      "2023-09-22 00:30:36.340879: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445900 of size 131072 next 477\n",
      "2023-09-22 00:30:36.340890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242465900 of size 131072 next 1452\n",
      "2023-09-22 00:30:36.340900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242485900 of size 58310144 next 744\n",
      "2023-09-22 00:30:36.340911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c21700 of size 8192 next 747\n",
      "2023-09-22 00:30:36.340921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c23700 of size 8192 next 974\n",
      "2023-09-22 00:30:36.340930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c25700 of size 8192 next 1106\n",
      "2023-09-22 00:30:36.340939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c27700 of size 8192 next 571\n",
      "2023-09-22 00:30:36.340949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c29700 of size 8192 next 921\n",
      "2023-09-22 00:30:36.340958: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c2b700 of size 8192 next 307\n",
      "2023-09-22 00:30:36.340968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c2d700 of size 8192 next 441\n",
      "2023-09-22 00:30:36.340977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c2f700 of size 8192 next 415\n",
      "2023-09-22 00:30:36.340985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c31700 of size 524288 next 711\n",
      "2023-09-22 00:30:36.340994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245cb1700 of size 524288 next 297\n",
      "2023-09-22 00:30:36.341004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245d31700 of size 524288 next 799\n",
      "2023-09-22 00:30:36.341013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245db1700 of size 524288 next 849\n",
      "2023-09-22 00:30:36.341022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e31700 of size 524288 next 1417\n",
      "2023-09-22 00:30:36.341031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245eb1700 of size 524288 next 835\n",
      "2023-09-22 00:30:36.341040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245f31700 of size 524288 next 665\n",
      "2023-09-22 00:30:36.341050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245fb1700 of size 524288 next 942\n",
      "2023-09-22 00:30:36.341059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246031700 of size 524288 next 754\n",
      "2023-09-22 00:30:36.341068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12460b1700 of size 524288 next 887\n",
      "2023-09-22 00:30:36.341077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246131700 of size 524288 next 1020\n",
      "2023-09-22 00:30:36.341086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12461b1700 of size 524288 next 702\n",
      "2023-09-22 00:30:36.341096: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246231700 of size 566784 next 358\n",
      "2023-09-22 00:30:36.341107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462bbd00 of size 21504 next 1307\n",
      "2023-09-22 00:30:36.341117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c1100 of size 21504 next 1245\n",
      "2023-09-22 00:30:36.341126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c6500 of size 4096 next 793\n",
      "2023-09-22 00:30:36.341136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c7500 of size 512 next 1455\n",
      "2023-09-22 00:30:36.341145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c7700 of size 256 next 872\n",
      "2023-09-22 00:30:36.341154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c7800 of size 512 next 44\n",
      "2023-09-22 00:30:36.341163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c7a00 of size 512 next 211\n",
      "2023-09-22 00:30:36.341172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c7c00 of size 512 next 371\n",
      "2023-09-22 00:30:36.341182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c7e00 of size 4096 next 1276\n",
      "2023-09-22 00:30:36.341191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c8e00 of size 4096 next 885\n",
      "2023-09-22 00:30:36.341200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462c9e00 of size 4096 next 778\n",
      "2023-09-22 00:30:36.341209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cae00 of size 512 next 1369\n",
      "2023-09-22 00:30:36.341218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cb000 of size 512 next 829\n",
      "2023-09-22 00:30:36.341228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cb200 of size 512 next 1123\n",
      "2023-09-22 00:30:36.341237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cb400 of size 256 next 210\n",
      "2023-09-22 00:30:36.341246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cb500 of size 512 next 562\n",
      "2023-09-22 00:30:36.341255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cb700 of size 512 next 943\n",
      "2023-09-22 00:30:36.341264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cb900 of size 512 next 920\n",
      "2023-09-22 00:30:36.341273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbb00 of size 256 next 894\n",
      "2023-09-22 00:30:36.341282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbc00 of size 256 next 695\n",
      "2023-09-22 00:30:36.341290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbd00 of size 256 next 1266\n",
      "2023-09-22 00:30:36.341299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbe00 of size 256 next 906\n",
      "2023-09-22 00:30:36.341309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbf00 of size 23040 next 265\n",
      "2023-09-22 00:30:36.341319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d1900 of size 25600 next 1102\n",
      "2023-09-22 00:30:36.341328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d7d00 of size 114688 next 1322\n",
      "2023-09-22 00:30:36.341338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462f3d00 of size 21504 next 176\n",
      "2023-09-22 00:30:36.341348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462f9100 of size 32768 next 23\n",
      "2023-09-22 00:30:36.341357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246301100 of size 60416 next 599\n",
      "2023-09-22 00:30:36.341367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124630fd00 of size 114688 next 1331\n",
      "2023-09-22 00:30:36.341375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124632bd00 of size 147456 next 824\n",
      "2023-09-22 00:30:36.341384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124634fd00 of size 131072 next 1345\n",
      "2023-09-22 00:30:36.341394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124636fd00 of size 131072 next 1242\n",
      "2023-09-22 00:30:36.341404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124638fd00 of size 131072 next 864\n",
      "2023-09-22 00:30:36.341413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463afd00 of size 131072 next 1071\n",
      "2023-09-22 00:30:36.341423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463cfd00 of size 131072 next 1349\n",
      "2023-09-22 00:30:36.341433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463efd00 of size 131072 next 505\n",
      "2023-09-22 00:30:36.341441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124640fd00 of size 131072 next 1348\n",
      "2023-09-22 00:30:36.341448: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124642fd00 of size 131072 next 1126\n",
      "2023-09-22 00:30:36.341457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124644fd00 of size 131072 next 1368\n",
      "2023-09-22 00:30:36.341468: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124646fd00 of size 131072 next 1160\n",
      "2023-09-22 00:30:36.341477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124648fd00 of size 131072 next 1183\n",
      "2023-09-22 00:30:36.341488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464afd00 of size 131072 next 1158\n",
      "2023-09-22 00:30:36.341498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464cfd00 of size 131072 next 1372\n",
      "2023-09-22 00:30:36.341507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464efd00 of size 131072 next 1051\n",
      "2023-09-22 00:30:36.341517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124650fd00 of size 131072 next 1371\n",
      "2023-09-22 00:30:36.341527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124652fd00 of size 164096 next 1264\n",
      "2023-09-22 00:30:36.341537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246557e00 of size 131072 next 1390\n",
      "2023-09-22 00:30:36.341547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246577e00 of size 135168 next 1136\n",
      "2023-09-22 00:30:36.341556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246598e00 of size 131072 next 1259\n",
      "2023-09-22 00:30:36.341566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465b8e00 of size 135168 next 1269\n",
      "2023-09-22 00:30:36.341575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465d9e00 of size 131072 next 1394\n",
      "2023-09-22 00:30:36.341584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465f9e00 of size 131072 next 1395\n",
      "2023-09-22 00:30:36.341594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246619e00 of size 114688 next 1289\n",
      "2023-09-22 00:30:36.341604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246635e00 of size 114688 next 1287\n",
      "2023-09-22 00:30:36.341614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246651e00 of size 32768 next 1310\n",
      "2023-09-22 00:30:36.341624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246659e00 of size 32768 next 712\n",
      "2023-09-22 00:30:36.341633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246661e00 of size 32768 next 447\n",
      "2023-09-22 00:30:36.341643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246669e00 of size 32768 next 1404\n",
      "2023-09-22 00:30:36.341653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246671e00 of size 57088 next 1220\n",
      "2023-09-22 00:30:36.341663: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124667fd00 of size 8192 next 1052\n",
      "2023-09-22 00:30:36.341672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246681d00 of size 8192 next 1221\n",
      "2023-09-22 00:30:36.341681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1246683d00 of size 37632 next 365\n",
      "2023-09-22 00:30:36.341691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124668d000 of size 8192 next 918\n",
      "2023-09-22 00:30:36.341700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124668f000 of size 8448 next 1256\n",
      "2023-09-22 00:30:36.341709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246691100 of size 2048 next 1302\n",
      "2023-09-22 00:30:36.341719: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246691900 of size 2048 next 851\n",
      "2023-09-22 00:30:36.341728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246692100 of size 2048 next 804\n",
      "2023-09-22 00:30:36.341737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246692900 of size 2048 next 437\n",
      "2023-09-22 00:30:36.341745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246693100 of size 15360 next 1378\n",
      "2023-09-22 00:30:36.341754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246696d00 of size 8192 next 16\n",
      "2023-09-22 00:30:36.341764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246698d00 of size 11008 next 1026\n",
      "2023-09-22 00:30:36.341773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124669b800 of size 2048 next 1258\n",
      "2023-09-22 00:30:36.341782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124669c000 of size 2048 next 1077\n",
      "2023-09-22 00:30:36.341791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124669c800 of size 2048 next 1350\n",
      "2023-09-22 00:30:36.341801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124669d000 of size 2048 next 1192\n",
      "2023-09-22 00:30:36.341810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124669d800 of size 8192 next 1125\n",
      "2023-09-22 00:30:36.341818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124669f800 of size 14336 next 979\n",
      "2023-09-22 00:30:36.341825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3000 of size 2048 next 1028\n",
      "2023-09-22 00:30:36.341833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3800 of size 256 next 1367\n",
      "2023-09-22 00:30:36.341842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3900 of size 256 next 1364\n",
      "2023-09-22 00:30:36.341852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3a00 of size 256 next 1361\n",
      "2023-09-22 00:30:36.341861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3b00 of size 256 next 1113\n",
      "2023-09-22 00:30:36.341871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3c00 of size 256 next 1161\n",
      "2023-09-22 00:30:36.341880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3d00 of size 256 next 1357\n",
      "2023-09-22 00:30:36.341890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3e00 of size 256 next 1229\n",
      "2023-09-22 00:30:36.341899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a3f00 of size 256 next 1087\n",
      "2023-09-22 00:30:36.341908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a4000 of size 2048 next 1373\n",
      "2023-09-22 00:30:36.341918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a4800 of size 3584 next 65\n",
      "2023-09-22 00:30:36.341929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5600 of size 256 next 1388\n",
      "2023-09-22 00:30:36.341939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5700 of size 256 next 160\n",
      "2023-09-22 00:30:36.341948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5800 of size 256 next 1110\n",
      "2023-09-22 00:30:36.341957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5900 of size 256 next 1166\n",
      "2023-09-22 00:30:36.341966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5a00 of size 256 next 1380\n",
      "2023-09-22 00:30:36.341976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5b00 of size 256 next 1383\n",
      "2023-09-22 00:30:36.341985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5c00 of size 256 next 664\n",
      "2023-09-22 00:30:36.341995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466a5d00 of size 131072 next 1068\n",
      "2023-09-22 00:30:36.342004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466c5d00 of size 131072 next 1069\n",
      "2023-09-22 00:30:36.342013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e5d00 of size 2048 next 481\n",
      "2023-09-22 00:30:36.342022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6500 of size 256 next 741\n",
      "2023-09-22 00:30:36.342032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6600 of size 256 next 675\n",
      "2023-09-22 00:30:36.342041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6700 of size 256 next 1326\n",
      "2023-09-22 00:30:36.342048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6800 of size 256 next 1352\n",
      "2023-09-22 00:30:36.342057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6900 of size 256 next 46\n",
      "2023-09-22 00:30:36.342067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6a00 of size 256 next 1143\n",
      "2023-09-22 00:30:36.342076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6b00 of size 256 next 90\n",
      "2023-09-22 00:30:36.342085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6c00 of size 256 next 1391\n",
      "2023-09-22 00:30:36.342094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6d00 of size 2048 next 988\n",
      "2023-09-22 00:30:36.342103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e7500 of size 2048 next 833\n",
      "2023-09-22 00:30:36.342113: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e7d00 of size 2048 next 1146\n",
      "2023-09-22 00:30:36.342122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e8500 of size 2048 next 499\n",
      "2023-09-22 00:30:36.342131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e8d00 of size 2048 next 18\n",
      "2023-09-22 00:30:36.342140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e9500 of size 2048 next 1405\n",
      "2023-09-22 00:30:36.342150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e9d00 of size 8192 next 1008\n",
      "2023-09-22 00:30:36.342159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ebd00 of size 8192 next 1420\n",
      "2023-09-22 00:30:36.342169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466edd00 of size 8192 next 1400\n",
      "2023-09-22 00:30:36.342178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466efd00 of size 8192 next 1399\n",
      "2023-09-22 00:30:36.342187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f1d00 of size 8192 next 1377\n",
      "2023-09-22 00:30:36.342197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3d00 of size 256 next 1449\n",
      "2023-09-22 00:30:36.342206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3e00 of size 256 next 1009\n",
      "2023-09-22 00:30:36.342215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3f00 of size 256 next 1262\n",
      "2023-09-22 00:30:36.342224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4000 of size 256 next 526\n",
      "2023-09-22 00:30:36.342234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4100 of size 256 next 559\n",
      "2023-09-22 00:30:36.342243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4200 of size 256 next 888\n",
      "2023-09-22 00:30:36.342252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4300 of size 256 next 158\n",
      "2023-09-22 00:30:36.342261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4400 of size 256 next 1444\n",
      "2023-09-22 00:30:36.342270: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4500 of size 2048 next 650\n",
      "2023-09-22 00:30:36.342280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4d00 of size 2048 next 496\n",
      "2023-09-22 00:30:36.342289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5500 of size 256 next 777\n",
      "2023-09-22 00:30:36.342299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5600 of size 512 next 98\n",
      "2023-09-22 00:30:36.342308: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5800 of size 256 next 385\n",
      "2023-09-22 00:30:36.342317: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5900 of size 256 next 705\n",
      "2023-09-22 00:30:36.342326: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5a00 of size 256 next 225\n",
      "2023-09-22 00:30:36.342336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5b00 of size 512 next 1228\n",
      "2023-09-22 00:30:36.342346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5d00 of size 8192 next 1362\n",
      "2023-09-22 00:30:36.342353: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f7d00 of size 8192 next 1366\n",
      "2023-09-22 00:30:36.342362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f9d00 of size 32768 next 1356\n",
      "2023-09-22 00:30:36.342370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246701d00 of size 16384 next 1091\n",
      "2023-09-22 00:30:36.342378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246705d00 of size 131072 next 1410\n",
      "2023-09-22 00:30:36.342387: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246725d00 of size 135168 next 1083\n",
      "2023-09-22 00:30:36.342397: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246746d00 of size 131072 next 1064\n",
      "2023-09-22 00:30:36.342406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246766d00 of size 135168 next 989\n",
      "2023-09-22 00:30:36.342416: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246787d00 of size 178176 next 634\n",
      "2023-09-22 00:30:36.342425: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12467b3500 of size 10240 next 1049\n",
      "2023-09-22 00:30:36.342435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b5d00 of size 256 next 1433\n",
      "2023-09-22 00:30:36.342445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b5e00 of size 256 next 1273\n",
      "2023-09-22 00:30:36.342455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b5f00 of size 256 next 1270\n",
      "2023-09-22 00:30:36.342464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b6000 of size 2048 next 990\n",
      "2023-09-22 00:30:36.342473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b6800 of size 2048 next 454\n",
      "2023-09-22 00:30:36.342483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b7000 of size 2560 next 1440\n",
      "2023-09-22 00:30:36.342492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b7a00 of size 256 next 1437\n",
      "2023-09-22 00:30:36.342502: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b7b00 of size 256 next 1439\n",
      "2023-09-22 00:30:36.342511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b7c00 of size 256 next 1300\n",
      "2023-09-22 00:30:36.342521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b7d00 of size 256 next 1301\n",
      "2023-09-22 00:30:36.342530: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b7e00 of size 256 next 1438\n",
      "2023-09-22 00:30:36.342540: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b7f00 of size 256 next 1082\n",
      "2023-09-22 00:30:36.342550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8000 of size 256 next 735\n",
      "2023-09-22 00:30:36.342559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8100 of size 256 next 1305\n",
      "2023-09-22 00:30:36.342568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8200 of size 256 next 1306\n",
      "2023-09-22 00:30:36.342578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8300 of size 256 next 1309\n",
      "2023-09-22 00:30:36.342588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8400 of size 256 next 1105\n",
      "2023-09-22 00:30:36.342597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8500 of size 256 next 1308\n",
      "2023-09-22 00:30:36.342607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8600 of size 256 next 1311\n",
      "2023-09-22 00:30:36.342616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8700 of size 256 next 1316\n",
      "2023-09-22 00:30:36.342625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8800 of size 256 next 1317\n",
      "2023-09-22 00:30:36.342634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8900 of size 256 next 1318\n",
      "2023-09-22 00:30:36.342644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12467b8a00 of size 524288 next 957\n",
      "2023-09-22 00:30:36.342653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246838a00 of size 512 next 324\n",
      "2023-09-22 00:30:36.342662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246838c00 of size 512 next 321\n",
      "2023-09-22 00:30:36.342672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246838e00 of size 512 next 316\n",
      "2023-09-22 00:30:36.342680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246839000 of size 512 next 314\n",
      "2023-09-22 00:30:36.342688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246839200 of size 512 next 168\n",
      "2023-09-22 00:30:36.342698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246839400 of size 512 next 763\n",
      "2023-09-22 00:30:36.342708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246839600 of size 32768 next 182\n",
      "2023-09-22 00:30:36.342717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246841600 of size 32768 next 466\n",
      "2023-09-22 00:30:36.342726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246849600 of size 256 next 489\n",
      "2023-09-22 00:30:36.342736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246849700 of size 256 next 615\n",
      "2023-09-22 00:30:36.342745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246849800 of size 32768 next 518\n",
      "2023-09-22 00:30:36.342755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246851800 of size 32768 next 403\n",
      "2023-09-22 00:30:36.342764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246859800 of size 512 next 8\n",
      "2023-09-22 00:30:36.342773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246859a00 of size 512 next 198\n",
      "2023-09-22 00:30:36.342782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246859c00 of size 512 next 685\n",
      "2023-09-22 00:30:36.342792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246859e00 of size 512 next 282\n",
      "2023-09-22 00:30:36.342801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124685a000 of size 512 next 704\n",
      "2023-09-22 00:30:36.342810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124685a200 of size 512 next 696\n",
      "2023-09-22 00:30:36.342820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124685a400 of size 524288 next 87\n",
      "2023-09-22 00:30:36.342830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12468da400 of size 524288 next 686\n",
      "2023-09-22 00:30:36.342839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124695a400 of size 4096 next 483\n",
      "2023-09-22 00:30:36.342848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124695b400 of size 4096 next 681\n",
      "2023-09-22 00:30:36.342857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124695c400 of size 524288 next 17\n",
      "2023-09-22 00:30:36.342867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12469dc400 of size 524288 next 680\n",
      "2023-09-22 00:30:36.342876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246a5c400 of size 4096 next 697\n",
      "2023-09-22 00:30:36.342886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246a5d400 of size 4096 next 478\n",
      "2023-09-22 00:30:36.342896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246a5e400 of size 524288 next 132\n",
      "2023-09-22 00:30:36.342906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246ade400 of size 524288 next 476\n",
      "2023-09-22 00:30:36.342916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246b5e400 of size 4096 next 728\n",
      "2023-09-22 00:30:36.342926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246b5f400 of size 4096 next 536\n",
      "2023-09-22 00:30:36.342936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246b60400 of size 524288 next 605\n",
      "2023-09-22 00:30:36.342945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246be0400 of size 524288 next 529\n",
      "2023-09-22 00:30:36.342954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c60400 of size 512 next 698\n",
      "2023-09-22 00:30:36.342963: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c60600 of size 512 next 205\n",
      "2023-09-22 00:30:36.342973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c60800 of size 512 next 328\n",
      "2023-09-22 00:30:36.342982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c60a00 of size 512 next 195\n",
      "2023-09-22 00:30:36.342990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c60c00 of size 512 next 41\n",
      "2023-09-22 00:30:36.342999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c60e00 of size 512 next 25\n",
      "2023-09-22 00:30:36.343008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c61000 of size 32768 next 710\n",
      "2023-09-22 00:30:36.343017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c69000 of size 32768 next 56\n",
      "2023-09-22 00:30:36.343027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c71000 of size 256 next 512\n",
      "2023-09-22 00:30:36.343036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c71100 of size 256 next 707\n",
      "2023-09-22 00:30:36.343045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c71200 of size 32768 next 384\n",
      "2023-09-22 00:30:36.343055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c79200 of size 32768 next 150\n",
      "2023-09-22 00:30:36.343064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c81200 of size 512 next 720\n",
      "2023-09-22 00:30:36.343074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c81400 of size 512 next 721\n",
      "2023-09-22 00:30:36.343083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c81600 of size 512 next 718\n",
      "2023-09-22 00:30:36.343093: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c81800 of size 512 next 719\n",
      "2023-09-22 00:30:36.343102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c81a00 of size 512 next 609\n",
      "2023-09-22 00:30:36.343111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c81c00 of size 512 next 530\n",
      "2023-09-22 00:30:36.343121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246c81e00 of size 524288 next 716\n",
      "2023-09-22 00:30:36.343130: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246d01e00 of size 524288 next 528\n",
      "2023-09-22 00:30:36.343152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246d81e00 of size 4096 next 216\n",
      "2023-09-22 00:30:36.343160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246d82e00 of size 4096 next 717\n",
      "2023-09-22 00:30:36.343168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246d83e00 of size 524288 next 714\n",
      "2023-09-22 00:30:36.343175: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246e03e00 of size 524288 next 590\n",
      "2023-09-22 00:30:36.343183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246e83e00 of size 4096 next 723\n",
      "2023-09-22 00:30:36.343191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246e84e00 of size 4096 next 725\n",
      "2023-09-22 00:30:36.343198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246e85e00 of size 524288 next 739\n",
      "2023-09-22 00:30:36.343206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246f05e00 of size 524288 next 724\n",
      "2023-09-22 00:30:36.343213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246f85e00 of size 4096 next 534\n",
      "2023-09-22 00:30:36.343220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246f86e00 of size 4096 next 727\n",
      "2023-09-22 00:30:36.343228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246f87e00 of size 524288 next 635\n",
      "2023-09-22 00:30:36.343235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247007e00 of size 524288 next 165\n",
      "2023-09-22 00:30:36.343243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247087e00 of size 512 next 510\n",
      "2023-09-22 00:30:36.343251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247088000 of size 512 next 428\n",
      "2023-09-22 00:30:36.343258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247088200 of size 512 next 516\n",
      "2023-09-22 00:30:36.343265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247088400 of size 512 next 500\n",
      "2023-09-22 00:30:36.343273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247088600 of size 512 next 633\n",
      "2023-09-22 00:30:36.343280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247088800 of size 512 next 756\n",
      "2023-09-22 00:30:36.343288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247088a00 of size 32768 next 192\n",
      "2023-09-22 00:30:36.343295: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247090a00 of size 32768 next 59\n",
      "2023-09-22 00:30:36.343303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247098a00 of size 256 next 731\n",
      "2023-09-22 00:30:36.343310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247098b00 of size 256 next 517\n",
      "2023-09-22 00:30:36.343318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247098c00 of size 32768 next 567\n",
      "2023-09-22 00:30:36.343325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a0c00 of size 32768 next 737\n",
      "2023-09-22 00:30:36.343333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a8c00 of size 512 next 736\n",
      "2023-09-22 00:30:36.343340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a8e00 of size 512 next 311\n",
      "2023-09-22 00:30:36.343348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a9000 of size 512 next 124\n",
      "2023-09-22 00:30:36.343355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a9200 of size 512 next 734\n",
      "2023-09-22 00:30:36.343366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a9400 of size 512 next 550\n",
      "2023-09-22 00:30:36.343376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a9600 of size 512 next 75\n",
      "2023-09-22 00:30:36.343386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12470a9800 of size 524288 next 138\n",
      "2023-09-22 00:30:36.343395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129800 of size 524288 next 738\n",
      "2023-09-22 00:30:36.343404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a9800 of size 4096 next 151\n",
      "2023-09-22 00:30:36.343414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471aa800 of size 4096 next 342\n",
      "2023-09-22 00:30:36.343424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ab800 of size 524288 next 774\n",
      "2023-09-22 00:30:36.343433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124722b800 of size 524288 next 773\n",
      "2023-09-22 00:30:36.343443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12472ab800 of size 4096 next 553\n",
      "2023-09-22 00:30:36.343452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12472ac800 of size 4096 next 325\n",
      "2023-09-22 00:30:36.343461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12472ad800 of size 524288 next 62\n",
      "2023-09-22 00:30:36.343471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124732d800 of size 524288 next 745\n",
      "2023-09-22 00:30:36.343480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473ad800 of size 4096 next 616\n",
      "2023-09-22 00:30:36.343489: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473ae800 of size 4096 next 762\n",
      "2023-09-22 00:30:36.343498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473af800 of size 524288 next 289\n",
      "2023-09-22 00:30:36.343507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124742f800 of size 524288 next 121\n",
      "2023-09-22 00:30:36.343517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474af800 of size 512 next 414\n",
      "2023-09-22 00:30:36.343526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474afa00 of size 512 next 285\n",
      "2023-09-22 00:30:36.343536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474afc00 of size 512 next 749\n",
      "2023-09-22 00:30:36.343545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474afe00 of size 512 next 393\n",
      "2023-09-22 00:30:36.343554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474b0000 of size 512 next 226\n",
      "2023-09-22 00:30:36.343562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474b0200 of size 512 next 750\n",
      "2023-09-22 00:30:36.343569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474b0400 of size 32768 next 303\n",
      "2023-09-22 00:30:36.343579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474b8400 of size 32768 next 438\n",
      "2023-09-22 00:30:36.343589: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474c0400 of size 256 next 759\n",
      "2023-09-22 00:30:36.343598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474c0500 of size 256 next 760\n",
      "2023-09-22 00:30:36.343608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474c0600 of size 32768 next 758\n",
      "2023-09-22 00:30:36.343617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474c8600 of size 32768 next 209\n",
      "2023-09-22 00:30:36.343627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d0600 of size 512 next 604\n",
      "2023-09-22 00:30:36.343636: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d0800 of size 512 next 335\n",
      "2023-09-22 00:30:36.343646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d0a00 of size 512 next 224\n",
      "2023-09-22 00:30:36.343655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d0c00 of size 512 next 643\n",
      "2023-09-22 00:30:36.343664: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d0e00 of size 512 next 426\n",
      "2023-09-22 00:30:36.343674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d1000 of size 512 next 257\n",
      "2023-09-22 00:30:36.343683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d1200 of size 32768 next 573\n",
      "2023-09-22 00:30:36.343692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474d9200 of size 32768 next 88\n",
      "2023-09-22 00:30:36.343702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1200 of size 256 next 764\n",
      "2023-09-22 00:30:36.343711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1300 of size 256 next 575\n",
      "2023-09-22 00:30:36.343721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1400 of size 256 next 376\n",
      "2023-09-22 00:30:36.343731: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1500 of size 256 next 127\n",
      "2023-09-22 00:30:36.343740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1600 of size 256 next 765\n",
      "2023-09-22 00:30:36.343750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1700 of size 256 next 120\n",
      "2023-09-22 00:30:36.343759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1800 of size 256 next 768\n",
      "2023-09-22 00:30:36.343768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474e1900 of size 256 next 600\n",
      "2023-09-22 00:30:36.343778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12474e1a00 of size 6713856 next 1321\n",
      "2023-09-22 00:30:36.343787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b48c00 of size 256 next 1324\n",
      "2023-09-22 00:30:36.343796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b48d00 of size 256 next 1327\n",
      "2023-09-22 00:30:36.343806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b48e00 of size 256 next 1328\n",
      "2023-09-22 00:30:36.343815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b48f00 of size 256 next 1329\n",
      "2023-09-22 00:30:36.343824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b49000 of size 22752512 next 1227\n",
      "2023-09-22 00:30:36.343834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12490fbd00 of size 8192 next 1090\n",
      "2023-09-22 00:30:36.343843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12490fdd00 of size 206080 next 1248\n",
      "2023-09-22 00:30:36.343853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249130200 of size 8192 next 1088\n",
      "2023-09-22 00:30:36.343862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249132200 of size 8192 next 1247\n",
      "2023-09-22 00:30:36.343870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249134200 of size 114688 next 684\n",
      "2023-09-22 00:30:36.343879: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249150200 of size 147456 next 919\n",
      "2023-09-22 00:30:36.343888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249174200 of size 131072 next 1450\n",
      "2023-09-22 00:30:36.343897: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249194200 of size 131072 next 1040\n",
      "2023-09-22 00:30:36.343907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12491b4200 of size 131072 next 1342\n",
      "2023-09-22 00:30:36.343916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12491d4200 of size 131072 next 842\n",
      "2023-09-22 00:30:36.343925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12491f4200 of size 131072 next 670\n",
      "2023-09-22 00:30:36.343934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249214200 of size 131072 next 607\n",
      "2023-09-22 00:30:36.343944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249234200 of size 131072 next 975\n",
      "2023-09-22 00:30:36.343953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249254200 of size 131072 next 1347\n",
      "2023-09-22 00:30:36.343962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249274200 of size 131072 next 490\n",
      "2023-09-22 00:30:36.343971: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249294200 of size 131072 next 1392\n",
      "2023-09-22 00:30:36.343981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12492b4200 of size 131072 next 1235\n",
      "2023-09-22 00:30:36.343990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12492d4200 of size 131072 next 983\n",
      "2023-09-22 00:30:36.343999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12492f4200 of size 131072 next 196\n",
      "2023-09-22 00:30:36.344008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249314200 of size 131072 next 1243\n",
      "2023-09-22 00:30:36.344018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249334200 of size 131072 next 978\n",
      "2023-09-22 00:30:36.344027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249354200 of size 132608 next 1459\n",
      "2023-09-22 00:30:36.344037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249374800 of size 131072 next 873\n",
      "2023-09-22 00:30:36.344046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249394800 of size 135168 next 1415\n",
      "2023-09-22 00:30:36.344055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12493b5800 of size 131072 next 1204\n",
      "2023-09-22 00:30:36.344064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12493d5800 of size 135168 next 1419\n",
      "2023-09-22 00:30:36.344073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12493f6800 of size 131072 next 457\n",
      "2023-09-22 00:30:36.344082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249416800 of size 135168 next 1443\n",
      "2023-09-22 00:30:36.344092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249437800 of size 131072 next 594\n",
      "2023-09-22 00:30:36.344101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249457800 of size 167424 next 1363\n",
      "2023-09-22 00:30:36.344110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249480600 of size 131072 next 964\n",
      "2023-09-22 00:30:36.344119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12494a0600 of size 135168 next 657\n",
      "2023-09-22 00:30:36.344129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12494c1600 of size 131072 next 1168\n",
      "2023-09-22 00:30:36.344138: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12494e1600 of size 135168 next 1065\n",
      "2023-09-22 00:30:36.344147: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249502600 of size 131072 next 870\n",
      "2023-09-22 00:30:36.344156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249522600 of size 153088 next 1099\n",
      "2023-09-22 00:30:36.344164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249547c00 of size 8192 next 390\n",
      "2023-09-22 00:30:36.344173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249549c00 of size 8704 next 1304\n",
      "2023-09-22 00:30:36.344182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124954be00 of size 8192 next 383\n",
      "2023-09-22 00:30:36.344192: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124954de00 of size 10752 next 903\n",
      "2023-09-22 00:30:36.344201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249550800 of size 256 next 513\n",
      "2023-09-22 00:30:36.344211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249550900 of size 256 next 1469\n",
      "2023-09-22 00:30:36.344220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249550a00 of size 131072 next 1212\n",
      "2023-09-22 00:30:36.344229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249570a00 of size 131072 next 647\n",
      "2023-09-22 00:30:36.344238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249590a00 of size 131072 next 1448\n",
      "2023-09-22 00:30:36.344248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12495b0a00 of size 131072 next 1470\n",
      "2023-09-22 00:30:36.344257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12495d0a00 of size 131072 next 207\n",
      "2023-09-22 00:30:36.344266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12495f0a00 of size 210944 next 1330\n",
      "2023-09-22 00:30:36.344276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249624200 of size 256 next 1336\n",
      "2023-09-22 00:30:36.344286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1249624300 of size 64635136 next 1379\n",
      "2023-09-22 00:30:36.344297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124d3c8400 of size 256 next 1387\n",
      "2023-09-22 00:30:36.344306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124d3c8500 of size 256 next 1381\n",
      "2023-09-22 00:30:36.344317: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124d3c8600 of size 44892160 next 26\n",
      "2023-09-22 00:30:36.344326: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fe98600 of size 8192 next 1291\n",
      "2023-09-22 00:30:36.344335: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fe9a600 of size 8192 next 522\n",
      "2023-09-22 00:30:36.344345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fe9c600 of size 8192 next 422\n",
      "2023-09-22 00:30:36.344354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fe9e600 of size 16384 next 879\n",
      "2023-09-22 00:30:36.344363: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fea2600 of size 131072 next 732\n",
      "2023-09-22 00:30:36.344372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fec2600 of size 237568 next 627\n",
      "2023-09-22 00:30:36.344381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fefc600 of size 256 next 901\n",
      "2023-09-22 00:30:36.344391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fefc700 of size 524288 next 191\n",
      "2023-09-22 00:30:36.344400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124ff7c700 of size 524288 next 955\n",
      "2023-09-22 00:30:36.344409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124fffc700 of size 524288 next 133\n",
      "2023-09-22 00:30:36.344418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125007c700 of size 524288 next 380\n",
      "2023-09-22 00:30:36.344428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12500fc700 of size 524288 next 144\n",
      "2023-09-22 00:30:36.344437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125017c700 of size 524288 next 805\n",
      "2023-09-22 00:30:36.344446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12501fc700 of size 524288 next 941\n",
      "2023-09-22 00:30:36.344455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125027c700 of size 524288 next 708\n",
      "2023-09-22 00:30:36.344465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12502fc700 of size 524288 next 980\n",
      "2023-09-22 00:30:36.344472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125037c700 of size 524288 next 558\n",
      "2023-09-22 00:30:36.344481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12503fc700 of size 524288 next 1428\n",
      "2023-09-22 00:30:36.344490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125047c700 of size 524288 next 915\n",
      "2023-09-22 00:30:36.344500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12504fc700 of size 32768 next 865\n",
      "2023-09-22 00:30:36.344509: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250504700 of size 256 next 801\n",
      "2023-09-22 00:30:36.344518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250504800 of size 256 next 878\n",
      "2023-09-22 00:30:36.344527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250504900 of size 32768 next 709\n",
      "2023-09-22 00:30:36.344536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125050c900 of size 32768 next 409\n",
      "2023-09-22 00:30:36.344545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250514900 of size 512 next 243\n",
      "2023-09-22 00:30:36.344555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250514b00 of size 512 next 823\n",
      "2023-09-22 00:30:36.344564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250514d00 of size 512 next 331\n",
      "2023-09-22 00:30:36.344573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250514f00 of size 512 next 92\n",
      "2023-09-22 00:30:36.344583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250515100 of size 512 next 930\n",
      "2023-09-22 00:30:36.344592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250515300 of size 512 next 74\n",
      "2023-09-22 00:30:36.344601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250515500 of size 524288 next 931\n",
      "2023-09-22 00:30:36.344610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250595500 of size 524288 next 902\n",
      "2023-09-22 00:30:36.344619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250615500 of size 4096 next 363\n",
      "2023-09-22 00:30:36.344629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250616500 of size 4096 next 433\n",
      "2023-09-22 00:30:36.344638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250617500 of size 524288 next 770\n",
      "2023-09-22 00:30:36.344647: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250697500 of size 524288 next 818\n",
      "2023-09-22 00:30:36.344657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250717500 of size 4096 next 524\n",
      "2023-09-22 00:30:36.344666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250718500 of size 4096 next 952\n",
      "2023-09-22 00:30:36.344675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250719500 of size 524288 next 822\n",
      "2023-09-22 00:30:36.344684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250799500 of size 524288 next 954\n",
      "2023-09-22 00:30:36.344693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250819500 of size 4096 next 956\n",
      "2023-09-22 00:30:36.344703: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125081a500 of size 4096 next 821\n",
      "2023-09-22 00:30:36.344712: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125081b500 of size 773632 next 1384\n",
      "2023-09-22 00:30:36.344721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508d8300 of size 8192 next 1397\n",
      "2023-09-22 00:30:36.344730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508da300 of size 8192 next 1044\n",
      "2023-09-22 00:30:36.344740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508dc300 of size 2048 next 899\n",
      "2023-09-22 00:30:36.344749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508dcb00 of size 2048 next 281\n",
      "2023-09-22 00:30:36.344758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508dd300 of size 2048 next 1359\n",
      "2023-09-22 00:30:36.344768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508ddb00 of size 2048 next 1386\n",
      "2023-09-22 00:30:36.344776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508de300 of size 131072 next 1267\n",
      "2023-09-22 00:30:36.344785: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12508fe300 of size 114688 next 1332\n",
      "2023-09-22 00:30:36.344794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125091a300 of size 122880 next 1398\n",
      "2023-09-22 00:30:36.344804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1250938300 of size 54771712 next 1139\n",
      "2023-09-22 00:30:36.344813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1253d74300 of size 217088 next 1406\n",
      "2023-09-22 00:30:36.344821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1253da9300 of size 131072 next 1413\n",
      "2023-09-22 00:30:36.344829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1253dc9300 of size 131072 next 1416\n",
      "2023-09-22 00:30:36.344838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1253de9300 of size 131072 next 1414\n",
      "2023-09-22 00:30:36.344848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1253e09300 of size 33149952 next 514\n",
      "2023-09-22 00:30:36.344857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6700 of size 256 next 284\n",
      "2023-09-22 00:30:36.344867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6800 of size 256 next 796\n",
      "2023-09-22 00:30:36.344876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6900 of size 3072 next 958\n",
      "2023-09-22 00:30:36.344885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7500 of size 256 next 436\n",
      "2023-09-22 00:30:36.344894: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7600 of size 256 next 857\n",
      "2023-09-22 00:30:36.344904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7700 of size 256 next 58\n",
      "2023-09-22 00:30:36.344913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7800 of size 256 next 630\n",
      "2023-09-22 00:30:36.344923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7900 of size 256 next 971\n",
      "2023-09-22 00:30:36.344933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7a00 of size 256 next 366\n",
      "2023-09-22 00:30:36.344942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7b00 of size 256 next 840\n",
      "2023-09-22 00:30:36.344951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7c00 of size 256 next 828\n",
      "2023-09-22 00:30:36.344960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7d00 of size 256 next 827\n",
      "2023-09-22 00:30:36.344969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7e00 of size 256 next 845\n",
      "2023-09-22 00:30:36.344979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da7f00 of size 131072 next 949\n",
      "2023-09-22 00:30:36.344988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255dc7f00 of size 131072 next 387\n",
      "2023-09-22 00:30:36.344997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255de7f00 of size 131072 next 847\n",
      "2023-09-22 00:30:36.345006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e07f00 of size 131072 next 806\n",
      "2023-09-22 00:30:36.345016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e27f00 of size 131072 next 946\n",
      "2023-09-22 00:30:36.345025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e47f00 of size 114688 next 743\n",
      "2023-09-22 00:30:36.345034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e63f00 of size 114688 next 391\n",
      "2023-09-22 00:30:36.345043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e7ff00 of size 114688 next 451\n",
      "2023-09-22 00:30:36.345053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e9bf00 of size 114688 next 1061\n",
      "2023-09-22 00:30:36.345062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eb7f00 of size 23040 next 1019\n",
      "2023-09-22 00:30:36.345072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ebd900 of size 256 next 146\n",
      "2023-09-22 00:30:36.345082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ebda00 of size 256 next 113\n",
      "2023-09-22 00:30:36.345091: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ebdb00 of size 256 next 21\n",
      "2023-09-22 00:30:36.345100: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ebdc00 of size 256 next 492\n",
      "2023-09-22 00:30:36.345109: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ebdd00 of size 256 next 945\n",
      "2023-09-22 00:30:36.345118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ebde00 of size 256 next 389\n",
      "2023-09-22 00:30:36.345128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ebdf00 of size 61440 next 766\n",
      "2023-09-22 00:30:36.345140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eccf00 of size 61440 next 701\n",
      "2023-09-22 00:30:36.345147: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255edbf00 of size 256 next 898\n",
      "2023-09-22 00:30:36.345155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255edc000 of size 256 next 1268\n",
      "2023-09-22 00:30:36.345164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255edc100 of size 256 next 1453\n",
      "2023-09-22 00:30:36.345173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255edc200 of size 256 next 883\n",
      "2023-09-22 00:30:36.345182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255edc300 of size 256 next 1263\n",
      "2023-09-22 00:30:36.345192: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255edc400 of size 256 next 480\n",
      "2023-09-22 00:30:36.345202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255edc500 of size 16384 next 937\n",
      "2023-09-22 00:30:36.345211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee0500 of size 16384 next 1314\n",
      "2023-09-22 00:30:36.345221: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee4500 of size 512 next 814\n",
      "2023-09-22 00:30:36.345230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee4700 of size 512 next 302\n",
      "2023-09-22 00:30:36.345240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee4900 of size 4096 next 279\n",
      "2023-09-22 00:30:36.345249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee5900 of size 4096 next 547\n",
      "2023-09-22 00:30:36.345258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee6900 of size 4096 next 423\n",
      "2023-09-22 00:30:36.345267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee7900 of size 4096 next 352\n",
      "2023-09-22 00:30:36.345277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee8900 of size 4096 next 79\n",
      "2023-09-22 00:30:36.345287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee9900 of size 4096 next 482\n",
      "2023-09-22 00:30:36.345296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eea900 of size 512 next 299\n",
      "2023-09-22 00:30:36.345306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eeab00 of size 512 next 831\n",
      "2023-09-22 00:30:36.345315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eead00 of size 512 next 819\n",
      "2023-09-22 00:30:36.345324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eeaf00 of size 512 next 20\n",
      "2023-09-22 00:30:36.345333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eeb100 of size 512 next 653\n",
      "2023-09-22 00:30:36.345342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eeb300 of size 512 next 784\n",
      "2023-09-22 00:30:36.345352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eeb500 of size 33280 next 856\n",
      "2023-09-22 00:30:36.345361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef3700 of size 8192 next 1214\n",
      "2023-09-22 00:30:36.345371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5700 of size 2048 next 1209\n",
      "2023-09-22 00:30:36.345380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5f00 of size 2048 next 1027\n",
      "2023-09-22 00:30:36.345389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6700 of size 8192 next 987\n",
      "2023-09-22 00:30:36.345399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8700 of size 8192 next 713\n",
      "2023-09-22 00:30:36.345408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa700 of size 8192 next 1177\n",
      "2023-09-22 00:30:36.345417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc700 of size 2048 next 1431\n",
      "2023-09-22 00:30:36.345426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efcf00 of size 256 next 240\n",
      "2023-09-22 00:30:36.345435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd000 of size 256 next 173\n",
      "2023-09-22 00:30:36.345445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd100 of size 256 next 683\n",
      "2023-09-22 00:30:36.345452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd200 of size 256 next 1296\n",
      "2023-09-22 00:30:36.345461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd300 of size 256 next 1294\n",
      "2023-09-22 00:30:36.345470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd400 of size 256 next 1293\n",
      "2023-09-22 00:30:36.345480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd500 of size 256 next 60\n",
      "2023-09-22 00:30:36.345489: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd600 of size 256 next 1191\n",
      "2023-09-22 00:30:36.345498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd700 of size 2048 next 1411\n",
      "2023-09-22 00:30:36.345508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efdf00 of size 2048 next 1048\n",
      "2023-09-22 00:30:36.345517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efe700 of size 256 next 1422\n",
      "2023-09-22 00:30:36.345526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efe800 of size 256 next 874\n",
      "2023-09-22 00:30:36.345535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efe900 of size 256 next 1145\n",
      "2023-09-22 00:30:36.345544: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efea00 of size 256 next 1434\n",
      "2023-09-22 00:30:36.345554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efeb00 of size 256 next 1050\n",
      "2023-09-22 00:30:36.345563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efec00 of size 256 next 1427\n",
      "2023-09-22 00:30:36.345572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efed00 of size 256 next 1418\n",
      "2023-09-22 00:30:36.345582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efee00 of size 256 next 1412\n",
      "2023-09-22 00:30:36.345592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efef00 of size 2048 next 1180\n",
      "2023-09-22 00:30:36.345601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255eff700 of size 2048 next 1120\n",
      "2023-09-22 00:30:36.345610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efff00 of size 2048 next 1155\n",
      "2023-09-22 00:30:36.345619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f00700 of size 16384 next 783\n",
      "2023-09-22 00:30:36.345628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f04700 of size 16384 next 970\n",
      "2023-09-22 00:30:36.345637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f08700 of size 2048 next 693\n",
      "2023-09-22 00:30:36.345647: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f08f00 of size 2048 next 1285\n",
      "2023-09-22 00:30:36.345656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f09700 of size 2048 next 487\n",
      "2023-09-22 00:30:36.345665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f09f00 of size 2048 next 1409\n",
      "2023-09-22 00:30:36.345674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f0a700 of size 2048 next 911\n",
      "2023-09-22 00:30:36.345684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f0af00 of size 2048 next 472\n",
      "2023-09-22 00:30:36.345693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f0b700 of size 9216 next 1298\n",
      "2023-09-22 00:30:36.345702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1255f0db00 of size 23552 next 667\n",
      "2023-09-22 00:30:36.345711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f13700 of size 131072 next 1226\n",
      "2023-09-22 00:30:36.345721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f33700 of size 229888 next 399\n",
      "2023-09-22 00:30:36.345730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1255f6b900 of size 526169600 next 843\n",
      "2023-09-22 00:30:36.345740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275536f00 of size 256 next 1043\n",
      "2023-09-22 00:30:36.345749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537000 of size 256 next 1222\n",
      "2023-09-22 00:30:36.345757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537100 of size 256 next 1041\n",
      "2023-09-22 00:30:36.345766: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537200 of size 256 next 1012\n",
      "2023-09-22 00:30:36.345775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537300 of size 256 next 1190\n",
      "2023-09-22 00:30:36.345784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537400 of size 256 next 981\n",
      "2023-09-22 00:30:36.345794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537500 of size 256 next 1184\n",
      "2023-09-22 00:30:36.345803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537600 of size 256 next 1181\n",
      "2023-09-22 00:30:36.345812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537700 of size 256 next 992\n",
      "2023-09-22 00:30:36.345821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537800 of size 256 next 993\n",
      "2023-09-22 00:30:36.345830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537900 of size 256 next 1178\n",
      "2023-09-22 00:30:36.345840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537a00 of size 256 next 1073\n",
      "2023-09-22 00:30:36.345849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537b00 of size 256 next 858\n",
      "2023-09-22 00:30:36.345858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537c00 of size 256 next 1078\n",
      "2023-09-22 00:30:36.345868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537d00 of size 256 next 1081\n",
      "2023-09-22 00:30:36.345877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537e00 of size 256 next 972\n",
      "2023-09-22 00:30:36.345886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537f00 of size 256 next 929\n",
      "2023-09-22 00:30:36.345895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538000 of size 256 next 940\n",
      "2023-09-22 00:30:36.345904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538100 of size 256 next 691\n",
      "2023-09-22 00:30:36.345914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538200 of size 256 next 1131\n",
      "2023-09-22 00:30:36.345923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538300 of size 256 next 398\n",
      "2023-09-22 00:30:36.345932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538400 of size 256 next 969\n",
      "2023-09-22 00:30:36.345941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538500 of size 2560 next 820\n",
      "2023-09-22 00:30:36.345950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538f00 of size 2048 next 1159\n",
      "2023-09-22 00:30:36.345960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539700 of size 2048 next 1165\n",
      "2023-09-22 00:30:36.345969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539f00 of size 2048 next 876\n",
      "2023-09-22 00:30:36.345978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a700 of size 256 next 1179\n",
      "2023-09-22 00:30:36.345987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a800 of size 256 next 1403\n",
      "2023-09-22 00:30:36.345997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a900 of size 256 next 1299\n",
      "2023-09-22 00:30:36.346006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553aa00 of size 256 next 776\n",
      "2023-09-22 00:30:36.346015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553ab00 of size 256 next 227\n",
      "2023-09-22 00:30:36.346024: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553ac00 of size 256 next 230\n",
      "2023-09-22 00:30:36.346033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553ad00 of size 256 next 612\n",
      "2023-09-22 00:30:36.346042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553ae00 of size 256 next 404\n",
      "2023-09-22 00:30:36.346051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553af00 of size 256 next 637\n",
      "2023-09-22 00:30:36.346059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b000 of size 256 next 535\n",
      "2023-09-22 00:30:36.346068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b100 of size 256 next 771\n",
      "2023-09-22 00:30:36.346077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b200 of size 256 next 551\n",
      "2023-09-22 00:30:36.346086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b300 of size 256 next 498\n",
      "2023-09-22 00:30:36.346095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b400 of size 256 next 772\n",
      "2023-09-22 00:30:36.346104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b500 of size 256 next 141\n",
      "2023-09-22 00:30:36.346114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b600 of size 512 next 780\n",
      "2023-09-22 00:30:36.346124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b800 of size 256 next 781\n",
      "2023-09-22 00:30:36.346133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553b900 of size 256 next 789\n",
      "2023-09-22 00:30:36.346142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553ba00 of size 256 next 779\n",
      "2023-09-22 00:30:36.346151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553bb00 of size 256 next 782\n",
      "2023-09-22 00:30:36.346161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553bc00 of size 256 next 94\n",
      "2023-09-22 00:30:36.346170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553bd00 of size 256 next 237\n",
      "2023-09-22 00:30:36.346179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553be00 of size 256 next 453\n",
      "2023-09-22 00:30:36.346188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553bf00 of size 256 next 52\n",
      "2023-09-22 00:30:36.346197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c000 of size 256 next 286\n",
      "2023-09-22 00:30:36.346207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c100 of size 256 next 642\n",
      "2023-09-22 00:30:36.346216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c200 of size 256 next 639\n",
      "2023-09-22 00:30:36.346225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c300 of size 256 next 788\n",
      "2023-09-22 00:30:36.346234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f127553c400 of size 512 next 640\n",
      "2023-09-22 00:30:36.346243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c600 of size 256 next 786\n",
      "2023-09-22 00:30:36.346253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c700 of size 256 next 644\n",
      "2023-09-22 00:30:36.346262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c800 of size 256 next 300\n",
      "2023-09-22 00:30:36.346271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f127553c900 of size 1536 next 236\n",
      "2023-09-22 00:30:36.346281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553cf00 of size 2048 next 291\n",
      "2023-09-22 00:30:36.346290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553d700 of size 2048 next 1185\n",
      "2023-09-22 00:30:36.346299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553df00 of size 2048 next 1007\n",
      "2023-09-22 00:30:36.346309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553e700 of size 2048 next 895\n",
      "2023-09-22 00:30:36.346318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553ef00 of size 2048 next 753\n",
      "2023-09-22 00:30:36.346327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553f700 of size 256 next 1153\n",
      "2023-09-22 00:30:36.346337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553f800 of size 256 next 1154\n",
      "2023-09-22 00:30:36.346346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553f900 of size 256 next 1018\n",
      "2023-09-22 00:30:36.346355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553fa00 of size 256 next 877\n",
      "2023-09-22 00:30:36.346362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553fb00 of size 256 next 1133\n",
      "2023-09-22 00:30:36.346371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553fc00 of size 256 next 1127\n",
      "2023-09-22 00:30:36.346381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553fd00 of size 256 next 1095\n",
      "2023-09-22 00:30:36.346389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553fe00 of size 256 next 673\n",
      "2023-09-22 00:30:36.346399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553ff00 of size 2048 next 646\n",
      "2023-09-22 00:30:36.346408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275540700 of size 3584 next 1167\n",
      "2023-09-22 00:30:36.346417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275541500 of size 256 next 800\n",
      "2023-09-22 00:30:36.346426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275541600 of size 256 next 641\n",
      "2023-09-22 00:30:36.346436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275541700 of size 186368 next 537\n",
      "2023-09-22 00:30:36.346445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556ef00 of size 256 next 869\n",
      "2023-09-22 00:30:36.346455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556f000 of size 256 next 424\n",
      "2023-09-22 00:30:36.346464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556f100 of size 256 next 27\n",
      "2023-09-22 00:30:36.346473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556f200 of size 256 next 561\n",
      "2023-09-22 00:30:36.346482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556f300 of size 256 next 544\n",
      "2023-09-22 00:30:36.346492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556f400 of size 2048 next 889\n",
      "2023-09-22 00:30:36.346501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556fc00 of size 2048 next 1393\n",
      "2023-09-22 00:30:36.346510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275570400 of size 2048 next 1030\n",
      "2023-09-22 00:30:36.346519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275570c00 of size 2048 next 1223\n",
      "2023-09-22 00:30:36.346528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571400 of size 256 next 706\n",
      "2023-09-22 00:30:36.346538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571500 of size 256 next 938\n",
      "2023-09-22 00:30:36.346547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571600 of size 256 next 84\n",
      "2023-09-22 00:30:36.346556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571700 of size 256 next 1353\n",
      "2023-09-22 00:30:36.346565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571800 of size 256 next 924\n",
      "2023-09-22 00:30:36.346574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571900 of size 256 next 1272\n",
      "2023-09-22 00:30:36.346583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571a00 of size 256 next 913\n",
      "2023-09-22 00:30:36.346593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571b00 of size 256 next 545\n",
      "2023-09-22 00:30:36.346602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571c00 of size 256 next 72\n",
      "2023-09-22 00:30:36.346611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571d00 of size 256 next 923\n",
      "2023-09-22 00:30:36.346620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571e00 of size 256 next 703\n",
      "2023-09-22 00:30:36.346629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571f00 of size 256 next 917\n",
      "2023-09-22 00:30:36.346639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572000 of size 256 next 810\n",
      "2023-09-22 00:30:36.346648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572100 of size 256 next 812\n",
      "2023-09-22 00:30:36.346657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572200 of size 256 next 618\n",
      "2023-09-22 00:30:36.346665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572300 of size 256 next 909\n",
      "2023-09-22 00:30:36.346674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572400 of size 256 next 147\n",
      "2023-09-22 00:30:36.346683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572500 of size 256 next 1460\n",
      "2023-09-22 00:30:36.346692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572600 of size 256 next 246\n",
      "2023-09-22 00:30:36.346701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572700 of size 256 next 1275\n",
      "2023-09-22 00:30:36.346711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572800 of size 256 next 977\n",
      "2023-09-22 00:30:36.346720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572900 of size 512 next 860\n",
      "2023-09-22 00:30:36.346729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572b00 of size 512 next 563\n",
      "2023-09-22 00:30:36.346738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572d00 of size 512 next 886\n",
      "2023-09-22 00:30:36.346747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572f00 of size 512 next 1454\n",
      "2023-09-22 00:30:36.346757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275573100 of size 768 next 966\n",
      "2023-09-22 00:30:36.346766: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275573400 of size 2048 next 1206\n",
      "2023-09-22 00:30:36.346775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275573c00 of size 2048 next 1213\n",
      "2023-09-22 00:30:36.346784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574400 of size 256 next 660\n",
      "2023-09-22 00:30:36.346794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574500 of size 256 next 1408\n",
      "2023-09-22 00:30:36.346803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574600 of size 256 next 128\n",
      "2023-09-22 00:30:36.346812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574700 of size 256 next 1401\n",
      "2023-09-22 00:30:36.346822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574800 of size 256 next 656\n",
      "2023-09-22 00:30:36.346831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574900 of size 256 next 1265\n",
      "2023-09-22 00:30:36.346840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574a00 of size 256 next 1215\n",
      "2023-09-22 00:30:36.346849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574b00 of size 256 next 1205\n",
      "2023-09-22 00:30:36.346859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574c00 of size 2048 next 948\n",
      "2023-09-22 00:30:36.346868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275575400 of size 8192 next 963\n",
      "2023-09-22 00:30:36.346877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577400 of size 256 next 690\n",
      "2023-09-22 00:30:36.346886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577500 of size 256 next 839\n",
      "2023-09-22 00:30:36.346895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577600 of size 256 next 1093\n",
      "2023-09-22 00:30:36.346904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577700 of size 256 next 1255\n",
      "2023-09-22 00:30:36.346914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577800 of size 2048 next 795\n",
      "2023-09-22 00:30:36.346923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275578000 of size 2048 next 506\n",
      "2023-09-22 00:30:36.346932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275578800 of size 3072 next 807\n",
      "2023-09-22 00:30:36.346941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275579400 of size 2048 next 1072\n",
      "2023-09-22 00:30:36.346951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275579c00 of size 2048 next 1233\n",
      "2023-09-22 00:30:36.346960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557a400 of size 256 next 1042\n",
      "2023-09-22 00:30:36.346967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557a500 of size 256 next 1067\n",
      "2023-09-22 00:30:36.346976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557a600 of size 256 next 1315\n",
      "2023-09-22 00:30:36.346986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557a700 of size 256 next 1312\n",
      "2023-09-22 00:30:36.346995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557a800 of size 256 next 811\n",
      "2023-09-22 00:30:36.347004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557a900 of size 256 next 803\n",
      "2023-09-22 00:30:36.347013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557aa00 of size 256 next 1097\n",
      "2023-09-22 00:30:36.347023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ab00 of size 256 next 1096\n",
      "2023-09-22 00:30:36.347032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ac00 of size 256 next 468\n",
      "2023-09-22 00:30:36.347039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ad00 of size 256 next 1231\n",
      "2023-09-22 00:30:36.347047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ae00 of size 2048 next 1066\n",
      "2023-09-22 00:30:36.347054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557b600 of size 2048 next 649\n",
      "2023-09-22 00:30:36.347062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557be00 of size 2048 next 1058\n",
      "2023-09-22 00:30:36.347071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557c600 of size 512 next 934\n",
      "2023-09-22 00:30:36.347080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557c800 of size 256 next 458\n",
      "2023-09-22 00:30:36.347088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557c900 of size 512 next 1333\n",
      "2023-09-22 00:30:36.347098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557cb00 of size 512 next 1338\n",
      "2023-09-22 00:30:36.347107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557cd00 of size 512 next 1015\n",
      "2023-09-22 00:30:36.347116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557cf00 of size 512 next 628\n",
      "2023-09-22 00:30:36.347126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557d100 of size 768 next 546\n",
      "2023-09-22 00:30:36.347135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557d400 of size 256 next 896\n",
      "2023-09-22 00:30:36.347149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557d500 of size 256 next 1240\n",
      "2023-09-22 00:30:36.347157: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557d600 of size 256 next 1236\n",
      "2023-09-22 00:30:36.347164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557d700 of size 256 next 1241\n",
      "2023-09-22 00:30:36.347172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557d800 of size 256 next 1249\n",
      "2023-09-22 00:30:36.347179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557d900 of size 256 next 1074\n",
      "2023-09-22 00:30:36.347187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557da00 of size 256 next 497\n",
      "2023-09-22 00:30:36.347194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557db00 of size 256 next 1232\n",
      "2023-09-22 00:30:36.347202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557dc00 of size 256 next 1244\n",
      "2023-09-22 00:30:36.347209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557dd00 of size 512 next 904\n",
      "2023-09-22 00:30:36.347217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557df00 of size 512 next 1468\n",
      "2023-09-22 00:30:36.347224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557e100 of size 512 next 1283\n",
      "2023-09-22 00:30:36.347232: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557e300 of size 512 next 1335\n",
      "2023-09-22 00:30:36.347239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557e500 of size 512 next 614\n",
      "2023-09-22 00:30:36.347247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557e700 of size 512 next 1278\n",
      "2023-09-22 00:30:36.347254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557e900 of size 256 next 1277\n",
      "2023-09-22 00:30:36.347264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ea00 of size 256 next 1407\n",
      "2023-09-22 00:30:36.347274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557eb00 of size 256 next 838\n",
      "2023-09-22 00:30:36.347284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ec00 of size 256 next 402\n",
      "2023-09-22 00:30:36.347293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ed00 of size 256 next 452\n",
      "2023-09-22 00:30:36.347303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ee00 of size 256 next 329\n",
      "2023-09-22 00:30:36.347312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557ef00 of size 256 next 369\n",
      "2023-09-22 00:30:36.347320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557f000 of size 256 next 1033\n",
      "2023-09-22 00:30:36.347329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557f100 of size 256 next 1389\n",
      "2023-09-22 00:30:36.347339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557f200 of size 256 next 1070\n",
      "2023-09-22 00:30:36.347348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557f300 of size 256 next 965\n",
      "2023-09-22 00:30:36.347358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127557f400 of size 152320 next 1132\n",
      "2023-09-22 00:30:36.347367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755a4700 of size 32768 next 527\n",
      "2023-09-22 00:30:36.347377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755ac700 of size 32768 next 1104\n",
      "2023-09-22 00:30:36.347386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b4700 of size 49152 next 1295\n",
      "2023-09-22 00:30:36.347396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c0700 of size 147712 next 841\n",
      "2023-09-22 00:30:36.347408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e4800 of size 21504 next 1116\n",
      "2023-09-22 00:30:36.347417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e9c00 of size 27648 next 982\n",
      "2023-09-22 00:30:36.347426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f0800 of size 8192 next 1169\n",
      "2023-09-22 00:30:36.347436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f2800 of size 13824 next 995\n",
      "2023-09-22 00:30:36.347445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f5e00 of size 2048 next 997\n",
      "2023-09-22 00:30:36.347454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6600 of size 256 next 1171\n",
      "2023-09-22 00:30:36.347463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6700 of size 256 next 1176\n",
      "2023-09-22 00:30:36.347473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6800 of size 256 next 984\n",
      "2023-09-22 00:30:36.347482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6900 of size 256 next 985\n",
      "2023-09-22 00:30:36.347492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6a00 of size 256 next 871\n",
      "2023-09-22 00:30:36.347501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6b00 of size 256 next 1156\n",
      "2023-09-22 00:30:36.347510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6c00 of size 256 next 854\n",
      "2023-09-22 00:30:36.347519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6d00 of size 256 next 999\n",
      "2023-09-22 00:30:36.347528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f6e00 of size 2048 next 1004\n",
      "2023-09-22 00:30:36.347538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f7600 of size 2048 next 1005\n",
      "2023-09-22 00:30:36.347547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f7e00 of size 2048 next 139\n",
      "2023-09-22 00:30:36.347557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f8600 of size 4096 next 273\n",
      "2023-09-22 00:30:36.347566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f9600 of size 4096 next 748\n",
      "2023-09-22 00:30:36.347575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755fa600 of size 7680 next 1013\n",
      "2023-09-22 00:30:36.347586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755fc400 of size 12288 next 868\n",
      "2023-09-22 00:30:36.347595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755ff400 of size 16384 next 986\n",
      "2023-09-22 00:30:36.347605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275603400 of size 114688 next 164\n",
      "2023-09-22 00:30:36.347615: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127561f400 of size 131072 next 967\n",
      "2023-09-22 00:30:36.347625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127563f400 of size 131072 next 10\n",
      "2023-09-22 00:30:36.347632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127565f400 of size 8192 next 1446\n",
      "2023-09-22 00:30:36.347641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275661400 of size 8192 next 484\n",
      "2023-09-22 00:30:36.347651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275663400 of size 8192 next 808\n",
      "2023-09-22 00:30:36.347660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275665400 of size 8192 next 817\n",
      "2023-09-22 00:30:36.347669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275667400 of size 8192 next 425\n",
      "2023-09-22 00:30:36.347678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275669400 of size 8192 next 1354\n",
      "2023-09-22 00:30:36.347688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127566b400 of size 16384 next 444\n",
      "2023-09-22 00:30:36.347697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127566f400 of size 16384 next 368\n",
      "2023-09-22 00:30:36.347706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275673400 of size 21504 next 625\n",
      "2023-09-22 00:30:36.347716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275678800 of size 27648 next 308\n",
      "2023-09-22 00:30:36.347725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f400 of size 165120 next 430\n",
      "2023-09-22 00:30:36.347735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a7900 of size 256 next 163\n",
      "2023-09-22 00:30:36.347744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a7a00 of size 256 next 179\n",
      "2023-09-22 00:30:36.347753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a7b00 of size 256 next 85\n",
      "2023-09-22 00:30:36.347762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a7c00 of size 256 next 111\n",
      "2023-09-22 00:30:36.347772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a7d00 of size 256 next 610\n",
      "2023-09-22 00:30:36.347781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a7e00 of size 256 next 405\n",
      "2023-09-22 00:30:36.347790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a7f00 of size 256 next 298\n",
      "2023-09-22 00:30:36.347799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8000 of size 256 next 950\n",
      "2023-09-22 00:30:36.347809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8100 of size 256 next 212\n",
      "2023-09-22 00:30:36.347818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8200 of size 256 next 275\n",
      "2023-09-22 00:30:36.347827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8300 of size 256 next 345\n",
      "2023-09-22 00:30:36.347837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8400 of size 256 next 658\n",
      "2023-09-22 00:30:36.347846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8500 of size 256 next 338\n",
      "2023-09-22 00:30:36.347855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8600 of size 256 next 751\n",
      "2023-09-22 00:30:36.347864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8700 of size 256 next 474\n",
      "2023-09-22 00:30:36.347873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8800 of size 256 next 859\n",
      "2023-09-22 00:30:36.347882: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8900 of size 256 next 24\n",
      "2023-09-22 00:30:36.347891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8a00 of size 256 next 855\n",
      "2023-09-22 00:30:36.347901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8b00 of size 15616 next 491\n",
      "2023-09-22 00:30:36.347911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ac800 of size 2048 next 682\n",
      "2023-09-22 00:30:36.347920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad000 of size 256 next 836\n",
      "2023-09-22 00:30:36.347929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad100 of size 256 next 659\n",
      "2023-09-22 00:30:36.347936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad200 of size 256 next 813\n",
      "2023-09-22 00:30:36.347945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad300 of size 256 next 626\n",
      "2023-09-22 00:30:36.347955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad400 of size 256 next 897\n",
      "2023-09-22 00:30:36.347964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad500 of size 256 next 93\n",
      "2023-09-22 00:30:36.347973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad600 of size 256 next 928\n",
      "2023-09-22 00:30:36.347983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad700 of size 256 next 1170\n",
      "2023-09-22 00:30:36.347992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad800 of size 256 next 306\n",
      "2023-09-22 00:30:36.348002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad900 of size 655360000 next 613\n",
      "2023-09-22 00:30:36.348011: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f129c7ad900 of size 655360000 next 495\n",
      "2023-09-22 00:30:36.348020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12c38ad900 of size 422397952 next 960\n",
      "2023-09-22 00:30:36.348029: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcb82100 of size 114688 next 939\n",
      "2023-09-22 00:30:36.348039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcb9e100 of size 114688 next 1134\n",
      "2023-09-22 00:30:36.348048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcbba100 of size 114688 next 755\n",
      "2023-09-22 00:30:36.348057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcbd6100 of size 114688 next 1135\n",
      "2023-09-22 00:30:36.348066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcbf2100 of size 114688 next 908\n",
      "2023-09-22 00:30:36.348076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcc0e100 of size 114688 next 844\n",
      "2023-09-22 00:30:36.348085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcc2a100 of size 114688 next 1144\n",
      "2023-09-22 00:30:36.348095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcc46100 of size 163840 next 268\n",
      "2023-09-22 00:30:36.348107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcc6e100 of size 131072 next 446\n",
      "2023-09-22 00:30:36.348116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcc8e100 of size 131072 next 313\n",
      "2023-09-22 00:30:36.348125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dccae100 of size 131072 next 1162\n",
      "2023-09-22 00:30:36.348134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dccce100 of size 131072 next 961\n",
      "2023-09-22 00:30:36.348143: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dccee100 of size 131072 next 1163\n",
      "2023-09-22 00:30:36.348153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcd0e100 of size 131072 next 891\n",
      "2023-09-22 00:30:36.348162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcd2e100 of size 131072 next 1164\n",
      "2023-09-22 00:30:36.348171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcd4e100 of size 131072 next 994\n",
      "2023-09-22 00:30:36.348181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcd6e100 of size 131072 next 996\n",
      "2023-09-22 00:30:36.348190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcd8e100 of size 131072 next 998\n",
      "2023-09-22 00:30:36.348199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcdae100 of size 131072 next 1001\n",
      "2023-09-22 00:30:36.348208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcdce100 of size 131072 next 1002\n",
      "2023-09-22 00:30:36.348219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcdee100 of size 131072 next 1188\n",
      "2023-09-22 00:30:36.348226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dce0e100 of size 131072 next 1006\n",
      "2023-09-22 00:30:36.348235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dce2e100 of size 131072 next 1186\n",
      "2023-09-22 00:30:36.348243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dce4e100 of size 140800 next 1025\n",
      "2023-09-22 00:30:36.348252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dce70700 of size 131072 next 1031\n",
      "2023-09-22 00:30:36.348262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dce90700 of size 135168 next 1029\n",
      "2023-09-22 00:30:36.348271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dceb1700 of size 131072 next 746\n",
      "2023-09-22 00:30:36.348280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dced1700 of size 238336 next 580\n",
      "2023-09-22 00:30:36.348289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf0ba00 of size 8192 next 574\n",
      "2023-09-22 00:30:36.348299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf0da00 of size 4096 next 1346\n",
      "2023-09-22 00:30:36.348308: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf0ea00 of size 4096 next 769\n",
      "2023-09-22 00:30:36.348318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf0fa00 of size 4096 next 1451\n",
      "2023-09-22 00:30:36.348327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf10a00 of size 4096 next 256\n",
      "2023-09-22 00:30:36.348336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf11a00 of size 18688 next 863\n",
      "2023-09-22 00:30:36.348345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16300 of size 256 next 867\n",
      "2023-09-22 00:30:36.348354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16400 of size 2048 next 617\n",
      "2023-09-22 00:30:36.348365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16c00 of size 256 next 588\n",
      "2023-09-22 00:30:36.348374: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16d00 of size 256 next 1094\n",
      "2023-09-22 00:30:36.348383: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16e00 of size 256 next 740\n",
      "2023-09-22 00:30:36.348393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16f00 of size 256 next 508\n",
      "2023-09-22 00:30:36.348402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17000 of size 256 next 1441\n",
      "2023-09-22 00:30:36.348411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17100 of size 256 next 1100\n",
      "2023-09-22 00:30:36.348420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17200 of size 256 next 326\n",
      "2023-09-22 00:30:36.348429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17300 of size 256 next 1447\n",
      "2023-09-22 00:30:36.348439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17400 of size 256 next 1445\n",
      "2023-09-22 00:30:36.348448: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17500 of size 256 next 448\n",
      "2023-09-22 00:30:36.348458: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17600 of size 256 next 431\n",
      "2023-09-22 00:30:36.348467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17700 of size 256 next 1319\n",
      "2023-09-22 00:30:36.348476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17800 of size 256 next 648\n",
      "2023-09-22 00:30:36.348486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17900 of size 256 next 1101\n",
      "2023-09-22 00:30:36.348495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17a00 of size 256 next 263\n",
      "2023-09-22 00:30:36.348504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17b00 of size 256 next 96\n",
      "2023-09-22 00:30:36.348514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17c00 of size 256 next 654\n",
      "2023-09-22 00:30:36.348523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17d00 of size 256 next 1320\n",
      "2023-09-22 00:30:36.348532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17e00 of size 256 next 866\n",
      "2023-09-22 00:30:36.348542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17f00 of size 256 next 1462\n",
      "2023-09-22 00:30:36.348549: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18000 of size 256 next 1463\n",
      "2023-09-22 00:30:36.348558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18100 of size 256 next 1464\n",
      "2023-09-22 00:30:36.348567: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18200 of size 256 next 1461\n",
      "2023-09-22 00:30:36.348577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18300 of size 256 next 215\n",
      "2023-09-22 00:30:36.348586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18400 of size 256 next 1103\n",
      "2023-09-22 00:30:36.348595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18500 of size 256 next 288\n",
      "2023-09-22 00:30:36.348604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18600 of size 256 next 742\n",
      "2023-09-22 00:30:36.348614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18700 of size 256 next 1038\n",
      "2023-09-22 00:30:36.348623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18800 of size 256 next 652\n",
      "2023-09-22 00:30:36.348633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18900 of size 3584 next 471\n",
      "2023-09-22 00:30:36.348642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19700 of size 61440 next 57\n",
      "2023-09-22 00:30:36.348651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf28700 of size 256 next 43\n",
      "2023-09-22 00:30:36.348660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf28800 of size 256 next 450\n",
      "2023-09-22 00:30:36.348669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf28900 of size 256 next 834\n",
      "2023-09-22 00:30:36.348679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf28a00 of size 32000 next 936\n",
      "2023-09-22 00:30:36.348688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf30700 of size 36864 next 926\n",
      "2023-09-22 00:30:36.348698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf39700 of size 157184 next 892\n",
      "2023-09-22 00:30:36.348707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5fd00 of size 256 next 1313\n",
      "2023-09-22 00:30:36.348716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5fe00 of size 8192 next 1382\n",
      "2023-09-22 00:30:36.348726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf61e00 of size 40960 next 175\n",
      "2023-09-22 00:30:36.348735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf6be00 of size 8192 next 1111\n",
      "2023-09-22 00:30:36.348744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf6de00 of size 8192 next 1187\n",
      "2023-09-22 00:30:36.348753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf6fe00 of size 8192 next 881\n",
      "2023-09-22 00:30:36.348762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf71e00 of size 8192 next 951\n",
      "2023-09-22 00:30:36.348772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf73e00 of size 8192 next 1108\n",
      "2023-09-22 00:30:36.348781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf75e00 of size 8192 next 269\n",
      "2023-09-22 00:30:36.348790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf77e00 of size 8192 next 905\n",
      "2023-09-22 00:30:36.348799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf79e00 of size 2048 next 1466\n",
      "2023-09-22 00:30:36.348809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7a600 of size 2048 next 1053\n",
      "2023-09-22 00:30:36.348818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7ae00 of size 2048 next 1375\n",
      "2023-09-22 00:30:36.348827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7b600 of size 2048 next 1045\n",
      "2023-09-22 00:30:36.348837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7be00 of size 8960 next 671\n",
      "2023-09-22 00:30:36.348849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7e100 of size 11264 next 791\n",
      "2023-09-22 00:30:36.348857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf80d00 of size 256 next 1467\n",
      "2023-09-22 00:30:36.348866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf80e00 of size 256 next 470\n",
      "2023-09-22 00:30:36.348875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf80f00 of size 256 next 83\n",
      "2023-09-22 00:30:36.348885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf81000 of size 256 next 1109\n",
      "2023-09-22 00:30:36.348895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf81100 of size 256 next 1107\n",
      "2023-09-22 00:30:36.348906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf81200 of size 256 next 1471\n",
      "2023-09-22 00:30:36.348916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf81300 of size 256 next 726\n",
      "2023-09-22 00:30:36.348924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf81400 of size 256 next 1458\n",
      "2023-09-22 00:30:36.348933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf81500 of size 2048 next 1456\n",
      "2023-09-22 00:30:36.348942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf81d00 of size 3328 next 669\n",
      "2023-09-22 00:30:36.348951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82a00 of size 256 next 785\n",
      "2023-09-22 00:30:36.348960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82b00 of size 256 next 672\n",
      "2023-09-22 00:30:36.348969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82c00 of size 256 next 296\n",
      "2023-09-22 00:30:36.348978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82d00 of size 256 next 674\n",
      "2023-09-22 00:30:36.348987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82e00 of size 256 next 1355\n",
      "2023-09-22 00:30:36.348996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82f00 of size 256 next 485\n",
      "2023-09-22 00:30:36.349005: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83000 of size 256 next 679\n",
      "2023-09-22 00:30:36.349014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83100 of size 256 next 539\n",
      "2023-09-22 00:30:36.349022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83200 of size 256 next 583\n",
      "2023-09-22 00:30:36.349031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83300 of size 256 next 63\n",
      "2023-09-22 00:30:36.349040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83400 of size 256 next 565\n",
      "2023-09-22 00:30:36.349049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83500 of size 256 next 689\n",
      "2023-09-22 00:30:36.349057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83600 of size 256 next 826\n",
      "2023-09-22 00:30:36.349066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83700 of size 256 next 825\n",
      "2023-09-22 00:30:36.349075: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83800 of size 256 next 692\n",
      "2023-09-22 00:30:36.349084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83900 of size 256 next 91\n",
      "2023-09-22 00:30:36.349092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83a00 of size 256 next 15\n",
      "2023-09-22 00:30:36.349101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83b00 of size 256 next 910\n",
      "2023-09-22 00:30:36.349110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83c00 of size 256 next 218\n",
      "2023-09-22 00:30:36.349119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83d00 of size 256 next 676\n",
      "2023-09-22 00:30:36.349128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83e00 of size 256 next 677\n",
      "2023-09-22 00:30:36.349137: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83f00 of size 256 next 357\n",
      "2023-09-22 00:30:36.349145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf84000 of size 256 next 1000\n",
      "2023-09-22 00:30:36.349154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf84100 of size 4096 next 1376\n",
      "2023-09-22 00:30:36.349163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85100 of size 256 next 792\n",
      "2023-09-22 00:30:36.349172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85200 of size 256 next 277\n",
      "2023-09-22 00:30:36.349181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85300 of size 256 next 1432\n",
      "2023-09-22 00:30:36.349190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85400 of size 256 next 1286\n",
      "2023-09-22 00:30:36.349198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85500 of size 256 next 794\n",
      "2023-09-22 00:30:36.349207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85600 of size 256 next 1119\n",
      "2023-09-22 00:30:36.349216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85700 of size 256 next 1122\n",
      "2023-09-22 00:30:36.349225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85800 of size 256 next 1034\n",
      "2023-09-22 00:30:36.349233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85900 of size 256 next 1121\n",
      "2023-09-22 00:30:36.349242: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85a00 of size 256 next 1124\n",
      "2023-09-22 00:30:36.349251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85b00 of size 256 next 1129\n",
      "2023-09-22 00:30:36.349261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85c00 of size 256 next 1128\n",
      "2023-09-22 00:30:36.349269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85d00 of size 256 next 1130\n",
      "2023-09-22 00:30:36.349278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85e00 of size 256 next 1138\n",
      "2023-09-22 00:30:36.349287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf85f00 of size 256 next 1402\n",
      "2023-09-22 00:30:36.349296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86000 of size 256 next 830\n",
      "2023-09-22 00:30:36.349305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86100 of size 256 next 1140\n",
      "2023-09-22 00:30:36.349314: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86200 of size 256 next 1137\n",
      "2023-09-22 00:30:36.349322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86300 of size 256 next 1141\n",
      "2023-09-22 00:30:36.349331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86400 of size 256 next 1142\n",
      "2023-09-22 00:30:36.349340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86500 of size 256 next 1148\n",
      "2023-09-22 00:30:36.349349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86600 of size 256 next 1147\n",
      "2023-09-22 00:30:36.349357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86700 of size 256 next 1149\n",
      "2023-09-22 00:30:36.349366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86800 of size 256 next 1150\n",
      "2023-09-22 00:30:36.349375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86900 of size 256 next 1151\n",
      "2023-09-22 00:30:36.349384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86a00 of size 256 next 1152\n",
      "2023-09-22 00:30:36.349393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86b00 of size 256 next 1182\n",
      "2023-09-22 00:30:36.349402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86c00 of size 256 next 1172\n",
      "2023-09-22 00:30:36.349411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86d00 of size 256 next 1173\n",
      "2023-09-22 00:30:36.349419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86e00 of size 256 next 1174\n",
      "2023-09-22 00:30:36.349428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf86f00 of size 256 next 1175\n",
      "2023-09-22 00:30:36.349437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87000 of size 256 next 1194\n",
      "2023-09-22 00:30:36.349446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87100 of size 256 next 1195\n",
      "2023-09-22 00:30:36.349455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87200 of size 256 next 1196\n",
      "2023-09-22 00:30:36.349463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87300 of size 256 next 1197\n",
      "2023-09-22 00:30:36.349472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87400 of size 256 next 1216\n",
      "2023-09-22 00:30:36.349481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87500 of size 256 next 1217\n",
      "2023-09-22 00:30:36.349489: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87600 of size 256 next 1218\n",
      "2023-09-22 00:30:36.349496: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87700 of size 256 next 1254\n",
      "2023-09-22 00:30:36.349504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87800 of size 256 next 1237\n",
      "2023-09-22 00:30:36.349513: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87900 of size 256 next 421\n",
      "2023-09-22 00:30:36.349522: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87a00 of size 256 next 1239\n",
      "2023-09-22 00:30:36.349531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf87b00 of size 16384 next 19\n",
      "2023-09-22 00:30:36.349540: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf8bb00 of size 39936 next 730\n",
      "2023-09-22 00:30:36.349550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95700 of size 256 next 1203\n",
      "2023-09-22 00:30:36.349559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95800 of size 256 next 1023\n",
      "2023-09-22 00:30:36.349568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95900 of size 256 next 1024\n",
      "2023-09-22 00:30:36.349577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95a00 of size 256 next 1198\n",
      "2023-09-22 00:30:36.349585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95b00 of size 256 next 1199\n",
      "2023-09-22 00:30:36.349594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95c00 of size 256 next 1189\n",
      "2023-09-22 00:30:36.349603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95d00 of size 256 next 1010\n",
      "2023-09-22 00:30:36.349612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95e00 of size 256 next 976\n",
      "2023-09-22 00:30:36.349622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf95f00 of size 3072 next 662\n",
      "2023-09-22 00:30:36.349631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf96b00 of size 2048 next 798\n",
      "2023-09-22 00:30:36.349640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf97300 of size 3072 next 661\n",
      "2023-09-22 00:30:36.349649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf97f00 of size 256 next 655\n",
      "2023-09-22 00:30:36.349658: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98000 of size 256 next 1396\n",
      "2023-09-22 00:30:36.349667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98100 of size 256 next 1039\n",
      "2023-09-22 00:30:36.349675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98200 of size 256 next 1011\n",
      "2023-09-22 00:30:36.349684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98300 of size 256 next 1076\n",
      "2023-09-22 00:30:36.349693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98400 of size 256 next 1374\n",
      "2023-09-22 00:30:36.349702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98500 of size 256 next 1370\n",
      "2023-09-22 00:30:36.349711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98600 of size 256 next 1234\n",
      "2023-09-22 00:30:36.349720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98700 of size 256 next 1251\n",
      "2023-09-22 00:30:36.349729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98800 of size 256 next 1337\n",
      "2023-09-22 00:30:36.349738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98900 of size 256 next 1193\n",
      "2023-09-22 00:30:36.349747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98a00 of size 256 next 1339\n",
      "2023-09-22 00:30:36.349756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98b00 of size 256 next 853\n",
      "2023-09-22 00:30:36.349765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98c00 of size 256 next 933\n",
      "2023-09-22 00:30:36.349774: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98d00 of size 256 next 1037\n",
      "2023-09-22 00:30:36.349783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98e00 of size 256 next 1351\n",
      "2023-09-22 00:30:36.349792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf98f00 of size 256 next 1014\n",
      "2023-09-22 00:30:36.349801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99000 of size 256 next 1360\n",
      "2023-09-22 00:30:36.349810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99100 of size 256 next 1112\n",
      "2023-09-22 00:30:36.349819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99200 of size 256 next 1250\n",
      "2023-09-22 00:30:36.349827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99300 of size 256 next 1118\n",
      "2023-09-22 00:30:36.349836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99400 of size 256 next 1092\n",
      "2023-09-22 00:30:36.349845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99500 of size 256 next 1086\n",
      "2023-09-22 00:30:36.349854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99600 of size 256 next 1114\n",
      "2023-09-22 00:30:36.349863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99700 of size 256 next 1115\n",
      "2023-09-22 00:30:36.349872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99800 of size 256 next 1117\n",
      "2023-09-22 00:30:36.349880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf99900 of size 2560 next 802\n",
      "2023-09-22 00:30:36.349889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9a300 of size 256 next 632\n",
      "2023-09-22 00:30:36.349898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9a400 of size 256 next 947\n",
      "2023-09-22 00:30:36.349907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9a500 of size 256 next 1060\n",
      "2023-09-22 00:30:36.349916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9a600 of size 256 next 1054\n",
      "2023-09-22 00:30:36.349925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9a700 of size 256 next 1057\n",
      "2023-09-22 00:30:36.349933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9a800 of size 256 next 1225\n",
      "2023-09-22 00:30:36.349942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9a900 of size 256 next 1219\n",
      "2023-09-22 00:30:36.349951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9aa00 of size 256 next 1046\n",
      "2023-09-22 00:30:36.349960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9ab00 of size 256 next 1047\n",
      "2023-09-22 00:30:36.349968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9ac00 of size 256 next 666\n",
      "2023-09-22 00:30:36.349977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf9ad00 of size 3072 next 651\n",
      "2023-09-22 00:30:36.349986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12dcf9b900 of size 451946752 next 1017\n",
      "2023-09-22 00:30:36.349995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9e200 of size 2048 next 922\n",
      "2023-09-22 00:30:36.350004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9ea00 of size 2048 next 1003\n",
      "2023-09-22 00:30:36.350013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f200 of size 512 next 927\n",
      "2023-09-22 00:30:36.350022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f400 of size 512 next 932\n",
      "2023-09-22 00:30:36.350031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f600 of size 256 next 101\n",
      "2023-09-22 00:30:36.350039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f700 of size 256 next 761\n",
      "2023-09-22 00:30:36.350048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f800 of size 256 next 287\n",
      "2023-09-22 00:30:36.350057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f900 of size 256 next 752\n",
      "2023-09-22 00:30:36.350066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9fa00 of size 2048 next 907\n",
      "2023-09-22 00:30:36.350075: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea0200 of size 8192 next 1224\n",
      "2023-09-22 00:30:36.350083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea2200 of size 8192 next 1200\n",
      "2023-09-22 00:30:36.350092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea4200 of size 2048 next 1084\n",
      "2023-09-22 00:30:36.350101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea4a00 of size 2048 next 410\n",
      "2023-09-22 00:30:36.350110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea5200 of size 2048 next 488\n",
      "2023-09-22 00:30:36.350119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea5a00 of size 256 next 852\n",
      "2023-09-22 00:30:36.350128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea5b00 of size 256 next 1253\n",
      "2023-09-22 00:30:36.350136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea5c00 of size 256 next 67\n",
      "2023-09-22 00:30:36.350145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea5d00 of size 256 next 511\n",
      "2023-09-22 00:30:36.350154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea5e00 of size 256 next 1157\n",
      "2023-09-22 00:30:36.350163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea5f00 of size 256 next 270\n",
      "2023-09-22 00:30:36.350172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea6000 of size 256 next 332\n",
      "2023-09-22 00:30:36.350180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea6100 of size 256 next 1202\n",
      "2023-09-22 00:30:36.350189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ea6200 of size 131072 next 1207\n",
      "2023-09-22 00:30:36.350199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7ec6200 of size 41025536 next 1323\n",
      "2023-09-22 00:30:36.350208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa5e6200 of size 256 next 1325\n",
      "2023-09-22 00:30:36.350217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa5e6300 of size 32994816 next 623\n",
      "2023-09-22 00:30:36.350226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fc55d900 of size 256 next 832\n",
      "2023-09-22 00:30:36.350234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fc55da00 of size 256 next 620\n",
      "2023-09-22 00:30:36.350244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fc55db00 of size 676422912 next 1303\n",
      "2023-09-22 00:30:36.350253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324a74000 of size 256 next 1424\n",
      "2023-09-22 00:30:36.350261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324a74100 of size 256 next 1425\n",
      "2023-09-22 00:30:36.350270: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324a74200 of size 131072 next 1279\n",
      "2023-09-22 00:30:36.350279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324a94200 of size 131072 next 991\n",
      "2023-09-22 00:30:36.350288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324ab4200 of size 131072 next 475\n",
      "2023-09-22 00:30:36.350297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324ad4200 of size 131072 next 1343\n",
      "2023-09-22 00:30:36.350306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324af4200 of size 131072 next 1340\n",
      "2023-09-22 00:30:36.350315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324b14200 of size 131072 next 280\n",
      "2023-09-22 00:30:36.350324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324b34200 of size 131072 next 130\n",
      "2023-09-22 00:30:36.350333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324b54200 of size 131072 next 884\n",
      "2023-09-22 00:30:36.350342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324b74200 of size 131072 next 566\n",
      "2023-09-22 00:30:36.350351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324b94200 of size 131072 next 1442\n",
      "2023-09-22 00:30:36.350361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324bb4200 of size 157696 next 1282\n",
      "2023-09-22 00:30:36.350369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324bdaa00 of size 131072 next 797\n",
      "2023-09-22 00:30:36.350378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324bfaa00 of size 135168 next 66\n",
      "2023-09-22 00:30:36.350387: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324c1ba00 of size 131072 next 469\n",
      "2023-09-22 00:30:36.350396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324c3ba00 of size 135168 next 161\n",
      "2023-09-22 00:30:36.350405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324c5ca00 of size 131072 next 733\n",
      "2023-09-22 00:30:36.350414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324c7ca00 of size 135168 next 1292\n",
      "2023-09-22 00:30:36.350423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324c9da00 of size 131072 next 900\n",
      "2023-09-22 00:30:36.350432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324cbda00 of size 167424 next 305\n",
      "2023-09-22 00:30:36.350440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324ce6800 of size 131072 next 486\n",
      "2023-09-22 00:30:36.350449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324d06800 of size 135168 next 515\n",
      "2023-09-22 00:30:36.350458: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324d27800 of size 131072 next 1280\n",
      "2023-09-22 00:30:36.350467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324d47800 of size 135168 next 1297\n",
      "2023-09-22 00:30:36.350476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324d68800 of size 131072 next 449\n",
      "2023-09-22 00:30:36.350485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324d88800 of size 178176 next 301\n",
      "2023-09-22 00:30:36.350494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db4000 of size 4096 next 232\n",
      "2023-09-22 00:30:36.350503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db5000 of size 6656 next 790\n",
      "2023-09-22 00:30:36.350515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db6a00 of size 256 next 412\n",
      "2023-09-22 00:30:36.350523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db6b00 of size 256 next 420\n",
      "2023-09-22 00:30:36.350532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db6c00 of size 6144 next 636\n",
      "2023-09-22 00:30:36.350541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8400 of size 256 next 353\n",
      "2023-09-22 00:30:36.350550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8500 of size 256 next 460\n",
      "2023-09-22 00:30:36.350559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8600 of size 256 next 364\n",
      "2023-09-22 00:30:36.350568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8700 of size 256 next 944\n",
      "2023-09-22 00:30:36.350577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8800 of size 256 next 959\n",
      "2023-09-22 00:30:36.350586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8900 of size 256 next 112\n",
      "2023-09-22 00:30:36.350594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8a00 of size 256 next 687\n",
      "2023-09-22 00:30:36.350603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8b00 of size 256 next 688\n",
      "2023-09-22 00:30:36.350612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8c00 of size 256 next 935\n",
      "2023-09-22 00:30:36.350621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8d00 of size 256 next 775\n",
      "2023-09-22 00:30:36.350630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8e00 of size 256 next 86\n",
      "2023-09-22 00:30:36.350638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8f00 of size 256 next 493\n",
      "2023-09-22 00:30:36.350647: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9000 of size 256 next 699\n",
      "2023-09-22 00:30:36.350656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9100 of size 256 next 700\n",
      "2023-09-22 00:30:36.350665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9200 of size 256 next 678\n",
      "2023-09-22 00:30:36.350674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9300 of size 256 next 848\n",
      "2023-09-22 00:30:36.350682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9400 of size 256 next 283\n",
      "2023-09-22 00:30:36.350691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9500 of size 256 next 809\n",
      "2023-09-22 00:30:36.350700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9600 of size 256 next 668\n",
      "2023-09-22 00:30:36.350709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9700 of size 256 next 473\n",
      "2023-09-22 00:30:36.350718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9800 of size 256 next 434\n",
      "2023-09-22 00:30:36.350726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9900 of size 256 next 846\n",
      "2023-09-22 00:30:36.350735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9a00 of size 256 next 645\n",
      "2023-09-22 00:30:36.350744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9b00 of size 256 next 850\n",
      "2023-09-22 00:30:36.350753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9c00 of size 256 next 715\n",
      "2023-09-22 00:30:36.350762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9d00 of size 256 next 861\n",
      "2023-09-22 00:30:36.350770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9e00 of size 256 next 862\n",
      "2023-09-22 00:30:36.350779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9f00 of size 256 next 407\n",
      "2023-09-22 00:30:36.350788: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324dba000 of size 256 next 722\n",
      "2023-09-22 00:30:36.350797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324dba100 of size 524288 next 1457\n",
      "2023-09-22 00:30:36.350806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324e3a100 of size 524288 next 914\n",
      "2023-09-22 00:30:36.350815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324eba100 of size 1047808 next 1421\n",
      "2023-09-22 00:30:36.350824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fb9e00 of size 8192 next 1423\n",
      "2023-09-22 00:30:36.350833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fbbe00 of size 8192 next 1435\n",
      "2023-09-22 00:30:36.350842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fbde00 of size 2048 next 464\n",
      "2023-09-22 00:30:36.350850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fbe600 of size 2048 next 1290\n",
      "2023-09-22 00:30:36.350859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fbee00 of size 2048 next 592\n",
      "2023-09-22 00:30:36.350868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fbf600 of size 2048 next 1260\n",
      "2023-09-22 00:30:36.350877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fbfe00 of size 8192 next 1271\n",
      "2023-09-22 00:30:36.350886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc1e00 of size 8192 next 1430\n",
      "2023-09-22 00:30:36.350895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc3e00 of size 2048 next 837\n",
      "2023-09-22 00:30:36.350904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc4600 of size 2048 next 916\n",
      "2023-09-22 00:30:36.350912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc4e00 of size 2048 next 586\n",
      "2023-09-22 00:30:36.350921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc5600 of size 2048 next 1436\n",
      "2023-09-22 00:30:36.350930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc5e00 of size 8192 next 467\n",
      "2023-09-22 00:30:36.350939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc7e00 of size 8192 next 1274\n",
      "2023-09-22 00:30:36.350948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324fc9e00 of size 6400000000 next 596\n",
      "2023-09-22 00:30:36.350957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f14a274de00 of size 1310720000 next 504\n",
      "2023-09-22 00:30:36.350966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14f094de00 of size 6400000000 next 501\n",
      "2023-09-22 00:30:36.350975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f166e0d1e00 of size 3426673152 next 18446744073709551615\n",
      "2023-09-22 00:30:36.350984: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-09-22 00:30:36.350997: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 567 Chunks of size 256 totalling 141.8KiB\n",
      "2023-09-22 00:30:36.351008: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 92 Chunks of size 512 totalling 46.0KiB\n",
      "2023-09-22 00:30:36.351018: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2023-09-22 00:30:36.351028: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-09-22 00:30:36.351039: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 94 Chunks of size 2048 totalling 188.0KiB\n",
      "2023-09-22 00:30:36.351049: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2304 totalling 2.2KiB\n",
      "2023-09-22 00:30:36.351059: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 2560 totalling 10.0KiB\n",
      "2023-09-22 00:30:36.351069: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 3072 totalling 15.0KiB\n",
      "2023-09-22 00:30:36.351079: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3328 totalling 3.2KiB\n",
      "2023-09-22 00:30:36.351089: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 3584 totalling 10.5KiB\n",
      "2023-09-22 00:30:36.351100: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 42 Chunks of size 4096 totalling 168.0KiB\n",
      "2023-09-22 00:30:36.351110: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6144 totalling 6.0KiB\n",
      "2023-09-22 00:30:36.351120: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6656 totalling 6.5KiB\n",
      "2023-09-22 00:30:36.351130: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 7680 totalling 7.5KiB\n",
      "2023-09-22 00:30:36.351157: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 65 Chunks of size 8192 totalling 520.0KiB\n",
      "2023-09-22 00:30:36.351169: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 8448 totalling 8.2KiB\n",
      "2023-09-22 00:30:36.351179: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 8704 totalling 17.0KiB\n",
      "2023-09-22 00:30:36.351190: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 8960 totalling 8.8KiB\n",
      "2023-09-22 00:30:36.351200: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9216 totalling 9.0KiB\n",
      "2023-09-22 00:30:36.351210: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2023-09-22 00:30:36.351221: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10496 totalling 10.2KiB\n",
      "2023-09-22 00:30:36.351231: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10752 totalling 10.5KiB\n",
      "2023-09-22 00:30:36.351241: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 11008 totalling 10.8KiB\n",
      "2023-09-22 00:30:36.351251: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 11264 totalling 11.0KiB\n",
      "2023-09-22 00:30:36.351261: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12288 totalling 12.0KiB\n",
      "2023-09-22 00:30:36.351271: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12544 totalling 12.2KiB\n",
      "2023-09-22 00:30:36.351282: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 13824 totalling 13.5KiB\n",
      "2023-09-22 00:30:36.351292: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2023-09-22 00:30:36.351302: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15360 totalling 15.0KiB\n",
      "2023-09-22 00:30:36.351312: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15616 totalling 15.2KiB\n",
      "2023-09-22 00:30:36.351322: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 10 Chunks of size 16384 totalling 160.0KiB\n",
      "2023-09-22 00:30:36.351332: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 18688 totalling 18.2KiB\n",
      "2023-09-22 00:30:36.351342: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 21504 totalling 105.0KiB\n",
      "2023-09-22 00:30:36.351353: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 23040 totalling 45.0KiB\n",
      "2023-09-22 00:30:36.351363: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 25600 totalling 25.0KiB\n",
      "2023-09-22 00:30:36.351373: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 27648 totalling 54.0KiB\n",
      "2023-09-22 00:30:36.351383: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 32000 totalling 31.2KiB\n",
      "2023-09-22 00:30:36.351393: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 29 Chunks of size 32768 totalling 928.0KiB\n",
      "2023-09-22 00:30:36.351403: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 33280 totalling 32.5KiB\n",
      "2023-09-22 00:30:36.351413: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 36864 totalling 36.0KiB\n",
      "2023-09-22 00:30:36.351424: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 39936 totalling 39.0KiB\n",
      "2023-09-22 00:30:36.351434: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 40960 totalling 40.0KiB\n",
      "2023-09-22 00:30:36.351444: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 49152 totalling 48.0KiB\n",
      "2023-09-22 00:30:36.351454: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 57088 totalling 55.8KiB\n",
      "2023-09-22 00:30:36.351464: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 60416 totalling 59.0KiB\n",
      "2023-09-22 00:30:36.351474: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 61440 totalling 180.0KiB\n",
      "2023-09-22 00:30:36.351484: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 18 Chunks of size 114688 totalling 1.97MiB\n",
      "2023-09-22 00:30:36.351495: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 122880 totalling 120.0KiB\n",
      "2023-09-22 00:30:36.351505: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 107 Chunks of size 131072 totalling 13.38MiB\n",
      "2023-09-22 00:30:36.351515: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 132608 totalling 129.5KiB\n",
      "2023-09-22 00:30:36.351525: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 17 Chunks of size 135168 totalling 2.19MiB\n",
      "2023-09-22 00:30:36.351535: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 140800 totalling 137.5KiB\n",
      "2023-09-22 00:30:36.351546: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 144128 totalling 140.8KiB\n",
      "2023-09-22 00:30:36.351556: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 147456 totalling 288.0KiB\n",
      "2023-09-22 00:30:36.351567: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 147712 totalling 144.2KiB\n",
      "2023-09-22 00:30:36.351577: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 152320 totalling 148.8KiB\n",
      "2023-09-22 00:30:36.351587: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 153088 totalling 299.0KiB\n",
      "2023-09-22 00:30:36.351597: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 157184 totalling 153.5KiB\n",
      "2023-09-22 00:30:36.351608: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 157696 totalling 154.0KiB\n",
      "2023-09-22 00:30:36.351618: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 163840 totalling 160.0KiB\n",
      "2023-09-22 00:30:36.351628: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 164096 totalling 160.2KiB\n",
      "2023-09-22 00:30:36.351638: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 165120 totalling 161.2KiB\n",
      "2023-09-22 00:30:36.351648: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 167424 totalling 490.5KiB\n",
      "2023-09-22 00:30:36.351659: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 178176 totalling 348.0KiB\n",
      "2023-09-22 00:30:36.351669: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 186368 totalling 182.0KiB\n",
      "2023-09-22 00:30:36.351679: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 196608 totalling 192.0KiB\n",
      "2023-09-22 00:30:36.351690: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 206080 totalling 201.2KiB\n",
      "2023-09-22 00:30:36.351700: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 210944 totalling 206.0KiB\n",
      "2023-09-22 00:30:36.351710: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 217088 totalling 212.0KiB\n",
      "2023-09-22 00:30:36.351720: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 229888 totalling 224.5KiB\n",
      "2023-09-22 00:30:36.351731: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 237568 totalling 464.0KiB\n",
      "2023-09-22 00:30:36.351741: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 238336 totalling 232.8KiB\n",
      "2023-09-22 00:30:36.351751: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 57 Chunks of size 524288 totalling 28.50MiB\n",
      "2023-09-22 00:30:36.351761: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 566784 totalling 553.5KiB\n",
      "2023-09-22 00:30:36.351771: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 773632 totalling 755.5KiB\n",
      "2023-09-22 00:30:36.351782: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1047808 totalling 1023.2KiB\n",
      "2023-09-22 00:30:36.351792: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 22752512 totalling 21.70MiB\n",
      "2023-09-22 00:30:36.351803: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 32994816 totalling 31.47MiB\n",
      "2023-09-22 00:30:36.351813: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 33149952 totalling 31.61MiB\n",
      "2023-09-22 00:30:36.351823: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 41025536 totalling 39.12MiB\n",
      "2023-09-22 00:30:36.351833: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 44892160 totalling 42.81MiB\n",
      "2023-09-22 00:30:36.351844: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 54771712 totalling 52.23MiB\n",
      "2023-09-22 00:30:36.351854: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 58310144 totalling 55.61MiB\n",
      "2023-09-22 00:30:36.351864: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 64635136 totalling 61.64MiB\n",
      "2023-09-22 00:30:36.351874: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 81920000 totalling 156.25MiB\n",
      "2023-09-22 00:30:36.351884: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 84213760 totalling 80.31MiB\n",
      "2023-09-22 00:30:36.351895: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 102847232 totalling 98.08MiB\n",
      "2023-09-22 00:30:36.351901: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 655360000 totalling 1.22GiB\n",
      "2023-09-22 00:30:36.351906: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 676422912 totalling 645.09MiB\n",
      "2023-09-22 00:30:36.351911: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1263704320 totalling 1.18GiB\n",
      "2023-09-22 00:30:36.351916: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 6400000000 totalling 11.92GiB\n",
      "2023-09-22 00:30:36.351922: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 15.66GiB\n",
      "2023-09-22 00:30:36.351926: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 23023321088 memory_limit_: 23023321088 available bytes: 0 curr_region_allocation_bytes_: 46046642176\n",
      "2023-09-22 00:30:36.351936: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     23023321088\n",
      "InUse:                     16813245952\n",
      "MaxInUse:                  18123965952\n",
      "NumAllocs:                     2650399\n",
      "MaxAllocSize:               6400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-22 00:30:36.351968: W tensorflow/tsl/framework/bfc_allocator.cc:492] *********__******_*_********************************_____*****************************______________\n",
      "2023-09-22 00:30:36.351995: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at softmax_op_gpu.cu.cc:222 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,8,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'model/multi_head_attention/softmax/Softmax' defined at (most recent call last):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_3386617/1959657965.py\", line 121, in <module>\n",
      "      hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3},\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 526, in _compute_attention\n",
      "      attention_scores = self._masked_softmax(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 492, in _masked_softmax\n",
      "      return self._softmax(attention_scores, attention_mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/activation/softmax.py\", line 103, in call\n",
      "      return backend.softmax(inputs, axis=self.axis[0])\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/backend.py\", line 5416, in softmax\n",
      "      return tf.nn.softmax(x, axis=axis)\n",
      "Node: 'model/multi_head_attention/softmax/Softmax'\n",
      "OOM when allocating tensor with shape[128,8,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/multi_head_attention/softmax/Softmax}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_182097]\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1174 - mean_squared_error: 0.0305\n",
      "Epoch 1: val_loss improved from inf to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 26s 308ms/step - loss: 0.1174 - mean_squared_error: 0.0305 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss improved from 0.11003 to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 276ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.11003 to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 277ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss improved from 0.11003 to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 5: val_loss improved from 0.11003 to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 6: val_loss improved from 0.11003 to 0.11002, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 286ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0206\n",
      "Epoch 7: val_loss improved from 0.11002 to 0.11001, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0207\n",
      "Epoch 8: val_loss improved from 0.11001 to 0.11000, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 9: val_loss improved from 0.11000 to 0.10997, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 10: val_loss did not improve from 0.10997\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0206\n",
      "Epoch 11: val_loss improved from 0.10997 to 0.10996, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 12: val_loss did not improve from 0.10996\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 13: val_loss improved from 0.10996 to 0.10994, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1099 - val_mean_squared_error: 0.0216\n",
      "Epoch 14/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 14: val_loss did not improve from 0.10994\n",
      "42/42 [==============================] - 12s 285ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 15: val_loss did not improve from 0.10994\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 16/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0208\n",
      "Epoch 16: val_loss did not improve from 0.10994\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1065 - mean_squared_error: 0.0208 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1189 - mean_squared_error: 0.0317\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 27s 307ms/step - loss: 0.1189 - mean_squared_error: 0.0317 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 285ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 8: val_loss improved from 0.10696 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 281ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 9: val_loss improved from 0.10695 to 0.10692, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 10: val_loss improved from 0.10692 to 0.10629, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 281ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 11: val_loss did not improve from 0.10629\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 12: val_loss did not improve from 0.10629\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 13: val_loss did not improve from 0.10629\n",
      "42/42 [==============================] - 12s 276ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 29ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1194 - mean_squared_error: 0.0318\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 26s 311ms/step - loss: 0.1193 - mean_squared_error: 0.0318 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 5: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 6: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 7: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 294ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 8: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 9: val_loss improved from 0.10585 to 0.10584, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 10: val_loss did not improve from 0.10584\n",
      "42/42 [==============================] - 12s 276ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 11: val_loss did not improve from 0.10584\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 12: val_loss did not improve from 0.10584\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 2s 28ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1194 - mean_squared_error: 0.0318\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 26s 308ms/step - loss: 0.1193 - mean_squared_error: 0.0318 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10639 to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 277ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10639 to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10639 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 278ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 8: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 279ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 9: val_loss improved from 0.10638 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 10: val_loss improved from 0.10637 to 0.10636, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 11: val_loss improved from 0.10636 to 0.10541, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1054 - val_mean_squared_error: 0.0205\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 12: val_loss improved from 0.10541 to 0.09552, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size9_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 280ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.0955 - val_mean_squared_error: 0.0184\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 13: val_loss did not improve from 0.09552\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1048 - val_mean_squared_error: 0.0204\n",
      "Epoch 14/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 14: val_loss did not improve from 0.09552\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1040 - val_mean_squared_error: 0.0203\n",
      "Epoch 15/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 15: val_loss did not improve from 0.09552\n",
      "42/42 [==============================] - 12s 275ms/step - loss: 0.1076 - mean_squared_error: 0.0209 - val_loss: 0.1041 - val_mean_squared_error: 0.0203\n",
      "55/55 [==============================] - 2s 29ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae2.20+-0.09\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt64_size19_pool5_do0.1_tra3_head8_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1370 - mean_squared_error: 0.0474\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt64_size19_pool5_do0.1_tra3_head8_kdim128_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 14s 271ms/step - loss: 0.1370 - mean_squared_error: 0.0474 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 5s 222ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 5s 222ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1381 - mean_squared_error: 0.0482\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt64_size19_pool5_do0.1_tra3_head8_kdim128_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 15s 276ms/step - loss: 0.1381 - mean_squared_error: 0.0482 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 5s 222ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 5s 228ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 14ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1354 - mean_squared_error: 0.0453\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt64_size19_pool5_do0.1_tra3_head8_kdim128_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 13s 263ms/step - loss: 0.1354 - mean_squared_error: 0.0453 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 5s 221ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 5s 234ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 2s 14ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1363 - mean_squared_error: 0.0461\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt64_size19_pool5_do0.1_tra3_head8_kdim128_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 13s 261ms/step - loss: 0.1363 - mean_squared_error: 0.0461 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 5s 221ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 14ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt32_size15_pool5_do0.1_tra5_head8_kdim256_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0234\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt32_size15_pool5_do0.1_tra5_head8_kdim256_fnn64/weights_0.hdf5\n",
      "83/83 [==============================] - 18s 61ms/step - loss: 0.1103 - mean_squared_error: 0.0234 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 1s 12ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1108 - mean_squared_error: 0.0233\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt32_size15_pool5_do0.1_tra5_head8_kdim256_fnn64/weights_1.hdf5\n",
      "83/83 [==============================] - 20s 67ms/step - loss: 0.1108 - mean_squared_error: 0.0233 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 4s 47ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 4s 48ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 13ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0231\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt32_size15_pool5_do0.1_tra5_head8_kdim256_fnn64/weights_2.hdf5\n",
      "83/83 [==============================] - 18s 59ms/step - loss: 0.1109 - mean_squared_error: 0.0231 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 4s 47ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 1s 13ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0234\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt32_size15_pool5_do0.1_tra5_head8_kdim256_fnn64/weights_3.hdf5\n",
      "83/83 [==============================] - 18s 60ms/step - loss: 0.1114 - mean_squared_error: 0.0234 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 4s 47ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 4s 54ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size7_pool5_do0.2_tra3_head8_kdim128_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0248\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size7_pool5_do0.2_tra3_head8_kdim128_fnn128/weights_0.hdf5\n",
      "21/21 [==============================] - 13s 228ms/step - loss: 0.1125 - mean_squared_error: 0.0248 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 4s 211ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 2s 13ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1150 - mean_squared_error: 0.0268\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size7_pool5_do0.2_tra3_head8_kdim128_fnn128/weights_1.hdf5\n",
      "21/21 [==============================] - 15s 246ms/step - loss: 0.1150 - mean_squared_error: 0.0268 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 4s 215ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size7_pool5_do0.2_tra3_head8_kdim128_fnn128/weights_1.hdf5\n",
      "21/21 [==============================] - 4s 215ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 4s 205ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 12ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1139 - mean_squared_error: 0.0254\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size7_pool5_do0.2_tra3_head8_kdim128_fnn128/weights_2.hdf5\n",
      "21/21 [==============================] - 13s 254ms/step - loss: 0.1139 - mean_squared_error: 0.0254 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 4s 215ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 4s 211ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1135 - mean_squared_error: 0.0250\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size7_pool5_do0.2_tra3_head8_kdim128_fnn128/weights_3.hdf5\n",
      "21/21 [==============================] - 13s 227ms/step - loss: 0.1135 - mean_squared_error: 0.0250 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 4s 187ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 4s 186ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 4s 203ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 13ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0835 - mean_squared_error: 0.0143\n",
      "Epoch 1: val_loss improved from inf to 0.06920, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 11s 56ms/step - loss: 0.0835 - mean_squared_error: 0.0143 - val_loss: 0.0692 - val_mean_squared_error: 0.0107\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.0061\n",
      "Epoch 2: val_loss improved from 0.06920 to 0.04880, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.0538 - mean_squared_error: 0.0061 - val_loss: 0.0488 - val_mean_squared_error: 0.0056\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.0045\n",
      "Epoch 3: val_loss improved from 0.04880 to 0.04697, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0447 - mean_squared_error: 0.0045 - val_loss: 0.0470 - val_mean_squared_error: 0.0050\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0040\n",
      "Epoch 4: val_loss improved from 0.04697 to 0.04140, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0421 - mean_squared_error: 0.0040 - val_loss: 0.0414 - val_mean_squared_error: 0.0041\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0038\n",
      "Epoch 5: val_loss did not improve from 0.04140\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0404 - mean_squared_error: 0.0037 - val_loss: 0.0456 - val_mean_squared_error: 0.0046\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0035\n",
      "Epoch 6: val_loss did not improve from 0.04140\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0391 - mean_squared_error: 0.0035 - val_loss: 0.0451 - val_mean_squared_error: 0.0046\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0033\n",
      "Epoch 7: val_loss improved from 0.04140 to 0.03639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.0377 - mean_squared_error: 0.0033 - val_loss: 0.0364 - val_mean_squared_error: 0.0032\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0031\n",
      "Epoch 8: val_loss did not improve from 0.03639\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0362 - mean_squared_error: 0.0031 - val_loss: 0.0447 - val_mean_squared_error: 0.0046\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0353 - mean_squared_error: 0.0030\n",
      "Epoch 9: val_loss did not improve from 0.03639\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0353 - mean_squared_error: 0.0030 - val_loss: 0.0495 - val_mean_squared_error: 0.0054\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0029\n",
      "Epoch 10: val_loss did not improve from 0.03639\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0345 - mean_squared_error: 0.0029 - val_loss: 0.0391 - val_mean_squared_error: 0.0037\n",
      "55/55 [==============================] - 1s 6ms/step\n",
      " ###0 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.0141\n",
      "Epoch 1: val_loss improved from inf to 0.07112, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 12s 71ms/step - loss: 0.0841 - mean_squared_error: 0.0141 - val_loss: 0.0711 - val_mean_squared_error: 0.0113\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0543 - mean_squared_error: 0.0062\n",
      "Epoch 2: val_loss improved from 0.07112 to 0.05247, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0543 - mean_squared_error: 0.0062 - val_loss: 0.0525 - val_mean_squared_error: 0.0058\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0452 - mean_squared_error: 0.0046\n",
      "Epoch 3: val_loss improved from 0.05247 to 0.04033, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0452 - mean_squared_error: 0.0045 - val_loss: 0.0403 - val_mean_squared_error: 0.0038\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0433 - mean_squared_error: 0.0042\n",
      "Epoch 4: val_loss did not improve from 0.04033\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.0433 - mean_squared_error: 0.0042 - val_loss: 0.0570 - val_mean_squared_error: 0.0068\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0037\n",
      "Epoch 5: val_loss did not improve from 0.04033\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0400 - mean_squared_error: 0.0037 - val_loss: 0.0407 - val_mean_squared_error: 0.0040\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0035\n",
      "Epoch 6: val_loss did not improve from 0.04033\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0389 - mean_squared_error: 0.0035 - val_loss: 0.0571 - val_mean_squared_error: 0.0067\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###1 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.0142\n",
      "Epoch 1: val_loss improved from inf to 0.07178, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 12s 56ms/step - loss: 0.0851 - mean_squared_error: 0.0142 - val_loss: 0.0718 - val_mean_squared_error: 0.0116\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.0068\n",
      "Epoch 2: val_loss improved from 0.07178 to 0.04916, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0570 - mean_squared_error: 0.0068 - val_loss: 0.0492 - val_mean_squared_error: 0.0051\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.0050\n",
      "Epoch 3: val_loss improved from 0.04916 to 0.04311, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0471 - mean_squared_error: 0.0049 - val_loss: 0.0431 - val_mean_squared_error: 0.0040\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0434 - mean_squared_error: 0.0042\n",
      "Epoch 4: val_loss improved from 0.04311 to 0.03642, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0434 - mean_squared_error: 0.0042 - val_loss: 0.0364 - val_mean_squared_error: 0.0032\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0040\n",
      "Epoch 5: val_loss did not improve from 0.03642\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0421 - mean_squared_error: 0.0040 - val_loss: 0.0431 - val_mean_squared_error: 0.0041\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0036\n",
      "Epoch 6: val_loss did not improve from 0.03642\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0394 - mean_squared_error: 0.0036 - val_loss: 0.0444 - val_mean_squared_error: 0.0047\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0034\n",
      "Epoch 7: val_loss did not improve from 0.03642\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0384 - mean_squared_error: 0.0034 - val_loss: 0.0467 - val_mean_squared_error: 0.0049\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###2 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0834 - mean_squared_error: 0.0141\n",
      "Epoch 1: val_loss improved from inf to 0.06506, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 11s 56ms/step - loss: 0.0833 - mean_squared_error: 0.0141 - val_loss: 0.0651 - val_mean_squared_error: 0.0096\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.0060\n",
      "Epoch 2: val_loss improved from 0.06506 to 0.05808, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.0538 - mean_squared_error: 0.0060 - val_loss: 0.0581 - val_mean_squared_error: 0.0069\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0046\n",
      "Epoch 3: val_loss improved from 0.05808 to 0.04516, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0454 - mean_squared_error: 0.0046 - val_loss: 0.0452 - val_mean_squared_error: 0.0047\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0040\n",
      "Epoch 4: val_loss improved from 0.04516 to 0.04243, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0423 - mean_squared_error: 0.0040 - val_loss: 0.0424 - val_mean_squared_error: 0.0042\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0037\n",
      "Epoch 5: val_loss improved from 0.04243 to 0.04202, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0400 - mean_squared_error: 0.0037 - val_loss: 0.0420 - val_mean_squared_error: 0.0042\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0035\n",
      "Epoch 6: val_loss did not improve from 0.04202\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0386 - mean_squared_error: 0.0035 - val_loss: 0.0448 - val_mean_squared_error: 0.0046\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.0031\n",
      "Epoch 7: val_loss improved from 0.04202 to 0.03813, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size9_pool5_do0.1_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.0367 - mean_squared_error: 0.0031 - val_loss: 0.0381 - val_mean_squared_error: 0.0035\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0031\n",
      "Epoch 8: val_loss did not improve from 0.03813\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.0363 - mean_squared_error: 0.0031 - val_loss: 0.0451 - val_mean_squared_error: 0.0046\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0031\n",
      "Epoch 9: val_loss did not improve from 0.03813\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0362 - mean_squared_error: 0.0031 - val_loss: 0.0611 - val_mean_squared_error: 0.0070\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0343 - mean_squared_error: 0.0028\n",
      "Epoch 10: val_loss did not improve from 0.03813\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0342 - mean_squared_error: 0.0028 - val_loss: 0.0448 - val_mean_squared_error: 0.0045\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###3 fold : val mae 0.04###\n",
      "mae0.77+-0.04\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool2_do0.5_tra3_head8_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 00:51:24.841293: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.98GiB (rounded to 3200000000)requested by op model/multi_head_attention_2/einsum/Einsum\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-22 00:51:24.841428: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-22 00:51:24.841446: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 535, Chunks in use: 534. 133.8KiB allocated for chunks. 133.5KiB in use in bin. 36.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841459: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 45, Chunks in use: 45. 22.8KiB allocated for chunks. 22.8KiB in use in bin. 22.5KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841473: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 67, Chunks in use: 67. 69.0KiB allocated for chunks. 69.0KiB in use in bin. 67.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841488: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 108, Chunks in use: 108. 235.0KiB allocated for chunks. 235.0KiB in use in bin. 216.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841503: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 6, Chunks in use: 5. 37.8KiB allocated for chunks. 33.8KiB in use in bin. 33.8KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841518: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 112, Chunks in use: 112. 1023.0KiB allocated for chunks. 1023.0KiB in use in bin. 909.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841533: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 2, Chunks in use: 0. 51.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841550: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 25, Chunks in use: 25. 889.2KiB allocated for chunks. 889.2KiB in use in bin. 827.6KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841565: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 214.0KiB allocated for chunks. 214.0KiB in use in bin. 192.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841580: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 480.0KiB allocated for chunks. 480.0KiB in use in bin. 480.0KiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841595: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 9, Chunks in use: 9. 3.00MiB allocated for chunks. 3.00MiB in use in bin. 2.68MiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841610: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 932.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841623: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841640: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 36, Chunks in use: 36. 83.13MiB allocated for chunks. 83.13MiB in use in bin. 72.00MiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841654: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841671: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 2. 24.41MiB allocated for chunks. 24.41MiB in use in bin. 24.41MiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841687: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 7, Chunks in use: 7. 134.73MiB allocated for chunks. 134.73MiB in use in bin. 126.95MiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841704: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 6, Chunks in use: 5. 252.95MiB allocated for chunks. 204.12MiB in use in bin. 195.31MiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841719: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 14, Chunks in use: 13. 1.14GiB allocated for chunks. 1.06GiB in use in bin. 1015.62MiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841742: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 5, Chunks in use: 3. 856.25MiB allocated for chunks. 443.25MiB in use in bin. 234.38MiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841759: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 19, Chunks in use: 17. 18.98GiB allocated for chunks. 18.10GiB in use in bin. 18.05GiB client-requested in use in bin.\n",
      "2023-09-22 00:51:24.841775: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 2.98GiB was 256.00MiB, Chunk State: \n",
      "2023-09-22 00:51:24.841803: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 345.98MiB | Requested Size: 64B | in_use: 0 | bin_num: 20, prev:   Size: 78.12MiB | Requested Size: 78.12MiB | in_use: 1 | bin_num: -1, next:   Size: 256B | Requested Size: 4B | in_use: 1 | bin_num: -1\n",
      "2023-09-22 00:51:24.841827: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 551.76MiB | Requested Size: 64B | in_use: 0 | bin_num: 20, prev:   Size: 625.00MiB | Requested Size: 625.00MiB | in_use: 1 | bin_num: -1, next:   Size: 2.98GiB | Requested Size: 2.98GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 00:51:24.841840: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 23023321088\n",
      "2023-09-22 00:51:24.841856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000000 of size 1280 next 1\n",
      "2023-09-22 00:51:24.841868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000500 of size 256 next 2\n",
      "2023-09-22 00:51:24.841878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000600 of size 256 next 3\n",
      "2023-09-22 00:51:24.841886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000700 of size 256 next 5\n",
      "2023-09-22 00:51:24.841893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000800 of size 256 next 6\n",
      "2023-09-22 00:51:24.841901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000900 of size 256 next 4\n",
      "2023-09-22 00:51:24.841908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000a00 of size 256 next 1474\n",
      "2023-09-22 00:51:24.841915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000b00 of size 256 next 293\n",
      "2023-09-22 00:51:24.841923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000c00 of size 256 next 1704\n",
      "2023-09-22 00:51:24.841931: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000d00 of size 256 next 12\n",
      "2023-09-22 00:51:24.841938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000e00 of size 256 next 13\n",
      "2023-09-22 00:51:24.841946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000f00 of size 256 next 14\n",
      "2023-09-22 00:51:24.841954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001000 of size 512 next 1148\n",
      "2023-09-22 00:51:24.841965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001200 of size 512 next 193\n",
      "2023-09-22 00:51:24.841973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001400 of size 256 next 1235\n",
      "2023-09-22 00:51:24.841980: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001500 of size 256 next 1640\n",
      "2023-09-22 00:51:24.841993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001600 of size 256 next 174\n",
      "2023-09-22 00:51:24.842001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001700 of size 256 next 668\n",
      "2023-09-22 00:51:24.842008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001800 of size 256 next 1297\n",
      "2023-09-22 00:51:24.842018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001900 of size 256 next 1163\n",
      "2023-09-22 00:51:24.842025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001a00 of size 256 next 610\n",
      "2023-09-22 00:51:24.842036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001b00 of size 256 next 15\n",
      "2023-09-22 00:51:24.842043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001c00 of size 256 next 1586\n",
      "2023-09-22 00:51:24.842053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001d00 of size 256 next 1422\n",
      "2023-09-22 00:51:24.842060: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001e00 of size 256 next 7\n",
      "2023-09-22 00:51:24.842070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001f00 of size 256 next 1419\n",
      "2023-09-22 00:51:24.842077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002000 of size 256 next 358\n",
      "2023-09-22 00:51:24.842085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002100 of size 256 next 971\n",
      "2023-09-22 00:51:24.842094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002200 of size 512 next 1634\n",
      "2023-09-22 00:51:24.842101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002400 of size 512 next 733\n",
      "2023-09-22 00:51:24.842110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002600 of size 512 next 1385\n",
      "2023-09-22 00:51:24.842118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002800 of size 256 next 889\n",
      "2023-09-22 00:51:24.842126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002900 of size 2048 next 288\n",
      "2023-09-22 00:51:24.842135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003100 of size 256 next 938\n",
      "2023-09-22 00:51:24.842145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003200 of size 256 next 97\n",
      "2023-09-22 00:51:24.842153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003300 of size 256 next 693\n",
      "2023-09-22 00:51:24.842162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003400 of size 256 next 1233\n",
      "2023-09-22 00:51:24.842169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003500 of size 256 next 892\n",
      "2023-09-22 00:51:24.842177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003600 of size 256 next 434\n",
      "2023-09-22 00:51:24.842186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003700 of size 256 next 1635\n",
      "2023-09-22 00:51:24.842196: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003800 of size 256 next 1352\n",
      "2023-09-22 00:51:24.842204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003900 of size 2048 next 28\n",
      "2023-09-22 00:51:24.842213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004100 of size 256 next 29\n",
      "2023-09-22 00:51:24.842220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004200 of size 256 next 30\n",
      "2023-09-22 00:51:24.842228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004300 of size 256 next 61\n",
      "2023-09-22 00:51:24.842237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004400 of size 256 next 309\n",
      "2023-09-22 00:51:24.842247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004500 of size 256 next 577\n",
      "2023-09-22 00:51:24.842257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004600 of size 256 next 42\n",
      "2023-09-22 00:51:24.842264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004700 of size 256 next 37\n",
      "2023-09-22 00:51:24.842274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004800 of size 256 next 36\n",
      "2023-09-22 00:51:24.842281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004900 of size 2048 next 349\n",
      "2023-09-22 00:51:24.842289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005100 of size 2048 next 664\n",
      "2023-09-22 00:51:24.842296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005900 of size 1024 next 85\n",
      "2023-09-22 00:51:24.842305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005d00 of size 1024 next 32\n",
      "2023-09-22 00:51:24.842316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006100 of size 256 next 31\n",
      "2023-09-22 00:51:24.842326: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006200 of size 256 next 33\n",
      "2023-09-22 00:51:24.842336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006300 of size 256 next 1312\n",
      "2023-09-22 00:51:24.842346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006400 of size 256 next 565\n",
      "2023-09-22 00:51:24.842356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006500 of size 256 next 1147\n",
      "2023-09-22 00:51:24.842366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006600 of size 256 next 732\n",
      "2023-09-22 00:51:24.842376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006700 of size 256 next 911\n",
      "2023-09-22 00:51:24.842386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006800 of size 256 next 35\n",
      "2023-09-22 00:51:24.842396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006900 of size 256 next 45\n",
      "2023-09-22 00:51:24.842406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006a00 of size 256 next 48\n",
      "2023-09-22 00:51:24.842414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006b00 of size 256 next 49\n",
      "2023-09-22 00:51:24.842424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006c00 of size 9216 next 755\n",
      "2023-09-22 00:51:24.842434: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de009000 of size 15360 next 1387\n",
      "2023-09-22 00:51:24.842444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00cc00 of size 1024 next 581\n",
      "2023-09-22 00:51:24.842453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00d000 of size 1024 next 684\n",
      "2023-09-22 00:51:24.842464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00d400 of size 256 next 1138\n",
      "2023-09-22 00:51:24.842474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00d500 of size 1024 next 513\n",
      "2023-09-22 00:51:24.842484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00d900 of size 1024 next 1569\n",
      "2023-09-22 00:51:24.842494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00dd00 of size 1024 next 661\n",
      "2023-09-22 00:51:24.842504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e100 of size 256 next 1081\n",
      "2023-09-22 00:51:24.842514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e200 of size 256 next 347\n",
      "2023-09-22 00:51:24.842524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e300 of size 256 next 1362\n",
      "2023-09-22 00:51:24.842534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e400 of size 256 next 1127\n",
      "2023-09-22 00:51:24.842545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e500 of size 256 next 411\n",
      "2023-09-22 00:51:24.842552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e600 of size 256 next 767\n",
      "2023-09-22 00:51:24.842561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e700 of size 256 next 444\n",
      "2023-09-22 00:51:24.842569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e800 of size 256 next 402\n",
      "2023-09-22 00:51:24.842577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00e900 of size 256 next 9\n",
      "2023-09-22 00:51:24.842584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ea00 of size 256 next 978\n",
      "2023-09-22 00:51:24.842593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00eb00 of size 256 next 502\n",
      "2023-09-22 00:51:24.842604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ec00 of size 256 next 543\n",
      "2023-09-22 00:51:24.842614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ed00 of size 2048 next 464\n",
      "2023-09-22 00:51:24.842624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00f500 of size 3584 next 1368\n",
      "2023-09-22 00:51:24.842633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de010300 of size 2048 next 1566\n",
      "2023-09-22 00:51:24.842643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de010b00 of size 2048 next 779\n",
      "2023-09-22 00:51:24.842653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de011300 of size 2048 next 515\n",
      "2023-09-22 00:51:24.842662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de011b00 of size 2048 next 217\n",
      "2023-09-22 00:51:24.842672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de012300 of size 1024 next 611\n",
      "2023-09-22 00:51:24.842682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de012700 of size 6912 next 162\n",
      "2023-09-22 00:51:24.842691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de014200 of size 10752 next 613\n",
      "2023-09-22 00:51:24.842702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016c00 of size 8192 next 1571\n",
      "2023-09-22 00:51:24.842713: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de018c00 of size 9216 next 343\n",
      "2023-09-22 00:51:24.842723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01b000 of size 8192 next 382\n",
      "2023-09-22 00:51:24.842732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01d000 of size 10752 next 387\n",
      "2023-09-22 00:51:24.842742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01fa00 of size 256 next 1619\n",
      "2023-09-22 00:51:24.842751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01fb00 of size 256 next 1004\n",
      "2023-09-22 00:51:24.842761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01fc00 of size 512 next 1304\n",
      "2023-09-22 00:51:24.842770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01fe00 of size 512 next 1587\n",
      "2023-09-22 00:51:24.842779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020000 of size 256 next 1512\n",
      "2023-09-22 00:51:24.842789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020100 of size 256 next 1139\n",
      "2023-09-22 00:51:24.842798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020200 of size 1024 next 477\n",
      "2023-09-22 00:51:24.842807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020600 of size 1024 next 505\n",
      "2023-09-22 00:51:24.842816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020a00 of size 1024 next 775\n",
      "2023-09-22 00:51:24.842827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020e00 of size 1792 next 840\n",
      "2023-09-22 00:51:24.842836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021500 of size 256 next 1308\n",
      "2023-09-22 00:51:24.842846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021600 of size 256 next 1359\n",
      "2023-09-22 00:51:24.842855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021700 of size 256 next 154\n",
      "2023-09-22 00:51:24.842864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021800 of size 256 next 1078\n",
      "2023-09-22 00:51:24.842875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021900 of size 256 next 862\n",
      "2023-09-22 00:51:24.842885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021a00 of size 256 next 1522\n",
      "2023-09-22 00:51:24.842894: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021b00 of size 256 next 1270\n",
      "2023-09-22 00:51:24.842902: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021c00 of size 256 next 568\n",
      "2023-09-22 00:51:24.842912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021d00 of size 256 next 1101\n",
      "2023-09-22 00:51:24.842922: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021e00 of size 256 next 1554\n",
      "2023-09-22 00:51:24.842931: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de021f00 of size 256 next 651\n",
      "2023-09-22 00:51:24.842941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022000 of size 256 next 853\n",
      "2023-09-22 00:51:24.842950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022100 of size 256 next 539\n",
      "2023-09-22 00:51:24.842960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022200 of size 256 next 427\n",
      "2023-09-22 00:51:24.842969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022300 of size 256 next 381\n",
      "2023-09-22 00:51:24.842978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022400 of size 1280 next 372\n",
      "2023-09-22 00:51:24.842987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022900 of size 256 next 1334\n",
      "2023-09-22 00:51:24.842997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022a00 of size 256 next 1411\n",
      "2023-09-22 00:51:24.843006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022b00 of size 256 next 1377\n",
      "2023-09-22 00:51:24.843016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022c00 of size 256 next 1443\n",
      "2023-09-22 00:51:24.843025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022d00 of size 256 next 741\n",
      "2023-09-22 00:51:24.843034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022e00 of size 9216 next 277\n",
      "2023-09-22 00:51:24.843043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de025200 of size 8192 next 1293\n",
      "2023-09-22 00:51:24.843053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de027200 of size 8192 next 1396\n",
      "2023-09-22 00:51:24.843063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de029200 of size 8192 next 1415\n",
      "2023-09-22 00:51:24.843072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02b200 of size 8192 next 189\n",
      "2023-09-22 00:51:24.843083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02d200 of size 10496 next 105\n",
      "2023-09-22 00:51:24.843092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fb00 of size 256 next 103\n",
      "2023-09-22 00:51:24.843102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fc00 of size 256 next 104\n",
      "2023-09-22 00:51:24.843112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fd00 of size 256 next 107\n",
      "2023-09-22 00:51:24.843121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fe00 of size 256 next 110\n",
      "2023-09-22 00:51:24.843130: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ff00 of size 256 next 115\n",
      "2023-09-22 00:51:24.843150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030000 of size 256 next 116\n",
      "2023-09-22 00:51:24.843158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030100 of size 256 next 117\n",
      "2023-09-22 00:51:24.843166: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030200 of size 256 next 359\n",
      "2023-09-22 00:51:24.843173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030300 of size 256 next 1395\n",
      "2023-09-22 00:51:24.843181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030400 of size 256 next 455\n",
      "2023-09-22 00:51:24.843190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030500 of size 256 next 646\n",
      "2023-09-22 00:51:24.843200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030600 of size 256 next 108\n",
      "2023-09-22 00:51:24.843210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030700 of size 256 next 109\n",
      "2023-09-22 00:51:24.843218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030800 of size 655360000 next 398\n",
      "2023-09-22 00:51:24.843228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1205130800 of size 655360000 next 1633\n",
      "2023-09-22 00:51:24.843237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122c230800 of size 81920000 next 401\n",
      "2023-09-22 00:51:24.843247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1231050800 of size 81920000 next 1242\n",
      "2023-09-22 00:51:24.843256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1235e70800 of size 20480000 next 678\n",
      "2023-09-22 00:51:24.843265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12371f8800 of size 81920000 next 40\n",
      "2023-09-22 00:51:24.843274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123c018800 of size 105041920 next 953\n",
      "2023-09-22 00:51:24.843284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445800 of size 256 next 925\n",
      "2023-09-22 00:51:24.843293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445900 of size 15360000 next 1460\n",
      "2023-09-22 00:51:24.843302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12432eb900 of size 50201344 next 894\n",
      "2023-09-22 00:51:24.843314: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbc00 of size 256 next 695\n",
      "2023-09-22 00:51:24.843323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbd00 of size 256 next 1266\n",
      "2023-09-22 00:51:24.843333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbe00 of size 2097152 next 350\n",
      "2023-09-22 00:51:24.843342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464cbe00 of size 2188800 next 959\n",
      "2023-09-22 00:51:24.843351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2400 of size 256 next 1426\n",
      "2023-09-22 00:51:24.843361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2500 of size 8192 next 888\n",
      "2023-09-22 00:51:24.843371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e4500 of size 12288 next 373\n",
      "2023-09-22 00:51:24.843381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e7500 of size 8192 next 742\n",
      "2023-09-22 00:51:24.843391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e9500 of size 8192 next 569\n",
      "2023-09-22 00:51:24.843400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eb500 of size 256 next 1265\n",
      "2023-09-22 00:51:24.843411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eb600 of size 256 next 700\n",
      "2023-09-22 00:51:24.843422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eb700 of size 256 next 1372\n",
      "2023-09-22 00:51:24.843432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eb800 of size 256 next 176\n",
      "2023-09-22 00:51:24.843443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eb900 of size 512 next 1660\n",
      "2023-09-22 00:51:24.843454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ebb00 of size 512 next 1524\n",
      "2023-09-22 00:51:24.843465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ebd00 of size 2048 next 90\n",
      "2023-09-22 00:51:24.843476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ec500 of size 2048 next 1194\n",
      "2023-09-22 00:51:24.843487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ecd00 of size 2560 next 882\n",
      "2023-09-22 00:51:24.843497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ed700 of size 256 next 690\n",
      "2023-09-22 00:51:24.843506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ed800 of size 256 next 1126\n",
      "2023-09-22 00:51:24.843515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ed900 of size 256 next 1119\n",
      "2023-09-22 00:51:24.843524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eda00 of size 256 next 91\n",
      "2023-09-22 00:51:24.843535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466edb00 of size 8192 next 1378\n",
      "2023-09-22 00:51:24.843545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466efb00 of size 9472 next 291\n",
      "2023-09-22 00:51:24.843556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2000 of size 256 next 880\n",
      "2023-09-22 00:51:24.843564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2100 of size 14080 next 98\n",
      "2023-09-22 00:51:24.843573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5800 of size 256 next 385\n",
      "2023-09-22 00:51:24.843584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5900 of size 256 next 705\n",
      "2023-09-22 00:51:24.843594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5a00 of size 256 next 225\n",
      "2023-09-22 00:51:24.843604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5b00 of size 2097152 next 275\n",
      "2023-09-22 00:51:24.843614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12468f5b00 of size 2097152 next 81\n",
      "2023-09-22 00:51:24.843625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246af5b00 of size 2097152 next 1570\n",
      "2023-09-22 00:51:24.843635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246cf5b00 of size 2097152 next 557\n",
      "2023-09-22 00:51:24.843646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246ef5b00 of size 2168320 next 1155\n",
      "2023-09-22 00:51:24.843656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107100 of size 256 next 995\n",
      "2023-09-22 00:51:24.843667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107200 of size 245760 next 1215\n",
      "2023-09-22 00:51:24.843679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143200 of size 32768 next 1659\n",
      "2023-09-22 00:51:24.843689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124714b200 of size 46080 next 1223\n",
      "2023-09-22 00:51:24.843698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247156600 of size 46080 next 545\n",
      "2023-09-22 00:51:24.843708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247161a00 of size 65536 next 1646\n",
      "2023-09-22 00:51:24.843717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247171a00 of size 88064 next 1253\n",
      "2023-09-22 00:51:24.843726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247187200 of size 2048 next 1273\n",
      "2023-09-22 00:51:24.843735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247187a00 of size 2048 next 1021\n",
      "2023-09-22 00:51:24.843744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247188200 of size 2048 next 360\n",
      "2023-09-22 00:51:24.843754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247188a00 of size 2048 next 280\n",
      "2023-09-22 00:51:24.843763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189200 of size 256 next 620\n",
      "2023-09-22 00:51:24.843773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189300 of size 256 next 64\n",
      "2023-09-22 00:51:24.843783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189400 of size 256 next 220\n",
      "2023-09-22 00:51:24.843793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189500 of size 256 next 1339\n",
      "2023-09-22 00:51:24.843802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189600 of size 256 next 1317\n",
      "2023-09-22 00:51:24.843812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189700 of size 256 next 1129\n",
      "2023-09-22 00:51:24.843822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189800 of size 256 next 178\n",
      "2023-09-22 00:51:24.843832: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189900 of size 256 next 1217\n",
      "2023-09-22 00:51:24.843842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247189a00 of size 2048 next 1649\n",
      "2023-09-22 00:51:24.843851: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718a200 of size 2048 next 726\n",
      "2023-09-22 00:51:24.843861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718aa00 of size 256 next 1064\n",
      "2023-09-22 00:51:24.843871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718ab00 of size 256 next 508\n",
      "2023-09-22 00:51:24.843880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718ac00 of size 256 next 390\n",
      "2023-09-22 00:51:24.843890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718ad00 of size 256 next 18\n",
      "2023-09-22 00:51:24.843899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718ae00 of size 256 next 1292\n",
      "2023-09-22 00:51:24.843908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718af00 of size 256 next 315\n",
      "2023-09-22 00:51:24.843918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718b000 of size 256 next 475\n",
      "2023-09-22 00:51:24.843927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718b100 of size 256 next 854\n",
      "2023-09-22 00:51:24.843937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718b200 of size 8192 next 1521\n",
      "2023-09-22 00:51:24.843946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718d200 of size 2048 next 1340\n",
      "2023-09-22 00:51:24.843956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718da00 of size 1024 next 1140\n",
      "2023-09-22 00:51:24.843965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718de00 of size 1024 next 1286\n",
      "2023-09-22 00:51:24.843974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718e200 of size 2048 next 246\n",
      "2023-09-22 00:51:24.843984: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718ea00 of size 2048 next 909\n",
      "2023-09-22 00:51:24.843993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124718f200 of size 8192 next 346\n",
      "2023-09-22 00:51:24.844002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247191200 of size 9216 next 27\n",
      "2023-09-22 00:51:24.844012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193600 of size 256 next 1100\n",
      "2023-09-22 00:51:24.844021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193700 of size 256 next 1184\n",
      "2023-09-22 00:51:24.844029: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193800 of size 256 next 552\n",
      "2023-09-22 00:51:24.844038: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193900 of size 256 next 283\n",
      "2023-09-22 00:51:24.844047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193a00 of size 512 next 629\n",
      "2023-09-22 00:51:24.844057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193c00 of size 512 next 163\n",
      "2023-09-22 00:51:24.844066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193e00 of size 256 next 123\n",
      "2023-09-22 00:51:24.844075: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193f00 of size 256 next 1630\n",
      "2023-09-22 00:51:24.844085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194000 of size 256 next 1708\n",
      "2023-09-22 00:51:24.844094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194100 of size 256 next 276\n",
      "2023-09-22 00:51:24.844103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194200 of size 256 next 465\n",
      "2023-09-22 00:51:24.844113: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194300 of size 256 next 1069\n",
      "2023-09-22 00:51:24.844123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194400 of size 256 next 989\n",
      "2023-09-22 00:51:24.844132: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194500 of size 256 next 1131\n",
      "2023-09-22 00:51:24.844142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194600 of size 256 next 1095\n",
      "2023-09-22 00:51:24.844152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194700 of size 256 next 1202\n",
      "2023-09-22 00:51:24.844161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194800 of size 256 next 907\n",
      "2023-09-22 00:51:24.844170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194900 of size 256 next 815\n",
      "2023-09-22 00:51:24.844180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194a00 of size 256 next 1459\n",
      "2023-09-22 00:51:24.844189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194b00 of size 256 next 1108\n",
      "2023-09-22 00:51:24.844199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194c00 of size 256 next 34\n",
      "2023-09-22 00:51:24.844208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194d00 of size 256 next 369\n",
      "2023-09-22 00:51:24.844217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194e00 of size 2048 next 1700\n",
      "2023-09-22 00:51:24.844227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247195600 of size 8192 next 800\n",
      "2023-09-22 00:51:24.844238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247197600 of size 12800 next 587\n",
      "2023-09-22 00:51:24.844248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124719a800 of size 8192 next 1351\n",
      "2023-09-22 00:51:24.844258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124719c800 of size 9216 next 46\n",
      "2023-09-22 00:51:24.844268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124719ec00 of size 8192 next 650\n",
      "2023-09-22 00:51:24.844278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a0c00 of size 10752 next 958\n",
      "2023-09-22 00:51:24.844287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a3600 of size 256 next 1037\n",
      "2023-09-22 00:51:24.844296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a3700 of size 256 next 1674\n",
      "2023-09-22 00:51:24.844306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a3800 of size 512 next 179\n",
      "2023-09-22 00:51:24.844315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a3a00 of size 512 next 1257\n",
      "2023-09-22 00:51:24.844325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a3c00 of size 2048 next 1488\n",
      "2023-09-22 00:51:24.844335: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a4400 of size 2048 next 1065\n",
      "2023-09-22 00:51:24.844342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a4c00 of size 2048 next 1561\n",
      "2023-09-22 00:51:24.844350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a5400 of size 10240 next 670\n",
      "2023-09-22 00:51:24.844360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a7c00 of size 8192 next 1665\n",
      "2023-09-22 00:51:24.844369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a9c00 of size 8192 next 1156\n",
      "2023-09-22 00:51:24.844379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471abc00 of size 2048 next 599\n",
      "2023-09-22 00:51:24.844389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ac400 of size 256 next 1653\n",
      "2023-09-22 00:51:24.844398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ac500 of size 256 next 461\n",
      "2023-09-22 00:51:24.844408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ac600 of size 256 next 520\n",
      "2023-09-22 00:51:24.844417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ac700 of size 256 next 1675\n",
      "2023-09-22 00:51:24.844426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ac800 of size 256 next 1367\n",
      "2023-09-22 00:51:24.844435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ac900 of size 256 next 1165\n",
      "2023-09-22 00:51:24.844445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471aca00 of size 256 next 1379\n",
      "2023-09-22 00:51:24.844455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471acb00 of size 256 next 400\n",
      "2023-09-22 00:51:24.844465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471acc00 of size 256 next 332\n",
      "2023-09-22 00:51:24.844474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471acd00 of size 256 next 1097\n",
      "2023-09-22 00:51:24.844484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ace00 of size 256 next 639\n",
      "2023-09-22 00:51:24.844494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471acf00 of size 256 next 1535\n",
      "2023-09-22 00:51:24.844504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ad000 of size 256 next 591\n",
      "2023-09-22 00:51:24.844514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ad100 of size 256 next 1102\n",
      "2023-09-22 00:51:24.844524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ad200 of size 512 next 990\n",
      "2023-09-22 00:51:24.844534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ad400 of size 2048 next 456\n",
      "2023-09-22 00:51:24.844543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471adc00 of size 2048 next 522\n",
      "2023-09-22 00:51:24.844553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ae400 of size 2048 next 1685\n",
      "2023-09-22 00:51:24.844563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471aec00 of size 2048 next 783\n",
      "2023-09-22 00:51:24.844572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471af400 of size 2048 next 848\n",
      "2023-09-22 00:51:24.844582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471afc00 of size 2048 next 1442\n",
      "2023-09-22 00:51:24.844591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b0400 of size 13312 next 175\n",
      "2023-09-22 00:51:24.844600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b3800 of size 2048 next 949\n",
      "2023-09-22 00:51:24.844610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b4000 of size 2048 next 1051\n",
      "2023-09-22 00:51:24.844619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b4800 of size 256 next 362\n",
      "2023-09-22 00:51:24.844629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b4900 of size 256 next 1507\n",
      "2023-09-22 00:51:24.844638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b4a00 of size 256 next 850\n",
      "2023-09-22 00:51:24.844648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b4b00 of size 256 next 370\n",
      "2023-09-22 00:51:24.844657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b4c00 of size 1024 next 1213\n",
      "2023-09-22 00:51:24.844665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b5000 of size 1024 next 1492\n",
      "2023-09-22 00:51:24.844674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b5400 of size 1024 next 470\n",
      "2023-09-22 00:51:24.844683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b5800 of size 8192 next 1285\n",
      "2023-09-22 00:51:24.844693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b7800 of size 9216 next 137\n",
      "2023-09-22 00:51:24.844702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471b9c00 of size 2048 next 531\n",
      "2023-09-22 00:51:24.844711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ba400 of size 2048 next 94\n",
      "2023-09-22 00:51:24.844720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471bac00 of size 2048 next 667\n",
      "2023-09-22 00:51:24.844730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471bb400 of size 2048 next 1342\n",
      "2023-09-22 00:51:24.844739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471bbc00 of size 8192 next 1682\n",
      "2023-09-22 00:51:24.844748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471bdc00 of size 12800 next 1629\n",
      "2023-09-22 00:51:24.844758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c0e00 of size 8192 next 268\n",
      "2023-09-22 00:51:24.844767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c2e00 of size 9216 next 1437\n",
      "2023-09-22 00:51:24.844776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c5200 of size 8192 next 443\n",
      "2023-09-22 00:51:24.844785: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c7200 of size 2048 next 1562\n",
      "2023-09-22 00:51:24.844794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c7a00 of size 2048 next 875\n",
      "2023-09-22 00:51:24.844804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c8200 of size 2048 next 540\n",
      "2023-09-22 00:51:24.844813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c8a00 of size 2048 next 874\n",
      "2023-09-22 00:51:24.844823: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9200 of size 512 next 637\n",
      "2023-09-22 00:51:24.844830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9400 of size 256 next 1701\n",
      "2023-09-22 00:51:24.844839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9500 of size 256 next 1146\n",
      "2023-09-22 00:51:24.844849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9600 of size 256 next 893\n",
      "2023-09-22 00:51:24.844859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9700 of size 256 next 269\n",
      "2023-09-22 00:51:24.844868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9800 of size 256 next 595\n",
      "2023-09-22 00:51:24.844878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9900 of size 256 next 1173\n",
      "2023-09-22 00:51:24.844887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9a00 of size 256 next 1374\n",
      "2023-09-22 00:51:24.844896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9b00 of size 256 next 790\n",
      "2023-09-22 00:51:24.844906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9c00 of size 256 next 1120\n",
      "2023-09-22 00:51:24.844915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9d00 of size 256 next 1576\n",
      "2023-09-22 00:51:24.844924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471c9e00 of size 512 next 837\n",
      "2023-09-22 00:51:24.844934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ca000 of size 512 next 1515\n",
      "2023-09-22 00:51:24.844943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ca200 of size 1024 next 1641\n",
      "2023-09-22 00:51:24.844952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ca600 of size 1024 next 1407\n",
      "2023-09-22 00:51:24.844962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471caa00 of size 3584 next 722\n",
      "2023-09-22 00:51:24.844969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cb800 of size 256 next 194\n",
      "2023-09-22 00:51:24.844978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cb900 of size 512 next 374\n",
      "2023-09-22 00:51:24.844988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cbb00 of size 256 next 752\n",
      "2023-09-22 00:51:24.844997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cbc00 of size 256 next 845\n",
      "2023-09-22 00:51:24.845006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cbd00 of size 256 next 1494\n",
      "2023-09-22 00:51:24.845016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cbe00 of size 256 next 624\n",
      "2023-09-22 00:51:24.845026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cbf00 of size 1024 next 869\n",
      "2023-09-22 00:51:24.845035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cc300 of size 256 next 973\n",
      "2023-09-22 00:51:24.845044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cc400 of size 256 next 1655\n",
      "2023-09-22 00:51:24.845053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cc500 of size 256 next 1183\n",
      "2023-09-22 00:51:24.845063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cc600 of size 256 next 1350\n",
      "2023-09-22 00:51:24.845072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cc700 of size 256 next 148\n",
      "2023-09-22 00:51:24.845081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cc800 of size 256 next 501\n",
      "2023-09-22 00:51:24.845090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cc900 of size 256 next 136\n",
      "2023-09-22 00:51:24.845100: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471cca00 of size 46080 next 1392\n",
      "2023-09-22 00:51:24.845109: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471d7e00 of size 64256 next 383\n",
      "2023-09-22 00:51:24.845121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471e7900 of size 14080 next 441\n",
      "2023-09-22 00:51:24.845130: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471eb000 of size 8192 next 1234\n",
      "2023-09-22 00:51:24.845139: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ed000 of size 9216 next 691\n",
      "2023-09-22 00:51:24.845149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ef400 of size 256 next 881\n",
      "2023-09-22 00:51:24.845158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ef500 of size 256 next 53\n",
      "2023-09-22 00:51:24.845167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ef600 of size 256 next 566\n",
      "2023-09-22 00:51:24.845177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ef700 of size 256 next 1436\n",
      "2023-09-22 00:51:24.845186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ef800 of size 256 next 798\n",
      "2023-09-22 00:51:24.845195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ef900 of size 256 next 1402\n",
      "2023-09-22 00:51:24.845204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471efa00 of size 256 next 156\n",
      "2023-09-22 00:51:24.845214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471efb00 of size 256 next 262\n",
      "2023-09-22 00:51:24.845223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471efc00 of size 256 next 706\n",
      "2023-09-22 00:51:24.845233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471efd00 of size 256 next 1098\n",
      "2023-09-22 00:51:24.845242: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471efe00 of size 256 next 583\n",
      "2023-09-22 00:51:24.845252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471eff00 of size 1024 next 1191\n",
      "2023-09-22 00:51:24.845261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471f0300 of size 1024 next 1425\n",
      "2023-09-22 00:51:24.845271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471f0700 of size 1024 next 1536\n",
      "2023-09-22 00:51:24.845278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471f0b00 of size 1024 next 100\n",
      "2023-09-22 00:51:24.845288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471f0f00 of size 11520 next 102\n",
      "2023-09-22 00:51:24.845297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471f3c00 of size 9216 next 1473\n",
      "2023-09-22 00:51:24.845306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471f6000 of size 9216 next 1467\n",
      "2023-09-22 00:51:24.845315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471f8400 of size 9216 next 1117\n",
      "2023-09-22 00:51:24.845325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471fa800 of size 6912 next 509\n",
      "2023-09-22 00:51:24.845334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471fc300 of size 9728 next 256\n",
      "2023-09-22 00:51:24.845343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471fe900 of size 8192 next 1463\n",
      "2023-09-22 00:51:24.845353: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247200900 of size 14848 next 580\n",
      "2023-09-22 00:51:24.845362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247204300 of size 2048 next 215\n",
      "2023-09-22 00:51:24.845371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247204b00 of size 2560 next 961\n",
      "2023-09-22 00:51:24.845381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247205500 of size 2048 next 229\n",
      "2023-09-22 00:51:24.845390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247205d00 of size 2048 next 264\n",
      "2023-09-22 00:51:24.845399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247206500 of size 3328 next 245\n",
      "2023-09-22 00:51:24.845409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247207200 of size 2097152 next 1615\n",
      "2023-09-22 00:51:24.845418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247407200 of size 4072704 next 918\n",
      "2023-09-22 00:51:24.845427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9700 of size 256 next 440\n",
      "2023-09-22 00:51:24.845437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9800 of size 256 next 999\n",
      "2023-09-22 00:51:24.845447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9900 of size 2048 next 495\n",
      "2023-09-22 00:51:24.845456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ea100 of size 2048 next 1440\n",
      "2023-09-22 00:51:24.845465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ea900 of size 2048 next 1330\n",
      "2023-09-22 00:51:24.845475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb100 of size 2048 next 617\n",
      "2023-09-22 00:51:24.845485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb900 of size 256 next 430\n",
      "2023-09-22 00:51:24.845494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eba00 of size 256 next 811\n",
      "2023-09-22 00:51:24.845504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebb00 of size 256 next 1083\n",
      "2023-09-22 00:51:24.845513: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebc00 of size 256 next 233\n",
      "2023-09-22 00:51:24.845523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebd00 of size 256 next 1433\n",
      "2023-09-22 00:51:24.845532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebe00 of size 256 next 498\n",
      "2023-09-22 00:51:24.845541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebf00 of size 256 next 214\n",
      "2023-09-22 00:51:24.845551: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec000 of size 256 next 1389\n",
      "2023-09-22 00:51:24.845561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec100 of size 256 next 485\n",
      "2023-09-22 00:51:24.845571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec200 of size 256 next 453\n",
      "2023-09-22 00:51:24.845581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec300 of size 256 next 965\n",
      "2023-09-22 00:51:24.845590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec400 of size 256 next 1657\n",
      "2023-09-22 00:51:24.845600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec500 of size 256 next 250\n",
      "2023-09-22 00:51:24.845609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec600 of size 256 next 1264\n",
      "2023-09-22 00:51:24.845618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec700 of size 256 next 825\n",
      "2023-09-22 00:51:24.845628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec800 of size 256 next 145\n",
      "2023-09-22 00:51:24.845637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec900 of size 256 next 1617\n",
      "2023-09-22 00:51:24.845646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eca00 of size 256 next 429\n",
      "2023-09-22 00:51:24.845655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecb00 of size 256 next 926\n",
      "2023-09-22 00:51:24.845665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecc00 of size 256 next 1549\n",
      "2023-09-22 00:51:24.845675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecd00 of size 256 next 946\n",
      "2023-09-22 00:51:24.845685: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ece00 of size 256 next 128\n",
      "2023-09-22 00:51:24.845694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecf00 of size 256 next 841\n",
      "2023-09-22 00:51:24.845704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed000 of size 256 next 131\n",
      "2023-09-22 00:51:24.845713: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed100 of size 256 next 1424\n",
      "2023-09-22 00:51:24.845722: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed200 of size 256 next 851\n",
      "2023-09-22 00:51:24.845730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed300 of size 256 next 935\n",
      "2023-09-22 00:51:24.845737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed400 of size 256 next 452\n",
      "2023-09-22 00:51:24.845747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed500 of size 256 next 1702\n",
      "2023-09-22 00:51:24.845757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed600 of size 256 next 1547\n",
      "2023-09-22 00:51:24.845766: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed700 of size 256 next 308\n",
      "2023-09-22 00:51:24.845776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed800 of size 256 next 1356\n",
      "2023-09-22 00:51:24.845783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12477ed900 of size 256 next 203\n",
      "2023-09-22 00:51:24.845792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eda00 of size 256 next 1412\n",
      "2023-09-22 00:51:24.845802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477edb00 of size 256 next 1237\n",
      "2023-09-22 00:51:24.845811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12477edc00 of size 4096 next 817\n",
      "2023-09-22 00:51:24.845820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eec00 of size 9216 next 114\n",
      "2023-09-22 00:51:24.845830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f1000 of size 6912 next 1311\n",
      "2023-09-22 00:51:24.845839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f2b00 of size 2048 next 212\n",
      "2023-09-22 00:51:24.845848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f3300 of size 2048 next 421\n",
      "2023-09-22 00:51:24.845858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f3b00 of size 2816 next 1056\n",
      "2023-09-22 00:51:24.845867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f4600 of size 11776 next 1341\n",
      "2023-09-22 00:51:24.845877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7400 of size 2563328 next 1048\n",
      "2023-09-22 00:51:24.845889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69100 of size 256 next 1393\n",
      "2023-09-22 00:51:24.845898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69200 of size 256 next 184\n",
      "2023-09-22 00:51:24.845908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69300 of size 2097152 next 1084\n",
      "2023-09-22 00:51:24.845917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247c69300 of size 2097152 next 278\n",
      "2023-09-22 00:51:24.845927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e69300 of size 2487040 next 122\n",
      "2023-09-22 00:51:24.845936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8600 of size 256 next 1698\n",
      "2023-09-22 00:51:24.845946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8700 of size 256 next 1380\n",
      "2023-09-22 00:51:24.845955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8800 of size 256 next 1450\n",
      "2023-09-22 00:51:24.845964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8900 of size 256 next 1694\n",
      "2023-09-22 00:51:24.845973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8a00 of size 256 next 526\n",
      "2023-09-22 00:51:24.845982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8b00 of size 256 next 689\n",
      "2023-09-22 00:51:24.845992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8c00 of size 256 next 1590\n",
      "2023-09-22 00:51:24.846001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8d00 of size 256 next 167\n",
      "2023-09-22 00:51:24.846010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c8e00 of size 2048 next 1361\n",
      "2023-09-22 00:51:24.846019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480c9600 of size 3840 next 1295\n",
      "2023-09-22 00:51:24.846028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca500 of size 256 next 671\n",
      "2023-09-22 00:51:24.846037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca600 of size 256 next 1061\n",
      "2023-09-22 00:51:24.846047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca700 of size 256 next 1514\n",
      "2023-09-22 00:51:24.846056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca800 of size 81920000 next 782\n",
      "2023-09-22 00:51:24.846066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124ceea800 of size 149667584 next 514\n",
      "2023-09-22 00:51:24.846075: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6700 of size 256 next 284\n",
      "2023-09-22 00:51:24.846084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6800 of size 256 next 796\n",
      "2023-09-22 00:51:24.846092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6900 of size 320000 next 1489\n",
      "2023-09-22 00:51:24.846101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255df4b00 of size 320000 next 1589\n",
      "2023-09-22 00:51:24.846111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e42d00 of size 320000 next 58\n",
      "2023-09-22 00:51:24.846120: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e90f00 of size 443136 next 683\n",
      "2023-09-22 00:51:24.846129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd200 of size 256 next 1296\n",
      "2023-09-22 00:51:24.846139: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1255efd300 of size 81920000 next 747\n",
      "2023-09-22 00:51:24.846148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125ad1d300 of size 81920000 next 519\n",
      "2023-09-22 00:51:24.846158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f125fb3d300 of size 362785792 next 972\n",
      "2023-09-22 00:51:24.846167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537f00 of size 256 next 929\n",
      "2023-09-22 00:51:24.846176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538000 of size 256 next 940\n",
      "2023-09-22 00:51:24.846185: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538100 of size 9984 next 1179\n",
      "2023-09-22 00:51:24.846195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a800 of size 256 next 771\n",
      "2023-09-22 00:51:24.846204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a900 of size 8192 next 295\n",
      "2023-09-22 00:51:24.846213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c900 of size 8192 next 431\n",
      "2023-09-22 00:51:24.846222: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553e900 of size 8192 next 457\n",
      "2023-09-22 00:51:24.846231: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275540900 of size 8192 next 1624\n",
      "2023-09-22 00:51:24.846240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275542900 of size 32768 next 16\n",
      "2023-09-22 00:51:24.846249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127554a900 of size 65536 next 422\n",
      "2023-09-22 00:51:24.846258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555a900 of size 32768 next 448\n",
      "2023-09-22 00:51:24.846268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275562900 of size 32768 next 329\n",
      "2023-09-22 00:51:24.846277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556a900 of size 52736 next 1093\n",
      "2023-09-22 00:51:24.846286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577700 of size 256 next 1255\n",
      "2023-09-22 00:51:24.846296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577800 of size 245760 next 804\n",
      "2023-09-22 00:51:24.846305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b3800 of size 8192 next 1319\n",
      "2023-09-22 00:51:24.846314: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b5800 of size 1024 next 879\n",
      "2023-09-22 00:51:24.846324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b5c00 of size 1024 next 579\n",
      "2023-09-22 00:51:24.846333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b6000 of size 1024 next 317\n",
      "2023-09-22 00:51:24.846342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b6400 of size 1024 next 1563\n",
      "2023-09-22 00:51:24.846351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b6800 of size 32768 next 1445\n",
      "2023-09-22 00:51:24.846360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755be800 of size 32768 next 469\n",
      "2023-09-22 00:51:24.846369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c6800 of size 256 next 1067\n",
      "2023-09-22 00:51:24.846378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c6900 of size 256 next 1427\n",
      "2023-09-22 00:51:24.846388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c6a00 of size 32768 next 730\n",
      "2023-09-22 00:51:24.846395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755cea00 of size 32768 next 1205\n",
      "2023-09-22 00:51:24.846404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d6a00 of size 1024 next 699\n",
      "2023-09-22 00:51:24.846413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d6e00 of size 1024 next 84\n",
      "2023-09-22 00:51:24.846423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d7200 of size 1024 next 1371\n",
      "2023-09-22 00:51:24.846432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d7600 of size 1024 next 118\n",
      "2023-09-22 00:51:24.846442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d7a00 of size 1024 next 1112\n",
      "2023-09-22 00:51:24.846451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d7e00 of size 1024 next 623\n",
      "2023-09-22 00:51:24.846460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d8200 of size 8192 next 487\n",
      "2023-09-22 00:51:24.846469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755da200 of size 8192 next 307\n",
      "2023-09-22 00:51:24.846479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755dc200 of size 8192 next 1044\n",
      "2023-09-22 00:51:24.846488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755de200 of size 8192 next 735\n",
      "2023-09-22 00:51:24.846497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e0200 of size 8192 next 808\n",
      "2023-09-22 00:51:24.846506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e2200 of size 8192 next 589\n",
      "2023-09-22 00:51:24.846515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e4200 of size 1024 next 1160\n",
      "2023-09-22 00:51:24.846524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e4600 of size 1024 next 1318\n",
      "2023-09-22 00:51:24.846534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e4a00 of size 1024 next 1347\n",
      "2023-09-22 00:51:24.846543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e4e00 of size 1024 next 1168\n",
      "2023-09-22 00:51:24.846553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e5200 of size 1024 next 1461\n",
      "2023-09-22 00:51:24.846562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e5600 of size 1024 next 919\n",
      "2023-09-22 00:51:24.846571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e5a00 of size 32768 next 1435\n",
      "2023-09-22 00:51:24.846581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755eda00 of size 32768 next 1008\n",
      "2023-09-22 00:51:24.846590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f5a00 of size 256 next 537\n",
      "2023-09-22 00:51:24.846599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f5b00 of size 256 next 351\n",
      "2023-09-22 00:51:24.846609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f5c00 of size 32768 next 1190\n",
      "2023-09-22 00:51:24.846618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755fdc00 of size 32768 next 654\n",
      "2023-09-22 00:51:24.846628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275605c00 of size 1024 next 564\n",
      "2023-09-22 00:51:24.846637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275606000 of size 1024 next 1145\n",
      "2023-09-22 00:51:24.846646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275606400 of size 1024 next 1408\n",
      "2023-09-22 00:51:24.846656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275606800 of size 1024 next 1185\n",
      "2023-09-22 00:51:24.846665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275606c00 of size 1024 next 1028\n",
      "2023-09-22 00:51:24.846674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275607000 of size 1024 next 1345\n",
      "2023-09-22 00:51:24.846683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275607400 of size 8192 next 71\n",
      "2023-09-22 00:51:24.846693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275609400 of size 8192 next 259\n",
      "2023-09-22 00:51:24.846700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127560b400 of size 8192 next 197\n",
      "2023-09-22 00:51:24.846709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127560d400 of size 8192 next 1390\n",
      "2023-09-22 00:51:24.846719: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127560f400 of size 8192 next 1055\n",
      "2023-09-22 00:51:24.846728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275611400 of size 8192 next 1558\n",
      "2023-09-22 00:51:24.846738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275613400 of size 1024 next 1218\n",
      "2023-09-22 00:51:24.846747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275613800 of size 1024 next 1301\n",
      "2023-09-22 00:51:24.846756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275613c00 of size 1024 next 1622\n",
      "2023-09-22 00:51:24.846766: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275614000 of size 1024 next 1322\n",
      "2023-09-22 00:51:24.846775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275614400 of size 1024 next 180\n",
      "2023-09-22 00:51:24.846784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275614800 of size 1024 next 1596\n",
      "2023-09-22 00:51:24.846794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275614c00 of size 32768 next 459\n",
      "2023-09-22 00:51:24.846803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127561cc00 of size 32768 next 408\n",
      "2023-09-22 00:51:24.846811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275624c00 of size 256 next 1625\n",
      "2023-09-22 00:51:24.846821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275624d00 of size 256 next 1169\n",
      "2023-09-22 00:51:24.846830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275624e00 of size 32768 next 1520\n",
      "2023-09-22 00:51:24.846840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127562ce00 of size 32768 next 852\n",
      "2023-09-22 00:51:24.846849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275634e00 of size 1024 next 185\n",
      "2023-09-22 00:51:24.846859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275635200 of size 1024 next 877\n",
      "2023-09-22 00:51:24.846868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275635600 of size 1024 next 1228\n",
      "2023-09-22 00:51:24.846878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275635a00 of size 1024 next 511\n",
      "2023-09-22 00:51:24.846887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275635e00 of size 1024 next 903\n",
      "2023-09-22 00:51:24.846897: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275636200 of size 1024 next 454\n",
      "2023-09-22 00:51:24.846906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275636600 of size 32768 next 235\n",
      "2023-09-22 00:51:24.846915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127563e600 of size 32768 next 962\n",
      "2023-09-22 00:51:24.846925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646600 of size 256 next 984\n",
      "2023-09-22 00:51:24.846934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646700 of size 256 next 913\n",
      "2023-09-22 00:51:24.846943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646800 of size 256 next 1059\n",
      "2023-09-22 00:51:24.846953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646900 of size 256 next 70\n",
      "2023-09-22 00:51:24.846962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646a00 of size 256 next 1447\n",
      "2023-09-22 00:51:24.846972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646b00 of size 256 next 679\n",
      "2023-09-22 00:51:24.846982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646c00 of size 256 next 743\n",
      "2023-09-22 00:51:24.846991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646d00 of size 256 next 357\n",
      "2023-09-22 00:51:24.847001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275646e00 of size 358656 next 640\n",
      "2023-09-22 00:51:24.847013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127569e700 of size 8192 next 1277\n",
      "2023-09-22 00:51:24.847023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a0700 of size 9216 next 608\n",
      "2023-09-22 00:51:24.847032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a2b00 of size 9216 next 1645\n",
      "2023-09-22 00:51:24.847042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a4f00 of size 14592 next 474\n",
      "2023-09-22 00:51:24.847051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8800 of size 256 next 859\n",
      "2023-09-22 00:51:24.847060: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8900 of size 256 next 24\n",
      "2023-09-22 00:51:24.847070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8a00 of size 8192 next 1532\n",
      "2023-09-22 00:51:24.847079: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aaa00 of size 9728 next 682\n",
      "2023-09-22 00:51:24.847089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad000 of size 256 next 836\n",
      "2023-09-22 00:51:24.847098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad100 of size 256 next 659\n",
      "2023-09-22 00:51:24.847107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad200 of size 256 next 612\n",
      "2023-09-22 00:51:24.847117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad300 of size 256 next 521\n",
      "2023-09-22 00:51:24.847124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad400 of size 256 next 897\n",
      "2023-09-22 00:51:24.847133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad500 of size 256 next 93\n",
      "2023-09-22 00:51:24.847149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad600 of size 256 next 928\n",
      "2023-09-22 00:51:24.847158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad700 of size 655360000 next 1153\n",
      "2023-09-22 00:51:24.847167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f129c7ad700 of size 655360000 next 1679\n",
      "2023-09-22 00:51:24.847177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c38ad700 of size 20480000 next 1502\n",
      "2023-09-22 00:51:24.847188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c4c35700 of size 10240000 next 1227\n",
      "2023-09-22 00:51:24.847197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c55f9700 of size 20480000 next 1605\n",
      "2023-09-22 00:51:24.847208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12c6981700 of size 51200000 next 1247\n",
      "2023-09-22 00:51:24.847217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c9a55700 of size 81920000 next 1284\n",
      "2023-09-22 00:51:24.847227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ce875700 of size 81920000 next 789\n",
      "2023-09-22 00:51:24.847238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12d3695700 of size 159910912 next 863\n",
      "2023-09-22 00:51:24.847247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16300 of size 256 next 867\n",
      "2023-09-22 00:51:24.847257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16400 of size 1024 next 130\n",
      "2023-09-22 00:51:24.847267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16800 of size 1536 next 1143\n",
      "2023-09-22 00:51:24.847276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16e00 of size 256 next 406\n",
      "2023-09-22 00:51:24.847285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16f00 of size 256 next 301\n",
      "2023-09-22 00:51:24.847294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17000 of size 256 next 1511\n",
      "2023-09-22 00:51:24.847303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17100 of size 256 next 1271\n",
      "2023-09-22 00:51:24.847312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17200 of size 256 next 230\n",
      "2023-09-22 00:51:24.847322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17300 of size 512 next 820\n",
      "2023-09-22 00:51:24.847332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17500 of size 256 next 983\n",
      "2023-09-22 00:51:24.847341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17600 of size 256 next 1175\n",
      "2023-09-22 00:51:24.847350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17700 of size 256 next 1199\n",
      "2023-09-22 00:51:24.847360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17800 of size 256 next 1510\n",
      "2023-09-22 00:51:24.847369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17900 of size 256 next 876\n",
      "2023-09-22 00:51:24.847378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17a00 of size 256 next 368\n",
      "2023-09-22 00:51:24.847388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17b00 of size 256 next 251\n",
      "2023-09-22 00:51:24.847397: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17c00 of size 256 next 1504\n",
      "2023-09-22 00:51:24.847407: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17d00 of size 256 next 1135\n",
      "2023-09-22 00:51:24.847416: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17e00 of size 256 next 638\n",
      "2023-09-22 00:51:24.847426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17f00 of size 256 next 901\n",
      "2023-09-22 00:51:24.847435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18000 of size 256 next 1526\n",
      "2023-09-22 00:51:24.847443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18100 of size 256 next 1626\n",
      "2023-09-22 00:51:24.847452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18200 of size 256 next 1598\n",
      "2023-09-22 00:51:24.847461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18300 of size 256 next 824\n",
      "2023-09-22 00:51:24.847471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18400 of size 256 next 1490\n",
      "2023-09-22 00:51:24.847480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18500 of size 256 next 1111\n",
      "2023-09-22 00:51:24.847489: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18600 of size 256 next 1239\n",
      "2023-09-22 00:51:24.847498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18700 of size 256 next 1162\n",
      "2023-09-22 00:51:24.847508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18800 of size 256 next 842\n",
      "2023-09-22 00:51:24.847517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18900 of size 256 next 1157\n",
      "2023-09-22 00:51:24.847526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18a00 of size 512 next 1658\n",
      "2023-09-22 00:51:24.847536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18c00 of size 768 next 1429\n",
      "2023-09-22 00:51:24.847545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18f00 of size 256 next 985\n",
      "2023-09-22 00:51:24.847554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19000 of size 512 next 68\n",
      "2023-09-22 00:51:24.847564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19200 of size 256 next 375\n",
      "2023-09-22 00:51:24.847573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19300 of size 256 next 1149\n",
      "2023-09-22 00:51:24.847582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19400 of size 256 next 570\n",
      "2023-09-22 00:51:24.847592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19500 of size 256 next 548\n",
      "2023-09-22 00:51:24.847601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19600 of size 256 next 1434\n",
      "2023-09-22 00:51:24.847611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19700 of size 512 next 806\n",
      "2023-09-22 00:51:24.847620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19900 of size 512 next 396\n",
      "2023-09-22 00:51:24.847630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19b00 of size 256 next 780\n",
      "2023-09-22 00:51:24.847640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19c00 of size 256 next 1470\n",
      "2023-09-22 00:51:24.847650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19d00 of size 256 next 1458\n",
      "2023-09-22 00:51:24.847660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19e00 of size 256 next 905\n",
      "2023-09-22 00:51:24.847669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19f00 of size 256 next 1651\n",
      "2023-09-22 00:51:24.847678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1a000 of size 256 next 1071\n",
      "2023-09-22 00:51:24.847688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1a100 of size 428288 next 669\n",
      "2023-09-22 00:51:24.847697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82a00 of size 256 next 785\n",
      "2023-09-22 00:51:24.847707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82b00 of size 256 next 672\n",
      "2023-09-22 00:51:24.847716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82c00 of size 256 next 296\n",
      "2023-09-22 00:51:24.847725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82d00 of size 256 next 674\n",
      "2023-09-22 00:51:24.847734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82e00 of size 256 next 592\n",
      "2023-09-22 00:51:24.847743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82f00 of size 256 next 1400\n",
      "2023-09-22 00:51:24.847751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83000 of size 256 next 206\n",
      "2023-09-22 00:51:24.847760: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83100 of size 256 next 1678\n",
      "2023-09-22 00:51:24.847769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83200 of size 256 next 467\n",
      "2023-09-22 00:51:24.847779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83300 of size 256 next 792\n",
      "2023-09-22 00:51:24.847788: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83400 of size 256 next 111\n",
      "2023-09-22 00:51:24.847797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83500 of size 256 next 294\n",
      "2023-09-22 00:51:24.847806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83600 of size 256 next 642\n",
      "2023-09-22 00:51:24.847815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83700 of size 256 next 523\n",
      "2023-09-22 00:51:24.847825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83800 of size 256 next 463\n",
      "2023-09-22 00:51:24.847834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83900 of size 256 next 1279\n",
      "2023-09-22 00:51:24.847843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83a00 of size 256 next 551\n",
      "2023-09-22 00:51:24.847853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83b00 of size 256 next 910\n",
      "2023-09-22 00:51:24.847862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83c00 of size 40960000 next 1593\n",
      "2023-09-22 00:51:24.847872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12df693c00 of size 40960000 next 1439\n",
      "2023-09-22 00:51:24.847881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e1da3c00 of size 40960000 next 1577\n",
      "2023-09-22 00:51:24.847890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e44b3c00 of size 40960000 next 1267\n",
      "2023-09-22 00:51:24.847899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e6bc3c00 of size 20480000 next 994\n",
      "2023-09-22 00:51:24.847909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e7f4bc00 of size 20480000 next 1094\n",
      "2023-09-22 00:51:24.847918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e92d3c00 of size 81961472 next 1017\n",
      "2023-09-22 00:51:24.847929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fde00 of size 2048 next 933\n",
      "2023-09-22 00:51:24.847938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fe600 of size 2048 next 442\n",
      "2023-09-22 00:51:24.847948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fee00 of size 2048 next 1305\n",
      "2023-09-22 00:51:24.847957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0ff600 of size 2048 next 1082\n",
      "2023-09-22 00:51:24.847967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee0ffe00 of size 30464 next 917\n",
      "2023-09-22 00:51:24.847976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee107500 of size 9216 next 386\n",
      "2023-09-22 00:51:24.847985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee109900 of size 12032 next 1107\n",
      "2023-09-22 00:51:24.847995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee10c800 of size 9216 next 981\n",
      "2023-09-22 00:51:24.848004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee10ec00 of size 9216 next 129\n",
      "2023-09-22 00:51:24.848013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee111000 of size 2048 next 1241\n",
      "2023-09-22 00:51:24.848022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee111800 of size 2048 next 99\n",
      "2023-09-22 00:51:24.848031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee112000 of size 2048 next 1541\n",
      "2023-09-22 00:51:24.848041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee112800 of size 3072 next 846\n",
      "2023-09-22 00:51:24.848050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee113400 of size 13056 next 1245\n",
      "2023-09-22 00:51:24.848058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee116700 of size 8192 next 884\n",
      "2023-09-22 00:51:24.848068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee118700 of size 10240 next 832\n",
      "2023-09-22 00:51:24.848077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11af00 of size 256 next 83\n",
      "2023-09-22 00:51:24.848086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b000 of size 256 next 412\n",
      "2023-09-22 00:51:24.848095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b100 of size 256 next 688\n",
      "2023-09-22 00:51:24.848104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b200 of size 256 next 344\n",
      "2023-09-22 00:51:24.848114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b300 of size 256 next 676\n",
      "2023-09-22 00:51:24.848123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b400 of size 256 next 1033\n",
      "2023-09-22 00:51:24.848133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b500 of size 256 next 1423\n",
      "2023-09-22 00:51:24.848142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b600 of size 512 next 982\n",
      "2023-09-22 00:51:24.848151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11b800 of size 512 next 1090\n",
      "2023-09-22 00:51:24.848160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11ba00 of size 256 next 435\n",
      "2023-09-22 00:51:24.848169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11bb00 of size 256 next 1654\n",
      "2023-09-22 00:51:24.848179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11bc00 of size 256 next 1636\n",
      "2023-09-22 00:51:24.848188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11bd00 of size 256 next 1161\n",
      "2023-09-22 00:51:24.848197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11be00 of size 256 next 625\n",
      "2023-09-22 00:51:24.848207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11bf00 of size 256 next 1329\n",
      "2023-09-22 00:51:24.848216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11c000 of size 256 next 1152\n",
      "2023-09-22 00:51:24.848225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11c100 of size 2048 next 1482\n",
      "2023-09-22 00:51:24.848234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11c900 of size 2560 next 219\n",
      "2023-09-22 00:51:24.848244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11d300 of size 2816 next 1477\n",
      "2023-09-22 00:51:24.848253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee11de00 of size 3952896 next 313\n",
      "2023-09-22 00:51:24.848262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4e2f00 of size 8192 next 1315\n",
      "2023-09-22 00:51:24.848271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4e4f00 of size 8192 next 1692\n",
      "2023-09-22 00:51:24.848281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4e6f00 of size 8192 next 238\n",
      "2023-09-22 00:51:24.848291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4e8f00 of size 8192 next 395\n",
      "2023-09-22 00:51:24.848301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eaf00 of size 32768 next 1011\n",
      "2023-09-22 00:51:24.848310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f2f00 of size 32768 next 353\n",
      "2023-09-22 00:51:24.848319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4faf00 of size 8192 next 560\n",
      "2023-09-22 00:51:24.848328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4fcf00 of size 8192 next 861\n",
      "2023-09-22 00:51:24.848338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4fef00 of size 8192 next 1325\n",
      "2023-09-22 00:51:24.848347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee500f00 of size 8192 next 1192\n",
      "2023-09-22 00:51:24.848356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee502f00 of size 8192 next 446\n",
      "2023-09-22 00:51:24.848364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee504f00 of size 256 next 239\n",
      "2023-09-22 00:51:24.848373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505000 of size 256 next 1150\n",
      "2023-09-22 00:51:24.848382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505100 of size 256 next 967\n",
      "2023-09-22 00:51:24.848391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505200 of size 256 next 1321\n",
      "2023-09-22 00:51:24.848401: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505300 of size 256 next 1115\n",
      "2023-09-22 00:51:24.848410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505400 of size 256 next 1159\n",
      "2023-09-22 00:51:24.848417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505500 of size 512 next 187\n",
      "2023-09-22 00:51:24.848425: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505700 of size 512 next 1391\n",
      "2023-09-22 00:51:24.848435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505900 of size 8192 next 1249\n",
      "2023-09-22 00:51:24.848445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee507900 of size 3640320 next 140\n",
      "2023-09-22 00:51:24.848454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880500 of size 256 next 52\n",
      "2023-09-22 00:51:24.848464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880600 of size 256 next 1690\n",
      "2023-09-22 00:51:24.848473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880700 of size 256 next 950\n",
      "2023-09-22 00:51:24.848483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880800 of size 256 next 648\n",
      "2023-09-22 00:51:24.848492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880900 of size 256 next 281\n",
      "2023-09-22 00:51:24.848502: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880a00 of size 512 next 312\n",
      "2023-09-22 00:51:24.848512: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880c00 of size 512 next 1601\n",
      "2023-09-22 00:51:24.848521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee880e00 of size 22272 next 1523\n",
      "2023-09-22 00:51:24.848530: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee886500 of size 10240 next 1032\n",
      "2023-09-22 00:51:24.848539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee888d00 of size 8192 next 1416\n",
      "2023-09-22 00:51:24.848549: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee88ad00 of size 8192 next 1109\n",
      "2023-09-22 00:51:24.848559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee88cd00 of size 320000 next 407\n",
      "2023-09-22 00:51:24.848568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee8daf00 of size 320000 next 826\n",
      "2023-09-22 00:51:24.848577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee929100 of size 320000 next 488\n",
      "2023-09-22 00:51:24.848586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee977300 of size 954624 next 1053\n",
      "2023-09-22 00:51:24.848595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eea60400 of size 256 next 125\n",
      "2023-09-22 00:51:24.848604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eea60500 of size 256 next 864\n",
      "2023-09-22 00:51:24.848614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eea60600 of size 2097152 next 991\n",
      "2023-09-22 00:51:24.848623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eec60600 of size 2097152 next 1077\n",
      "2023-09-22 00:51:24.848632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eee60600 of size 2097152 next 1575\n",
      "2023-09-22 00:51:24.848641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ef060600 of size 2097152 next 986\n",
      "2023-09-22 00:51:24.848651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ef260600 of size 2097152 next 916\n",
      "2023-09-22 00:51:24.848661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ef460600 of size 2097152 next 202\n",
      "2023-09-22 00:51:24.848670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ef660600 of size 2097152 next 1360\n",
      "2023-09-22 00:51:24.848680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ef860600 of size 2097152 next 249\n",
      "2023-09-22 00:51:24.848689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12efa60600 of size 2097152 next 318\n",
      "2023-09-22 00:51:24.848698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12efc60600 of size 3364608 next 1357\n",
      "2023-09-22 00:51:24.848708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff95d00 of size 256 next 1568\n",
      "2023-09-22 00:51:24.848717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff95e00 of size 256 next 1231\n",
      "2023-09-22 00:51:24.848725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff95f00 of size 256 next 306\n",
      "2023-09-22 00:51:24.848734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96000 of size 256 next 987\n",
      "2023-09-22 00:51:24.848743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96100 of size 256 next 172\n",
      "2023-09-22 00:51:24.848753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96200 of size 512 next 621\n",
      "2023-09-22 00:51:24.848762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96400 of size 512 next 1591\n",
      "2023-09-22 00:51:24.848771: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96600 of size 1024 next 199\n",
      "2023-09-22 00:51:24.848780: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96a00 of size 256 next 1431\n",
      "2023-09-22 00:51:24.848789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96b00 of size 256 next 1344\n",
      "2023-09-22 00:51:24.848798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96c00 of size 256 next 1438\n",
      "2023-09-22 00:51:24.848807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96d00 of size 256 next 963\n",
      "2023-09-22 00:51:24.848817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff96e00 of size 2816 next 1506\n",
      "2023-09-22 00:51:24.848827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eff97900 of size 133201152 next 932\n",
      "2023-09-22 00:51:24.848836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f600 of size 256 next 101\n",
      "2023-09-22 00:51:24.848845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f700 of size 256 next 761\n",
      "2023-09-22 00:51:24.848854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f800 of size 2097152 next 1281\n",
      "2023-09-22 00:51:24.848864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f809f800 of size 2097152 next 1444\n",
      "2023-09-22 00:51:24.848873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f829f800 of size 18392064 next 366\n",
      "2023-09-22 00:51:24.848884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9429c00 of size 256 next 1291\n",
      "2023-09-22 00:51:24.848893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9429d00 of size 256 next 378\n",
      "2023-09-22 00:51:24.848903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9429e00 of size 256 next 1611\n",
      "2023-09-22 00:51:24.848912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9429f00 of size 256 next 1546\n",
      "2023-09-22 00:51:24.848921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f942a000 of size 512 next 1509\n",
      "2023-09-22 00:51:24.848930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f942a200 of size 512 next 1144\n",
      "2023-09-22 00:51:24.848939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f942a400 of size 2048 next 67\n",
      "2023-09-22 00:51:24.848949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f942ac00 of size 3104768 next 1122\n",
      "2023-09-22 00:51:24.848958: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9720c00 of size 2048 next 69\n",
      "2023-09-22 00:51:24.848967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9721400 of size 2048 next 436\n",
      "2023-09-22 00:51:24.848976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9721c00 of size 2048 next 1647\n",
      "2023-09-22 00:51:24.848986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9722400 of size 3072 next 405\n",
      "2023-09-22 00:51:24.848995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9723000 of size 2048 next 65\n",
      "2023-09-22 00:51:24.849004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9723800 of size 2048 next 873\n",
      "2023-09-22 00:51:24.849013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724000 of size 2048 next 1354\n",
      "2023-09-22 00:51:24.849023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724800 of size 512 next 634\n",
      "2023-09-22 00:51:24.849030: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724a00 of size 256 next 1606\n",
      "2023-09-22 00:51:24.849039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724b00 of size 256 next 1269\n",
      "2023-09-22 00:51:24.849048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724c00 of size 256 next 1375\n",
      "2023-09-22 00:51:24.849058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724d00 of size 256 next 1628\n",
      "2023-09-22 00:51:24.849067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724e00 of size 256 next 1262\n",
      "2023-09-22 00:51:24.849076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9724f00 of size 256 next 1164\n",
      "2023-09-22 00:51:24.849085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725000 of size 512 next 1644\n",
      "2023-09-22 00:51:24.849094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725200 of size 512 next 1200\n",
      "2023-09-22 00:51:24.849103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725400 of size 256 next 1394\n",
      "2023-09-22 00:51:24.849113: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725500 of size 256 next 1349\n",
      "2023-09-22 00:51:24.849122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725600 of size 256 next 1552\n",
      "2023-09-22 00:51:24.849131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725700 of size 256 next 895\n",
      "2023-09-22 00:51:24.849140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725800 of size 256 next 1221\n",
      "2023-09-22 00:51:24.849149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725900 of size 256 next 1049\n",
      "2023-09-22 00:51:24.849159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725a00 of size 256 next 1091\n",
      "2023-09-22 00:51:24.849168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725b00 of size 256 next 1604\n",
      "2023-09-22 00:51:24.849177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725c00 of size 256 next 1274\n",
      "2023-09-22 00:51:24.849187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725d00 of size 256 next 1573\n",
      "2023-09-22 00:51:24.849196: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725e00 of size 256 next 921\n",
      "2023-09-22 00:51:24.849206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9725f00 of size 256 next 1026\n",
      "2023-09-22 00:51:24.849215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9726000 of size 2048 next 890\n",
      "2023-09-22 00:51:24.849224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9726800 of size 2048 next 1189\n",
      "2023-09-22 00:51:24.849233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9727000 of size 2048 next 816\n",
      "2023-09-22 00:51:24.849243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9727800 of size 2048 next 1538\n",
      "2023-09-22 00:51:24.849252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9728000 of size 2048 next 1303\n",
      "2023-09-22 00:51:24.849261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9728800 of size 256 next 713\n",
      "2023-09-22 00:51:24.849270: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9728900 of size 256 next 807\n",
      "2023-09-22 00:51:24.849280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9728a00 of size 256 next 1141\n",
      "2023-09-22 00:51:24.849289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9728b00 of size 256 next 236\n",
      "2023-09-22 00:51:24.849298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9728c00 of size 2048 next 1448\n",
      "2023-09-22 00:51:24.849307: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9729400 of size 2048 next 1399\n",
      "2023-09-22 00:51:24.849317: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9729c00 of size 2048 next 677\n",
      "2023-09-22 00:51:24.849326: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972a400 of size 3072 next 794\n",
      "2023-09-22 00:51:24.849333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972b000 of size 2048 next 437\n",
      "2023-09-22 00:51:24.849342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972b800 of size 2048 next 944\n",
      "2023-09-22 00:51:24.849351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c000 of size 256 next 1599\n",
      "2023-09-22 00:51:24.849361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c100 of size 256 next 1537\n",
      "2023-09-22 00:51:24.849371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c200 of size 256 next 155\n",
      "2023-09-22 00:51:24.849380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c300 of size 256 next 1462\n",
      "2023-09-22 00:51:24.849389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c400 of size 256 next 1582\n",
      "2023-09-22 00:51:24.849398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c500 of size 256 next 326\n",
      "2023-09-22 00:51:24.849408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c600 of size 512 next 410\n",
      "2023-09-22 00:51:24.849417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972c800 of size 512 next 1287\n",
      "2023-09-22 00:51:24.849426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972ca00 of size 512 next 1706\n",
      "2023-09-22 00:51:24.849435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972cc00 of size 256 next 468\n",
      "2023-09-22 00:51:24.849445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972cd00 of size 256 next 164\n",
      "2023-09-22 00:51:24.849454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972ce00 of size 256 next 908\n",
      "2023-09-22 00:51:24.849463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972cf00 of size 256 next 1106\n",
      "2023-09-22 00:51:24.849472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972d000 of size 6912 next 1594\n",
      "2023-09-22 00:51:24.849481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972eb00 of size 2048 next 1664\n",
      "2023-09-22 00:51:24.849490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972f300 of size 2048 next 50\n",
      "2023-09-22 00:51:24.849499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f972fb00 of size 2048 next 787\n",
      "2023-09-22 00:51:24.849508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9730300 of size 2048 next 593\n",
      "2023-09-22 00:51:24.849517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9730b00 of size 8192 next 1413\n",
      "2023-09-22 00:51:24.849527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9732b00 of size 14336 next 252\n",
      "2023-09-22 00:51:24.849536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9736300 of size 8192 next 655\n",
      "2023-09-22 00:51:24.849545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9738300 of size 9216 next 1401\n",
      "2023-09-22 00:51:24.849555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f973a700 of size 8192 next 652\n",
      "2023-09-22 00:51:24.849564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f973c700 of size 8192 next 1534\n",
      "2023-09-22 00:51:24.849574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f973e700 of size 13568 next 844\n",
      "2023-09-22 00:51:24.849583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9741c00 of size 256 next 1614\n",
      "2023-09-22 00:51:24.849593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9741d00 of size 256 next 549\n",
      "2023-09-22 00:51:24.849602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9741e00 of size 256 next 1050\n",
      "2023-09-22 00:51:24.849611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9741f00 of size 256 next 449\n",
      "2023-09-22 00:51:24.849620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9742000 of size 256 next 662\n",
      "2023-09-22 00:51:24.849629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9742100 of size 256 next 923\n",
      "2023-09-22 00:51:24.849637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9742200 of size 2048 next 1103\n",
      "2023-09-22 00:51:24.849646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9742a00 of size 1024 next 594\n",
      "2023-09-22 00:51:24.849655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9742e00 of size 2816 next 1418\n",
      "2023-09-22 00:51:24.849664: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9743900 of size 256 next 753\n",
      "2023-09-22 00:51:24.849674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9743a00 of size 256 next 241\n",
      "2023-09-22 00:51:24.849683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9743b00 of size 256 next 263\n",
      "2023-09-22 00:51:24.849692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9743c00 of size 256 next 645\n",
      "2023-09-22 00:51:24.849701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9743d00 of size 256 next 1414\n",
      "2023-09-22 00:51:24.849711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9743e00 of size 256 next 1248\n",
      "2023-09-22 00:51:24.849720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9743f00 of size 256 next 1158\n",
      "2023-09-22 00:51:24.849729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9744000 of size 256 next 1132\n",
      "2023-09-22 00:51:24.849738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9744100 of size 256 next 340\n",
      "2023-09-22 00:51:24.849748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9744200 of size 8192 next 1176\n",
      "2023-09-22 00:51:24.849758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9746200 of size 2048 next 1030\n",
      "2023-09-22 00:51:24.849767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9746a00 of size 2048 next 1181\n",
      "2023-09-22 00:51:24.849776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9747200 of size 2048 next 924\n",
      "2023-09-22 00:51:24.849786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9747a00 of size 3328 next 666\n",
      "2023-09-22 00:51:24.849795: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748700 of size 256 next 554\n",
      "2023-09-22 00:51:24.849804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748800 of size 256 next 1500\n",
      "2023-09-22 00:51:24.849813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748900 of size 256 next 143\n",
      "2023-09-22 00:51:24.849823: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748a00 of size 256 next 496\n",
      "2023-09-22 00:51:24.849832: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748b00 of size 256 next 1258\n",
      "2023-09-22 00:51:24.849841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748c00 of size 256 next 1110\n",
      "2023-09-22 00:51:24.849850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748d00 of size 256 next 555\n",
      "2023-09-22 00:51:24.849860: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748e00 of size 256 next 1047\n",
      "2023-09-22 00:51:24.849869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9748f00 of size 256 next 1336\n",
      "2023-09-22 00:51:24.849878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9749000 of size 256 next 1684\n",
      "2023-09-22 00:51:24.849888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9749100 of size 256 next 1564\n",
      "2023-09-22 00:51:24.849897: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9749200 of size 256 next 1384\n",
      "2023-09-22 00:51:24.849906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9749300 of size 1024 next 1170\n",
      "2023-09-22 00:51:24.849915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9749700 of size 2097152 next 292\n",
      "2023-09-22 00:51:24.849925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9949700 of size 2097152 next 1203\n",
      "2023-09-22 00:51:24.849934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9b49700 of size 2097152 next 1358\n",
      "2023-09-22 00:51:24.849942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9d49700 of size 2097152 next 1337\n",
      "2023-09-22 00:51:24.849951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9f49700 of size 2097152 next 1182\n",
      "2023-09-22 00:51:24.849960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa149700 of size 2714880 next 657\n",
      "2023-09-22 00:51:24.849970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0400 of size 256 next 1326\n",
      "2023-09-22 00:51:24.849979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0500 of size 2048 next 231\n",
      "2023-09-22 00:51:24.849988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0d00 of size 2048 next 223\n",
      "2023-09-22 00:51:24.849998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e1500 of size 2816 next 1491\n",
      "2023-09-22 00:51:24.850007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2000 of size 256 next 255\n",
      "2023-09-22 00:51:24.850016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2100 of size 256 next 802\n",
      "2023-09-22 00:51:24.850025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2200 of size 256 next 1038\n",
      "2023-09-22 00:51:24.850034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2300 of size 256 next 1616\n",
      "2023-09-22 00:51:24.850043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2400 of size 512 next 38\n",
      "2023-09-22 00:51:24.850053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2600 of size 512 next 1324\n",
      "2023-09-22 00:51:24.850062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2800 of size 256 next 72\n",
      "2023-09-22 00:51:24.850071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2900 of size 256 next 1280\n",
      "2023-09-22 00:51:24.850081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2a00 of size 256 next 1320\n",
      "2023-09-22 00:51:24.850090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2b00 of size 256 next 1167\n",
      "2023-09-22 00:51:24.850099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2c00 of size 256 next 1508\n",
      "2023-09-22 00:51:24.850107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2d00 of size 256 next 1259\n",
      "2023-09-22 00:51:24.850117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2e00 of size 256 next 1699\n",
      "2023-09-22 00:51:24.850126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2f00 of size 256 next 969\n",
      "2023-09-22 00:51:24.850135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3000 of size 256 next 1085\n",
      "2023-09-22 00:51:24.850144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3100 of size 256 next 1592\n",
      "2023-09-22 00:51:24.850153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3200 of size 256 next 1204\n",
      "2023-09-22 00:51:24.850162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3300 of size 256 next 1076\n",
      "2023-09-22 00:51:24.850172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3400 of size 6912 next 1134\n",
      "2023-09-22 00:51:24.850181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4f00 of size 9216 next 1125\n",
      "2023-09-22 00:51:24.850190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e7300 of size 9984 next 1686\n",
      "2023-09-22 00:51:24.850199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9a00 of size 256 next 541\n",
      "2023-09-22 00:51:24.850209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9b00 of size 256 next 988\n",
      "2023-09-22 00:51:24.850218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9c00 of size 256 next 715\n",
      "2023-09-22 00:51:24.850227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9d00 of size 256 next 1294\n",
      "2023-09-22 00:51:24.850237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9e00 of size 256 next 1124\n",
      "2023-09-22 00:51:24.850244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9f00 of size 256 next 1386\n",
      "2023-09-22 00:51:24.850253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea000 of size 256 next 1278\n",
      "2023-09-22 00:51:24.850262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea100 of size 256 next 964\n",
      "2023-09-22 00:51:24.850271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea200 of size 256 next 47\n",
      "2023-09-22 00:51:24.850279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea300 of size 256 next 1154\n",
      "2023-09-22 00:51:24.850287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea400 of size 256 next 460\n",
      "2023-09-22 00:51:24.850294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea500 of size 256 next 1332\n",
      "2023-09-22 00:51:24.850304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea600 of size 256 next 1441\n",
      "2023-09-22 00:51:24.850313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea700 of size 256 next 1405\n",
      "2023-09-22 00:51:24.850323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea800 of size 256 next 777\n",
      "2023-09-22 00:51:24.850332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea900 of size 256 next 298\n",
      "2023-09-22 00:51:24.850341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eaa00 of size 256 next 1469\n",
      "2023-09-22 00:51:24.850350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eab00 of size 256 next 1543\n",
      "2023-09-22 00:51:24.850360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eac00 of size 256 next 503\n",
      "2023-09-22 00:51:24.850370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ead00 of size 256 next 1610\n",
      "2023-09-22 00:51:24.850379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eae00 of size 256 next 1578\n",
      "2023-09-22 00:51:24.850388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eaf00 of size 256 next 1039\n",
      "2023-09-22 00:51:24.850398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eb000 of size 256 next 1343\n",
      "2023-09-22 00:51:24.850407: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eb100 of size 256 next 419\n",
      "2023-09-22 00:51:24.850417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eb200 of size 256 next 1525\n",
      "2023-09-22 00:51:24.850426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eb300 of size 3328 next 417\n",
      "2023-09-22 00:51:24.850436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec000 of size 256 next 1034\n",
      "2023-09-22 00:51:24.850445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec100 of size 256 next 1466\n",
      "2023-09-22 00:51:24.850455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec200 of size 256 next 341\n",
      "2023-09-22 00:51:24.850464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec300 of size 512 next 166\n",
      "2023-09-22 00:51:24.850473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec500 of size 256 next 571\n",
      "2023-09-22 00:51:24.850482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec600 of size 256 next 532\n",
      "2023-09-22 00:51:24.850491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec700 of size 256 next 392\n",
      "2023-09-22 00:51:24.850501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec800 of size 256 next 1113\n",
      "2023-09-22 00:51:24.850510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ec900 of size 256 next 1618\n",
      "2023-09-22 00:51:24.850520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3eca00 of size 3471104 next 260\n",
      "2023-09-22 00:51:24.850529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c100 of size 256 next 286\n",
      "2023-09-22 00:51:24.850538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c200 of size 256 next 1256\n",
      "2023-09-22 00:51:24.850548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c300 of size 256 next 828\n",
      "2023-09-22 00:51:24.850557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c400 of size 256 next 1307\n",
      "2023-09-22 00:51:24.850566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c500 of size 256 next 922\n",
      "2023-09-22 00:51:24.850575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c600 of size 256 next 776\n",
      "2023-09-22 00:51:24.850583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c700 of size 256 next 729\n",
      "2023-09-22 00:51:24.850590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c800 of size 256 next 119\n",
      "2023-09-22 00:51:24.850598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73c900 of size 256 next 866\n",
      "2023-09-22 00:51:24.850605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ca00 of size 256 next 472\n",
      "2023-09-22 00:51:24.850614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73cb00 of size 256 next 451\n",
      "2023-09-22 00:51:24.850624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73cc00 of size 256 next 1313\n",
      "2023-09-22 00:51:24.850633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73cd00 of size 256 next 1696\n",
      "2023-09-22 00:51:24.850643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ce00 of size 256 next 106\n",
      "2023-09-22 00:51:24.850652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73cf00 of size 512 next 490\n",
      "2023-09-22 00:51:24.850662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d100 of size 512 next 218\n",
      "2023-09-22 00:51:24.850671: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d300 of size 256 next 588\n",
      "2023-09-22 00:51:24.850681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d400 of size 256 next 636\n",
      "2023-09-22 00:51:24.850690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d500 of size 256 next 391\n",
      "2023-09-22 00:51:24.850699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d600 of size 256 next 394\n",
      "2023-09-22 00:51:24.850708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d700 of size 256 next 1137\n",
      "2023-09-22 00:51:24.850717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d800 of size 256 next 673\n",
      "2023-09-22 00:51:24.850727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73d900 of size 1024 next 1446\n",
      "2023-09-22 00:51:24.850736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73dd00 of size 9216 next 157\n",
      "2023-09-22 00:51:24.850745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa740100 of size 11264 next 1695\n",
      "2023-09-22 00:51:24.850755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa742d00 of size 8192 next 77\n",
      "2023-09-22 00:51:24.850764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa744d00 of size 13056 next 1612\n",
      "2023-09-22 00:51:24.850773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa748000 of size 2048 next 290\n",
      "2023-09-22 00:51:24.850782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa748800 of size 2560 next 833\n",
      "2023-09-22 00:51:24.850791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa749200 of size 2048 next 473\n",
      "2023-09-22 00:51:24.850800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa749a00 of size 3840 next 319\n",
      "2023-09-22 00:51:24.850810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74a900 of size 2048 next 600\n",
      "2023-09-22 00:51:24.850819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74b100 of size 1280 next 630\n",
      "2023-09-22 00:51:24.850828: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74b600 of size 256 next 997\n",
      "2023-09-22 00:51:24.850838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74b700 of size 256 next 618\n",
      "2023-09-22 00:51:24.850847: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74b800 of size 256 next 891\n",
      "2023-09-22 00:51:24.850857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74b900 of size 256 next 1517\n",
      "2023-09-22 00:51:24.850866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74ba00 of size 256 next 1254\n",
      "2023-09-22 00:51:24.850875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74bb00 of size 256 next 424\n",
      "2023-09-22 00:51:24.850883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74bc00 of size 256 next 1022\n",
      "2023-09-22 00:51:24.850892: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74bd00 of size 256 next 1518\n",
      "2023-09-22 00:51:24.850901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74be00 of size 256 next 1420\n",
      "2023-09-22 00:51:24.850910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74bf00 of size 256 next 1707\n",
      "2023-09-22 00:51:24.850919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74c000 of size 256 next 675\n",
      "2023-09-22 00:51:24.850928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74c100 of size 3108864 next 1550\n",
      "2023-09-22 00:51:24.850937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43100 of size 256 next 1551\n",
      "2023-09-22 00:51:24.850947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43200 of size 708270080 next 112\n",
      "2023-09-22 00:51:24.850958: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8a00 of size 256 next 687\n",
      "2023-09-22 00:51:24.850967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8b00 of size 256 next 812\n",
      "2023-09-22 00:51:24.850976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8c00 of size 256 next 1656\n",
      "2023-09-22 00:51:24.850985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8d00 of size 256 next 1499\n",
      "2023-09-22 00:51:24.850994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8e00 of size 256 next 86\n",
      "2023-09-22 00:51:24.851003: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8f00 of size 256 next 493\n",
      "2023-09-22 00:51:24.851013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9000 of size 81920000 next 1691\n",
      "2023-09-22 00:51:24.851022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1329bd9000 of size 20480000 next 1177\n",
      "2023-09-22 00:51:24.851031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f132af61000 of size 81920000 next 486\n",
      "2023-09-22 00:51:24.851040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f132fd81000 of size 81920000 next 1642\n",
      "2023-09-22 00:51:24.851050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1334ba1000 of size 155200000 next 10\n",
      "2023-09-22 00:51:24.851059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f133dfa3a00 of size 1263600128 next 1363\n",
      "2023-09-22 00:51:24.851069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13894b3c00 of size 655360000 next 900\n",
      "2023-09-22 00:51:24.851078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13b05b3c00 of size 655360000 next 1677\n",
      "2023-09-22 00:51:24.851087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13d76b3c00 of size 655360000 next 1151\n",
      "2023-09-22 00:51:24.851096: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13fe7b3c00 of size 655360000 next 1529\n",
      "2023-09-22 00:51:24.851106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f14258b3c00 of size 241092864 next 1130\n",
      "2023-09-22 00:51:24.851115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1433ea0500 of size 8192 next 740\n",
      "2023-09-22 00:51:24.851124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1433ea2500 of size 8192 next 1365\n",
      "2023-09-22 00:51:24.851133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1433ea4500 of size 655360000 next 1370\n",
      "2023-09-22 00:51:24.851162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f145afa4500 of size 655360000 next 1527\n",
      "2023-09-22 00:51:24.851173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14820a4500 of size 655360000 next 1495\n",
      "2023-09-22 00:51:24.851183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14a91a4500 of size 655360000 next 1060\n",
      "2023-09-22 00:51:24.851194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f14d02a4500 of size 578560000 next 1703\n",
      "2023-09-22 00:51:24.851202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14f2a66500 of size 3200000000 next 576\n",
      "2023-09-22 00:51:24.851211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15b1628500 of size 3200000000 next 1487\n",
      "2023-09-22 00:51:24.851221: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16701ea500 of size 3200000000 next 647\n",
      "2023-09-22 00:51:24.851232: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f172edac500 of size 191970048 next 18446744073709551615\n",
      "2023-09-22 00:51:24.851241: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-09-22 00:51:24.851256: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 534 Chunks of size 256 totalling 133.5KiB\n",
      "2023-09-22 00:51:24.851267: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 44 Chunks of size 512 totalling 22.0KiB\n",
      "2023-09-22 00:51:24.851277: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 768 totalling 768B\n",
      "2023-09-22 00:51:24.851287: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 62 Chunks of size 1024 totalling 62.0KiB\n",
      "2023-09-22 00:51:24.851298: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 1280 totalling 3.8KiB\n",
      "2023-09-22 00:51:24.851308: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1536 totalling 1.5KiB\n",
      "2023-09-22 00:51:24.851318: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2023-09-22 00:51:24.851329: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 89 Chunks of size 2048 totalling 178.0KiB\n",
      "2023-09-22 00:51:24.851339: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 2560 totalling 10.0KiB\n",
      "2023-09-22 00:51:24.851349: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 2816 totalling 13.8KiB\n",
      "2023-09-22 00:51:24.851360: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 3072 totalling 9.0KiB\n",
      "2023-09-22 00:51:24.851370: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 3328 totalling 9.8KiB\n",
      "2023-09-22 00:51:24.851380: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2023-09-22 00:51:24.851390: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 3840 totalling 7.5KiB\n",
      "2023-09-22 00:51:24.851401: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 6912 totalling 33.8KiB\n",
      "2023-09-22 00:51:24.851411: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 63 Chunks of size 8192 totalling 504.0KiB\n",
      "2023-09-22 00:51:24.851422: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 20 Chunks of size 9216 totalling 180.0KiB\n",
      "2023-09-22 00:51:24.851432: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9472 totalling 9.2KiB\n",
      "2023-09-22 00:51:24.851443: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 9728 totalling 19.0KiB\n",
      "2023-09-22 00:51:24.851453: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 9984 totalling 19.5KiB\n",
      "2023-09-22 00:51:24.851463: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 10240 totalling 30.0KiB\n",
      "2023-09-22 00:51:24.851474: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10496 totalling 10.2KiB\n",
      "2023-09-22 00:51:24.851484: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 10752 totalling 31.5KiB\n",
      "2023-09-22 00:51:24.851495: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 11264 totalling 11.0KiB\n",
      "2023-09-22 00:51:24.851505: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 11520 totalling 11.2KiB\n",
      "2023-09-22 00:51:24.851515: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 11776 totalling 11.5KiB\n",
      "2023-09-22 00:51:24.851525: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12032 totalling 11.8KiB\n",
      "2023-09-22 00:51:24.851536: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12288 totalling 12.0KiB\n",
      "2023-09-22 00:51:24.851546: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 12800 totalling 25.0KiB\n",
      "2023-09-22 00:51:24.851557: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 13056 totalling 25.5KiB\n",
      "2023-09-22 00:51:24.851567: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 13312 totalling 13.0KiB\n",
      "2023-09-22 00:51:24.851577: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 13568 totalling 13.2KiB\n",
      "2023-09-22 00:51:24.851588: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 14080 totalling 27.5KiB\n",
      "2023-09-22 00:51:24.851598: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2023-09-22 00:51:24.851608: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14592 totalling 14.2KiB\n",
      "2023-09-22 00:51:24.851618: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14848 totalling 14.5KiB\n",
      "2023-09-22 00:51:24.851629: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15360 totalling 15.0KiB\n",
      "2023-09-22 00:51:24.851639: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 20 Chunks of size 32768 totalling 640.0KiB\n",
      "2023-09-22 00:51:24.851649: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 46080 totalling 135.0KiB\n",
      "2023-09-22 00:51:24.851660: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 52736 totalling 51.5KiB\n",
      "2023-09-22 00:51:24.851670: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 64256 totalling 62.8KiB\n",
      "2023-09-22 00:51:24.851680: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 65536 totalling 128.0KiB\n",
      "2023-09-22 00:51:24.851691: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 88064 totalling 86.0KiB\n",
      "2023-09-22 00:51:24.851701: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 245760 totalling 480.0KiB\n",
      "2023-09-22 00:51:24.851711: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 320000 totalling 1.83MiB\n",
      "2023-09-22 00:51:24.851722: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 358656 totalling 350.2KiB\n",
      "2023-09-22 00:51:24.851732: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 428288 totalling 418.2KiB\n",
      "2023-09-22 00:51:24.851742: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 443136 totalling 432.8KiB\n",
      "2023-09-22 00:51:24.851753: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 24 Chunks of size 2097152 totalling 48.00MiB\n",
      "2023-09-22 00:51:24.851763: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2168320 totalling 2.07MiB\n",
      "2023-09-22 00:51:24.851773: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2188800 totalling 2.09MiB\n",
      "2023-09-22 00:51:24.851783: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2487040 totalling 2.37MiB\n",
      "2023-09-22 00:51:24.851793: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2563328 totalling 2.44MiB\n",
      "2023-09-22 00:51:24.851803: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2714880 totalling 2.59MiB\n",
      "2023-09-22 00:51:24.851813: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3104768 totalling 2.96MiB\n",
      "2023-09-22 00:51:24.851823: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3108864 totalling 2.96MiB\n",
      "2023-09-22 00:51:24.851833: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3364608 totalling 3.21MiB\n",
      "2023-09-22 00:51:24.851843: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3471104 totalling 3.31MiB\n",
      "2023-09-22 00:51:24.851854: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3640320 totalling 3.47MiB\n",
      "2023-09-22 00:51:24.851864: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3952896 totalling 3.77MiB\n",
      "2023-09-22 00:51:24.851874: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4072704 totalling 3.88MiB\n",
      "2023-09-22 00:51:24.851884: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10240000 totalling 9.77MiB\n",
      "2023-09-22 00:51:24.851895: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15360000 totalling 14.65MiB\n",
      "2023-09-22 00:51:24.851907: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 18392064 totalling 17.54MiB\n",
      "2023-09-22 00:51:24.851917: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 20480000 totalling 117.19MiB\n",
      "2023-09-22 00:51:24.851928: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 40960000 totalling 156.25MiB\n",
      "2023-09-22 00:51:24.851938: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 50201344 totalling 47.88MiB\n",
      "2023-09-22 00:51:24.851949: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 10 Chunks of size 81920000 totalling 781.25MiB\n",
      "2023-09-22 00:51:24.851959: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 81961472 totalling 78.16MiB\n",
      "2023-09-22 00:51:24.851970: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 105041920 totalling 100.18MiB\n",
      "2023-09-22 00:51:24.851981: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 133201152 totalling 127.03MiB\n",
      "2023-09-22 00:51:24.851991: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 149667584 totalling 142.73MiB\n",
      "2023-09-22 00:51:24.852002: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 155200000 totalling 148.01MiB\n",
      "2023-09-22 00:51:24.852012: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 159910912 totalling 152.50MiB\n",
      "2023-09-22 00:51:24.852022: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 12 Chunks of size 655360000 totalling 7.32GiB\n",
      "2023-09-22 00:51:24.852033: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 708270080 totalling 675.46MiB\n",
      "2023-09-22 00:51:24.852043: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1263600128 totalling 1.18GiB\n",
      "2023-09-22 00:51:24.852053: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 3200000000 totalling 8.94GiB\n",
      "2023-09-22 00:51:24.852063: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 20.04GiB\n",
      "2023-09-22 00:51:24.852073: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 23023321088 memory_limit_: 23023321088 available bytes: 0 curr_region_allocation_bytes_: 46046642176\n",
      "2023-09-22 00:51:24.852088: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     23023321088\n",
      "InUse:                     21514780672\n",
      "MaxInUse:                  21514780928\n",
      "NumAllocs:                     7559992\n",
      "MaxAllocSize:               6400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-22 00:51:24.852148: W tensorflow/tsl/framework/bfc_allocator.cc:492] **********_********************************************__*******************************************\n",
      "2023-09-22 00:51:24.852186: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at einsum_op_impl.h:598 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[64,8,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'model/multi_head_attention_2/einsum/Einsum' defined at (most recent call last):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_3386617/1959657965.py\", line 121, in <module>\n",
      "      hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3},\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 524, in _compute_attention\n",
      "      attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
      "Node: 'model/multi_head_attention_2/einsum/Einsum'\n",
      "OOM when allocating tensor with shape[64,8,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/multi_head_attention_2/einsum/Einsum}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_517159]\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt16_size11_pool4_do0.5_tra3_head2_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2916 - mean_squared_error: 0.1767\n",
      "Epoch 1: val_loss improved from inf to 0.09186, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt16_size11_pool4_do0.5_tra3_head2_kdim16_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 11s 95ms/step - loss: 0.2916 - mean_squared_error: 0.1767 - val_loss: 0.0919 - val_mean_squared_error: 0.0174\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.09186\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.1047 - mean_squared_error: 0.0210 - val_loss: 0.0983 - val_mean_squared_error: 0.0190\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0200\n",
      "Epoch 3: val_loss did not improve from 0.09186\n",
      "21/21 [==============================] - 2s 74ms/step - loss: 0.1031 - mean_squared_error: 0.0200 - val_loss: 0.0978 - val_mean_squared_error: 0.0189\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0199\n",
      "Epoch 4: val_loss did not improve from 0.09186\n",
      "21/21 [==============================] - 2s 79ms/step - loss: 0.1025 - mean_squared_error: 0.0199 - val_loss: 0.0960 - val_mean_squared_error: 0.0185\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###0 fold : val mae 0.09###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2839 - mean_squared_error: 0.1707\n",
      "Epoch 1: val_loss improved from inf to 0.08962, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt16_size11_pool4_do0.5_tra3_head2_kdim16_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 11s 96ms/step - loss: 0.2839 - mean_squared_error: 0.1707 - val_loss: 0.0896 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0221\n",
      "Epoch 2: val_loss did not improve from 0.08962\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.1073 - mean_squared_error: 0.0221 - val_loss: 0.0954 - val_mean_squared_error: 0.0182\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0201\n",
      "Epoch 3: val_loss did not improve from 0.08962\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 0.1035 - mean_squared_error: 0.0201 - val_loss: 0.0945 - val_mean_squared_error: 0.0180\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss did not improve from 0.08962\n",
      "21/21 [==============================] - 2s 78ms/step - loss: 0.1045 - mean_squared_error: 0.0206 - val_loss: 0.0924 - val_mean_squared_error: 0.0175\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###1 fold : val mae 0.10###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2840 - mean_squared_error: 0.1704\n",
      "Epoch 1: val_loss improved from inf to 0.08726, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt16_size11_pool4_do0.5_tra3_head2_kdim16_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 13s 96ms/step - loss: 0.2840 - mean_squared_error: 0.1704 - val_loss: 0.0873 - val_mean_squared_error: 0.0163\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0214\n",
      "Epoch 2: val_loss did not improve from 0.08726\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.1066 - mean_squared_error: 0.0214 - val_loss: 0.0942 - val_mean_squared_error: 0.0179\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.08726\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.1055 - mean_squared_error: 0.0209 - val_loss: 0.0941 - val_mean_squared_error: 0.0179\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss did not improve from 0.08726\n",
      "21/21 [==============================] - 2s 79ms/step - loss: 0.1043 - mean_squared_error: 0.0206 - val_loss: 0.0920 - val_mean_squared_error: 0.0174\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###2 fold : val mae 0.09###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2829 - mean_squared_error: 0.1682\n",
      "Epoch 1: val_loss improved from inf to 0.08845, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt16_size11_pool4_do0.5_tra3_head2_kdim16_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 11s 95ms/step - loss: 0.2829 - mean_squared_error: 0.1682 - val_loss: 0.0885 - val_mean_squared_error: 0.0167\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.08845\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.1056 - mean_squared_error: 0.0211 - val_loss: 0.0941 - val_mean_squared_error: 0.0180\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.08845\n",
      "21/21 [==============================] - 1s 71ms/step - loss: 0.1046 - mean_squared_error: 0.0207 - val_loss: 0.0936 - val_mean_squared_error: 0.0179\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0204\n",
      "Epoch 4: val_loss did not improve from 0.08845\n",
      "21/21 [==============================] - 2s 79ms/step - loss: 0.1043 - mean_squared_error: 0.0204 - val_loss: 0.0911 - val_mean_squared_error: 0.0174\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###3 fold : val mae 0.09###\n",
      "mae1.89+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1390 - mean_squared_error: 0.0505\n",
      "Epoch 1: val_loss improved from inf to 0.10991, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 23s 224ms/step - loss: 0.1390 - mean_squared_error: 0.0505 - val_loss: 0.1099 - val_mean_squared_error: 0.0216\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0205\n",
      "Epoch 2: val_loss did not improve from 0.10991\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.1060 - mean_squared_error: 0.0205 - val_loss: 0.1099 - val_mean_squared_error: 0.0216\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.10991 to 0.10984, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 8s 201ms/step - loss: 0.1063 - mean_squared_error: 0.0207 - val_loss: 0.1098 - val_mean_squared_error: 0.0216\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0208\n",
      "Epoch 4: val_loss improved from 0.10984 to 0.10978, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 8s 202ms/step - loss: 0.1063 - mean_squared_error: 0.0207 - val_loss: 0.1098 - val_mean_squared_error: 0.0216\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0208\n",
      "Epoch 5: val_loss improved from 0.10978 to 0.10964, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 9s 216ms/step - loss: 0.1064 - mean_squared_error: 0.0208 - val_loss: 0.1096 - val_mean_squared_error: 0.0216\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0206\n",
      "Epoch 6: val_loss improved from 0.10964 to 0.10884, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 8s 202ms/step - loss: 0.1060 - mean_squared_error: 0.0206 - val_loss: 0.1088 - val_mean_squared_error: 0.0214\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10884 to 0.10862, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 0.1063 - mean_squared_error: 0.0209 - val_loss: 0.1086 - val_mean_squared_error: 0.0213\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0207\n",
      "Epoch 8: val_loss improved from 0.10862 to 0.10773, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 0.1059 - mean_squared_error: 0.0206 - val_loss: 0.1077 - val_mean_squared_error: 0.0212\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1058 - mean_squared_error: 0.0205\n",
      "Epoch 9: val_loss improved from 0.10773 to 0.10564, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1057 - mean_squared_error: 0.0205 - val_loss: 0.1056 - val_mean_squared_error: 0.0207\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0209\n",
      "Epoch 10: val_loss improved from 0.10564 to 0.10283, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 9s 217ms/step - loss: 0.1059 - mean_squared_error: 0.0209 - val_loss: 0.1028 - val_mean_squared_error: 0.0201\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0203\n",
      "Epoch 11: val_loss improved from 0.10283 to 0.09037, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 0.1042 - mean_squared_error: 0.0203 - val_loss: 0.0904 - val_mean_squared_error: 0.0170\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0199\n",
      "Epoch 12: val_loss improved from 0.09037 to 0.08021, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1027 - mean_squared_error: 0.0199 - val_loss: 0.0802 - val_mean_squared_error: 0.0136\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0975 - mean_squared_error: 0.0182\n",
      "Epoch 13: val_loss did not improve from 0.08021\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.0975 - mean_squared_error: 0.0182 - val_loss: 0.0828 - val_mean_squared_error: 0.0096\n",
      "Epoch 14/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0916 - mean_squared_error: 0.0162\n",
      "Epoch 14: val_loss did not improve from 0.08021\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.0916 - mean_squared_error: 0.0162 - val_loss: 0.1093 - val_mean_squared_error: 0.0140\n",
      "Epoch 15/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0874 - mean_squared_error: 0.0146\n",
      "Epoch 15: val_loss did not improve from 0.08021\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.0875 - mean_squared_error: 0.0146 - val_loss: 0.1326 - val_mean_squared_error: 0.0221\n",
      "55/55 [==============================] - 2s 22ms/step\n",
      " ###0 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1406 - mean_squared_error: 0.0510\n",
      "Epoch 1: val_loss improved from inf to 0.10678, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 22s 235ms/step - loss: 0.1406 - mean_squared_error: 0.0510 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10678 to 0.10670, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 8s 203ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10670 to 0.10669, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10669\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0211\n",
      "Epoch 5: val_loss improved from 0.10669 to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1073 - mean_squared_error: 0.0211 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss improved from 0.10639 to 0.10625, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 216ms/step - loss: 0.1070 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0206\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10625 to 0.10599, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 0.1072 - mean_squared_error: 0.0210 - val_loss: 0.1060 - val_mean_squared_error: 0.0206\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0211\n",
      "Epoch 8: val_loss did not improve from 0.10599\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.1071 - mean_squared_error: 0.0210 - val_loss: 0.1060 - val_mean_squared_error: 0.0206\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0208\n",
      "Epoch 9: val_loss improved from 0.10599 to 0.10542, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1068 - mean_squared_error: 0.0208 - val_loss: 0.1054 - val_mean_squared_error: 0.0205\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0207\n",
      "Epoch 10: val_loss improved from 0.10542 to 0.10068, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1059 - mean_squared_error: 0.0207 - val_loss: 0.1007 - val_mean_squared_error: 0.0194\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0208\n",
      "Epoch 11: val_loss improved from 0.10068 to 0.08947, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 0.1055 - mean_squared_error: 0.0208 - val_loss: 0.0895 - val_mean_squared_error: 0.0168\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0206\n",
      "Epoch 12: val_loss improved from 0.08947 to 0.08090, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.1043 - mean_squared_error: 0.0206 - val_loss: 0.0809 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1000 - mean_squared_error: 0.0189\n",
      "Epoch 13: val_loss improved from 0.08090 to 0.07598, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1001 - mean_squared_error: 0.0189 - val_loss: 0.0760 - val_mean_squared_error: 0.0103\n",
      "Epoch 14/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.0179\n",
      "Epoch 14: val_loss did not improve from 0.07598\n",
      "42/42 [==============================] - 8s 201ms/step - loss: 0.0959 - mean_squared_error: 0.0179 - val_loss: 0.0965 - val_mean_squared_error: 0.0109\n",
      "Epoch 15/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0913 - mean_squared_error: 0.0160\n",
      "Epoch 15: val_loss did not improve from 0.07598\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.0912 - mean_squared_error: 0.0160 - val_loss: 0.1207 - val_mean_squared_error: 0.0176\n",
      "Epoch 16/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0884 - mean_squared_error: 0.0149\n",
      "Epoch 16: val_loss did not improve from 0.07598\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.0884 - mean_squared_error: 0.0149 - val_loss: 0.1402 - val_mean_squared_error: 0.0248\n",
      "55/55 [==============================] - 3s 22ms/step\n",
      " ###1 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1401 - mean_squared_error: 0.0509\n",
      "Epoch 1: val_loss improved from inf to 0.10552, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 23s 236ms/step - loss: 0.1400 - mean_squared_error: 0.0508 - val_loss: 0.1055 - val_mean_squared_error: 0.0203\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.10552 to 0.10530, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 8s 203ms/step - loss: 0.1075 - mean_squared_error: 0.0211 - val_loss: 0.1053 - val_mean_squared_error: 0.0203\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss improved from 0.10530 to 0.10508, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 8s 203ms/step - loss: 0.1075 - mean_squared_error: 0.0211 - val_loss: 0.1051 - val_mean_squared_error: 0.0202\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10508 to 0.10429, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 9s 216ms/step - loss: 0.1070 - mean_squared_error: 0.0209 - val_loss: 0.1043 - val_mean_squared_error: 0.0201\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10429 to 0.09446, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1070 - mean_squared_error: 0.0210 - val_loss: 0.0945 - val_mean_squared_error: 0.0180\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss did not improve from 0.09446\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 0.1068 - mean_squared_error: 0.0210 - val_loss: 0.1022 - val_mean_squared_error: 0.0196\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0212\n",
      "Epoch 7: val_loss improved from 0.09446 to 0.08890, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 0.1070 - mean_squared_error: 0.0212 - val_loss: 0.0889 - val_mean_squared_error: 0.0167\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0210\n",
      "Epoch 8: val_loss improved from 0.08890 to 0.08678, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1060 - mean_squared_error: 0.0210 - val_loss: 0.0868 - val_mean_squared_error: 0.0162\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0201\n",
      "Epoch 9: val_loss improved from 0.08678 to 0.07603, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 9s 218ms/step - loss: 0.1035 - mean_squared_error: 0.0200 - val_loss: 0.0760 - val_mean_squared_error: 0.0124\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0195\n",
      "Epoch 10: val_loss did not improve from 0.07603\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.1014 - mean_squared_error: 0.0195 - val_loss: 0.0770 - val_mean_squared_error: 0.0097\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0980 - mean_squared_error: 0.0184\n",
      "Epoch 11: val_loss did not improve from 0.07603\n",
      "42/42 [==============================] - 8s 201ms/step - loss: 0.0980 - mean_squared_error: 0.0184 - val_loss: 0.0951 - val_mean_squared_error: 0.0105\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.0164\n",
      "Epoch 12: val_loss did not improve from 0.07603\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 0.0926 - mean_squared_error: 0.0164 - val_loss: 0.1125 - val_mean_squared_error: 0.0149\n",
      "55/55 [==============================] - 2s 21ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1382 - mean_squared_error: 0.0489\n",
      "Epoch 1: val_loss improved from inf to 0.10624, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 23s 237ms/step - loss: 0.1382 - mean_squared_error: 0.0488 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10624 to 0.10620, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 8s 203ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10620 to 0.10617, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.10617 to 0.10601, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1060 - val_mean_squared_error: 0.0207\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0211\n",
      "Epoch 5: val_loss improved from 0.10601 to 0.10590, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0206\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0211\n",
      "Epoch 6: val_loss improved from 0.10590 to 0.10479, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 213ms/step - loss: 0.1074 - mean_squared_error: 0.0211 - val_loss: 0.1048 - val_mean_squared_error: 0.0204\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0208\n",
      "Epoch 7: val_loss improved from 0.10479 to 0.10316, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1069 - mean_squared_error: 0.0208 - val_loss: 0.1032 - val_mean_squared_error: 0.0201\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0209\n",
      "Epoch 8: val_loss improved from 0.10316 to 0.10137, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1070 - mean_squared_error: 0.0210 - val_loss: 0.1014 - val_mean_squared_error: 0.0197\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0210\n",
      "Epoch 9: val_loss improved from 0.10137 to 0.08544, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 0.1066 - mean_squared_error: 0.0210 - val_loss: 0.0854 - val_mean_squared_error: 0.0159\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0213\n",
      "Epoch 10: val_loss improved from 0.08544 to 0.08010, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size15_pool2_do0.5_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.1058 - mean_squared_error: 0.0212 - val_loss: 0.0801 - val_mean_squared_error: 0.0143\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0195\n",
      "Epoch 11: val_loss did not improve from 0.08010\n",
      "42/42 [==============================] - 9s 212ms/step - loss: 0.1016 - mean_squared_error: 0.0195 - val_loss: 0.0818 - val_mean_squared_error: 0.0094\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0964 - mean_squared_error: 0.0178\n",
      "Epoch 12: val_loss did not improve from 0.08010\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.0963 - mean_squared_error: 0.0177 - val_loss: 0.1000 - val_mean_squared_error: 0.0116\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0920 - mean_squared_error: 0.0162\n",
      "Epoch 13: val_loss did not improve from 0.08010\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 0.0921 - mean_squared_error: 0.0162 - val_loss: 0.1307 - val_mean_squared_error: 0.0209\n",
      "55/55 [==============================] - 2s 22ms/step\n",
      " ###3 fold : val mae 0.09###\n",
      "mae1.64+-0.05\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size15_pool4_do0.1_tra3_head8_kdim256_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0207\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size15_pool4_do0.1_tra3_head8_kdim256_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 13s 46ms/step - loss: 0.1063 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size15_pool4_do0.1_tra3_head8_kdim256_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 13s 46ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0212\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size15_pool4_do0.1_tra3_head8_kdim256_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 15s 51ms/step - loss: 0.1079 - mean_squared_error: 0.0212 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size15_pool4_do0.1_tra3_head8_kdim256_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 13s 52ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1167 - mean_squared_error: 0.0270\n",
      "Epoch 1: val_loss improved from inf to 0.10841, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 17s 186ms/step - loss: 0.1167 - mean_squared_error: 0.0270 - val_loss: 0.1084 - val_mean_squared_error: 0.0213\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0925 - mean_squared_error: 0.0166\n",
      "Epoch 2: val_loss did not improve from 0.10841\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.0925 - mean_squared_error: 0.0166 - val_loss: 0.1167 - val_mean_squared_error: 0.0164\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.0128\n",
      "Epoch 3: val_loss improved from 0.10841 to 0.10166, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 3s 147ms/step - loss: 0.0819 - mean_squared_error: 0.0128 - val_loss: 0.1017 - val_mean_squared_error: 0.0121\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0743 - mean_squared_error: 0.0109\n",
      "Epoch 4: val_loss improved from 0.10166 to 0.05630, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0743 - mean_squared_error: 0.0109 - val_loss: 0.0563 - val_mean_squared_error: 0.0061\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0562 - mean_squared_error: 0.0068\n",
      "Epoch 5: val_loss did not improve from 0.05630\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.0562 - mean_squared_error: 0.0068 - val_loss: 0.0657 - val_mean_squared_error: 0.0079\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0485 - mean_squared_error: 0.0053\n",
      "Epoch 6: val_loss did not improve from 0.05630\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0485 - mean_squared_error: 0.0053 - val_loss: 0.0703 - val_mean_squared_error: 0.0073\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0045\n",
      "Epoch 7: val_loss improved from 0.05630 to 0.05594, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 3s 169ms/step - loss: 0.0442 - mean_squared_error: 0.0045 - val_loss: 0.0559 - val_mean_squared_error: 0.0054\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0040\n",
      "Epoch 8: val_loss improved from 0.05594 to 0.05243, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0421 - mean_squared_error: 0.0040 - val_loss: 0.0524 - val_mean_squared_error: 0.0043\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0035\n",
      "Epoch 9: val_loss improved from 0.05243 to 0.04883, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0382 - mean_squared_error: 0.0035 - val_loss: 0.0488 - val_mean_squared_error: 0.0040\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0032\n",
      "Epoch 10: val_loss did not improve from 0.04883\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.0362 - mean_squared_error: 0.0032 - val_loss: 0.0828 - val_mean_squared_error: 0.0100\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0031\n",
      "Epoch 11: val_loss did not improve from 0.04883\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0366 - mean_squared_error: 0.0031 - val_loss: 0.0542 - val_mean_squared_error: 0.0054\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0030\n",
      "Epoch 12: val_loss did not improve from 0.04883\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0352 - mean_squared_error: 0.0030 - val_loss: 0.0741 - val_mean_squared_error: 0.0074\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1182 - mean_squared_error: 0.0280\n",
      "Epoch 1: val_loss improved from inf to 0.10524, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 16s 200ms/step - loss: 0.1182 - mean_squared_error: 0.0280 - val_loss: 0.1052 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0924 - mean_squared_error: 0.0167\n",
      "Epoch 2: val_loss did not improve from 0.10524\n",
      "21/21 [==============================] - 3s 141ms/step - loss: 0.0924 - mean_squared_error: 0.0167 - val_loss: 0.1056 - val_mean_squared_error: 0.0130\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0827 - mean_squared_error: 0.0131\n",
      "Epoch 3: val_loss did not improve from 0.10524\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0827 - mean_squared_error: 0.0131 - val_loss: 0.1135 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0798 - mean_squared_error: 0.0122\n",
      "Epoch 4: val_loss improved from 0.10524 to 0.09348, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 139ms/step - loss: 0.0798 - mean_squared_error: 0.0122 - val_loss: 0.0935 - val_mean_squared_error: 0.0103\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0712 - mean_squared_error: 0.0100\n",
      "Epoch 5: val_loss improved from 0.09348 to 0.06693, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 140ms/step - loss: 0.0712 - mean_squared_error: 0.0100 - val_loss: 0.0669 - val_mean_squared_error: 0.0077\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.0058\n",
      "Epoch 6: val_loss improved from 0.06693 to 0.05166, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 139ms/step - loss: 0.0515 - mean_squared_error: 0.0058 - val_loss: 0.0517 - val_mean_squared_error: 0.0042\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0495 - mean_squared_error: 0.0054\n",
      "Epoch 7: val_loss did not improve from 0.05166\n",
      "21/21 [==============================] - 3s 144ms/step - loss: 0.0495 - mean_squared_error: 0.0054 - val_loss: 0.1016 - val_mean_squared_error: 0.0150\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0044\n",
      "Epoch 8: val_loss did not improve from 0.05166\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0442 - mean_squared_error: 0.0044 - val_loss: 0.0886 - val_mean_squared_error: 0.0125\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0035\n",
      "Epoch 9: val_loss did not improve from 0.05166\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0391 - mean_squared_error: 0.0035 - val_loss: 0.1045 - val_mean_squared_error: 0.0155\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###1 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1172 - mean_squared_error: 0.0273\n",
      "Epoch 1: val_loss improved from inf to 0.10371, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 17s 196ms/step - loss: 0.1172 - mean_squared_error: 0.0273 - val_loss: 0.1037 - val_mean_squared_error: 0.0200\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0925 - mean_squared_error: 0.0166\n",
      "Epoch 2: val_loss did not improve from 0.10371\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 0.0925 - mean_squared_error: 0.0166 - val_loss: 0.1318 - val_mean_squared_error: 0.0218\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0817 - mean_squared_error: 0.0127\n",
      "Epoch 3: val_loss improved from 0.10371 to 0.08581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 163ms/step - loss: 0.0817 - mean_squared_error: 0.0127 - val_loss: 0.0858 - val_mean_squared_error: 0.0088\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0695 - mean_squared_error: 0.0098\n",
      "Epoch 4: val_loss improved from 0.08581 to 0.05338, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0695 - mean_squared_error: 0.0098 - val_loss: 0.0534 - val_mean_squared_error: 0.0056\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.0070\n",
      "Epoch 5: val_loss improved from 0.05338 to 0.04446, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.0570 - mean_squared_error: 0.0070 - val_loss: 0.0445 - val_mean_squared_error: 0.0040\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0053\n",
      "Epoch 6: val_loss improved from 0.04446 to 0.04317, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0489 - mean_squared_error: 0.0053 - val_loss: 0.0432 - val_mean_squared_error: 0.0033\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0042\n",
      "Epoch 7: val_loss did not improve from 0.04317\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 0.0428 - mean_squared_error: 0.0042 - val_loss: 0.0498 - val_mean_squared_error: 0.0045\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0428 - mean_squared_error: 0.0042\n",
      "Epoch 8: val_loss did not improve from 0.04317\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0428 - mean_squared_error: 0.0042 - val_loss: 0.0470 - val_mean_squared_error: 0.0039\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0035\n",
      "Epoch 9: val_loss did not improve from 0.04317\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0387 - mean_squared_error: 0.0035 - val_loss: 0.0447 - val_mean_squared_error: 0.0039\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###2 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1181 - mean_squared_error: 0.0276\n",
      "Epoch 1: val_loss improved from inf to 0.10503, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 17s 191ms/step - loss: 0.1181 - mean_squared_error: 0.0276 - val_loss: 0.1050 - val_mean_squared_error: 0.0205\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0955 - mean_squared_error: 0.0174\n",
      "Epoch 2: val_loss improved from 0.10503 to 0.08660, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 0.0955 - mean_squared_error: 0.0174 - val_loss: 0.0866 - val_mean_squared_error: 0.0095\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0825 - mean_squared_error: 0.0130\n",
      "Epoch 3: val_loss did not improve from 0.08660\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 0.0825 - mean_squared_error: 0.0130 - val_loss: 0.0955 - val_mean_squared_error: 0.0107\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0793 - mean_squared_error: 0.0122\n",
      "Epoch 4: val_loss improved from 0.08660 to 0.07842, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 167ms/step - loss: 0.0793 - mean_squared_error: 0.0122 - val_loss: 0.0784 - val_mean_squared_error: 0.0080\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0634 - mean_squared_error: 0.0082\n",
      "Epoch 5: val_loss improved from 0.07842 to 0.07064, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0634 - mean_squared_error: 0.0082 - val_loss: 0.0706 - val_mean_squared_error: 0.0096\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.0055\n",
      "Epoch 6: val_loss did not improve from 0.07064\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.0492 - mean_squared_error: 0.0055 - val_loss: 0.0901 - val_mean_squared_error: 0.0113\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0462 - mean_squared_error: 0.0048\n",
      "Epoch 7: val_loss did not improve from 0.07064\n",
      "21/21 [==============================] - 3s 161ms/step - loss: 0.0462 - mean_squared_error: 0.0048 - val_loss: 0.0798 - val_mean_squared_error: 0.0103\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0042\n",
      "Epoch 8: val_loss improved from 0.07064 to 0.06618, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 167ms/step - loss: 0.0429 - mean_squared_error: 0.0042 - val_loss: 0.0662 - val_mean_squared_error: 0.0076\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0036\n",
      "Epoch 9: val_loss did not improve from 0.06618\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.0392 - mean_squared_error: 0.0036 - val_loss: 0.0814 - val_mean_squared_error: 0.0103\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0034\n",
      "Epoch 10: val_loss improved from 0.06618 to 0.03956, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt64_size5_pool4_do0.1_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 168ms/step - loss: 0.0375 - mean_squared_error: 0.0034 - val_loss: 0.0396 - val_mean_squared_error: 0.0035\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0032\n",
      "Epoch 11: val_loss did not improve from 0.03956\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.0365 - mean_squared_error: 0.0032 - val_loss: 0.0512 - val_mean_squared_error: 0.0053\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0030\n",
      "Epoch 12: val_loss did not improve from 0.03956\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0352 - mean_squared_error: 0.0030 - val_loss: 0.0574 - val_mean_squared_error: 0.0066\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0028\n",
      "Epoch 13: val_loss did not improve from 0.03956\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.0338 - mean_squared_error: 0.0028 - val_loss: 0.0955 - val_mean_squared_error: 0.0146\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###3 fold : val mae 0.04###\n",
      "mae0.94+-0.09\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra4_head2_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 1: val_loss improved from inf to 0.09373, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra4_head2_kdim128_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 14s 52ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.0937 - val_mean_squared_error: 0.0179\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0930 - mean_squared_error: 0.0168\n",
      "Epoch 2: val_loss did not improve from 0.09373\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0931 - mean_squared_error: 0.0168 - val_loss: 0.7923 - val_mean_squared_error: 0.6372\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0821 - mean_squared_error: 0.0130\n",
      "Epoch 3: val_loss did not improve from 0.09373\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0821 - mean_squared_error: 0.0130 - val_loss: 0.7693 - val_mean_squared_error: 0.6012\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0665 - mean_squared_error: 0.0089\n",
      "Epoch 4: val_loss did not improve from 0.09373\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0665 - mean_squared_error: 0.0089 - val_loss: 0.8505 - val_mean_squared_error: 0.7312\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###0 fold : val mae 0.10###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0962 - mean_squared_error: 0.0177\n",
      "Epoch 1: val_loss improved from inf to 0.40990, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra4_head2_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 15s 67ms/step - loss: 0.0962 - mean_squared_error: 0.0177 - val_loss: 0.4099 - val_mean_squared_error: 0.1752\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0671 - mean_squared_error: 0.0093\n",
      "Epoch 2: val_loss did not improve from 0.40990\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0671 - mean_squared_error: 0.0093 - val_loss: 0.5750 - val_mean_squared_error: 0.3508\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0540 - mean_squared_error: 0.0063\n",
      "Epoch 3: val_loss did not improve from 0.40990\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0540 - mean_squared_error: 0.0063 - val_loss: 0.5824 - val_mean_squared_error: 0.3550\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.0050\n",
      "Epoch 4: val_loss did not improve from 0.40990\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0479 - mean_squared_error: 0.0050 - val_loss: 0.6584 - val_mean_squared_error: 0.4409\n",
      "55/55 [==============================] - 2s 9ms/step\n",
      " ###1 fold : val mae 0.40###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1138 - mean_squared_error: 0.0262\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra4_head2_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 15s 49ms/step - loss: 0.1138 - mean_squared_error: 0.0262 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra4_head2_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 14s 49ms/step - loss: 0.1076 - mean_squared_error: 0.0209 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae3.64+-2.58\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1186 - mean_squared_error: 0.0313\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 15s 86ms/step - loss: 0.1186 - mean_squared_error: 0.0313 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11004\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss did not improve from 0.11004\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1182 - mean_squared_error: 0.0305\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 14s 76ms/step - loss: 0.1182 - mean_squared_error: 0.0305 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 69ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 7: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0242\n",
      "Epoch 8: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.1119 - mean_squared_error: 0.0242 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 9: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 10: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 69ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 11: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 12: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 13: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1184 - mean_squared_error: 0.0304\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 16s 75ms/step - loss: 0.1185 - mean_squared_error: 0.0305 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1188 - mean_squared_error: 0.0309\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt32_size11_pool5_do0.2_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 14s 72ms/step - loss: 0.1188 - mean_squared_error: 0.0309 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0957 - mean_squared_error: 0.0236\n",
      "Epoch 1: val_loss improved from inf to 0.10428, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 13s 39ms/step - loss: 0.0957 - mean_squared_error: 0.0236 - val_loss: 0.1043 - val_mean_squared_error: 0.0198\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.0063\n",
      "Epoch 2: val_loss improved from 0.10428 to 0.06652, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 0.0541 - mean_squared_error: 0.0063 - val_loss: 0.0665 - val_mean_squared_error: 0.0084\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0046\n",
      "Epoch 3: val_loss improved from 0.06652 to 0.03982, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0445 - mean_squared_error: 0.0046 - val_loss: 0.0398 - val_mean_squared_error: 0.0036\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0041\n",
      "Epoch 4: val_loss did not improve from 0.03982\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0424 - mean_squared_error: 0.0041 - val_loss: 0.0420 - val_mean_squared_error: 0.0038\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0037\n",
      "Epoch 5: val_loss did not improve from 0.03982\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0397 - mean_squared_error: 0.0037 - val_loss: 0.0444 - val_mean_squared_error: 0.0035\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0034\n",
      "Epoch 6: val_loss did not improve from 0.03982\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0383 - mean_squared_error: 0.0034 - val_loss: 0.0412 - val_mean_squared_error: 0.0039\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###0 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0232\n",
      "Epoch 1: val_loss improved from inf to 0.10223, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 12s 41ms/step - loss: 0.0953 - mean_squared_error: 0.0232 - val_loss: 0.1022 - val_mean_squared_error: 0.0194\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0536 - mean_squared_error: 0.0062\n",
      "Epoch 2: val_loss improved from 0.10223 to 0.04254, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0536 - mean_squared_error: 0.0062 - val_loss: 0.0425 - val_mean_squared_error: 0.0039\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0432 - mean_squared_error: 0.0043\n",
      "Epoch 3: val_loss improved from 0.04254 to 0.03729, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 0.0432 - mean_squared_error: 0.0043 - val_loss: 0.0373 - val_mean_squared_error: 0.0034\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0418 - mean_squared_error: 0.0040\n",
      "Epoch 4: val_loss did not improve from 0.03729\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0418 - mean_squared_error: 0.0040 - val_loss: 0.0592 - val_mean_squared_error: 0.0072\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0036\n",
      "Epoch 5: val_loss improved from 0.03729 to 0.03673, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0391 - mean_squared_error: 0.0036 - val_loss: 0.0367 - val_mean_squared_error: 0.0035\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0033\n",
      "Epoch 6: val_loss did not improve from 0.03673\n",
      "83/83 [==============================] - 3s 30ms/step - loss: 0.0376 - mean_squared_error: 0.0033 - val_loss: 0.0375 - val_mean_squared_error: 0.0033\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0032\n",
      "Epoch 7: val_loss improved from 0.03673 to 0.03650, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0371 - mean_squared_error: 0.0032 - val_loss: 0.0365 - val_mean_squared_error: 0.0033\n",
      "Epoch 8/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0031\n",
      "Epoch 8: val_loss improved from 0.03650 to 0.03441, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0361 - mean_squared_error: 0.0031 - val_loss: 0.0344 - val_mean_squared_error: 0.0028\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0342 - mean_squared_error: 0.0029\n",
      "Epoch 9: val_loss did not improve from 0.03441\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0342 - mean_squared_error: 0.0029 - val_loss: 0.0368 - val_mean_squared_error: 0.0035\n",
      "Epoch 10/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0027\n",
      "Epoch 10: val_loss did not improve from 0.03441\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0334 - mean_squared_error: 0.0027 - val_loss: 0.0448 - val_mean_squared_error: 0.0048\n",
      "Epoch 11/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0027\n",
      "Epoch 11: val_loss did not improve from 0.03441\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0337 - mean_squared_error: 0.0027 - val_loss: 0.0347 - val_mean_squared_error: 0.0029\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###1 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.1123 - mean_squared_error: 0.0280\n",
      "Epoch 1: val_loss improved from inf to 0.09742, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 15s 47ms/step - loss: 0.1119 - mean_squared_error: 0.0278 - val_loss: 0.0974 - val_mean_squared_error: 0.0186\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0840 - mean_squared_error: 0.0136\n",
      "Epoch 2: val_loss improved from 0.09742 to 0.08457, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0840 - mean_squared_error: 0.0136 - val_loss: 0.0846 - val_mean_squared_error: 0.0156\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0637 - mean_squared_error: 0.0085\n",
      "Epoch 3: val_loss improved from 0.08457 to 0.05062, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0637 - mean_squared_error: 0.0085 - val_loss: 0.0506 - val_mean_squared_error: 0.0056\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.0054\n",
      "Epoch 4: val_loss improved from 0.05062 to 0.03456, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0492 - mean_squared_error: 0.0054 - val_loss: 0.0346 - val_mean_squared_error: 0.0031\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0038\n",
      "Epoch 5: val_loss did not improve from 0.03456\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0407 - mean_squared_error: 0.0038 - val_loss: 0.0373 - val_mean_squared_error: 0.0034\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0037\n",
      "Epoch 6: val_loss did not improve from 0.03456\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0401 - mean_squared_error: 0.0037 - val_loss: 0.0395 - val_mean_squared_error: 0.0039\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0036\n",
      "Epoch 7: val_loss did not improve from 0.03456\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0388 - mean_squared_error: 0.0036 - val_loss: 0.0376 - val_mean_squared_error: 0.0034\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###2 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0950 - mean_squared_error: 0.0227\n",
      "Epoch 1: val_loss improved from inf to 0.07363, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 13s 44ms/step - loss: 0.0948 - mean_squared_error: 0.0226 - val_loss: 0.0736 - val_mean_squared_error: 0.0109\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0556 - mean_squared_error: 0.0066\n",
      "Epoch 2: val_loss improved from 0.07363 to 0.06000, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0555 - mean_squared_error: 0.0066 - val_loss: 0.0600 - val_mean_squared_error: 0.0075\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0468 - mean_squared_error: 0.0049\n",
      "Epoch 3: val_loss improved from 0.06000 to 0.05149, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0468 - mean_squared_error: 0.0049 - val_loss: 0.0515 - val_mean_squared_error: 0.0043\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0041\n",
      "Epoch 4: val_loss improved from 0.05149 to 0.04980, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0426 - mean_squared_error: 0.0041 - val_loss: 0.0498 - val_mean_squared_error: 0.0052\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0036\n",
      "Epoch 5: val_loss improved from 0.04980 to 0.04314, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0394 - mean_squared_error: 0.0036 - val_loss: 0.0431 - val_mean_squared_error: 0.0042\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0378 - mean_squared_error: 0.0034\n",
      "Epoch 6: val_loss did not improve from 0.04314\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0378 - mean_squared_error: 0.0034 - val_loss: 0.0437 - val_mean_squared_error: 0.0044\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0033\n",
      "Epoch 7: val_loss improved from 0.04314 to 0.03551, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 0.0371 - mean_squared_error: 0.0033 - val_loss: 0.0355 - val_mean_squared_error: 0.0030\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0033\n",
      "Epoch 8: val_loss did not improve from 0.03551\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0374 - mean_squared_error: 0.0033 - val_loss: 0.0394 - val_mean_squared_error: 0.0040\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0029\n",
      "Epoch 9: val_loss improved from 0.03551 to 0.03299, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.0344 - mean_squared_error: 0.0029 - val_loss: 0.0330 - val_mean_squared_error: 0.0028\n",
      "Epoch 10/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.0028\n",
      "Epoch 10: val_loss improved from 0.03299 to 0.03126, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool4_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0337 - mean_squared_error: 0.0028 - val_loss: 0.0313 - val_mean_squared_error: 0.0025\n",
      "Epoch 11/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0329 - mean_squared_error: 0.0027\n",
      "Epoch 11: val_loss did not improve from 0.03126\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0331 - mean_squared_error: 0.0027 - val_loss: 0.0374 - val_mean_squared_error: 0.0034\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0026\n",
      "Epoch 12: val_loss did not improve from 0.03126\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0332 - mean_squared_error: 0.0026 - val_loss: 0.0397 - val_mean_squared_error: 0.0037\n",
      "Epoch 13/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.0028\n",
      "Epoch 13: val_loss did not improve from 0.03126\n",
      "83/83 [==============================] - 3s 30ms/step - loss: 0.0332 - mean_squared_error: 0.0028 - val_loss: 0.0379 - val_mean_squared_error: 0.0030\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###3 fold : val mae 0.03###\n",
      "mae0.72+-0.06\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0226\n",
      "Epoch 1: val_loss improved from inf to 0.10876, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 60ms/step - loss: 0.1086 - mean_squared_error: 0.0226 - val_loss: 0.1088 - val_mean_squared_error: 0.0213\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss improved from 0.10876 to 0.09089, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.1059 - mean_squared_error: 0.0207 - val_loss: 0.0909 - val_mean_squared_error: 0.0170\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.09089\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1060 - mean_squared_error: 0.0207 - val_loss: 0.0927 - val_mean_squared_error: 0.0175\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1051 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss improved from 0.09089 to 0.09063, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.1051 - mean_squared_error: 0.0207 - val_loss: 0.0906 - val_mean_squared_error: 0.0095\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0196\n",
      "Epoch 5: val_loss did not improve from 0.09063\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1012 - mean_squared_error: 0.0196 - val_loss: 0.1388 - val_mean_squared_error: 0.0246\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0855 - mean_squared_error: 0.0150\n",
      "Epoch 6: val_loss did not improve from 0.09063\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0854 - mean_squared_error: 0.0149 - val_loss: 0.1101 - val_mean_squared_error: 0.0260\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0697 - mean_squared_error: 0.0101\n",
      "Epoch 7: val_loss did not improve from 0.09063\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0698 - mean_squared_error: 0.0101 - val_loss: 0.1300 - val_mean_squared_error: 0.0310\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###0 fold : val mae 0.09###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0228\n",
      "Epoch 1: val_loss improved from inf to 0.10444, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 15s 73ms/step - loss: 0.1092 - mean_squared_error: 0.0228 - val_loss: 0.1044 - val_mean_squared_error: 0.0202\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10444 to 0.08854, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.1065 - mean_squared_error: 0.0209 - val_loss: 0.0885 - val_mean_squared_error: 0.0093\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0208\n",
      "Epoch 3: val_loss did not improve from 0.08854\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.1047 - mean_squared_error: 0.0208 - val_loss: 0.0949 - val_mean_squared_error: 0.0104\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0938 - mean_squared_error: 0.0173\n",
      "Epoch 4: val_loss did not improve from 0.08854\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0938 - mean_squared_error: 0.0173 - val_loss: 0.0928 - val_mean_squared_error: 0.0214\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0778 - mean_squared_error: 0.0123\n",
      "Epoch 5: val_loss improved from 0.08854 to 0.05808, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0778 - mean_squared_error: 0.0123 - val_loss: 0.0581 - val_mean_squared_error: 0.0071\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0670 - mean_squared_error: 0.0091\n",
      "Epoch 6: val_loss improved from 0.05808 to 0.04566, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0669 - mean_squared_error: 0.0091 - val_loss: 0.0457 - val_mean_squared_error: 0.0052\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0564 - mean_squared_error: 0.0066\n",
      "Epoch 7: val_loss did not improve from 0.04566\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0564 - mean_squared_error: 0.0066 - val_loss: 0.0594 - val_mean_squared_error: 0.0054\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.0055\n",
      "Epoch 8: val_loss did not improve from 0.04566\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0518 - mean_squared_error: 0.0055 - val_loss: 0.0722 - val_mean_squared_error: 0.0088\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0480 - mean_squared_error: 0.0048\n",
      "Epoch 9: val_loss did not improve from 0.04566\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0481 - mean_squared_error: 0.0048 - val_loss: 0.0699 - val_mean_squared_error: 0.0080\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###1 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0232\n",
      "Epoch 1: val_loss improved from inf to 0.10487, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 11s 55ms/step - loss: 0.1099 - mean_squared_error: 0.0232 - val_loss: 0.1049 - val_mean_squared_error: 0.0202\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10487\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1049 - val_mean_squared_error: 0.0202\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss improved from 0.10487 to 0.08941, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.1074 - mean_squared_error: 0.0211 - val_loss: 0.0894 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0213\n",
      "Epoch 4: val_loss improved from 0.08941 to 0.07669, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.1072 - mean_squared_error: 0.0213 - val_loss: 0.0767 - val_mean_squared_error: 0.0132\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0195\n",
      "Epoch 5: val_loss improved from 0.07669 to 0.05733, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.1007 - mean_squared_error: 0.0195 - val_loss: 0.0573 - val_mean_squared_error: 0.0076\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.0136\n",
      "Epoch 6: val_loss did not improve from 0.05733\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0806 - mean_squared_error: 0.0136 - val_loss: 0.0591 - val_mean_squared_error: 0.0085\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0647 - mean_squared_error: 0.0086\n",
      "Epoch 7: val_loss did not improve from 0.05733\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0648 - mean_squared_error: 0.0086 - val_loss: 0.0786 - val_mean_squared_error: 0.0134\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0565 - mean_squared_error: 0.0067\n",
      "Epoch 8: val_loss did not improve from 0.05733\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0565 - mean_squared_error: 0.0067 - val_loss: 0.2267 - val_mean_squared_error: 0.0620\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###2 fold : val mae 0.06###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1104 - mean_squared_error: 0.0233\n",
      "Epoch 1: val_loss improved from inf to 0.10612, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 12s 58ms/step - loss: 0.1103 - mean_squared_error: 0.0232 - val_loss: 0.1061 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10612 to 0.09926, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.1066 - mean_squared_error: 0.0209 - val_loss: 0.0993 - val_mean_squared_error: 0.0192\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0208\n",
      "Epoch 3: val_loss improved from 0.09926 to 0.07711, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.1055 - mean_squared_error: 0.0207 - val_loss: 0.0771 - val_mean_squared_error: 0.0089\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0976 - mean_squared_error: 0.0183\n",
      "Epoch 4: val_loss improved from 0.07711 to 0.06587, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0975 - mean_squared_error: 0.0183 - val_loss: 0.0659 - val_mean_squared_error: 0.0104\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0777 - mean_squared_error: 0.0125\n",
      "Epoch 5: val_loss improved from 0.06587 to 0.06505, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0777 - mean_squared_error: 0.0125 - val_loss: 0.0650 - val_mean_squared_error: 0.0095\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0688 - mean_squared_error: 0.0098\n",
      "Epoch 6: val_loss improved from 0.06505 to 0.04286, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0689 - mean_squared_error: 0.0098 - val_loss: 0.0429 - val_mean_squared_error: 0.0041\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0560 - mean_squared_error: 0.0066\n",
      "Epoch 7: val_loss improved from 0.04286 to 0.04024, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size11_pool5_do0.5_tra3_head2_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0560 - mean_squared_error: 0.0066 - val_loss: 0.0402 - val_mean_squared_error: 0.0038\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0514 - mean_squared_error: 0.0055\n",
      "Epoch 8: val_loss did not improve from 0.04024\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0513 - mean_squared_error: 0.0055 - val_loss: 0.0486 - val_mean_squared_error: 0.0054\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0477 - mean_squared_error: 0.0048\n",
      "Epoch 9: val_loss did not improve from 0.04024\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0477 - mean_squared_error: 0.0048 - val_loss: 0.0531 - val_mean_squared_error: 0.0062\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0443 - mean_squared_error: 0.0042\n",
      "Epoch 10: val_loss did not improve from 0.04024\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0442 - mean_squared_error: 0.0042 - val_loss: 0.1076 - val_mean_squared_error: 0.0176\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###3 fold : val mae 0.04###\n",
      "mae1.20+-0.38\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1172 - mean_squared_error: 0.0296\n",
      "Epoch 1: val_loss improved from inf to 0.10974, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 16s 69ms/step - loss: 0.1172 - mean_squared_error: 0.0296 - val_loss: 0.1097 - val_mean_squared_error: 0.0216\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss improved from 0.10974 to 0.10959, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.1063 - mean_squared_error: 0.0207 - val_loss: 0.1096 - val_mean_squared_error: 0.0216\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.10959 to 0.10954, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.1065 - mean_squared_error: 0.0207 - val_loss: 0.1095 - val_mean_squared_error: 0.0215\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss improved from 0.10954 to 0.10938, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1094 - val_mean_squared_error: 0.0215\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss improved from 0.10938 to 0.10910, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1091 - val_mean_squared_error: 0.0215\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 6: val_loss improved from 0.10910 to 0.10844, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1084 - val_mean_squared_error: 0.0213\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0207\n",
      "Epoch 7: val_loss improved from 0.10844 to 0.08887, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.1060 - mean_squared_error: 0.0206 - val_loss: 0.0889 - val_mean_squared_error: 0.0166\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1057 - mean_squared_error: 0.0210\n",
      "Epoch 8: val_loss improved from 0.08887 to 0.08628, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.1057 - mean_squared_error: 0.0209 - val_loss: 0.0863 - val_mean_squared_error: 0.0159\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0204\n",
      "Epoch 9: val_loss improved from 0.08628 to 0.08201, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.1037 - mean_squared_error: 0.0204 - val_loss: 0.0820 - val_mean_squared_error: 0.0096\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0188\n",
      "Epoch 10: val_loss did not improve from 0.08201\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.0983 - mean_squared_error: 0.0188 - val_loss: 0.0911 - val_mean_squared_error: 0.0100\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0900 - mean_squared_error: 0.0157\n",
      "Epoch 11: val_loss did not improve from 0.08201\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0900 - mean_squared_error: 0.0157 - val_loss: 0.1296 - val_mean_squared_error: 0.0209\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.0140\n",
      "Epoch 12: val_loss did not improve from 0.08201\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0852 - mean_squared_error: 0.0140 - val_loss: 0.2159 - val_mean_squared_error: 0.0559\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###0 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1175 - mean_squared_error: 0.0298\n",
      "Epoch 1: val_loss improved from inf to 0.10667, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 18s 81ms/step - loss: 0.1175 - mean_squared_error: 0.0298 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10667 to 0.10648, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1065 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss improved from 0.10648 to 0.10555, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1056 - val_mean_squared_error: 0.0205\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0208\n",
      "Epoch 4: val_loss improved from 0.10555 to 0.10441, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1044 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10441 to 0.09865, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1071 - mean_squared_error: 0.0209 - val_loss: 0.0986 - val_mean_squared_error: 0.0190\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 6: val_loss improved from 0.09865 to 0.08005, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 60ms/step - loss: 0.1066 - mean_squared_error: 0.0207 - val_loss: 0.0800 - val_mean_squared_error: 0.0139\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.08005\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.1068 - mean_squared_error: 0.0209 - val_loss: 0.0820 - val_mean_squared_error: 0.0146\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0209\n",
      "Epoch 8: val_loss improved from 0.08005 to 0.07567, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1066 - mean_squared_error: 0.0209 - val_loss: 0.0757 - val_mean_squared_error: 0.0117\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0207\n",
      "Epoch 9: val_loss did not improve from 0.07567\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.1055 - mean_squared_error: 0.0207 - val_loss: 0.1186 - val_mean_squared_error: 0.0168\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0192\n",
      "Epoch 10: val_loss did not improve from 0.07567\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.1003 - mean_squared_error: 0.0191 - val_loss: 0.3179 - val_mean_squared_error: 0.1104\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.0171\n",
      "Epoch 11: val_loss did not improve from 0.07567\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.0935 - mean_squared_error: 0.0171 - val_loss: 0.4768 - val_mean_squared_error: 0.2366\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1192 - mean_squared_error: 0.0314\n",
      "Epoch 1: val_loss improved from inf to 0.10566, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 16s 78ms/step - loss: 0.1192 - mean_squared_error: 0.0313 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0212\n",
      "Epoch 2: val_loss improved from 0.10566 to 0.10566, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.1078 - mean_squared_error: 0.0212 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.10566 to 0.10540, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1054 - val_mean_squared_error: 0.0203\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.10540 to 0.10511, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1051 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10511 to 0.10508, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1051 - val_mean_squared_error: 0.0203\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0213\n",
      "Epoch 6: val_loss improved from 0.10508 to 0.10077, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.1077 - mean_squared_error: 0.0213 - val_loss: 0.1008 - val_mean_squared_error: 0.0193\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10077 to 0.09398, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.1068 - mean_squared_error: 0.0209 - val_loss: 0.0940 - val_mean_squared_error: 0.0179\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0210\n",
      "Epoch 8: val_loss improved from 0.09398 to 0.07648, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.1064 - mean_squared_error: 0.0211 - val_loss: 0.0765 - val_mean_squared_error: 0.0126\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0196\n",
      "Epoch 9: val_loss did not improve from 0.07648\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.1010 - mean_squared_error: 0.0196 - val_loss: 0.0832 - val_mean_squared_error: 0.0092\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0918 - mean_squared_error: 0.0160\n",
      "Epoch 10: val_loss did not improve from 0.07648\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.0918 - mean_squared_error: 0.0160 - val_loss: 0.1174 - val_mean_squared_error: 0.0164\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0867 - mean_squared_error: 0.0142\n",
      "Epoch 11: val_loss did not improve from 0.07648\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0867 - mean_squared_error: 0.0142 - val_loss: 0.1587 - val_mean_squared_error: 0.0322\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1181 - mean_squared_error: 0.0300\n",
      "Epoch 1: val_loss improved from inf to 0.10602, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 16s 76ms/step - loss: 0.1179 - mean_squared_error: 0.0299 - val_loss: 0.1060 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10602 to 0.10566, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1057 - val_mean_squared_error: 0.0206\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10566 to 0.10461, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1046 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10461 to 0.10375, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.1073 - mean_squared_error: 0.0210 - val_loss: 0.1038 - val_mean_squared_error: 0.0202\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10375 to 0.09950, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.1067 - mean_squared_error: 0.0209 - val_loss: 0.0995 - val_mean_squared_error: 0.0193\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss improved from 0.09950 to 0.09095, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.1065 - mean_squared_error: 0.0209 - val_loss: 0.0909 - val_mean_squared_error: 0.0173\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.0203\n",
      "Epoch 7: val_loss improved from 0.09095 to 0.07905, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.5_tra5_head2_kdim64_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.1045 - mean_squared_error: 0.0203 - val_loss: 0.0790 - val_mean_squared_error: 0.0138\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0186\n",
      "Epoch 8: val_loss did not improve from 0.07905\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0984 - mean_squared_error: 0.0186 - val_loss: 0.0795 - val_mean_squared_error: 0.0096\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0161\n",
      "Epoch 9: val_loss did not improve from 0.07905\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0917 - mean_squared_error: 0.0161 - val_loss: 0.0856 - val_mean_squared_error: 0.0095\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0867 - mean_squared_error: 0.0143\n",
      "Epoch 10: val_loss did not improve from 0.07905\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0867 - mean_squared_error: 0.0143 - val_loss: 0.1073 - val_mean_squared_error: 0.0133\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae1.64+-0.04\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1123 - mean_squared_error: 0.0260\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 17s 87ms/step - loss: 0.1122 - mean_squared_error: 0.0260 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 6: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 7: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 8/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 8: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.0254\n",
      "Epoch 1: val_loss improved from inf to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 17s 82ms/step - loss: 0.1123 - mean_squared_error: 0.0253 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 74ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.10695\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 8/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 8: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 9: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 10/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 10: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 11/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 11: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 12/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 12: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 13/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 13: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 14/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 14: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 15/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 15: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 16/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 16: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 17/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 17: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 18/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 18: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 19/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 19: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 20/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 20: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 21/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 21: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 22/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 22: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 23/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 23: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 24/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 24: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 25/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 25: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 26/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 26: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 27/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 27: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 28/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 28: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 29/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 29: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 30/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 30: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 31/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 31: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 32/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 32: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 33/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 33: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 34/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 34: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 35/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 35: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 36/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 36: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 37/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 37: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 38/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 38: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 39/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 39: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 40/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 40: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 41/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 41: val_loss improved from 0.10695 to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 42/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 42: val_loss improved from 0.10695 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 43/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 43: val_loss improved from 0.10694 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 44/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 44: val_loss improved from 0.10694 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 45/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 45: val_loss improved from 0.10694 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 46/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 46: val_loss improved from 0.10694 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 47/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 47: val_loss improved from 0.10694 to 0.10683, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "Epoch 48/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 48: val_loss improved from 0.10683 to 0.10669, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 49/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 49: val_loss improved from 0.10669 to 0.10608, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 6s 77ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1061 - val_mean_squared_error: 0.0206\n",
      "Epoch 50/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0214\n",
      "Epoch 50: val_loss did not improve from 0.10608\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1078 - mean_squared_error: 0.0214 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 51/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 51: val_loss did not improve from 0.10608\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 52/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 52: val_loss did not improve from 0.10608\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 15ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1140 - mean_squared_error: 0.0268\n",
      "Epoch 1: val_loss improved from inf to 0.10583, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 20s 84ms/step - loss: 0.1140 - mean_squared_error: 0.0268 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10583 to 0.10582, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss improved from 0.10582 to 0.10582, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.10582 to 0.10582, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 5: val_loss improved from 0.10582 to 0.10581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 6: val_loss improved from 0.10581 to 0.10581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 7: val_loss improved from 0.10581 to 0.10581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 8/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 8: val_loss improved from 0.10581 to 0.10581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 9: val_loss improved from 0.10581 to 0.10581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 10/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 10: val_loss improved from 0.10581 to 0.10581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 11/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 11: val_loss improved from 0.10581 to 0.10580, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 12/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 12: val_loss improved from 0.10580 to 0.10580, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 13/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 13: val_loss improved from 0.10580 to 0.10580, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 14/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 14: val_loss improved from 0.10580 to 0.10579, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 15/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 15: val_loss improved from 0.10579 to 0.10577, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 16/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 16: val_loss improved from 0.10577 to 0.10574, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 17/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 17: val_loss improved from 0.10574 to 0.10478, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 75ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1048 - val_mean_squared_error: 0.0202\n",
      "Epoch 18/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 18: val_loss improved from 0.10478 to 0.07938, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.0794 - val_mean_squared_error: 0.0099\n",
      "Epoch 19/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 19: val_loss did not improve from 0.07938\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1056 - val_mean_squared_error: 0.0204\n",
      "Epoch 20/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 20: val_loss did not improve from 0.07938\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1056 - val_mean_squared_error: 0.0204\n",
      "Epoch 21/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 21: val_loss did not improve from 0.07938\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1055 - val_mean_squared_error: 0.0203\n",
      "55/55 [==============================] - 1s 16ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1123 - mean_squared_error: 0.0254\n",
      "Epoch 1: val_loss improved from inf to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 18s 90ms/step - loss: 0.1123 - mean_squared_error: 0.0254 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 75ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 8/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 8: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 9: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 10/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 10: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 11/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 11: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 12/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 12: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 13/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 13: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 14/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 14: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 75ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 15/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 15: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 16/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 16: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 17/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 17: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 18/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 18: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 19/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 19: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 20/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 20: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 21/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 21: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 22/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 22: val_loss improved from 0.10638 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 23/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 23: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 24/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0210\n",
      "Epoch 24: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 25/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 25: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 26/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 26: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 27/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 27: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 80ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 28/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 28: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 29/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 29: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 30/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 30: val_loss improved from 0.10637 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 76ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 31/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 31: val_loss improved from 0.10637 to 0.10636, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 7s 79ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 32/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 32: val_loss improved from 0.10636 to 0.10636, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 33/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 33: val_loss improved from 0.10636 to 0.10636, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 78ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 34/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 34: val_loss improved from 0.10636 to 0.10636, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 35/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 35: val_loss improved from 0.10636 to 0.07554, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size15_pool5_do0.5_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 6s 73ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.0755 - val_mean_squared_error: 0.0110\n",
      "Epoch 36/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 36: val_loss did not improve from 0.07554\n",
      "83/83 [==============================] - 6s 74ms/step - loss: 0.1078 - mean_squared_error: 0.0212 - val_loss: 0.1039 - val_mean_squared_error: 0.0202\n",
      "Epoch 37/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 37: val_loss did not improve from 0.07554\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1010 - val_mean_squared_error: 0.0196\n",
      "Epoch 38/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 38: val_loss did not improve from 0.07554\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 0.1078 - mean_squared_error: 0.0210 - val_loss: 0.0994 - val_mean_squared_error: 0.0193\n",
      "55/55 [==============================] - 2s 16ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae1.93+-0.32\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size11_pool2_do0.5_tra4_head8_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2173 - mean_squared_error: 0.1184\n",
      "Epoch 1: val_loss improved from inf to 0.10283, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size11_pool2_do0.5_tra4_head8_kdim16_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 18s 270ms/step - loss: 0.2173 - mean_squared_error: 0.1184 - val_loss: 0.1028 - val_mean_squared_error: 0.0201\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1117 - mean_squared_error: 0.0249\n",
      "Epoch 2: val_loss did not improve from 0.10283\n",
      "21/21 [==============================] - 4s 209ms/step - loss: 0.1117 - mean_squared_error: 0.0249 - val_loss: 0.1049 - val_mean_squared_error: 0.0205\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0221\n",
      "Epoch 3: val_loss did not improve from 0.10283\n",
      "21/21 [==============================] - 4s 203ms/step - loss: 0.1081 - mean_squared_error: 0.0221 - val_loss: 0.1053 - val_mean_squared_error: 0.0206\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0222\n",
      "Epoch 4: val_loss did not improve from 0.10283\n",
      "21/21 [==============================] - 4s 202ms/step - loss: 0.1079 - mean_squared_error: 0.0222 - val_loss: 0.1055 - val_mean_squared_error: 0.0207\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2158 - mean_squared_error: 0.1157\n",
      "Epoch 1: val_loss improved from inf to 0.09926, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size11_pool2_do0.5_tra4_head8_kdim16_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 16s 251ms/step - loss: 0.2158 - mean_squared_error: 0.1157 - val_loss: 0.0993 - val_mean_squared_error: 0.0191\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1132 - mean_squared_error: 0.0255\n",
      "Epoch 2: val_loss did not improve from 0.09926\n",
      "21/21 [==============================] - 4s 204ms/step - loss: 0.1132 - mean_squared_error: 0.0255 - val_loss: 0.1013 - val_mean_squared_error: 0.0196\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0224\n",
      "Epoch 3: val_loss did not improve from 0.09926\n",
      "21/21 [==============================] - 4s 203ms/step - loss: 0.1090 - mean_squared_error: 0.0224 - val_loss: 0.1020 - val_mean_squared_error: 0.0197\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0223\n",
      "Epoch 4: val_loss did not improve from 0.09926\n",
      "21/21 [==============================] - 4s 203ms/step - loss: 0.1084 - mean_squared_error: 0.0223 - val_loss: 0.1023 - val_mean_squared_error: 0.0198\n",
      "55/55 [==============================] - 2s 14ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2185 - mean_squared_error: 0.1176\n",
      "Epoch 1: val_loss improved from inf to 0.09848, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size11_pool2_do0.5_tra4_head8_kdim16_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 20s 269ms/step - loss: 0.2185 - mean_squared_error: 0.1176 - val_loss: 0.0985 - val_mean_squared_error: 0.0189\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1106 - mean_squared_error: 0.0236\n",
      "Epoch 2: val_loss did not improve from 0.09848\n",
      "21/21 [==============================] - 4s 204ms/step - loss: 0.1106 - mean_squared_error: 0.0236 - val_loss: 0.0995 - val_mean_squared_error: 0.0191\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0226\n",
      "Epoch 3: val_loss did not improve from 0.09848\n",
      "21/21 [==============================] - 4s 202ms/step - loss: 0.1092 - mean_squared_error: 0.0226 - val_loss: 0.1007 - val_mean_squared_error: 0.0193\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0217\n",
      "Epoch 4: val_loss did not improve from 0.09848\n",
      "21/21 [==============================] - 4s 204ms/step - loss: 0.1076 - mean_squared_error: 0.0217 - val_loss: 0.1006 - val_mean_squared_error: 0.0193\n",
      "55/55 [==============================] - 2s 14ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2184 - mean_squared_error: 0.1175\n",
      "Epoch 1: val_loss improved from inf to 0.09866, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size11_pool2_do0.5_tra4_head8_kdim16_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 17s 273ms/step - loss: 0.2184 - mean_squared_error: 0.1175 - val_loss: 0.0987 - val_mean_squared_error: 0.0191\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1113 - mean_squared_error: 0.0247\n",
      "Epoch 2: val_loss did not improve from 0.09866\n",
      "21/21 [==============================] - 5s 224ms/step - loss: 0.1113 - mean_squared_error: 0.0247 - val_loss: 0.1009 - val_mean_squared_error: 0.0196\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0219\n",
      "Epoch 3: val_loss did not improve from 0.09866\n",
      "21/21 [==============================] - 4s 202ms/step - loss: 0.1084 - mean_squared_error: 0.0219 - val_loss: 0.1011 - val_mean_squared_error: 0.0196\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0218\n",
      "Epoch 4: val_loss did not improve from 0.09866\n",
      "21/21 [==============================] - 4s 201ms/step - loss: 0.1083 - mean_squared_error: 0.0218 - val_loss: 0.1012 - val_mean_squared_error: 0.0197\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.11+-0.01\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size19_pool4_do0.2_tra4_head8_kdim256_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 01:34:03.804769: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 765.38MiB (rounded to 802562048)requested by op model/multi_head_attention_3/einsum/Einsum\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-22 01:34:03.804973: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-22 01:34:03.804993: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 619, Chunks in use: 618. 154.8KiB allocated for chunks. 154.5KiB in use in bin. 30.6KiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805006: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 126, Chunks in use: 126. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 63.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805017: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 86, Chunks in use: 86. 90.5KiB allocated for chunks. 90.5KiB in use in bin. 86.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805028: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 81, Chunks in use: 81. 169.5KiB allocated for chunks. 169.5KiB in use in bin. 162.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805039: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805050: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 218, Chunks in use: 217. 1.95MiB allocated for chunks. 1.94MiB in use in bin. 1.78MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805062: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 12, Chunks in use: 12. 216.8KiB allocated for chunks. 216.8KiB in use in bin. 191.7KiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805073: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 37.2KiB allocated for chunks. 37.2KiB in use in bin. 19.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805083: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805093: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 27, Chunks in use: 27. 3.79MiB allocated for chunks. 3.79MiB in use in bin. 3.38MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805103: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 12, Chunks in use: 12. 4.22MiB allocated for chunks. 4.22MiB in use in bin. 3.67MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805112: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805122: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 0. 4.17MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805134: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 48, Chunks in use: 48. 109.71MiB allocated for chunks. 109.71MiB in use in bin. 96.00MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805144: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 9.78MiB allocated for chunks. 9.78MiB in use in bin. 9.78MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805153: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805165: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 12, Chunks in use: 11. 249.68MiB allocated for chunks. 230.12MiB in use in bin. 215.03MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805177: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 3, Chunks in use: 3. 122.32MiB allocated for chunks. 122.32MiB in use in bin. 117.38MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805187: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 20, Chunks in use: 19. 1.67GiB allocated for chunks. 1.59GiB in use in bin. 1.43GiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805198: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 4. 568.27MiB allocated for chunks. 568.27MiB in use in bin. 312.88MiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805213: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 29, Chunks in use: 27. 18.72GiB allocated for chunks. 17.81GiB in use in bin. 17.74GiB client-requested in use in bin.\n",
      "2023-09-22 01:34:03.805224: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 765.38MiB was 256.00MiB, Chunk State: \n",
      "2023-09-22 01:34:03.805244: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 373.10MiB | Requested Size: 512B | in_use: 0 | bin_num: 20, prev:   Size: 78.25MiB | Requested Size: 78.25MiB | in_use: 1 | bin_num: -1, next:   Size: 256B | Requested Size: 4B | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:34:03.805257: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 558.69MiB | Requested Size: 512B | in_use: 0 | bin_num: 20, prev:   Size: 626.00MiB | Requested Size: 626.00MiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:34:03.805264: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 23023321088\n",
      "2023-09-22 01:34:03.805276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000000 of size 1280 next 1\n",
      "2023-09-22 01:34:03.805284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000500 of size 256 next 2\n",
      "2023-09-22 01:34:03.805292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000600 of size 256 next 3\n",
      "2023-09-22 01:34:03.805299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000700 of size 256 next 5\n",
      "2023-09-22 01:34:03.805307: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000800 of size 256 next 6\n",
      "2023-09-22 01:34:03.805314: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000900 of size 256 next 4\n",
      "2023-09-22 01:34:03.805322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000a00 of size 256 next 529\n",
      "2023-09-22 01:34:03.805329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000b00 of size 256 next 735\n",
      "2023-09-22 01:34:03.805336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000c00 of size 256 next 711\n",
      "2023-09-22 01:34:03.805344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000d00 of size 256 next 12\n",
      "2023-09-22 01:34:03.805351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000e00 of size 256 next 13\n",
      "2023-09-22 01:34:03.805359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000f00 of size 256 next 14\n",
      "2023-09-22 01:34:03.805367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001000 of size 12544 next 28\n",
      "2023-09-22 01:34:03.805378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004100 of size 256 next 29\n",
      "2023-09-22 01:34:03.805386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004200 of size 256 next 30\n",
      "2023-09-22 01:34:03.805393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004300 of size 256 next 61\n",
      "2023-09-22 01:34:03.805401: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004400 of size 256 next 309\n",
      "2023-09-22 01:34:03.805415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004500 of size 256 next 50\n",
      "2023-09-22 01:34:03.805422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004600 of size 256 next 42\n",
      "2023-09-22 01:34:03.805430: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004700 of size 256 next 37\n",
      "2023-09-22 01:34:03.805437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004800 of size 256 next 36\n",
      "2023-09-22 01:34:03.805445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004900 of size 256 next 1655\n",
      "2023-09-22 01:34:03.805454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004a00 of size 256 next 348\n",
      "2023-09-22 01:34:03.805462: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004b00 of size 512 next 15\n",
      "2023-09-22 01:34:03.805471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004d00 of size 512 next 1703\n",
      "2023-09-22 01:34:03.805482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004f00 of size 256 next 63\n",
      "2023-09-22 01:34:03.805489: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005000 of size 256 next 318\n",
      "2023-09-22 01:34:03.805499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005100 of size 2048 next 1706\n",
      "2023-09-22 01:34:03.805506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005900 of size 2048 next 32\n",
      "2023-09-22 01:34:03.805514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006100 of size 256 next 31\n",
      "2023-09-22 01:34:03.805523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006200 of size 256 next 33\n",
      "2023-09-22 01:34:03.805533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006300 of size 1280 next 911\n",
      "2023-09-22 01:34:03.805543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006800 of size 256 next 35\n",
      "2023-09-22 01:34:03.805554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006900 of size 256 next 45\n",
      "2023-09-22 01:34:03.805564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006a00 of size 256 next 48\n",
      "2023-09-22 01:34:03.805574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006b00 of size 256 next 49\n",
      "2023-09-22 01:34:03.805584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006c00 of size 8192 next 811\n",
      "2023-09-22 01:34:03.805594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de008c00 of size 8192 next 1164\n",
      "2023-09-22 01:34:03.805604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ac00 of size 8192 next 202\n",
      "2023-09-22 01:34:03.805614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00cc00 of size 8192 next 992\n",
      "2023-09-22 01:34:03.805624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ec00 of size 8192 next 1267\n",
      "2023-09-22 01:34:03.805634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de010c00 of size 8192 next 1370\n",
      "2023-09-22 01:34:03.805641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de012c00 of size 8192 next 1056\n",
      "2023-09-22 01:34:03.805651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de014c00 of size 2048 next 1614\n",
      "2023-09-22 01:34:03.805658: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de015400 of size 2048 next 1157\n",
      "2023-09-22 01:34:03.805666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de015c00 of size 256 next 363\n",
      "2023-09-22 01:34:03.805675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de015d00 of size 256 next 327\n",
      "2023-09-22 01:34:03.805683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de015e00 of size 512 next 1013\n",
      "2023-09-22 01:34:03.805690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016000 of size 512 next 187\n",
      "2023-09-22 01:34:03.805699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016200 of size 512 next 203\n",
      "2023-09-22 01:34:03.805707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016400 of size 2048 next 1522\n",
      "2023-09-22 01:34:03.805715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016c00 of size 16384 next 700\n",
      "2023-09-22 01:34:03.805725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01ac00 of size 8192 next 351\n",
      "2023-09-22 01:34:03.805733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01cc00 of size 8192 next 183\n",
      "2023-09-22 01:34:03.805742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01ec00 of size 8192 next 1313\n",
      "2023-09-22 01:34:03.805750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020c00 of size 8192 next 21\n",
      "2023-09-22 01:34:03.805758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022c00 of size 8192 next 1690\n",
      "2023-09-22 01:34:03.805767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de024c00 of size 8192 next 1391\n",
      "2023-09-22 01:34:03.805774: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de026c00 of size 8192 next 601\n",
      "2023-09-22 01:34:03.805782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de028c00 of size 2048 next 508\n",
      "2023-09-22 01:34:03.805791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de029400 of size 2048 next 843\n",
      "2023-09-22 01:34:03.805800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de029c00 of size 256 next 557\n",
      "2023-09-22 01:34:03.805809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de029d00 of size 256 next 511\n",
      "2023-09-22 01:34:03.805819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de029e00 of size 256 next 1208\n",
      "2023-09-22 01:34:03.805828: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de029f00 of size 256 next 1535\n",
      "2023-09-22 01:34:03.805838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02a000 of size 256 next 1095\n",
      "2023-09-22 01:34:03.805847: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02a100 of size 256 next 1421\n",
      "2023-09-22 01:34:03.805856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02a200 of size 256 next 149\n",
      "2023-09-22 01:34:03.805865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02a300 of size 256 next 1387\n",
      "2023-09-22 01:34:03.805874: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02a400 of size 2048 next 1411\n",
      "2023-09-22 01:34:03.805884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ac00 of size 9216 next 1019\n",
      "2023-09-22 01:34:03.805893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02d000 of size 11008 next 105\n",
      "2023-09-22 01:34:03.805903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fb00 of size 256 next 103\n",
      "2023-09-22 01:34:03.805912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fc00 of size 256 next 104\n",
      "2023-09-22 01:34:03.805921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fd00 of size 256 next 107\n",
      "2023-09-22 01:34:03.805930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fe00 of size 256 next 110\n",
      "2023-09-22 01:34:03.805939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ff00 of size 256 next 115\n",
      "2023-09-22 01:34:03.805948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030000 of size 256 next 116\n",
      "2023-09-22 01:34:03.805957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030100 of size 256 next 117\n",
      "2023-09-22 01:34:03.805965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030200 of size 256 next 1334\n",
      "2023-09-22 01:34:03.805974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030300 of size 256 next 185\n",
      "2023-09-22 01:34:03.805983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030400 of size 256 next 938\n",
      "2023-09-22 01:34:03.805992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030500 of size 256 next 646\n",
      "2023-09-22 01:34:03.806001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030600 of size 256 next 108\n",
      "2023-09-22 01:34:03.806010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030700 of size 256 next 109\n",
      "2023-09-22 01:34:03.806020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030800 of size 421440000 next 304\n",
      "2023-09-22 01:34:03.806030: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11f721b200 of size 421200128 next 690\n",
      "2023-09-22 01:34:03.806042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12103cb300 of size 421440000 next 1450\n",
      "2023-09-22 01:34:03.806053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12295b5d00 of size 82051072 next 415\n",
      "2023-09-22 01:34:03.806066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122e3f5d00 of size 82051072 next 1532\n",
      "2023-09-22 01:34:03.806079: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1233235d00 of size 82051072 next 1503\n",
      "2023-09-22 01:34:03.806092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1238075d00 of size 84076800 next 874\n",
      "2023-09-22 01:34:03.806104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d0a4600 of size 8192 next 515\n",
      "2023-09-22 01:34:03.806118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d0a6600 of size 11264 next 856\n",
      "2023-09-22 01:34:03.806132: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d0a9200 of size 11264 next 742\n",
      "2023-09-22 01:34:03.806145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d0abe00 of size 11264 next 146\n",
      "2023-09-22 01:34:03.806158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d0aea00 of size 21248 next 1033\n",
      "2023-09-22 01:34:03.806168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d0b3d00 of size 131072 next 615\n",
      "2023-09-22 01:34:03.806177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d0d3d00 of size 232448 next 160\n",
      "2023-09-22 01:34:03.806187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d10c900 of size 256 next 1014\n",
      "2023-09-22 01:34:03.806197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d10ca00 of size 256 next 1427\n",
      "2023-09-22 01:34:03.806206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123d10cb00 of size 87264512 next 953\n",
      "2023-09-22 01:34:03.806215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445800 of size 256 next 925\n",
      "2023-09-22 01:34:03.806225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445900 of size 20480000 next 1217\n",
      "2023-09-22 01:34:03.806236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12437cd900 of size 20480000 next 810\n",
      "2023-09-22 01:34:03.806247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244b55900 of size 24601344 next 894\n",
      "2023-09-22 01:34:03.806256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbc00 of size 256 next 695\n",
      "2023-09-22 01:34:03.806265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbd00 of size 256 next 1266\n",
      "2023-09-22 01:34:03.806274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbe00 of size 14592 next 625\n",
      "2023-09-22 01:34:03.806283: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cf700 of size 19456 next 1512\n",
      "2023-09-22 01:34:03.806294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d4300 of size 16384 next 1156\n",
      "2023-09-22 01:34:03.806303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d8300 of size 8192 next 1043\n",
      "2023-09-22 01:34:03.806313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da300 of size 8192 next 77\n",
      "2023-09-22 01:34:03.806323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dc300 of size 8192 next 701\n",
      "2023-09-22 01:34:03.806332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462de300 of size 8192 next 17\n",
      "2023-09-22 01:34:03.806341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e0300 of size 8192 next 314\n",
      "2023-09-22 01:34:03.806351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e2300 of size 8192 next 1365\n",
      "2023-09-22 01:34:03.806358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e4300 of size 8192 next 170\n",
      "2023-09-22 01:34:03.806368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e6300 of size 1024 next 1611\n",
      "2023-09-22 01:34:03.806377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e6700 of size 1024 next 967\n",
      "2023-09-22 01:34:03.806386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e6b00 of size 512 next 1358\n",
      "2023-09-22 01:34:03.806395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e6d00 of size 1024 next 872\n",
      "2023-09-22 01:34:03.806405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7100 of size 1024 next 128\n",
      "2023-09-22 01:34:03.806414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7500 of size 1024 next 1616\n",
      "2023-09-22 01:34:03.806423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7900 of size 512 next 1198\n",
      "2023-09-22 01:34:03.806433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7b00 of size 256 next 680\n",
      "2023-09-22 01:34:03.806442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7c00 of size 256 next 922\n",
      "2023-09-22 01:34:03.806452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7d00 of size 256 next 1617\n",
      "2023-09-22 01:34:03.806461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7e00 of size 256 next 1629\n",
      "2023-09-22 01:34:03.806470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e7f00 of size 256 next 1591\n",
      "2023-09-22 01:34:03.806479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e8000 of size 256 next 72\n",
      "2023-09-22 01:34:03.806488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e8100 of size 256 next 1147\n",
      "2023-09-22 01:34:03.806497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e8200 of size 512 next 157\n",
      "2023-09-22 01:34:03.806507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462e8400 of size 21248 next 812\n",
      "2023-09-22 01:34:03.806516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ed700 of size 14592 next 497\n",
      "2023-09-22 01:34:03.806525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462f1000 of size 14592 next 1436\n",
      "2023-09-22 01:34:03.806534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462f4900 of size 256 next 490\n",
      "2023-09-22 01:34:03.806543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462f4a00 of size 256 next 430\n",
      "2023-09-22 01:34:03.806552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462f4b00 of size 38144 next 10\n",
      "2023-09-22 01:34:03.806561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe000 of size 256 next 391\n",
      "2023-09-22 01:34:03.806570: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe100 of size 256 next 1577\n",
      "2023-09-22 01:34:03.806579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe200 of size 256 next 67\n",
      "2023-09-22 01:34:03.806588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe300 of size 512 next 172\n",
      "2023-09-22 01:34:03.806597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe500 of size 256 next 1205\n",
      "2023-09-22 01:34:03.806606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe600 of size 256 next 273\n",
      "2023-09-22 01:34:03.806616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe700 of size 256 next 395\n",
      "2023-09-22 01:34:03.806625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe800 of size 256 next 220\n",
      "2023-09-22 01:34:03.806634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fe900 of size 256 next 1233\n",
      "2023-09-22 01:34:03.806643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fea00 of size 256 next 1561\n",
      "2023-09-22 01:34:03.806653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462feb00 of size 512 next 777\n",
      "2023-09-22 01:34:03.806661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fed00 of size 512 next 181\n",
      "2023-09-22 01:34:03.806670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462fef00 of size 256 next 896\n",
      "2023-09-22 01:34:03.806679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff000 of size 256 next 1055\n",
      "2023-09-22 01:34:03.806688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff100 of size 256 next 713\n",
      "2023-09-22 01:34:03.806697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff200 of size 256 next 1592\n",
      "2023-09-22 01:34:03.806707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff300 of size 256 next 130\n",
      "2023-09-22 01:34:03.806716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff400 of size 256 next 1488\n",
      "2023-09-22 01:34:03.806726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff500 of size 256 next 685\n",
      "2023-09-22 01:34:03.806735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff600 of size 256 next 404\n",
      "2023-09-22 01:34:03.806744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff700 of size 256 next 610\n",
      "2023-09-22 01:34:03.806756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ff800 of size 512 next 1343\n",
      "2023-09-22 01:34:03.806767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ffa00 of size 256 next 1029\n",
      "2023-09-22 01:34:03.806781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ffb00 of size 4073728 next 959\n",
      "2023-09-22 01:34:03.806794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2400 of size 256 next 1426\n",
      "2023-09-22 01:34:03.806804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2500 of size 8192 next 260\n",
      "2023-09-22 01:34:03.806816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e4500 of size 8192 next 167\n",
      "2023-09-22 01:34:03.806830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6500 of size 8192 next 580\n",
      "2023-09-22 01:34:03.806843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e8500 of size 8192 next 797\n",
      "2023-09-22 01:34:03.806853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ea500 of size 8192 next 990\n",
      "2023-09-22 01:34:03.806863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ec500 of size 2048 next 1632\n",
      "2023-09-22 01:34:03.806875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ecd00 of size 2048 next 558\n",
      "2023-09-22 01:34:03.806888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ed500 of size 2048 next 1554\n",
      "2023-09-22 01:34:03.806902: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466edd00 of size 512 next 966\n",
      "2023-09-22 01:34:03.806915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466edf00 of size 512 next 556\n",
      "2023-09-22 01:34:03.806924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ee100 of size 512 next 919\n",
      "2023-09-22 01:34:03.806937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ee300 of size 256 next 732\n",
      "2023-09-22 01:34:03.806950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ee400 of size 256 next 356\n",
      "2023-09-22 01:34:03.806964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ee500 of size 15104 next 291\n",
      "2023-09-22 01:34:03.806975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2000 of size 256 next 880\n",
      "2023-09-22 01:34:03.806985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2100 of size 2048 next 1354\n",
      "2023-09-22 01:34:03.806999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2900 of size 2048 next 96\n",
      "2023-09-22 01:34:03.807012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3100 of size 9984 next 98\n",
      "2023-09-22 01:34:03.807027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5800 of size 256 next 385\n",
      "2023-09-22 01:34:03.807038: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5900 of size 256 next 705\n",
      "2023-09-22 01:34:03.807050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5a00 of size 256 next 225\n",
      "2023-09-22 01:34:03.807064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5b00 of size 2097152 next 346\n",
      "2023-09-22 01:34:03.807075: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12468f5b00 of size 2097152 next 54\n",
      "2023-09-22 01:34:03.807086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246af5b00 of size 3495936 next 619\n",
      "2023-09-22 01:34:03.807096: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246e4b300 of size 8192 next 1177\n",
      "2023-09-22 01:34:03.807108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246e4d300 of size 2858496 next 1155\n",
      "2023-09-22 01:34:03.807121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107100 of size 256 next 995\n",
      "2023-09-22 01:34:03.807133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107200 of size 8192 next 389\n",
      "2023-09-22 01:34:03.807165: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247109200 of size 8192 next 1547\n",
      "2023-09-22 01:34:03.807176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710b200 of size 8192 next 323\n",
      "2023-09-22 01:34:03.807191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710d200 of size 8192 next 1091\n",
      "2023-09-22 01:34:03.807204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f200 of size 8192 next 1126\n",
      "2023-09-22 01:34:03.807214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111200 of size 1024 next 1493\n",
      "2023-09-22 01:34:03.807225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111600 of size 1024 next 522\n",
      "2023-09-22 01:34:03.807236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111a00 of size 1024 next 571\n",
      "2023-09-22 01:34:03.807250: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111e00 of size 1024 next 221\n",
      "2023-09-22 01:34:03.807264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247112200 of size 1024 next 712\n",
      "2023-09-22 01:34:03.807274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247112600 of size 1024 next 254\n",
      "2023-09-22 01:34:03.807286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247112a00 of size 131072 next 985\n",
      "2023-09-22 01:34:03.807295: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247132a00 of size 131072 next 1262\n",
      "2023-09-22 01:34:03.807309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247152a00 of size 512 next 1383\n",
      "2023-09-22 01:34:03.807322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247152c00 of size 512 next 883\n",
      "2023-09-22 01:34:03.807332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247152e00 of size 131072 next 831\n",
      "2023-09-22 01:34:03.807344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247172e00 of size 135168 next 163\n",
      "2023-09-22 01:34:03.807354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193e00 of size 256 next 123\n",
      "2023-09-22 01:34:03.807367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193f00 of size 256 next 1630\n",
      "2023-09-22 01:34:03.807379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194000 of size 256 next 18\n",
      "2023-09-22 01:34:03.807389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194100 of size 256 next 579\n",
      "2023-09-22 01:34:03.807399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194200 of size 256 next 287\n",
      "2023-09-22 01:34:03.807408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194300 of size 256 next 453\n",
      "2023-09-22 01:34:03.807421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194400 of size 256 next 989\n",
      "2023-09-22 01:34:03.807435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194500 of size 320512 next 692\n",
      "2023-09-22 01:34:03.807444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471e2900 of size 320512 next 408\n",
      "2023-09-22 01:34:03.807454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247230d00 of size 502272 next 1310\n",
      "2023-09-22 01:34:03.807464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12472ab700 of size 256 next 1064\n",
      "2023-09-22 01:34:03.807473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12472ab800 of size 2097152 next 1307\n",
      "2023-09-22 01:34:03.807483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474ab800 of size 2747392 next 1138\n",
      "2023-09-22 01:34:03.807492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774a400 of size 2048 next 1069\n",
      "2023-09-22 01:34:03.807506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774ac00 of size 256 next 496\n",
      "2023-09-22 01:34:03.807519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774ad00 of size 256 next 722\n",
      "2023-09-22 01:34:03.807528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774ae00 of size 512 next 1519\n",
      "2023-09-22 01:34:03.807538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774b000 of size 1024 next 1222\n",
      "2023-09-22 01:34:03.807547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774b400 of size 1024 next 697\n",
      "2023-09-22 01:34:03.807560: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774b800 of size 1024 next 46\n",
      "2023-09-22 01:34:03.807572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774bc00 of size 1024 next 191\n",
      "2023-09-22 01:34:03.807582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774c000 of size 1024 next 916\n",
      "2023-09-22 01:34:03.807592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774c400 of size 8192 next 135\n",
      "2023-09-22 01:34:03.807601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124774e400 of size 9216 next 1353\n",
      "2023-09-22 01:34:03.807612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247750800 of size 8192 next 248\n",
      "2023-09-22 01:34:03.807625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247752800 of size 9216 next 394\n",
      "2023-09-22 01:34:03.807636: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247754c00 of size 8192 next 1582\n",
      "2023-09-22 01:34:03.807646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247756c00 of size 9216 next 485\n",
      "2023-09-22 01:34:03.807656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247759000 of size 8192 next 308\n",
      "2023-09-22 01:34:03.807667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775b000 of size 512 next 1453\n",
      "2023-09-22 01:34:03.807681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775b200 of size 512 next 211\n",
      "2023-09-22 01:34:03.807691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775b400 of size 256 next 1505\n",
      "2023-09-22 01:34:03.807701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775b500 of size 256 next 1394\n",
      "2023-09-22 01:34:03.807711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775b600 of size 512 next 1584\n",
      "2023-09-22 01:34:03.807723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775b800 of size 256 next 799\n",
      "2023-09-22 01:34:03.807736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775b900 of size 256 next 502\n",
      "2023-09-22 01:34:03.807745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775ba00 of size 256 next 1020\n",
      "2023-09-22 01:34:03.807755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775bb00 of size 256 next 1090\n",
      "2023-09-22 01:34:03.807764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775bc00 of size 256 next 158\n",
      "2023-09-22 01:34:03.807776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775bd00 of size 256 next 1491\n",
      "2023-09-22 01:34:03.807789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775be00 of size 256 next 706\n",
      "2023-09-22 01:34:03.807800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775bf00 of size 256 next 1297\n",
      "2023-09-22 01:34:03.807810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775c000 of size 2048 next 1524\n",
      "2023-09-22 01:34:03.807819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775c800 of size 2048 next 1314\n",
      "2023-09-22 01:34:03.807829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775d000 of size 11776 next 469\n",
      "2023-09-22 01:34:03.807845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775fe00 of size 8192 next 374\n",
      "2023-09-22 01:34:03.807856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247761e00 of size 9216 next 1129\n",
      "2023-09-22 01:34:03.807866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247764200 of size 2048 next 537\n",
      "2023-09-22 01:34:03.807875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247764a00 of size 2048 next 1631\n",
      "2023-09-22 01:34:03.807885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247765200 of size 2048 next 361\n",
      "2023-09-22 01:34:03.807898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247765a00 of size 512 next 1339\n",
      "2023-09-22 01:34:03.807912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247765c00 of size 512 next 452\n",
      "2023-09-22 01:34:03.807922: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247765e00 of size 512 next 946\n",
      "2023-09-22 01:34:03.807931: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247766000 of size 512 next 1143\n",
      "2023-09-22 01:34:03.807940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247766200 of size 2048 next 455\n",
      "2023-09-22 01:34:03.807949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247766a00 of size 2048 next 1363\n",
      "2023-09-22 01:34:03.807962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767200 of size 512 next 751\n",
      "2023-09-22 01:34:03.807974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767400 of size 512 next 954\n",
      "2023-09-22 01:34:03.807984: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767600 of size 256 next 1261\n",
      "2023-09-22 01:34:03.807994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767700 of size 256 next 1122\n",
      "2023-09-22 01:34:03.808003: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767800 of size 256 next 345\n",
      "2023-09-22 01:34:03.808016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767900 of size 256 next 1291\n",
      "2023-09-22 01:34:03.808028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767a00 of size 256 next 905\n",
      "2023-09-22 01:34:03.808036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767b00 of size 256 next 421\n",
      "2023-09-22 01:34:03.808045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767c00 of size 512 next 1430\n",
      "2023-09-22 01:34:03.808054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247767e00 of size 512 next 1136\n",
      "2023-09-22 01:34:03.808069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247768000 of size 512 next 204\n",
      "2023-09-22 01:34:03.808081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247768200 of size 512 next 927\n",
      "2023-09-22 01:34:03.808090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247768400 of size 256 next 1349\n",
      "2023-09-22 01:34:03.808100: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247768500 of size 256 next 494\n",
      "2023-09-22 01:34:03.808111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247768600 of size 8192 next 1457\n",
      "2023-09-22 01:34:03.808124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124776a600 of size 9216 next 422\n",
      "2023-09-22 01:34:03.808136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124776ca00 of size 10240 next 439\n",
      "2023-09-22 01:34:03.808145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124776f200 of size 2048 next 310\n",
      "2023-09-22 01:34:03.808155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124776fa00 of size 2048 next 693\n",
      "2023-09-22 01:34:03.808164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770200 of size 256 next 952\n",
      "2023-09-22 01:34:03.808176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770300 of size 256 next 1245\n",
      "2023-09-22 01:34:03.808189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770400 of size 256 next 1080\n",
      "2023-09-22 01:34:03.808199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770500 of size 256 next 555\n",
      "2023-09-22 01:34:03.808209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770600 of size 256 next 866\n",
      "2023-09-22 01:34:03.808218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770700 of size 256 next 329\n",
      "2023-09-22 01:34:03.808228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770800 of size 256 next 262\n",
      "2023-09-22 01:34:03.808237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770900 of size 256 next 176\n",
      "2023-09-22 01:34:03.808249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247770a00 of size 8192 next 1346\n",
      "2023-09-22 01:34:03.808263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247772a00 of size 11776 next 85\n",
      "2023-09-22 01:34:03.808272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247775800 of size 10240 next 1469\n",
      "2023-09-22 01:34:03.808282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247778000 of size 512 next 1318\n",
      "2023-09-22 01:34:03.808291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247778200 of size 15872 next 1045\n",
      "2023-09-22 01:34:03.808304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124777c000 of size 8192 next 1287\n",
      "2023-09-22 01:34:03.808317: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124777e000 of size 14848 next 413\n",
      "2023-09-22 01:34:03.808327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247781a00 of size 256 next 1375\n",
      "2023-09-22 01:34:03.808337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247781b00 of size 256 next 597\n",
      "2023-09-22 01:34:03.808346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247781c00 of size 256 next 247\n",
      "2023-09-22 01:34:03.808359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247781d00 of size 256 next 965\n",
      "2023-09-22 01:34:03.808372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247781e00 of size 256 next 507\n",
      "2023-09-22 01:34:03.808381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247781f00 of size 256 next 1579\n",
      "2023-09-22 01:34:03.808389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247782000 of size 256 next 1065\n",
      "2023-09-22 01:34:03.808398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247782100 of size 256 next 436\n",
      "2023-09-22 01:34:03.808410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247782200 of size 2048 next 1148\n",
      "2023-09-22 01:34:03.808424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247782a00 of size 2560 next 1113\n",
      "2023-09-22 01:34:03.808435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247783400 of size 1280 next 1381\n",
      "2023-09-22 01:34:03.808444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247783900 of size 256 next 506\n",
      "2023-09-22 01:34:03.808453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247783a00 of size 256 next 694\n",
      "2023-09-22 01:34:03.808462: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247783b00 of size 256 next 1385\n",
      "2023-09-22 01:34:03.808475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247783c00 of size 2560 next 236\n",
      "2023-09-22 01:34:03.808488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247784600 of size 256 next 1373\n",
      "2023-09-22 01:34:03.808497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247784700 of size 256 next 283\n",
      "2023-09-22 01:34:03.808507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247784800 of size 256 next 1332\n",
      "2023-09-22 01:34:03.808517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247784900 of size 512 next 1039\n",
      "2023-09-22 01:34:03.808529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247784b00 of size 512 next 1560\n",
      "2023-09-22 01:34:03.808542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247784d00 of size 512 next 1510\n",
      "2023-09-22 01:34:03.808553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247784f00 of size 256 next 1619\n",
      "2023-09-22 01:34:03.808563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247785000 of size 256 next 1166\n",
      "2023-09-22 01:34:03.808573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247785100 of size 2048 next 1495\n",
      "2023-09-22 01:34:03.808584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247785900 of size 512 next 523\n",
      "2023-09-22 01:34:03.808597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247785b00 of size 512 next 1236\n",
      "2023-09-22 01:34:03.808608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247785d00 of size 512 next 755\n",
      "2023-09-22 01:34:03.808618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247785f00 of size 256 next 354\n",
      "2023-09-22 01:34:03.808628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786000 of size 256 next 94\n",
      "2023-09-22 01:34:03.808637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786100 of size 256 next 243\n",
      "2023-09-22 01:34:03.808651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786200 of size 256 next 40\n",
      "2023-09-22 01:34:03.808663: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786300 of size 256 next 1114\n",
      "2023-09-22 01:34:03.808672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786400 of size 256 next 441\n",
      "2023-09-22 01:34:03.808682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786500 of size 256 next 1118\n",
      "2023-09-22 01:34:03.808693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786600 of size 1280 next 471\n",
      "2023-09-22 01:34:03.808706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786b00 of size 256 next 34\n",
      "2023-09-22 01:34:03.808718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786c00 of size 256 next 860\n",
      "2023-09-22 01:34:03.808727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786d00 of size 256 next 274\n",
      "2023-09-22 01:34:03.808737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786e00 of size 256 next 776\n",
      "2023-09-22 01:34:03.808749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247786f00 of size 256 next 1340\n",
      "2023-09-22 01:34:03.808762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787000 of size 256 next 263\n",
      "2023-09-22 01:34:03.808772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787100 of size 256 next 272\n",
      "2023-09-22 01:34:03.808782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787200 of size 256 next 1654\n",
      "2023-09-22 01:34:03.808792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787300 of size 256 next 1439\n",
      "2023-09-22 01:34:03.808802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787400 of size 256 next 1409\n",
      "2023-09-22 01:34:03.808815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787500 of size 256 next 1429\n",
      "2023-09-22 01:34:03.808827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787600 of size 256 next 1038\n",
      "2023-09-22 01:34:03.808836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787700 of size 256 next 1665\n",
      "2023-09-22 01:34:03.808845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787800 of size 256 next 1440\n",
      "2023-09-22 01:34:03.808856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787900 of size 256 next 1342\n",
      "2023-09-22 01:34:03.808869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787a00 of size 256 next 1335\n",
      "2023-09-22 01:34:03.808880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787b00 of size 256 next 188\n",
      "2023-09-22 01:34:03.808890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787c00 of size 256 next 218\n",
      "2023-09-22 01:34:03.808900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787d00 of size 256 next 1289\n",
      "2023-09-22 01:34:03.808911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787e00 of size 256 next 546\n",
      "2023-09-22 01:34:03.808924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247787f00 of size 256 next 207\n",
      "2023-09-22 01:34:03.808935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788000 of size 256 next 1000\n",
      "2023-09-22 01:34:03.808945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788100 of size 256 next 1203\n",
      "2023-09-22 01:34:03.808955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788200 of size 256 next 152\n",
      "2023-09-22 01:34:03.808965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788300 of size 256 next 1298\n",
      "2023-09-22 01:34:03.808974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788400 of size 256 next 266\n",
      "2023-09-22 01:34:03.808985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788500 of size 256 next 1051\n",
      "2023-09-22 01:34:03.808998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788600 of size 256 next 288\n",
      "2023-09-22 01:34:03.809009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788700 of size 256 next 1324\n",
      "2023-09-22 01:34:03.809018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788800 of size 256 next 1682\n",
      "2023-09-22 01:34:03.809028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788900 of size 256 next 617\n",
      "2023-09-22 01:34:03.809037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788a00 of size 256 next 461\n",
      "2023-09-22 01:34:03.809051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788b00 of size 256 next 618\n",
      "2023-09-22 01:34:03.809063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788c00 of size 256 next 1663\n",
      "2023-09-22 01:34:03.809072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247788d00 of size 2048 next 974\n",
      "2023-09-22 01:34:03.809082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247789500 of size 14336 next 1322\n",
      "2023-09-22 01:34:03.809092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778cd00 of size 256 next 222\n",
      "2023-09-22 01:34:03.809105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778ce00 of size 256 next 1160\n",
      "2023-09-22 01:34:03.809117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778cf00 of size 256 next 602\n",
      "2023-09-22 01:34:03.809126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778d000 of size 256 next 599\n",
      "2023-09-22 01:34:03.809136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778d100 of size 1024 next 1057\n",
      "2023-09-22 01:34:03.809148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778d500 of size 2048 next 658\n",
      "2023-09-22 01:34:03.809161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778dd00 of size 2048 next 1416\n",
      "2023-09-22 01:34:03.809171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124778e500 of size 8192 next 1477\n",
      "2023-09-22 01:34:03.809181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247790500 of size 8192 next 1656\n",
      "2023-09-22 01:34:03.809190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247792500 of size 8192 next 1486\n",
      "2023-09-22 01:34:03.809201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247794500 of size 8192 next 307\n",
      "2023-09-22 01:34:03.809214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247796500 of size 8192 next 380\n",
      "2023-09-22 01:34:03.809226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247798500 of size 8192 next 1651\n",
      "2023-09-22 01:34:03.809235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124779a500 of size 8192 next 1170\n",
      "2023-09-22 01:34:03.809245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124779c500 of size 8192 next 1172\n",
      "2023-09-22 01:34:03.809255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124779e500 of size 8192 next 1102\n",
      "2023-09-22 01:34:03.809268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477a0500 of size 8192 next 1695\n",
      "2023-09-22 01:34:03.809281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477a2500 of size 10496 next 518\n",
      "2023-09-22 01:34:03.809291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477a4e00 of size 8192 next 1228\n",
      "2023-09-22 01:34:03.809301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477a6e00 of size 9216 next 89\n",
      "2023-09-22 01:34:03.809310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477a9200 of size 8192 next 1135\n",
      "2023-09-22 01:34:03.809320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ab200 of size 9216 next 409\n",
      "2023-09-22 01:34:03.809333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ad600 of size 8192 next 90\n",
      "2023-09-22 01:34:03.809345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477af600 of size 9216 next 1622\n",
      "2023-09-22 01:34:03.809354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477b1a00 of size 8192 next 68\n",
      "2023-09-22 01:34:03.809364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477b3a00 of size 8192 next 102\n",
      "2023-09-22 01:34:03.809375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477b5a00 of size 8192 next 437\n",
      "2023-09-22 01:34:03.809388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477b7a00 of size 9216 next 979\n",
      "2023-09-22 01:34:03.809400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477b9e00 of size 256 next 443\n",
      "2023-09-22 01:34:03.809410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477b9f00 of size 256 next 1076\n",
      "2023-09-22 01:34:03.809420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba000 of size 512 next 51\n",
      "2023-09-22 01:34:03.809432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba200 of size 512 next 1273\n",
      "2023-09-22 01:34:03.809445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba400 of size 256 next 608\n",
      "2023-09-22 01:34:03.809454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba500 of size 256 next 292\n",
      "2023-09-22 01:34:03.809464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba600 of size 256 next 1596\n",
      "2023-09-22 01:34:03.809474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba700 of size 256 next 868\n",
      "2023-09-22 01:34:03.809487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba800 of size 256 next 782\n",
      "2023-09-22 01:34:03.809501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ba900 of size 256 next 795\n",
      "2023-09-22 01:34:03.809510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477baa00 of size 256 next 196\n",
      "2023-09-22 01:34:03.809521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bab00 of size 256 next 450\n",
      "2023-09-22 01:34:03.809531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bac00 of size 256 next 1248\n",
      "2023-09-22 01:34:03.809542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bad00 of size 256 next 960\n",
      "2023-09-22 01:34:03.809556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bae00 of size 512 next 1109\n",
      "2023-09-22 01:34:03.809566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb000 of size 768 next 1229\n",
      "2023-09-22 01:34:03.809574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb300 of size 256 next 180\n",
      "2023-09-22 01:34:03.809581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb400 of size 256 next 120\n",
      "2023-09-22 01:34:03.809591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb500 of size 256 next 424\n",
      "2023-09-22 01:34:03.809603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb600 of size 256 next 775\n",
      "2023-09-22 01:34:03.809616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb700 of size 256 next 1496\n",
      "2023-09-22 01:34:03.809627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb800 of size 256 next 1402\n",
      "2023-09-22 01:34:03.809637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bb900 of size 256 next 1037\n",
      "2023-09-22 01:34:03.809646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bba00 of size 256 next 805\n",
      "2023-09-22 01:34:03.809657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bbb00 of size 256 next 446\n",
      "2023-09-22 01:34:03.809671: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bbc00 of size 8192 next 640\n",
      "2023-09-22 01:34:03.809682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477bdc00 of size 9216 next 1401\n",
      "2023-09-22 01:34:03.809692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477c0000 of size 8192 next 1636\n",
      "2023-09-22 01:34:03.809702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477c2000 of size 9216 next 255\n",
      "2023-09-22 01:34:03.809711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477c4400 of size 8192 next 1331\n",
      "2023-09-22 01:34:03.809721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477c6400 of size 14848 next 1074\n",
      "2023-09-22 01:34:03.809735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477c9e00 of size 2048 next 1390\n",
      "2023-09-22 01:34:03.809748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ca600 of size 512 next 1234\n",
      "2023-09-22 01:34:03.809757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ca800 of size 512 next 1121\n",
      "2023-09-22 01:34:03.809767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477caa00 of size 256 next 879\n",
      "2023-09-22 01:34:03.809776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cab00 of size 256 next 877\n",
      "2023-09-22 01:34:03.809787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cac00 of size 512 next 139\n",
      "2023-09-22 01:34:03.809801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cae00 of size 512 next 743\n",
      "2023-09-22 01:34:03.809812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cb000 of size 2048 next 81\n",
      "2023-09-22 01:34:03.809822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cb800 of size 2048 next 675\n",
      "2023-09-22 01:34:03.809831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc000 of size 256 next 402\n",
      "2023-09-22 01:34:03.809841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc100 of size 256 next 1639\n",
      "2023-09-22 01:34:03.809854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc200 of size 256 next 1320\n",
      "2023-09-22 01:34:03.809866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc300 of size 256 next 200\n",
      "2023-09-22 01:34:03.809875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc400 of size 256 next 790\n",
      "2023-09-22 01:34:03.809885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc500 of size 256 next 1050\n",
      "2023-09-22 01:34:03.809896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc600 of size 768 next 1700\n",
      "2023-09-22 01:34:03.809909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc900 of size 256 next 949\n",
      "2023-09-22 01:34:03.809921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cca00 of size 256 next 1247\n",
      "2023-09-22 01:34:03.809930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ccb00 of size 1024 next 1225\n",
      "2023-09-22 01:34:03.809940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ccf00 of size 512 next 641\n",
      "2023-09-22 01:34:03.809949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cd100 of size 1024 next 208\n",
      "2023-09-22 01:34:03.809962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cd500 of size 1024 next 1564\n",
      "2023-09-22 01:34:03.809975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cd900 of size 1024 next 1035\n",
      "2023-09-22 01:34:03.809985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cdd00 of size 1792 next 1215\n",
      "2023-09-22 01:34:03.809996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ce400 of size 256 next 367\n",
      "2023-09-22 01:34:03.810007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ce500 of size 256 next 570\n",
      "2023-09-22 01:34:03.810020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ce600 of size 256 next 767\n",
      "2023-09-22 01:34:03.810032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ce700 of size 256 next 1599\n",
      "2023-09-22 01:34:03.810042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ce800 of size 256 next 728\n",
      "2023-09-22 01:34:03.810052: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ce900 of size 256 next 656\n",
      "2023-09-22 01:34:03.810063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cea00 of size 256 next 834\n",
      "2023-09-22 01:34:03.810076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ceb00 of size 256 next 132\n",
      "2023-09-22 01:34:03.810087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cec00 of size 256 next 359\n",
      "2023-09-22 01:34:03.810097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ced00 of size 256 next 1558\n",
      "2023-09-22 01:34:03.810106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cee00 of size 256 next 1482\n",
      "2023-09-22 01:34:03.810118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cef00 of size 256 next 1221\n",
      "2023-09-22 01:34:03.810132: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf000 of size 256 next 53\n",
      "2023-09-22 01:34:03.810142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf100 of size 256 next 258\n",
      "2023-09-22 01:34:03.810152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf200 of size 256 next 1413\n",
      "2023-09-22 01:34:03.810162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf300 of size 256 next 169\n",
      "2023-09-22 01:34:03.810173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf400 of size 256 next 377\n",
      "2023-09-22 01:34:03.810187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf500 of size 256 next 542\n",
      "2023-09-22 01:34:03.810197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf600 of size 256 next 1197\n",
      "2023-09-22 01:34:03.810207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf700 of size 256 next 91\n",
      "2023-09-22 01:34:03.810214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf800 of size 256 next 559\n",
      "2023-09-22 01:34:03.810223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cf900 of size 256 next 1209\n",
      "2023-09-22 01:34:03.810235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cfa00 of size 256 next 1303\n",
      "2023-09-22 01:34:03.810248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cfb00 of size 256 next 803\n",
      "2023-09-22 01:34:03.810259: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cfc00 of size 256 next 622\n",
      "2023-09-22 01:34:03.810268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cfd00 of size 256 next 1671\n",
      "2023-09-22 01:34:03.810278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cfe00 of size 256 next 144\n",
      "2023-09-22 01:34:03.810287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cff00 of size 256 next 677\n",
      "2023-09-22 01:34:03.810300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0000 of size 256 next 1667\n",
      "2023-09-22 01:34:03.810313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0100 of size 256 next 330\n",
      "2023-09-22 01:34:03.810323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0200 of size 256 next 20\n",
      "2023-09-22 01:34:03.810333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0300 of size 256 next 1444\n",
      "2023-09-22 01:34:03.810342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0400 of size 256 next 627\n",
      "2023-09-22 01:34:03.810355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0500 of size 256 next 945\n",
      "2023-09-22 01:34:03.810368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0600 of size 256 next 943\n",
      "2023-09-22 01:34:03.810377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0700 of size 256 next 1559\n",
      "2023-09-22 01:34:03.810386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0800 of size 256 next 1565\n",
      "2023-09-22 01:34:03.810396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0900 of size 256 next 1528\n",
      "2023-09-22 01:34:03.810409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0a00 of size 256 next 1702\n",
      "2023-09-22 01:34:03.810422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0b00 of size 256 next 1169\n",
      "2023-09-22 01:34:03.810432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0c00 of size 256 next 817\n",
      "2023-09-22 01:34:03.810441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0d00 of size 256 next 47\n",
      "2023-09-22 01:34:03.810451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0e00 of size 256 next 1417\n",
      "2023-09-22 01:34:03.810464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0f00 of size 256 next 621\n",
      "2023-09-22 01:34:03.810476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d1000 of size 256 next 1675\n",
      "2023-09-22 01:34:03.810485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d1100 of size 256 next 1168\n",
      "2023-09-22 01:34:03.810495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d1200 of size 256 next 294\n",
      "2023-09-22 01:34:03.810505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d1300 of size 256 next 1238\n",
      "2023-09-22 01:34:03.810518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d1400 of size 512 next 445\n",
      "2023-09-22 01:34:03.810530: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d1600 of size 512 next 349\n",
      "2023-09-22 01:34:03.810540: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d1800 of size 2048 next 1299\n",
      "2023-09-22 01:34:03.810549: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d2000 of size 2048 next 993\n",
      "2023-09-22 01:34:03.810559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d2800 of size 2048 next 1250\n",
      "2023-09-22 01:34:03.810570: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d3000 of size 2048 next 583\n",
      "2023-09-22 01:34:03.810583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d3800 of size 8192 next 1283\n",
      "2023-09-22 01:34:03.810594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d5800 of size 8192 next 613\n",
      "2023-09-22 01:34:03.810605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d7800 of size 8192 next 1025\n",
      "2023-09-22 01:34:03.810616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9800 of size 8192 next 1258\n",
      "2023-09-22 01:34:03.810627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477db800 of size 8192 next 543\n",
      "2023-09-22 01:34:03.810640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477dd800 of size 11264 next 306\n",
      "2023-09-22 01:34:03.810653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e0400 of size 11264 next 1007\n",
      "2023-09-22 01:34:03.810662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e3000 of size 11264 next 419\n",
      "2023-09-22 01:34:03.810672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e5c00 of size 15104 next 918\n",
      "2023-09-22 01:34:03.810684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9700 of size 256 next 440\n",
      "2023-09-22 01:34:03.810697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9800 of size 256 next 999\n",
      "2023-09-22 01:34:03.810708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12477e9900 of size 1522688 next 466\n",
      "2023-09-22 01:34:03.810718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124795d500 of size 11264 next 532\n",
      "2023-09-22 01:34:03.810727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247960100 of size 14336 next 1010\n",
      "2023-09-22 01:34:03.810737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247963900 of size 512 next 1180\n",
      "2023-09-22 01:34:03.810749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247963b00 of size 512 next 681\n",
      "2023-09-22 01:34:03.810762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247963d00 of size 131072 next 1448\n",
      "2023-09-22 01:34:03.810773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247983d00 of size 131072 next 1351\n",
      "2023-09-22 01:34:03.810782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a3d00 of size 1024 next 686\n",
      "2023-09-22 01:34:03.810791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a4100 of size 1024 next 322\n",
      "2023-09-22 01:34:03.810801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a4500 of size 1024 next 1344\n",
      "2023-09-22 01:34:03.810813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a4900 of size 1024 next 519\n",
      "2023-09-22 01:34:03.810826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a4d00 of size 1024 next 1067\n",
      "2023-09-22 01:34:03.810836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a5100 of size 1024 next 1063\n",
      "2023-09-22 01:34:03.810845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a5500 of size 131072 next 1403\n",
      "2023-09-22 01:34:03.810854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479c5500 of size 131072 next 1517\n",
      "2023-09-22 01:34:03.810867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e5500 of size 512 next 1555\n",
      "2023-09-22 01:34:03.810879: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e5700 of size 512 next 145\n",
      "2023-09-22 01:34:03.810889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e5900 of size 512 next 223\n",
      "2023-09-22 01:34:03.810898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e5b00 of size 512 next 1319\n",
      "2023-09-22 01:34:03.810908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e5d00 of size 256 next 1097\n",
      "2023-09-22 01:34:03.810920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e5e00 of size 256 next 1600\n",
      "2023-09-22 01:34:03.810933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e5f00 of size 256 next 177\n",
      "2023-09-22 01:34:03.810943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6000 of size 256 next 249\n",
      "2023-09-22 01:34:03.810953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6100 of size 256 next 1036\n",
      "2023-09-22 01:34:03.810963: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6200 of size 256 next 963\n",
      "2023-09-22 01:34:03.810975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6300 of size 256 next 1081\n",
      "2023-09-22 01:34:03.810988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6400 of size 256 next 253\n",
      "2023-09-22 01:34:03.810997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6500 of size 256 next 280\n",
      "2023-09-22 01:34:03.811007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6600 of size 256 next 1028\n",
      "2023-09-22 01:34:03.811016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6700 of size 256 next 282\n",
      "2023-09-22 01:34:03.811028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6800 of size 256 next 1190\n",
      "2023-09-22 01:34:03.811041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6900 of size 256 next 768\n",
      "2023-09-22 01:34:03.811051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6a00 of size 256 next 1119\n",
      "2023-09-22 01:34:03.811060: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6b00 of size 256 next 331\n",
      "2023-09-22 01:34:03.811070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6c00 of size 256 next 1476\n",
      "2023-09-22 01:34:03.811084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6d00 of size 256 next 317\n",
      "2023-09-22 01:34:03.811096: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6e00 of size 256 next 1650\n",
      "2023-09-22 01:34:03.811106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6f00 of size 256 next 800\n",
      "2023-09-22 01:34:03.811115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7000 of size 256 next 1681\n",
      "2023-09-22 01:34:03.811124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7100 of size 256 next 417\n",
      "2023-09-22 01:34:03.811136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7200 of size 256 next 788\n",
      "2023-09-22 01:34:03.811160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7300 of size 256 next 813\n",
      "2023-09-22 01:34:03.811170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7400 of size 256 next 1005\n",
      "2023-09-22 01:34:03.811181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7500 of size 1024 next 696\n",
      "2023-09-22 01:34:03.811189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7900 of size 256 next 338\n",
      "2023-09-22 01:34:03.811201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7a00 of size 256 next 1589\n",
      "2023-09-22 01:34:03.811215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7b00 of size 256 next 429\n",
      "2023-09-22 01:34:03.811226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7c00 of size 256 next 1257\n",
      "2023-09-22 01:34:03.811236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7d00 of size 256 next 334\n",
      "2023-09-22 01:34:03.811247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7e00 of size 256 next 373\n",
      "2023-09-22 01:34:03.811257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e7f00 of size 256 next 1235\n",
      "2023-09-22 01:34:03.811270: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8000 of size 256 next 1092\n",
      "2023-09-22 01:34:03.811282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8100 of size 256 next 228\n",
      "2023-09-22 01:34:03.811292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8200 of size 256 next 991\n",
      "2023-09-22 01:34:03.811301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8300 of size 256 next 1327\n",
      "2023-09-22 01:34:03.811311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8400 of size 256 next 536\n",
      "2023-09-22 01:34:03.811324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8500 of size 256 next 1435\n",
      "2023-09-22 01:34:03.811337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8600 of size 256 next 1284\n",
      "2023-09-22 01:34:03.811346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8700 of size 256 next 1704\n",
      "2023-09-22 01:34:03.811356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8800 of size 256 next 649\n",
      "2023-09-22 01:34:03.811366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8900 of size 256 next 930\n",
      "2023-09-22 01:34:03.811376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8a00 of size 256 next 1099\n",
      "2023-09-22 01:34:03.811389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8b00 of size 256 next 581\n",
      "2023-09-22 01:34:03.811401: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8c00 of size 256 next 1329\n",
      "2023-09-22 01:34:03.811410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8d00 of size 256 next 1434\n",
      "2023-09-22 01:34:03.811420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8e00 of size 256 next 388\n",
      "2023-09-22 01:34:03.811429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e8f00 of size 256 next 1372\n",
      "2023-09-22 01:34:03.811442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e9000 of size 256 next 1508\n",
      "2023-09-22 01:34:03.811455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12479e9100 of size 256 next 1101\n",
      "2023-09-22 01:34:03.811464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e9200 of size 256 next 1260\n",
      "2023-09-22 01:34:03.811475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e9300 of size 256 next 1595\n",
      "2023-09-22 01:34:03.811484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12479e9400 of size 15104 next 1581\n",
      "2023-09-22 01:34:03.811497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479ecf00 of size 256 next 1464\n",
      "2023-09-22 01:34:03.811510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479ed000 of size 508160 next 1048\n",
      "2023-09-22 01:34:03.811520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69100 of size 256 next 1393\n",
      "2023-09-22 01:34:03.811529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69200 of size 256 next 184\n",
      "2023-09-22 01:34:03.811539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69300 of size 131072 next 87\n",
      "2023-09-22 01:34:03.811548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a89300 of size 131072 next 1312\n",
      "2023-09-22 01:34:03.811560: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247aa9300 of size 147712 next 227\n",
      "2023-09-22 01:34:03.811573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247acd400 of size 256 next 1315\n",
      "2023-09-22 01:34:03.811584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247acd500 of size 2097152 next 626\n",
      "2023-09-22 01:34:03.811594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ccd500 of size 4182016 next 1295\n",
      "2023-09-22 01:34:03.811604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca500 of size 256 next 671\n",
      "2023-09-22 01:34:03.811613: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca600 of size 256 next 1061\n",
      "2023-09-22 01:34:03.811626: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca700 of size 256 next 1514\n",
      "2023-09-22 01:34:03.811639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca800 of size 82051072 next 798\n",
      "2023-09-22 01:34:03.811648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124cf0a800 of size 20512768 next 198\n",
      "2023-09-22 01:34:03.811658: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124e29a800 of size 129023744 next 514\n",
      "2023-09-22 01:34:03.811669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6700 of size 256 next 284\n",
      "2023-09-22 01:34:03.811682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6800 of size 256 next 796\n",
      "2023-09-22 01:34:03.811694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6900 of size 320512 next 888\n",
      "2023-09-22 01:34:03.811704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255df4d00 of size 320512 next 175\n",
      "2023-09-22 01:34:03.811714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e43100 of size 320512 next 562\n",
      "2023-09-22 01:34:03.811726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e91500 of size 409856 next 673\n",
      "2023-09-22 01:34:03.811739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5600 of size 256 next 1259\n",
      "2023-09-22 01:34:03.811750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5700 of size 2048 next 903\n",
      "2023-09-22 01:34:03.811759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5f00 of size 2048 next 984\n",
      "2023-09-22 01:34:03.811769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6700 of size 256 next 405\n",
      "2023-09-22 01:34:03.811781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6800 of size 512 next 900\n",
      "2023-09-22 01:34:03.811794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6a00 of size 512 next 912\n",
      "2023-09-22 01:34:03.811805: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6c00 of size 256 next 1137\n",
      "2023-09-22 01:34:03.811815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6d00 of size 512 next 639\n",
      "2023-09-22 01:34:03.811824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6f00 of size 512 next 1003\n",
      "2023-09-22 01:34:03.811832: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7100 of size 768 next 332\n",
      "2023-09-22 01:34:03.811846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7400 of size 256 next 173\n",
      "2023-09-22 01:34:03.811858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7500 of size 256 next 520\n",
      "2023-09-22 01:34:03.811867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7600 of size 256 next 214\n",
      "2023-09-22 01:34:03.811877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7700 of size 3328 next 1573\n",
      "2023-09-22 01:34:03.811887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8400 of size 512 next 733\n",
      "2023-09-22 01:34:03.811900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8600 of size 256 next 1485\n",
      "2023-09-22 01:34:03.811912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8700 of size 256 next 161\n",
      "2023-09-22 01:34:03.811922: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8800 of size 256 next 456\n",
      "2023-09-22 01:34:03.811932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8900 of size 256 next 791\n",
      "2023-09-22 01:34:03.811942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8a00 of size 256 next 1683\n",
      "2023-09-22 01:34:03.811955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8b00 of size 256 next 1270\n",
      "2023-09-22 01:34:03.811967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8c00 of size 256 next 1085\n",
      "2023-09-22 01:34:03.811977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8d00 of size 256 next 566\n",
      "2023-09-22 01:34:03.811986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8e00 of size 256 next 1605\n",
      "2023-09-22 01:34:03.811996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8f00 of size 256 next 676\n",
      "2023-09-22 01:34:03.812006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9000 of size 256 next 666\n",
      "2023-09-22 01:34:03.812019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9100 of size 256 next 313\n",
      "2023-09-22 01:34:03.812031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9200 of size 256 next 1117\n",
      "2023-09-22 01:34:03.812041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9300 of size 9728 next 1027\n",
      "2023-09-22 01:34:03.812053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb900 of size 256 next 624\n",
      "2023-09-22 01:34:03.812064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efba00 of size 512 next 906\n",
      "2023-09-22 01:34:03.812078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbc00 of size 512 next 651\n",
      "2023-09-22 01:34:03.812088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbe00 of size 512 next 1688\n",
      "2023-09-22 01:34:03.812097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc000 of size 256 next 913\n",
      "2023-09-22 01:34:03.812106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc100 of size 256 next 1292\n",
      "2023-09-22 01:34:03.812119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc200 of size 512 next 1348\n",
      "2023-09-22 01:34:03.812132: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc400 of size 1536 next 1004\n",
      "2023-09-22 01:34:03.812141: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efca00 of size 256 next 778\n",
      "2023-09-22 01:34:03.812151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efcb00 of size 256 next 492\n",
      "2023-09-22 01:34:03.812161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efcc00 of size 256 next 886\n",
      "2023-09-22 01:34:03.812174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efcd00 of size 256 next 933\n",
      "2023-09-22 01:34:03.812187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efce00 of size 256 next 820\n",
      "2023-09-22 01:34:03.812195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efcf00 of size 256 next 1442\n",
      "2023-09-22 01:34:03.812204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd000 of size 256 next 540\n",
      "2023-09-22 01:34:03.812214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd100 of size 256 next 683\n",
      "2023-09-22 01:34:03.812226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd200 of size 256 next 1296\n",
      "2023-09-22 01:34:03.812239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd300 of size 2097152 next 982\n",
      "2023-09-22 01:34:03.812249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12560fd300 of size 2097152 next 828\n",
      "2023-09-22 01:34:03.812258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12562fd300 of size 2097152 next 1449\n",
      "2023-09-22 01:34:03.812268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12564fd300 of size 2097152 next 678\n",
      "2023-09-22 01:34:03.812280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12566fd300 of size 2097152 next 637\n",
      "2023-09-22 01:34:03.812294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12568fd300 of size 2097152 next 1418\n",
      "2023-09-22 01:34:03.812303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1256afd300 of size 2097152 next 708\n",
      "2023-09-22 01:34:03.812313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1256cfd300 of size 2097152 next 1603\n",
      "2023-09-22 01:34:03.812322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1256efd300 of size 2097152 next 1011\n",
      "2023-09-22 01:34:03.812332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12570fd300 of size 2097152 next 279\n",
      "2023-09-22 01:34:03.812346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12572fd300 of size 4014080 next 1634\n",
      "2023-09-22 01:34:03.812357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1300 of size 256 next 780\n",
      "2023-09-22 01:34:03.812367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1400 of size 501639936 next 972\n",
      "2023-09-22 01:34:03.812377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537f00 of size 256 next 929\n",
      "2023-09-22 01:34:03.812386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538000 of size 256 next 940\n",
      "2023-09-22 01:34:03.812399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538100 of size 2048 next 964\n",
      "2023-09-22 01:34:03.812412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538900 of size 2048 next 155\n",
      "2023-09-22 01:34:03.812421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539100 of size 256 next 1144\n",
      "2023-09-22 01:34:03.812431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539200 of size 256 next 1680\n",
      "2023-09-22 01:34:03.812440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539300 of size 256 next 547\n",
      "2023-09-22 01:34:03.812453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539400 of size 256 next 1231\n",
      "2023-09-22 01:34:03.812466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539500 of size 512 next 82\n",
      "2023-09-22 01:34:03.812475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539700 of size 256 next 1141\n",
      "2023-09-22 01:34:03.812484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539800 of size 256 next 1151\n",
      "2023-09-22 01:34:03.812494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539900 of size 256 next 818\n",
      "2023-09-22 01:34:03.812503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539a00 of size 256 next 1317\n",
      "2023-09-22 01:34:03.812515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539b00 of size 512 next 1066\n",
      "2023-09-22 01:34:03.812529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539d00 of size 256 next 1379\n",
      "2023-09-22 01:34:03.812539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539e00 of size 256 next 302\n",
      "2023-09-22 01:34:03.812547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539f00 of size 256 next 1016\n",
      "2023-09-22 01:34:03.812556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a000 of size 256 next 1237\n",
      "2023-09-22 01:34:03.812567: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a100 of size 256 next 1191\n",
      "2023-09-22 01:34:03.812579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a200 of size 256 next 1472\n",
      "2023-09-22 01:34:03.812591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a300 of size 256 next 1465\n",
      "2023-09-22 01:34:03.812601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a400 of size 256 next 355\n",
      "2023-09-22 01:34:03.812611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a500 of size 256 next 709\n",
      "2023-09-22 01:34:03.812622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a600 of size 256 next 397\n",
      "2023-09-22 01:34:03.812635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a700 of size 256 next 1179\n",
      "2023-09-22 01:34:03.812646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a800 of size 256 next 771\n",
      "2023-09-22 01:34:03.812656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a900 of size 249344 next 1093\n",
      "2023-09-22 01:34:03.812666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577700 of size 256 next 1255\n",
      "2023-09-22 01:34:03.812678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577800 of size 320512 next 885\n",
      "2023-09-22 01:34:03.812691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c5c00 of size 320512 next 576\n",
      "2023-09-22 01:34:03.812701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275614000 of size 439040 next 582\n",
      "2023-09-22 01:34:03.812711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f300 of size 256 next 801\n",
      "2023-09-22 01:34:03.812721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f400 of size 256 next 1015\n",
      "2023-09-22 01:34:03.812733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f500 of size 256 next 58\n",
      "2023-09-22 01:34:03.812746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f600 of size 256 next 245\n",
      "2023-09-22 01:34:03.812758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f700 of size 256 next 704\n",
      "2023-09-22 01:34:03.812767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f800 of size 256 next 73\n",
      "2023-09-22 01:34:03.812777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567f900 of size 512 next 1288\n",
      "2023-09-22 01:34:03.812786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567fb00 of size 512 next 1541\n",
      "2023-09-22 01:34:03.812799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567fd00 of size 512 next 1146\n",
      "2023-09-22 01:34:03.812812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127567ff00 of size 256 next 1142\n",
      "2023-09-22 01:34:03.812822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275680000 of size 256 next 538\n",
      "2023-09-22 01:34:03.812831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275680100 of size 512 next 219\n",
      "2023-09-22 01:34:03.812842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275680300 of size 2048 next 838\n",
      "2023-09-22 01:34:03.812855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275680b00 of size 2048 next 119\n",
      "2023-09-22 01:34:03.812866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275681300 of size 8192 next 1516\n",
      "2023-09-22 01:34:03.812874: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683300 of size 256 next 1106\n",
      "2023-09-22 01:34:03.812883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683400 of size 256 next 435\n",
      "2023-09-22 01:34:03.812893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683500 of size 256 next 129\n",
      "2023-09-22 01:34:03.812906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683600 of size 256 next 1608\n",
      "2023-09-22 01:34:03.812918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683700 of size 512 next 1380\n",
      "2023-09-22 01:34:03.812928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683900 of size 512 next 1239\n",
      "2023-09-22 01:34:03.812938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683b00 of size 256 next 947\n",
      "2023-09-22 01:34:03.812949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683c00 of size 256 next 833\n",
      "2023-09-22 01:34:03.812962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683d00 of size 512 next 154\n",
      "2023-09-22 01:34:03.812973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275683f00 of size 512 next 936\n",
      "2023-09-22 01:34:03.812983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684100 of size 256 next 427\n",
      "2023-09-22 01:34:03.812993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684200 of size 256 next 1131\n",
      "2023-09-22 01:34:03.813004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684300 of size 256 next 807\n",
      "2023-09-22 01:34:03.813017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684400 of size 256 next 1562\n",
      "2023-09-22 01:34:03.813028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684500 of size 256 next 779\n",
      "2023-09-22 01:34:03.813037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684600 of size 256 next 1661\n",
      "2023-09-22 01:34:03.813046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684700 of size 256 next 1034\n",
      "2023-09-22 01:34:03.813055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684800 of size 256 next 574\n",
      "2023-09-22 01:34:03.813068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684900 of size 256 next 620\n",
      "2023-09-22 01:34:03.813081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684a00 of size 256 next 839\n",
      "2023-09-22 01:34:03.813090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684b00 of size 512 next 448\n",
      "2023-09-22 01:34:03.813100: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275684d00 of size 1536 next 941\n",
      "2023-09-22 01:34:03.813110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275685300 of size 11264 next 9\n",
      "2023-09-22 01:34:03.813123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275687f00 of size 11264 next 715\n",
      "2023-09-22 01:34:03.813136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127568ab00 of size 2048 next 186\n",
      "2023-09-22 01:34:03.813145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127568b300 of size 2048 next 1132\n",
      "2023-09-22 01:34:03.813155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127568bb00 of size 1024 next 1171\n",
      "2023-09-22 01:34:03.813164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127568bf00 of size 1024 next 527\n",
      "2023-09-22 01:34:03.813176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127568c300 of size 2048 next 832\n",
      "2023-09-22 01:34:03.813189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127568cb00 of size 3072 next 480\n",
      "2023-09-22 01:34:03.813199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127568d700 of size 11264 next 1407\n",
      "2023-09-22 01:34:03.813209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275690300 of size 11264 next 1149\n",
      "2023-09-22 01:34:03.813219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275692f00 of size 11264 next 1544\n",
      "2023-09-22 01:34:03.813231: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275695b00 of size 11264 next 996\n",
      "2023-09-22 01:34:03.813245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275698700 of size 8448 next 420\n",
      "2023-09-22 01:34:03.813255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127569a800 of size 8448 next 1428\n",
      "2023-09-22 01:34:03.813264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127569c900 of size 8448 next 956\n",
      "2023-09-22 01:34:03.813274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127569ea00 of size 8192 next 19\n",
      "2023-09-22 01:34:03.813287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a0a00 of size 8192 next 835\n",
      "2023-09-22 01:34:03.813299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a2a00 of size 8192 next 847\n",
      "2023-09-22 01:34:03.813309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a4a00 of size 15872 next 474\n",
      "2023-09-22 01:34:03.813318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8800 of size 256 next 859\n",
      "2023-09-22 01:34:03.813330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8900 of size 256 next 24\n",
      "2023-09-22 01:34:03.813343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8a00 of size 17920 next 682\n",
      "2023-09-22 01:34:03.813356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad000 of size 256 next 836\n",
      "2023-09-22 01:34:03.813366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad100 of size 256 next 659\n",
      "2023-09-22 01:34:03.813376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad200 of size 256 next 276\n",
      "2023-09-22 01:34:03.813385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad300 of size 256 next 531\n",
      "2023-09-22 01:34:03.813397: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad400 of size 256 next 897\n",
      "2023-09-22 01:34:03.813410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad500 of size 256 next 93\n",
      "2023-09-22 01:34:03.813421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad600 of size 256 next 928\n",
      "2023-09-22 01:34:03.813431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad700 of size 1263600128 next 1502\n",
      "2023-09-22 01:34:03.813440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c0bbd900 of size 82051072 next 1691\n",
      "2023-09-22 01:34:03.813452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12c59fd900 of size 391219712 next 863\n",
      "2023-09-22 01:34:03.813465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16300 of size 256 next 867\n",
      "2023-09-22 01:34:03.813476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16400 of size 8192 next 824\n",
      "2023-09-22 01:34:03.813485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18400 of size 256 next 1490\n",
      "2023-09-22 01:34:03.813495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18500 of size 256 next 1111\n",
      "2023-09-22 01:34:03.813508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18600 of size 21248 next 948\n",
      "2023-09-22 01:34:03.813521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d900 of size 8448 next 978\n",
      "2023-09-22 01:34:03.813531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1fa00 of size 14080 next 1666\n",
      "2023-09-22 01:34:03.813540: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf23100 of size 11264 next 499\n",
      "2023-09-22 01:34:03.813550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf25d00 of size 11264 next 829\n",
      "2023-09-22 01:34:03.813561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf28900 of size 11264 next 855\n",
      "2023-09-22 01:34:03.813574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf2b500 of size 19456 next 78\n",
      "2023-09-22 01:34:03.813586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf30100 of size 8192 next 1352\n",
      "2023-09-22 01:34:03.813595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf32100 of size 8192 next 1649\n",
      "2023-09-22 01:34:03.813605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf34100 of size 8192 next 975\n",
      "2023-09-22 01:34:03.813617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf36100 of size 8192 next 934\n",
      "2023-09-22 01:34:03.813630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf38100 of size 8192 next 1479\n",
      "2023-09-22 01:34:03.813639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3a100 of size 8192 next 1415\n",
      "2023-09-22 01:34:03.813649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3c100 of size 2048 next 891\n",
      "2023-09-22 01:34:03.813659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3c900 of size 2048 next 1615\n",
      "2023-09-22 01:34:03.813670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3d100 of size 1024 next 442\n",
      "2023-09-22 01:34:03.813684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3d500 of size 1024 next 1463\n",
      "2023-09-22 01:34:03.813694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3d900 of size 1536 next 854\n",
      "2023-09-22 01:34:03.813704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3df00 of size 512 next 1374\n",
      "2023-09-22 01:34:03.813714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e100 of size 256 next 753\n",
      "2023-09-22 01:34:03.813724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e200 of size 256 next 908\n",
      "2023-09-22 01:34:03.813737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e300 of size 256 next 8\n",
      "2023-09-22 01:34:03.813749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e400 of size 256 next 1587\n",
      "2023-09-22 01:34:03.813759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e500 of size 256 next 52\n",
      "2023-09-22 01:34:03.813769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e600 of size 256 next 1357\n",
      "2023-09-22 01:34:03.813779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e700 of size 256 next 1112\n",
      "2023-09-22 01:34:03.813792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e800 of size 256 next 299\n",
      "2023-09-22 01:34:03.813805: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3e900 of size 256 next 914\n",
      "2023-09-22 01:34:03.813815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3ea00 of size 256 next 1460\n",
      "2023-09-22 01:34:03.813825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3eb00 of size 256 next 457\n",
      "2023-09-22 01:34:03.813835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3ec00 of size 256 next 1693\n",
      "2023-09-22 01:34:03.813848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3ed00 of size 256 next 423\n",
      "2023-09-22 01:34:03.813861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3ee00 of size 256 next 486\n",
      "2023-09-22 01:34:03.813870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3ef00 of size 256 next 901\n",
      "2023-09-22 01:34:03.813880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3f000 of size 256 next 60\n",
      "2023-09-22 01:34:03.813889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3f100 of size 256 next 357\n",
      "2023-09-22 01:34:03.813901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3f200 of size 12288 next 837\n",
      "2023-09-22 01:34:03.813916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf42200 of size 14336 next 862\n",
      "2023-09-22 01:34:03.813926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf45a00 of size 2048 next 1249\n",
      "2023-09-22 01:34:03.813936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf46200 of size 2048 next 968\n",
      "2023-09-22 01:34:03.813944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf46a00 of size 2048 next 521\n",
      "2023-09-22 01:34:03.813954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf47200 of size 2048 next 1281\n",
      "2023-09-22 01:34:03.813967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf47a00 of size 8192 next 370\n",
      "2023-09-22 01:34:03.813978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf49a00 of size 8192 next 1347\n",
      "2023-09-22 01:34:03.813988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf4ba00 of size 8192 next 1088\n",
      "2023-09-22 01:34:03.813997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf4da00 of size 8192 next 1330\n",
      "2023-09-22 01:34:03.814009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf4fa00 of size 8192 next 382\n",
      "2023-09-22 01:34:03.814022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf51a00 of size 8192 next 131\n",
      "2023-09-22 01:34:03.814033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf53a00 of size 8192 next 873\n",
      "2023-09-22 01:34:03.814043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf55a00 of size 8192 next 217\n",
      "2023-09-22 01:34:03.814053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf57a00 of size 9216 next 1345\n",
      "2023-09-22 01:34:03.814063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf59e00 of size 512 next 665\n",
      "2023-09-22 01:34:03.814076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a000 of size 512 next 1598\n",
      "2023-09-22 01:34:03.814088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a200 of size 512 next 1642\n",
      "2023-09-22 01:34:03.814097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a400 of size 256 next 1459\n",
      "2023-09-22 01:34:03.814107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a500 of size 256 next 1182\n",
      "2023-09-22 01:34:03.814116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a600 of size 256 next 1124\n",
      "2023-09-22 01:34:03.814129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a700 of size 256 next 572\n",
      "2023-09-22 01:34:03.814142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a800 of size 256 next 371\n",
      "2023-09-22 01:34:03.814151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5a900 of size 256 next 846\n",
      "2023-09-22 01:34:03.814160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5aa00 of size 256 next 1193\n",
      "2023-09-22 01:34:03.814170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5ab00 of size 256 next 212\n",
      "2023-09-22 01:34:03.814183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5ac00 of size 256 next 166\n",
      "2023-09-22 01:34:03.814195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5ad00 of size 256 next 1504\n",
      "2023-09-22 01:34:03.814205: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5ae00 of size 512 next 193\n",
      "2023-09-22 01:34:03.814215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b000 of size 512 next 564\n",
      "2023-09-22 01:34:03.814225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b200 of size 256 next 1640\n",
      "2023-09-22 01:34:03.814237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b300 of size 256 next 336\n",
      "2023-09-22 01:34:03.814250: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b400 of size 256 next 1406\n",
      "2023-09-22 01:34:03.814259: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b500 of size 256 next 973\n",
      "2023-09-22 01:34:03.814269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b600 of size 256 next 958\n",
      "2023-09-22 01:34:03.814279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b700 of size 256 next 577\n",
      "2023-09-22 01:34:03.814288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b800 of size 256 next 66\n",
      "2023-09-22 01:34:03.814297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5b900 of size 256 next 1192\n",
      "2023-09-22 01:34:03.814310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5ba00 of size 256 next 1232\n",
      "2023-09-22 01:34:03.814321: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5bb00 of size 256 next 234\n",
      "2023-09-22 01:34:03.814331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5bc00 of size 256 next 1404\n",
      "2023-09-22 01:34:03.814340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5bd00 of size 256 next 333\n",
      "2023-09-22 01:34:03.814350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5be00 of size 256 next 1633\n",
      "2023-09-22 01:34:03.814362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5bf00 of size 256 next 998\n",
      "2023-09-22 01:34:03.814375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c000 of size 256 next 197\n",
      "2023-09-22 01:34:03.814384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c100 of size 256 next 1506\n",
      "2023-09-22 01:34:03.814394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c200 of size 256 next 632\n",
      "2023-09-22 01:34:03.814403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c300 of size 256 next 79\n",
      "2023-09-22 01:34:03.814416: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c400 of size 256 next 213\n",
      "2023-09-22 01:34:03.814428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c500 of size 256 next 1498\n",
      "2023-09-22 01:34:03.814438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c600 of size 256 next 360\n",
      "2023-09-22 01:34:03.814447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5c700 of size 2048 next 171\n",
      "2023-09-22 01:34:03.814456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5cf00 of size 2048 next 431\n",
      "2023-09-22 01:34:03.814468: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5d700 of size 512 next 1337\n",
      "2023-09-22 01:34:03.814481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5d900 of size 256 next 541\n",
      "2023-09-22 01:34:03.814491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5da00 of size 256 next 1376\n",
      "2023-09-22 01:34:03.814500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5db00 of size 512 next 1189\n",
      "2023-09-22 01:34:03.814510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5dd00 of size 512 next 1388\n",
      "2023-09-22 01:34:03.814521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5df00 of size 512 next 1602\n",
      "2023-09-22 01:34:03.814534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5e100 of size 256 next 16\n",
      "2023-09-22 01:34:03.814544: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5e200 of size 256 next 869\n",
      "2023-09-22 01:34:03.814554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5e300 of size 1024 next 1110\n",
      "2023-09-22 01:34:03.814563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf5e700 of size 8192 next 482\n",
      "2023-09-22 01:34:03.814575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf60700 of size 9216 next 1072\n",
      "2023-09-22 01:34:03.814588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf62b00 of size 8192 next 1422\n",
      "2023-09-22 01:34:03.814599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf64b00 of size 9216 next 638\n",
      "2023-09-22 01:34:03.814608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf66f00 of size 2048 next 250\n",
      "2023-09-22 01:34:03.814617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf67700 of size 2048 next 465\n",
      "2023-09-22 01:34:03.814628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf67f00 of size 512 next 1673\n",
      "2023-09-22 01:34:03.814641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68100 of size 512 next 159\n",
      "2023-09-22 01:34:03.814652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68300 of size 256 next 470\n",
      "2023-09-22 01:34:03.814662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68400 of size 256 next 748\n",
      "2023-09-22 01:34:03.814671: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68500 of size 256 next 201\n",
      "2023-09-22 01:34:03.814683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68600 of size 256 next 1451\n",
      "2023-09-22 01:34:03.814694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68700 of size 256 next 1251\n",
      "2023-09-22 01:34:03.814704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68800 of size 256 next 375\n",
      "2023-09-22 01:34:03.814714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf68900 of size 2048 next 730\n",
      "2023-09-22 01:34:03.814724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf69100 of size 512 next 647\n",
      "2023-09-22 01:34:03.814735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf69300 of size 2048 next 1204\n",
      "2023-09-22 01:34:03.814749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf69b00 of size 512 next 324\n",
      "2023-09-22 01:34:03.814759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf69d00 of size 512 next 981\n",
      "2023-09-22 01:34:03.814769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf69f00 of size 2048 next 585\n",
      "2023-09-22 01:34:03.814778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf6a700 of size 2048 next 1478\n",
      "2023-09-22 01:34:03.814791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf6af00 of size 11776 next 942\n",
      "2023-09-22 01:34:03.814804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf6dd00 of size 8192 next 369\n",
      "2023-09-22 01:34:03.814813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf6fd00 of size 9216 next 1024\n",
      "2023-09-22 01:34:03.814824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf72100 of size 8192 next 1305\n",
      "2023-09-22 01:34:03.814832: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf74100 of size 9216 next 1473\n",
      "2023-09-22 01:34:03.814841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf76500 of size 8192 next 1350\n",
      "2023-09-22 01:34:03.814855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf78500 of size 9216 next 189\n",
      "2023-09-22 01:34:03.814867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7a900 of size 512 next 1533\n",
      "2023-09-22 01:34:03.814876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7ab00 of size 256 next 133\n",
      "2023-09-22 01:34:03.814886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7ac00 of size 256 next 1648\n",
      "2023-09-22 01:34:03.814898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7ad00 of size 256 next 623\n",
      "2023-09-22 01:34:03.814911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7ae00 of size 256 next 1441\n",
      "2023-09-22 01:34:03.814921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7af00 of size 256 next 1578\n",
      "2023-09-22 01:34:03.814930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7b000 of size 256 next 1585\n",
      "2023-09-22 01:34:03.814940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7b100 of size 1024 next 1207\n",
      "2023-09-22 01:34:03.814951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7b500 of size 1536 next 1031\n",
      "2023-09-22 01:34:03.814964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7bb00 of size 2048 next 1158\n",
      "2023-09-22 01:34:03.814975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7c300 of size 2048 next 1070\n",
      "2023-09-22 01:34:03.814984: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7cb00 of size 512 next 143\n",
      "2023-09-22 01:34:03.814994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7cd00 of size 256 next 1321\n",
      "2023-09-22 01:34:03.815006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7ce00 of size 256 next 889\n",
      "2023-09-22 01:34:03.815019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7cf00 of size 512 next 1244\n",
      "2023-09-22 01:34:03.815029: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7d100 of size 512 next 548\n",
      "2023-09-22 01:34:03.815039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7d300 of size 2048 next 1433\n",
      "2023-09-22 01:34:03.815047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7db00 of size 3584 next 784\n",
      "2023-09-22 01:34:03.815059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf7e900 of size 8192 next 1068\n",
      "2023-09-22 01:34:03.815073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf80900 of size 8448 next 669\n",
      "2023-09-22 01:34:03.815082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82a00 of size 256 next 785\n",
      "2023-09-22 01:34:03.815092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82b00 of size 256 next 672\n",
      "2023-09-22 01:34:03.815102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82c00 of size 256 next 296\n",
      "2023-09-22 01:34:03.815115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82d00 of size 256 next 674\n",
      "2023-09-22 01:34:03.815128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82e00 of size 256 next 587\n",
      "2023-09-22 01:34:03.815137: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82f00 of size 256 next 270\n",
      "2023-09-22 01:34:03.815168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83000 of size 256 next 1575\n",
      "2023-09-22 01:34:03.815177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83100 of size 256 next 1678\n",
      "2023-09-22 01:34:03.815190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83200 of size 256 next 467\n",
      "2023-09-22 01:34:03.815204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83300 of size 256 next 792\n",
      "2023-09-22 01:34:03.815215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83400 of size 256 next 1333\n",
      "2023-09-22 01:34:03.815225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83500 of size 256 next 1543\n",
      "2023-09-22 01:34:03.815234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83600 of size 256 next 1271\n",
      "2023-09-22 01:34:03.815244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83700 of size 256 next 970\n",
      "2023-09-22 01:34:03.815257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83800 of size 256 next 447\n",
      "2023-09-22 01:34:03.815269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83900 of size 256 next 545\n",
      "2023-09-22 01:34:03.815279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83a00 of size 256 next 551\n",
      "2023-09-22 01:34:03.815288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83b00 of size 256 next 910\n",
      "2023-09-22 01:34:03.815300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83c00 of size 82051072 next 1660\n",
      "2023-09-22 01:34:03.815313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e1dc3c00 of size 20512768 next 268\n",
      "2023-09-22 01:34:03.815325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e3153c00 of size 41025536 next 372\n",
      "2023-09-22 01:34:03.815334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e5873c00 of size 20512768 next 591\n",
      "2023-09-22 01:34:03.815344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e6c03c00 of size 20512768 next 1638\n",
      "2023-09-22 01:34:03.815355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e7f93c00 of size 102154752 next 1082\n",
      "2023-09-22 01:34:03.815369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0ffe00 of size 256 next 407\n",
      "2023-09-22 01:34:03.815380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fff00 of size 256 next 826\n",
      "2023-09-22 01:34:03.815390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100000 of size 256 next 1509\n",
      "2023-09-22 01:34:03.815399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100100 of size 256 next 563\n",
      "2023-09-22 01:34:03.815411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100200 of size 512 next 390\n",
      "2023-09-22 01:34:03.815424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100400 of size 512 next 1425\n",
      "2023-09-22 01:34:03.815434: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100600 of size 512 next 1002\n",
      "2023-09-22 01:34:03.815443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100800 of size 2048 next 611\n",
      "2023-09-22 01:34:03.815453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101000 of size 256 next 1279\n",
      "2023-09-22 01:34:03.815465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101100 of size 256 next 892\n",
      "2023-09-22 01:34:03.815479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101200 of size 3190784 next 513\n",
      "2023-09-22 01:34:03.815488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee40c200 of size 8448 next 1607\n",
      "2023-09-22 01:34:03.815498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee40e300 of size 12032 next 688\n",
      "2023-09-22 01:34:03.815510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee411200 of size 1024 next 766\n",
      "2023-09-22 01:34:03.815524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee411600 of size 1024 next 484\n",
      "2023-09-22 01:34:03.815536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee411a00 of size 1024 next 535\n",
      "2023-09-22 01:34:03.815546: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee411e00 of size 1024 next 763\n",
      "2023-09-22 01:34:03.815555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee412200 of size 1024 next 312\n",
      "2023-09-22 01:34:03.815566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee412600 of size 1024 next 1362\n",
      "2023-09-22 01:34:03.815580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee412a00 of size 8192 next 1537\n",
      "2023-09-22 01:34:03.815591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee414a00 of size 8192 next 1475\n",
      "2023-09-22 01:34:03.815600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee416a00 of size 8192 next 27\n",
      "2023-09-22 01:34:03.815610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee418a00 of size 8192 next 648\n",
      "2023-09-22 01:34:03.815620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41aa00 of size 8192 next 961\n",
      "2023-09-22 01:34:03.815633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41ca00 of size 8192 next 368\n",
      "2023-09-22 01:34:03.815645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41ea00 of size 1024 next 1366\n",
      "2023-09-22 01:34:03.815654: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41ee00 of size 1024 next 650\n",
      "2023-09-22 01:34:03.815664: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41f200 of size 1024 next 1530\n",
      "2023-09-22 01:34:03.815675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41f600 of size 1024 next 1041\n",
      "2023-09-22 01:34:03.815689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41fa00 of size 1024 next 1083\n",
      "2023-09-22 01:34:03.815699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee41fe00 of size 1024 next 629\n",
      "2023-09-22 01:34:03.815709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee420200 of size 131072 next 1128\n",
      "2023-09-22 01:34:03.815718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee440200 of size 131072 next 850\n",
      "2023-09-22 01:34:03.815730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee460200 of size 512 next 1227\n",
      "2023-09-22 01:34:03.815743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee460400 of size 512 next 1356\n",
      "2023-09-22 01:34:03.815753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee460600 of size 131072 next 1276\n",
      "2023-09-22 01:34:03.815763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee480600 of size 131072 next 1576\n",
      "2023-09-22 01:34:03.815773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a0600 of size 1024 next 1386\n",
      "2023-09-22 01:34:03.815786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a0a00 of size 1024 next 473\n",
      "2023-09-22 01:34:03.815798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a0e00 of size 1024 next 634\n",
      "2023-09-22 01:34:03.815808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a1200 of size 1024 next 1223\n",
      "2023-09-22 01:34:03.815817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a1600 of size 1024 next 1218\n",
      "2023-09-22 01:34:03.815826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a1a00 of size 1024 next 841\n",
      "2023-09-22 01:34:03.815839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a1e00 of size 8192 next 1644\n",
      "2023-09-22 01:34:03.815852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a3e00 of size 8192 next 7\n",
      "2023-09-22 01:34:03.815861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a5e00 of size 8192 next 588\n",
      "2023-09-22 01:34:03.815869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a7e00 of size 8192 next 1419\n",
      "2023-09-22 01:34:03.815877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4a9e00 of size 8192 next 488\n",
      "2023-09-22 01:34:03.815888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4abe00 of size 8192 next 483\n",
      "2023-09-22 01:34:03.815903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ade00 of size 1024 next 1120\n",
      "2023-09-22 01:34:03.815918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ae200 of size 1024 next 1571\n",
      "2023-09-22 01:34:03.815929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ae600 of size 1024 next 1187\n",
      "2023-09-22 01:34:03.815940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4aea00 of size 1024 next 1075\n",
      "2023-09-22 01:34:03.815953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4aee00 of size 1024 next 865\n",
      "2023-09-22 01:34:03.815968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4af200 of size 1024 next 772\n",
      "2023-09-22 01:34:03.815981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4af600 of size 131072 next 451\n",
      "2023-09-22 01:34:03.815993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4cf600 of size 211200 next 1658\n",
      "2023-09-22 01:34:03.816004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee502f00 of size 256 next 1100\n",
      "2023-09-22 01:34:03.816016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee503000 of size 8192 next 239\n",
      "2023-09-22 01:34:03.816031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505000 of size 256 next 1150\n",
      "2023-09-22 01:34:03.816044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505100 of size 19456 next 915\n",
      "2023-09-22 01:34:03.816055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee509d00 of size 256 next 1240\n",
      "2023-09-22 01:34:03.816066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee509e00 of size 256 next 1540\n",
      "2023-09-22 01:34:03.816077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee509f00 of size 256 next 1467\n",
      "2023-09-22 01:34:03.816088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee50a000 of size 256 next 1042\n",
      "2023-09-22 01:34:03.816101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee50a100 of size 256 next 997\n",
      "2023-09-22 01:34:03.816116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee50a200 of size 256 next 793\n",
      "2023-09-22 01:34:03.816129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee50a300 of size 16384 next 1077\n",
      "2023-09-22 01:34:03.816140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee50e300 of size 16384 next 1527\n",
      "2023-09-22 01:34:03.816151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee512300 of size 1024 next 565\n",
      "2023-09-22 01:34:03.816161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee512700 of size 1024 next 286\n",
      "2023-09-22 01:34:03.816173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee512b00 of size 8192 next 489\n",
      "2023-09-22 01:34:03.816189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee514b00 of size 8192 next 1185\n",
      "2023-09-22 01:34:03.816202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee516b00 of size 8192 next 1152\n",
      "2023-09-22 01:34:03.816213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee518b00 of size 8192 next 1184\n",
      "2023-09-22 01:34:03.816226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51ab00 of size 8192 next 660\n",
      "2023-09-22 01:34:03.816238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51cb00 of size 8192 next 1202\n",
      "2023-09-22 01:34:03.816253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51eb00 of size 1024 next 816\n",
      "2023-09-22 01:34:03.816267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51ef00 of size 1024 next 44\n",
      "2023-09-22 01:34:03.816276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51f300 of size 1024 next 366\n",
      "2023-09-22 01:34:03.816286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51f700 of size 1024 next 1624\n",
      "2023-09-22 01:34:03.816298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51fb00 of size 1024 next 1360\n",
      "2023-09-22 01:34:03.816311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee51ff00 of size 1024 next 1175\n",
      "2023-09-22 01:34:03.816325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee520300 of size 512 next 1073\n",
      "2023-09-22 01:34:03.816332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee520500 of size 512 next 1145\n",
      "2023-09-22 01:34:03.816336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee520700 of size 1024 next 1610\n",
      "2023-09-22 01:34:03.816340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee520b00 of size 1024 next 740\n",
      "2023-09-22 01:34:03.816345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee520f00 of size 1024 next 199\n",
      "2023-09-22 01:34:03.816349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee521300 of size 1024 next 783\n",
      "2023-09-22 01:34:03.816353: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee521700 of size 1024 next 295\n",
      "2023-09-22 01:34:03.816357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee521b00 of size 1024 next 387\n",
      "2023-09-22 01:34:03.816361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee521f00 of size 12800 next 1071\n",
      "2023-09-22 01:34:03.816366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee525100 of size 131072 next 935\n",
      "2023-09-22 01:34:03.816374: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee545100 of size 133632 next 1641\n",
      "2023-09-22 01:34:03.816382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee565b00 of size 14336 next 864\n",
      "2023-09-22 01:34:03.816386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee569300 of size 11264 next 347\n",
      "2023-09-22 01:34:03.816390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee56bf00 of size 11264 next 630\n",
      "2023-09-22 01:34:03.816395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee56eb00 of size 3220224 next 1601\n",
      "2023-09-22 01:34:03.816399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880e00 of size 256 next 1389\n",
      "2023-09-22 01:34:03.816404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880f00 of size 157411072 next 932\n",
      "2023-09-22 01:34:03.816408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f600 of size 256 next 101\n",
      "2023-09-22 01:34:03.816412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f700 of size 256 next 761\n",
      "2023-09-22 01:34:03.816416: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f800 of size 2097152 next 636\n",
      "2023-09-22 01:34:03.816421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f809f800 of size 2097152 next 533\n",
      "2023-09-22 01:34:03.816426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f829f800 of size 2097152 next 884\n",
      "2023-09-22 01:34:03.816433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f849f800 of size 2097152 next 1274\n",
      "2023-09-22 01:34:03.816440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f869f800 of size 2097152 next 1392\n",
      "2023-09-22 01:34:03.816444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f889f800 of size 2097152 next 259\n",
      "2023-09-22 01:34:03.816447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f8a9f800 of size 2097152 next 612\n",
      "2023-09-22 01:34:03.816450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f8c9f800 of size 2097152 next 11\n",
      "2023-09-22 01:34:03.816454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f8e9f800 of size 2097152 next 83\n",
      "2023-09-22 01:34:03.816457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f909f800 of size 2097152 next 1626\n",
      "2023-09-22 01:34:03.816461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f929f800 of size 2097152 next 957\n",
      "2023-09-22 01:34:03.816464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f949f800 of size 2097152 next 290\n",
      "2023-09-22 01:34:03.816467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f969f800 of size 2097152 next 111\n",
      "2023-09-22 01:34:03.816471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f989f800 of size 2097152 next 1556\n",
      "2023-09-22 01:34:03.816474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9a9f800 of size 2097152 next 264\n",
      "2023-09-22 01:34:03.816477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9c9f800 of size 2097152 next 1669\n",
      "2023-09-22 01:34:03.816482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9e9f800 of size 2097152 next 1480\n",
      "2023-09-22 01:34:03.816487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa09f800 of size 3410944 next 657\n",
      "2023-09-22 01:34:03.816491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0400 of size 256 next 1326\n",
      "2023-09-22 01:34:03.816497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa3e0500 of size 1761024 next 1686\n",
      "2023-09-22 01:34:03.816501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e400 of size 256 next 1096\n",
      "2023-09-22 01:34:03.816504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e500 of size 256 next 252\n",
      "2023-09-22 01:34:03.816508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e600 of size 256 next 1674\n",
      "2023-09-22 01:34:03.816511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e700 of size 256 next 825\n",
      "2023-09-22 01:34:03.816514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e800 of size 320512 next 955\n",
      "2023-09-22 01:34:03.816518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa5dcc00 of size 1089792 next 830\n",
      "2023-09-22 01:34:03.816521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e6d00 of size 9216 next 1507\n",
      "2023-09-22 01:34:03.816525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9100 of size 256 next 1364\n",
      "2023-09-22 01:34:03.816529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9200 of size 256 next 699\n",
      "2023-09-22 01:34:03.816532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9300 of size 256 next 1471\n",
      "2023-09-22 01:34:03.816536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9400 of size 256 next 1078\n",
      "2023-09-22 01:34:03.816543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9500 of size 512 next 726\n",
      "2023-09-22 01:34:03.816548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9700 of size 256 next 206\n",
      "2023-09-22 01:34:03.816553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9800 of size 131072 next 97\n",
      "2023-09-22 01:34:03.816557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa709800 of size 210432 next 1696\n",
      "2023-09-22 01:34:03.816560: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ce00 of size 256 next 106\n",
      "2023-09-22 01:34:03.816564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73cf00 of size 3142400 next 689\n",
      "2023-09-22 01:34:03.816571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c200 of size 256 next 383\n",
      "2023-09-22 01:34:03.816575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c300 of size 8192 next 1127\n",
      "2023-09-22 01:34:03.816578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3e300 of size 8192 next 1396\n",
      "2023-09-22 01:34:03.816582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40300 of size 11776 next 1550\n",
      "2023-09-22 01:34:03.816585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43100 of size 256 next 1551\n",
      "2023-09-22 01:34:03.816589: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43200 of size 82051072 next 137\n",
      "2023-09-22 01:34:03.816594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ff883200 of size 126922752 next 148\n",
      "2023-09-22 01:34:03.816599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130718e200 of size 8192 next 1662\n",
      "2023-09-22 01:34:03.816603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1307190200 of size 8192 next 475\n",
      "2023-09-22 01:34:03.816607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1307192200 of size 8192 next 1212\n",
      "2023-09-22 01:34:03.816610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1307194200 of size 82051072 next 1408\n",
      "2023-09-22 01:34:03.816614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130bfd4200 of size 117225728 next 1461\n",
      "2023-09-22 01:34:03.816617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312f9fb00 of size 10240 next 857\n",
      "2023-09-22 01:34:03.816620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa2300 of size 512 next 406\n",
      "2023-09-22 01:34:03.816624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa2500 of size 512 next 703\n",
      "2023-09-22 01:34:03.816627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa2700 of size 256 next 702\n",
      "2023-09-22 01:34:03.816631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa2800 of size 256 next 1470\n",
      "2023-09-22 01:34:03.816634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa2900 of size 512 next 95\n",
      "2023-09-22 01:34:03.816637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa2b00 of size 2048 next 1062\n",
      "2023-09-22 01:34:03.816641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa3300 of size 2048 next 977\n",
      "2023-09-22 01:34:03.816644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa3b00 of size 8192 next 487\n",
      "2023-09-22 01:34:03.816648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa5b00 of size 10240 next 275\n",
      "2023-09-22 01:34:03.816655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa8300 of size 2048 next 1241\n",
      "2023-09-22 01:34:03.816661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa8b00 of size 2048 next 769\n",
      "2023-09-22 01:34:03.816665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9300 of size 512 next 1697\n",
      "2023-09-22 01:34:03.816668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9500 of size 512 next 125\n",
      "2023-09-22 01:34:03.816672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9700 of size 512 next 378\n",
      "2023-09-22 01:34:03.816675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9900 of size 512 next 1199\n",
      "2023-09-22 01:34:03.816678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9b00 of size 256 next 1445\n",
      "2023-09-22 01:34:03.816682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9c00 of size 256 next 987\n",
      "2023-09-22 01:34:03.816685: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9d00 of size 256 next 1525\n",
      "2023-09-22 01:34:03.816689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9e00 of size 256 next 1286\n",
      "2023-09-22 01:34:03.816692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fa9f00 of size 256 next 870\n",
      "2023-09-22 01:34:03.816695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faa000 of size 256 next 1481\n",
      "2023-09-22 01:34:03.816699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faa100 of size 256 next 1323\n",
      "2023-09-22 01:34:03.816703: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faa200 of size 256 next 1538\n",
      "2023-09-22 01:34:03.816710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faa300 of size 1024 next 1161\n",
      "2023-09-22 01:34:03.816714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faa700 of size 1536 next 246\n",
      "2023-09-22 01:34:03.816717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faad00 of size 256 next 358\n",
      "2023-09-22 01:34:03.816721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faae00 of size 256 next 898\n",
      "2023-09-22 01:34:03.816724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faaf00 of size 512 next 882\n",
      "2023-09-22 01:34:03.816728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab100 of size 256 next 301\n",
      "2023-09-22 01:34:03.816731: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab200 of size 256 next 1677\n",
      "2023-09-22 01:34:03.816734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab300 of size 512 next 84\n",
      "2023-09-22 01:34:03.816738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab500 of size 256 next 231\n",
      "2023-09-22 01:34:03.816741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab600 of size 256 next 26\n",
      "2023-09-22 01:34:03.816744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab700 of size 256 next 1355\n",
      "2023-09-22 01:34:03.816748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab800 of size 256 next 293\n",
      "2023-09-22 01:34:03.816751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fab900 of size 256 next 321\n",
      "2023-09-22 01:34:03.816755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faba00 of size 256 next 1188\n",
      "2023-09-22 01:34:03.816759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fabb00 of size 256 next 472\n",
      "2023-09-22 01:34:03.816764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fabc00 of size 512 next 744\n",
      "2023-09-22 01:34:03.816769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fabe00 of size 512 next 1105\n",
      "2023-09-22 01:34:03.816772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fac000 of size 512 next 1709\n",
      "2023-09-22 01:34:03.816775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fac200 of size 256 next 645\n",
      "2023-09-22 01:34:03.816779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fac300 of size 256 next 122\n",
      "2023-09-22 01:34:03.816782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fac400 of size 512 next 261\n",
      "2023-09-22 01:34:03.816786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fac600 of size 512 next 1625\n",
      "2023-09-22 01:34:03.816789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fac800 of size 256 next 1526\n",
      "2023-09-22 01:34:03.816792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fac900 of size 256 next 1468\n",
      "2023-09-22 01:34:03.816796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312faca00 of size 512 next 781\n",
      "2023-09-22 01:34:03.816799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312facc00 of size 3840 next 561\n",
      "2023-09-22 01:34:03.816803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fadb00 of size 8192 next 1621\n",
      "2023-09-22 01:34:03.816806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fafb00 of size 8192 next 747\n",
      "2023-09-22 01:34:03.816810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1312fb1b00 of size 2097152 next 552\n",
      "2023-09-22 01:34:03.816814: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13131b1b00 of size 2097152 next 1613\n",
      "2023-09-22 01:34:03.816819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13133b1b00 of size 2097152 next 950\n",
      "2023-09-22 01:34:03.816826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13135b1b00 of size 2097152 next 491\n",
      "2023-09-22 01:34:03.816829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13137b1b00 of size 32178688 next 931\n",
      "2023-09-22 01:34:03.816833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315661d00 of size 8192 next 340\n",
      "2023-09-22 01:34:03.816836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315663d00 of size 9216 next 1341\n",
      "2023-09-22 01:34:03.816840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315666100 of size 8192 next 1643\n",
      "2023-09-22 01:34:03.816843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315668100 of size 9216 next 1645\n",
      "2023-09-22 01:34:03.816847: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131566a500 of size 8192 next 215\n",
      "2023-09-22 01:34:03.816850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131566c500 of size 14848 next 1501\n",
      "2023-09-22 01:34:03.816853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131566ff00 of size 512 next 1384\n",
      "2023-09-22 01:34:03.816857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670100 of size 256 next 815\n",
      "2023-09-22 01:34:03.816860: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670200 of size 256 next 241\n",
      "2023-09-22 01:34:03.816863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670300 of size 256 next 460\n",
      "2023-09-22 01:34:03.816868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670400 of size 256 next 297\n",
      "2023-09-22 01:34:03.816873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670500 of size 256 next 1511\n",
      "2023-09-22 01:34:03.816877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670600 of size 256 next 1206\n",
      "2023-09-22 01:34:03.816883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670700 of size 2048 next 464\n",
      "2023-09-22 01:34:03.816887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315670f00 of size 2560 next 584\n",
      "2023-09-22 01:34:03.816890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315671900 of size 1024 next 1466\n",
      "2023-09-22 01:34:03.816894: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315671d00 of size 256 next 1604\n",
      "2023-09-22 01:34:03.816897: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315671e00 of size 256 next 1570\n",
      "2023-09-22 01:34:03.816900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315671f00 of size 256 next 256\n",
      "2023-09-22 01:34:03.816904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315672000 of size 256 next 162\n",
      "2023-09-22 01:34:03.816907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315672100 of size 2560 next 890\n",
      "2023-09-22 01:34:03.816910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315672b00 of size 256 next 1521\n",
      "2023-09-22 01:34:03.816914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315672c00 of size 256 next 300\n",
      "2023-09-22 01:34:03.816918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315672d00 of size 1280 next 210\n",
      "2023-09-22 01:34:03.816925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673200 of size 256 next 444\n",
      "2023-09-22 01:34:03.816932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673300 of size 256 next 1542\n",
      "2023-09-22 01:34:03.816935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673400 of size 256 next 1213\n",
      "2023-09-22 01:34:03.816939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673500 of size 256 next 988\n",
      "2023-09-22 01:34:03.816942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673600 of size 256 next 1628\n",
      "2023-09-22 01:34:03.816945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673700 of size 2048 next 425\n",
      "2023-09-22 01:34:03.816949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673f00 of size 2048 next 594\n",
      "2023-09-22 01:34:03.816952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674700 of size 2048 next 1176\n",
      "2023-09-22 01:34:03.816955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674f00 of size 8192 next 1272\n",
      "2023-09-22 01:34:03.816959: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315676f00 of size 2048 next 569\n",
      "2023-09-22 01:34:03.816962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677700 of size 1024 next 1593\n",
      "2023-09-22 01:34:03.816966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677b00 of size 256 next 628\n",
      "2023-09-22 01:34:03.816969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677c00 of size 256 next 92\n",
      "2023-09-22 01:34:03.816973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677d00 of size 512 next 1022\n",
      "2023-09-22 01:34:03.816978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677f00 of size 2048 next 1030\n",
      "2023-09-22 01:34:03.816984: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315678700 of size 2048 next 1254\n",
      "2023-09-22 01:34:03.816988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315678f00 of size 256 next 1226\n",
      "2023-09-22 01:34:03.816991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315679000 of size 256 next 277\n",
      "2023-09-22 01:34:03.816995: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315679100 of size 256 next 1701\n",
      "2023-09-22 01:34:03.816998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315679200 of size 256 next 1006\n",
      "2023-09-22 01:34:03.817001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315679300 of size 256 next 752\n",
      "2023-09-22 01:34:03.817005: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315679400 of size 8192 next 787\n",
      "2023-09-22 01:34:03.817008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131567b400 of size 8192 next 326\n",
      "2023-09-22 01:34:03.817012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131567d400 of size 11264 next 1336\n",
      "2023-09-22 01:34:03.817015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315680000 of size 8448 next 983\n",
      "2023-09-22 01:34:03.817019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315682100 of size 14080 next 1378\n",
      "2023-09-22 01:34:03.817022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315685800 of size 11264 next 1454\n",
      "2023-09-22 01:34:03.817026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315688400 of size 11264 next 1265\n",
      "2023-09-22 01:34:03.817029: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131568b000 of size 11264 next 319\n",
      "2023-09-22 01:34:03.817032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131568dc00 of size 11264 next 399\n",
      "2023-09-22 01:34:03.817036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315690800 of size 16384 next 1367\n",
      "2023-09-22 01:34:03.817039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315694800 of size 8192 next 994\n",
      "2023-09-22 01:34:03.817043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315696800 of size 8192 next 251\n",
      "2023-09-22 01:34:03.817048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315698800 of size 8192 next 398\n",
      "2023-09-22 01:34:03.817055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131569a800 of size 8192 next 1304\n",
      "2023-09-22 01:34:03.817059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131569c800 of size 8192 next 1154\n",
      "2023-09-22 01:34:03.817062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131569e800 of size 8192 next 1216\n",
      "2023-09-22 01:34:03.817066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13156a0800 of size 9472 next 917\n",
      "2023-09-22 01:34:03.817069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13156a2d00 of size 2097152 next 1302\n",
      "2023-09-22 01:34:03.817073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158a2d00 of size 2097152 next 1462\n",
      "2023-09-22 01:34:03.817076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315aa2d00 of size 3110656 next 43\n",
      "2023-09-22 01:34:03.817080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9a400 of size 512 next 271\n",
      "2023-09-22 01:34:03.817083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9a600 of size 256 next 403\n",
      "2023-09-22 01:34:03.817087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9a700 of size 256 next 495\n",
      "2023-09-22 01:34:03.817090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9a800 of size 256 next 341\n",
      "2023-09-22 01:34:03.817094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9a900 of size 256 next 1705\n",
      "2023-09-22 01:34:03.817097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9aa00 of size 256 next 481\n",
      "2023-09-22 01:34:03.817102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9ab00 of size 256 next 1252\n",
      "2023-09-22 01:34:03.817107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9ac00 of size 256 next 670\n",
      "2023-09-22 01:34:03.817111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9ad00 of size 256 next 655\n",
      "2023-09-22 01:34:03.817115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9ae00 of size 256 next 1210\n",
      "2023-09-22 01:34:03.817118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9af00 of size 256 next 1181\n",
      "2023-09-22 01:34:03.817121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9b000 of size 256 next 1563\n",
      "2023-09-22 01:34:03.817125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9b100 of size 256 next 1054\n",
      "2023-09-22 01:34:03.817128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9b200 of size 256 next 194\n",
      "2023-09-22 01:34:03.817131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9b300 of size 8192 next 554\n",
      "2023-09-22 01:34:03.817135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9d300 of size 8448 next 1536\n",
      "2023-09-22 01:34:03.817138: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9f400 of size 256 next 1133\n",
      "2023-09-22 01:34:03.817142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d9f500 of size 8192 next 1040\n",
      "2023-09-22 01:34:03.817145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315da1500 of size 14592 next 179\n",
      "2023-09-22 01:34:03.817149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315da4e00 of size 131072 next 1597\n",
      "2023-09-22 01:34:03.817156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315dc4e00 of size 131072 next 814\n",
      "2023-09-22 01:34:03.817163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315de4e00 of size 160256 next 1308\n",
      "2023-09-22 01:34:03.817166: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c000 of size 256 next 164\n",
      "2023-09-22 01:34:03.817170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c100 of size 256 next 971\n",
      "2023-09-22 01:34:03.817173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c200 of size 768 next 844\n",
      "2023-09-22 01:34:03.817177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c500 of size 256 next 1079\n",
      "2023-09-22 01:34:03.817180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c600 of size 256 next 754\n",
      "2023-09-22 01:34:03.817183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c700 of size 256 next 848\n",
      "2023-09-22 01:34:03.817187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c800 of size 256 next 136\n",
      "2023-09-22 01:34:03.817190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c900 of size 256 next 265\n",
      "2023-09-22 01:34:03.817194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0ca00 of size 256 next 662\n",
      "2023-09-22 01:34:03.817197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0cb00 of size 256 next 1382\n",
      "2023-09-22 01:34:03.817204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0cc00 of size 256 next 1423\n",
      "2023-09-22 01:34:03.817208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0cd00 of size 256 next 1178\n",
      "2023-09-22 01:34:03.817214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0ce00 of size 512 next 853\n",
      "2023-09-22 01:34:03.817218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0d000 of size 512 next 64\n",
      "2023-09-22 01:34:03.817221: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0d200 of size 256 next 1316\n",
      "2023-09-22 01:34:03.817224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0d300 of size 256 next 969\n",
      "2023-09-22 01:34:03.817228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0d400 of size 256 next 1368\n",
      "2023-09-22 01:34:03.817231: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0d500 of size 256 next 1708\n",
      "2023-09-22 01:34:03.817235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0d600 of size 81920000 next 1173\n",
      "2023-09-22 01:34:03.817240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131ac2d600 of size 20480000 next 539\n",
      "2023-09-22 01:34:03.817244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131bfb5600 of size 5128192 next 1545\n",
      "2023-09-22 01:34:03.817247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131c499600 of size 5128192 next 232\n",
      "2023-09-22 01:34:03.817251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131c97d600 of size 20512768 next 238\n",
      "2023-09-22 01:34:03.817257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131dd0d600 of size 46213632 next 190\n",
      "2023-09-22 01:34:03.817262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920000 of size 256 next 1574\n",
      "2023-09-22 01:34:03.817265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920100 of size 71928064 next 112\n",
      "2023-09-22 01:34:03.817269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8a00 of size 256 next 687\n",
      "2023-09-22 01:34:03.817272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8b00 of size 512 next 504\n",
      "2023-09-22 01:34:03.817276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8d00 of size 256 next 1474\n",
      "2023-09-22 01:34:03.817279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8e00 of size 256 next 86\n",
      "2023-09-22 01:34:03.817282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8f00 of size 256 next 493\n",
      "2023-09-22 01:34:03.817286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9000 of size 1263840000 next 1692\n",
      "2023-09-22 01:34:03.817289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1370303b00 of size 41025536 next 1220\n",
      "2023-09-22 01:34:03.817293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1372a23b00 of size 20512768 next 1492\n",
      "2023-09-22 01:34:03.817296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1373db3b00 of size 20512768 next 1269\n",
      "2023-09-22 01:34:03.817300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1375143b00 of size 82051072 next 1183\n",
      "2023-09-22 01:34:03.817304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1379f83b00 of size 82051072 next 76\n",
      "2023-09-22 01:34:03.817309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f137edc3b00 of size 82051072 next 1458\n",
      "2023-09-22 01:34:03.817316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1383c03b00 of size 92755968 next 944\n",
      "2023-09-22 01:34:03.817320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1389479300 of size 1263840000 next 1531\n",
      "2023-09-22 01:34:03.817323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13d49c3e00 of size 656408576 next 1338\n",
      "2023-09-22 01:34:03.817327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13fbbc3e00 of size 656408576 next 1572\n",
      "2023-09-22 01:34:03.817330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1422dc3e00 of size 656408576 next 476\n",
      "2023-09-22 01:34:03.817334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1449fc3e00 of size 656408576 next 1134\n",
      "2023-09-22 01:34:03.817337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14711c3e00 of size 656408576 next 156\n",
      "2023-09-22 01:34:03.817340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14983c3e00 of size 656408576 next 605\n",
      "2023-09-22 01:34:03.817344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14bf5c3e00 of size 146153472 next 478\n",
      "2023-09-22 01:34:03.817348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14c8125e00 of size 802562048 next 1285\n",
      "2023-09-22 01:34:03.817351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14f7e87e00 of size 656408576 next 1627\n",
      "2023-09-22 01:34:03.817355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f151f087e00 of size 656408576 next 1211\n",
      "2023-09-22 01:34:03.817358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1546287e00 of size 656408576 next 153\n",
      "2023-09-22 01:34:03.817361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f156d487e00 of size 656408576 next 365\n",
      "2023-09-22 01:34:03.817366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1594687e00 of size 146153472 next 1153\n",
      "2023-09-22 01:34:03.817370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f159d1e9e00 of size 802562048 next 1049\n",
      "2023-09-22 01:34:03.817375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15ccf4be00 of size 656408576 next 353\n",
      "2023-09-22 01:34:03.817379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15f414be00 of size 656408576 next 1489\n",
      "2023-09-22 01:34:03.817382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f161b34be00 of size 656408576 next 1553\n",
      "2023-09-22 01:34:03.817386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f164254be00 of size 656408576 next 904\n",
      "2023-09-22 01:34:03.817389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f166974be00 of size 146153472 next 1306\n",
      "2023-09-22 01:34:03.817393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16722ade00 of size 802562048 next 1494\n",
      "2023-09-22 01:34:03.817396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16a200fe00 of size 656408576 next 1290\n",
      "2023-09-22 01:34:03.817399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16c920fe00 of size 656408576 next 418\n",
      "2023-09-22 01:34:03.817403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16f040fe00 of size 656408576 next 1623\n",
      "2023-09-22 01:34:03.817406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f171760fe00 of size 585826816 next 18446744073709551615\n",
      "2023-09-22 01:34:03.817409: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-09-22 01:34:03.817416: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 618 Chunks of size 256 totalling 154.5KiB\n",
      "2023-09-22 01:34:03.817423: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 122 Chunks of size 512 totalling 61.0KiB\n",
      "2023-09-22 01:34:03.817430: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 768 totalling 3.0KiB\n",
      "2023-09-22 01:34:03.817434: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 75 Chunks of size 1024 totalling 75.0KiB\n",
      "2023-09-22 01:34:03.817438: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 1280 totalling 6.2KiB\n",
      "2023-09-22 01:34:03.817442: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 1536 totalling 7.5KiB\n",
      "2023-09-22 01:34:03.817446: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2023-09-22 01:34:03.817450: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 73 Chunks of size 2048 totalling 146.0KiB\n",
      "2023-09-22 01:34:03.817455: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 2560 totalling 10.0KiB\n",
      "2023-09-22 01:34:03.817459: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3072 totalling 3.0KiB\n",
      "2023-09-22 01:34:03.817463: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3328 totalling 3.2KiB\n",
      "2023-09-22 01:34:03.817467: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2023-09-22 01:34:03.817471: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2023-09-22 01:34:03.817476: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 131 Chunks of size 8192 totalling 1.02MiB\n",
      "2023-09-22 01:34:03.817482: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 8448 totalling 66.0KiB\n",
      "2023-09-22 01:34:03.817489: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 21 Chunks of size 9216 totalling 189.0KiB\n",
      "2023-09-22 01:34:03.817493: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9472 totalling 9.2KiB\n",
      "2023-09-22 01:34:03.817497: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9728 totalling 9.5KiB\n",
      "2023-09-22 01:34:03.817501: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9984 totalling 9.8KiB\n",
      "2023-09-22 01:34:03.817505: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 10240 totalling 40.0KiB\n",
      "2023-09-22 01:34:03.817509: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10496 totalling 10.2KiB\n",
      "2023-09-22 01:34:03.817513: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 11008 totalling 10.8KiB\n",
      "2023-09-22 01:34:03.817517: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 23 Chunks of size 11264 totalling 253.0KiB\n",
      "2023-09-22 01:34:03.817520: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 11776 totalling 46.0KiB\n",
      "2023-09-22 01:34:03.817524: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12032 totalling 11.8KiB\n",
      "2023-09-22 01:34:03.817529: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12288 totalling 12.0KiB\n",
      "2023-09-22 01:34:03.817535: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12544 totalling 12.2KiB\n",
      "2023-09-22 01:34:03.817542: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 12800 totalling 12.5KiB\n",
      "2023-09-22 01:34:03.817547: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 14080 totalling 27.5KiB\n",
      "2023-09-22 01:34:03.817550: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 14336 totalling 56.0KiB\n",
      "2023-09-22 01:34:03.817554: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 14592 totalling 57.0KiB\n",
      "2023-09-22 01:34:03.817560: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 14848 totalling 43.5KiB\n",
      "2023-09-22 01:34:03.817564: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 15104 totalling 29.5KiB\n",
      "2023-09-22 01:34:03.817568: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 15872 totalling 31.0KiB\n",
      "2023-09-22 01:34:03.817572: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 16384 totalling 80.0KiB\n",
      "2023-09-22 01:34:03.817576: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 17920 totalling 17.5KiB\n",
      "2023-09-22 01:34:03.817582: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 19456 totalling 57.0KiB\n",
      "2023-09-22 01:34:03.817588: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 21248 totalling 62.2KiB\n",
      "2023-09-22 01:34:03.817594: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 38144 totalling 37.2KiB\n",
      "2023-09-22 01:34:03.817598: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 19 Chunks of size 131072 totalling 2.38MiB\n",
      "2023-09-22 01:34:03.817602: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 133632 totalling 130.5KiB\n",
      "2023-09-22 01:34:03.817606: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 135168 totalling 132.0KiB\n",
      "2023-09-22 01:34:03.817612: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 147712 totalling 144.2KiB\n",
      "2023-09-22 01:34:03.817616: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 160256 totalling 156.5KiB\n",
      "2023-09-22 01:34:03.817620: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 210432 totalling 205.5KiB\n",
      "2023-09-22 01:34:03.817624: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 211200 totalling 206.2KiB\n",
      "2023-09-22 01:34:03.817628: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 232448 totalling 227.0KiB\n",
      "2023-09-22 01:34:03.817633: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 249344 totalling 243.5KiB\n",
      "2023-09-22 01:34:03.817639: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 320512 totalling 2.45MiB\n",
      "2023-09-22 01:34:03.817646: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 409856 totalling 400.2KiB\n",
      "2023-09-22 01:34:03.817651: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 439040 totalling 428.8KiB\n",
      "2023-09-22 01:34:03.817654: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 502272 totalling 490.5KiB\n",
      "2023-09-22 01:34:03.817658: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 508160 totalling 496.2KiB\n",
      "2023-09-22 01:34:03.817664: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 37 Chunks of size 2097152 totalling 74.00MiB\n",
      "2023-09-22 01:34:03.817668: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2747392 totalling 2.62MiB\n",
      "2023-09-22 01:34:03.817672: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2858496 totalling 2.73MiB\n",
      "2023-09-22 01:34:03.817676: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3110656 totalling 2.97MiB\n",
      "2023-09-22 01:34:03.817680: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3142400 totalling 3.00MiB\n",
      "2023-09-22 01:34:03.817684: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3190784 totalling 3.04MiB\n",
      "2023-09-22 01:34:03.817687: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3220224 totalling 3.07MiB\n",
      "2023-09-22 01:34:03.817691: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3410944 totalling 3.25MiB\n",
      "2023-09-22 01:34:03.817695: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3495936 totalling 3.33MiB\n",
      "2023-09-22 01:34:03.817701: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4014080 totalling 3.83MiB\n",
      "2023-09-22 01:34:03.817705: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4073728 totalling 3.88MiB\n",
      "2023-09-22 01:34:03.817708: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4182016 totalling 3.99MiB\n",
      "2023-09-22 01:34:03.817712: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 5128192 totalling 9.78MiB\n",
      "2023-09-22 01:34:03.817716: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 20480000 totalling 58.59MiB\n",
      "2023-09-22 01:34:03.817720: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 20512768 totalling 117.38MiB\n",
      "2023-09-22 01:34:03.817724: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 24601344 totalling 23.46MiB\n",
      "2023-09-22 01:34:03.817730: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 32178688 totalling 30.69MiB\n",
      "2023-09-22 01:34:03.817734: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 41025536 totalling 78.25MiB\n",
      "2023-09-22 01:34:03.817739: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 46213632 totalling 44.07MiB\n",
      "2023-09-22 01:34:03.817744: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 71928064 totalling 68.60MiB\n",
      "2023-09-22 01:34:03.817752: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 81920000 totalling 78.12MiB\n",
      "2023-09-22 01:34:03.817758: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 11 Chunks of size 82051072 totalling 860.75MiB\n",
      "2023-09-22 01:34:03.817762: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 84076800 totalling 80.18MiB\n",
      "2023-09-22 01:34:03.817766: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 87264512 totalling 83.22MiB\n",
      "2023-09-22 01:34:03.817770: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 102154752 totalling 97.42MiB\n",
      "2023-09-22 01:34:03.817774: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 117225728 totalling 111.79MiB\n",
      "2023-09-22 01:34:03.817780: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 126922752 totalling 121.04MiB\n",
      "2023-09-22 01:34:03.817784: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 129023744 totalling 123.05MiB\n",
      "2023-09-22 01:34:03.817788: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 146153472 totalling 418.15MiB\n",
      "2023-09-22 01:34:03.817792: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 157411072 totalling 150.12MiB\n",
      "2023-09-22 01:34:03.817799: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 421200128 totalling 401.69MiB\n",
      "2023-09-22 01:34:03.817806: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 421440000 totalling 803.83MiB\n",
      "2023-09-22 01:34:03.817810: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 501639936 totalling 478.40MiB\n",
      "2023-09-22 01:34:03.817816: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 17 Chunks of size 656408576 totalling 10.39GiB\n",
      "2023-09-22 01:34:03.817820: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 802562048 totalling 2.24GiB\n",
      "2023-09-22 01:34:03.817824: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1263600128 totalling 1.18GiB\n",
      "2023-09-22 01:34:03.817828: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 1263840000 totalling 2.35GiB\n",
      "2023-09-22 01:34:03.817831: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 20.42GiB\n",
      "2023-09-22 01:34:03.817835: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 23023321088 memory_limit_: 23023321088 available bytes: 0 curr_region_allocation_bytes_: 46046642176\n",
      "2023-09-22 01:34:03.817842: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     23023321088\n",
      "InUse:                     21928616960\n",
      "MaxInUse:                  21928617216\n",
      "NumAllocs:                    25846090\n",
      "MaxAllocSize:               6400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-22 01:34:03.817880: W tensorflow/tsl/framework/bfc_allocator.cc:492] *****************_********************************************************************************__\n",
      "2023-09-22 01:34:03.817909: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at einsum_op_impl.h:525 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[256,8,313,313] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'model/multi_head_attention_3/einsum/Einsum' defined at (most recent call last):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_3386617/1959657965.py\", line 121, in <module>\n",
      "      hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3},\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 524, in _compute_attention\n",
      "      attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
      "Node: 'model/multi_head_attention_3/einsum/Einsum'\n",
      "OOM when allocating tensor with shape[256,8,313,313] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/multi_head_attention_3/einsum/Einsum}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_1381415]\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1228 - mean_squared_error: 0.0339\n",
      "Epoch 1: val_loss improved from inf to 0.09799, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 20s 307ms/step - loss: 0.1228 - mean_squared_error: 0.0339 - val_loss: 0.0980 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.0144\n",
      "Epoch 2: val_loss improved from 0.09799 to 0.07778, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 227ms/step - loss: 0.0861 - mean_squared_error: 0.0144 - val_loss: 0.0778 - val_mean_squared_error: 0.0117\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.0127\n",
      "Epoch 3: val_loss improved from 0.07778 to 0.07726, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 227ms/step - loss: 0.0807 - mean_squared_error: 0.0127 - val_loss: 0.0773 - val_mean_squared_error: 0.0115\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0804 - mean_squared_error: 0.0127\n",
      "Epoch 4: val_loss improved from 0.07726 to 0.07429, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.0804 - mean_squared_error: 0.0127 - val_loss: 0.0743 - val_mean_squared_error: 0.0116\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0652 - mean_squared_error: 0.0086\n",
      "Epoch 5: val_loss improved from 0.07429 to 0.06494, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 240ms/step - loss: 0.0652 - mean_squared_error: 0.0086 - val_loss: 0.0649 - val_mean_squared_error: 0.0092\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0521 - mean_squared_error: 0.0060\n",
      "Epoch 6: val_loss improved from 0.06494 to 0.05667, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 0.0521 - mean_squared_error: 0.0060 - val_loss: 0.0567 - val_mean_squared_error: 0.0072\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0046\n",
      "Epoch 7: val_loss did not improve from 0.05667\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.0454 - mean_squared_error: 0.0046 - val_loss: 0.0589 - val_mean_squared_error: 0.0076\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0042\n",
      "Epoch 8: val_loss improved from 0.05667 to 0.03884, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 248ms/step - loss: 0.0435 - mean_squared_error: 0.0042 - val_loss: 0.0388 - val_mean_squared_error: 0.0038\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0038\n",
      "Epoch 9: val_loss improved from 0.03884 to 0.03737, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.0405 - mean_squared_error: 0.0038 - val_loss: 0.0374 - val_mean_squared_error: 0.0033\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0402 - mean_squared_error: 0.0038\n",
      "Epoch 10: val_loss did not improve from 0.03737\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.0402 - mean_squared_error: 0.0038 - val_loss: 0.0423 - val_mean_squared_error: 0.0036\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0379 - mean_squared_error: 0.0034\n",
      "Epoch 11: val_loss did not improve from 0.03737\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 0.0379 - mean_squared_error: 0.0034 - val_loss: 0.0413 - val_mean_squared_error: 0.0034\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0031\n",
      "Epoch 12: val_loss did not improve from 0.03737\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.0360 - mean_squared_error: 0.0031 - val_loss: 0.0425 - val_mean_squared_error: 0.0036\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###0 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1243 - mean_squared_error: 0.0340\n",
      "Epoch 1: val_loss improved from inf to 0.10537, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 19s 306ms/step - loss: 0.1243 - mean_squared_error: 0.0340 - val_loss: 0.1054 - val_mean_squared_error: 0.0205\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0901 - mean_squared_error: 0.0158\n",
      "Epoch 2: val_loss improved from 0.10537 to 0.07579, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.0901 - mean_squared_error: 0.0158 - val_loss: 0.0758 - val_mean_squared_error: 0.0116\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0833 - mean_squared_error: 0.0131\n",
      "Epoch 3: val_loss improved from 0.07579 to 0.07555, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.0833 - mean_squared_error: 0.0131 - val_loss: 0.0756 - val_mean_squared_error: 0.0115\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0821 - mean_squared_error: 0.0130\n",
      "Epoch 4: val_loss did not improve from 0.07555\n",
      "21/21 [==============================] - 5s 223ms/step - loss: 0.0821 - mean_squared_error: 0.0130 - val_loss: 0.0765 - val_mean_squared_error: 0.0125\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.0122\n",
      "Epoch 5: val_loss improved from 0.07555 to 0.07554, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 5s 247ms/step - loss: 0.0794 - mean_squared_error: 0.0122 - val_loss: 0.0755 - val_mean_squared_error: 0.0127\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0657 - mean_squared_error: 0.0089\n",
      "Epoch 6: val_loss improved from 0.07554 to 0.05542, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.0657 - mean_squared_error: 0.0089 - val_loss: 0.0554 - val_mean_squared_error: 0.0066\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.0063\n",
      "Epoch 7: val_loss improved from 0.05542 to 0.04673, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 0.0542 - mean_squared_error: 0.0063 - val_loss: 0.0467 - val_mean_squared_error: 0.0041\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0456 - mean_squared_error: 0.0046\n",
      "Epoch 8: val_loss did not improve from 0.04673\n",
      "21/21 [==============================] - 5s 225ms/step - loss: 0.0456 - mean_squared_error: 0.0046 - val_loss: 0.0545 - val_mean_squared_error: 0.0056\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0421 - mean_squared_error: 0.0041\n",
      "Epoch 9: val_loss did not improve from 0.04673\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 0.0421 - mean_squared_error: 0.0041 - val_loss: 0.0493 - val_mean_squared_error: 0.0048\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0040\n",
      "Epoch 10: val_loss did not improve from 0.04673\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 0.0417 - mean_squared_error: 0.0040 - val_loss: 0.0511 - val_mean_squared_error: 0.0055\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###1 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1256 - mean_squared_error: 0.0352\n",
      "Epoch 1: val_loss improved from inf to 0.09974, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 22s 283ms/step - loss: 0.1256 - mean_squared_error: 0.0352 - val_loss: 0.0997 - val_mean_squared_error: 0.0191\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0864 - mean_squared_error: 0.0143\n",
      "Epoch 2: val_loss improved from 0.09974 to 0.07506, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.0864 - mean_squared_error: 0.0143 - val_loss: 0.0751 - val_mean_squared_error: 0.0116\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.0130\n",
      "Epoch 3: val_loss did not improve from 0.07506\n",
      "21/21 [==============================] - 5s 224ms/step - loss: 0.0819 - mean_squared_error: 0.0130 - val_loss: 0.0757 - val_mean_squared_error: 0.0124\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0765 - mean_squared_error: 0.0114\n",
      "Epoch 4: val_loss did not improve from 0.07506\n",
      "21/21 [==============================] - 5s 224ms/step - loss: 0.0765 - mean_squared_error: 0.0114 - val_loss: 0.0950 - val_mean_squared_error: 0.0170\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0594 - mean_squared_error: 0.0076\n",
      "Epoch 5: val_loss improved from 0.07506 to 0.06941, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.0594 - mean_squared_error: 0.0076 - val_loss: 0.0694 - val_mean_squared_error: 0.0101\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.0057\n",
      "Epoch 6: val_loss did not improve from 0.06941\n",
      "21/21 [==============================] - 5s 225ms/step - loss: 0.0508 - mean_squared_error: 0.0057 - val_loss: 0.0735 - val_mean_squared_error: 0.0110\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0052\n",
      "Epoch 7: val_loss improved from 0.06941 to 0.04105, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 5s 245ms/step - loss: 0.0486 - mean_squared_error: 0.0052 - val_loss: 0.0411 - val_mean_squared_error: 0.0037\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0046\n",
      "Epoch 8: val_loss did not improve from 0.04105\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.0450 - mean_squared_error: 0.0046 - val_loss: 0.0459 - val_mean_squared_error: 0.0049\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0038\n",
      "Epoch 9: val_loss improved from 0.04105 to 0.03573, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 5s 246ms/step - loss: 0.0405 - mean_squared_error: 0.0038 - val_loss: 0.0357 - val_mean_squared_error: 0.0029\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0033\n",
      "Epoch 10: val_loss improved from 0.03573 to 0.03386, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 0.0380 - mean_squared_error: 0.0033 - val_loss: 0.0339 - val_mean_squared_error: 0.0028\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0384 - mean_squared_error: 0.0034\n",
      "Epoch 11: val_loss improved from 0.03386 to 0.03354, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 0.0384 - mean_squared_error: 0.0034 - val_loss: 0.0335 - val_mean_squared_error: 0.0026\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0032\n",
      "Epoch 12: val_loss did not improve from 0.03354\n",
      "21/21 [==============================] - 5s 225ms/step - loss: 0.0370 - mean_squared_error: 0.0032 - val_loss: 0.0524 - val_mean_squared_error: 0.0046\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0030\n",
      "Epoch 13: val_loss did not improve from 0.03354\n",
      "21/21 [==============================] - 5s 234ms/step - loss: 0.0360 - mean_squared_error: 0.0030 - val_loss: 0.0391 - val_mean_squared_error: 0.0031\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0030\n",
      "Epoch 14: val_loss did not improve from 0.03354\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 0.0356 - mean_squared_error: 0.0030 - val_loss: 0.0386 - val_mean_squared_error: 0.0031\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###2 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1248 - mean_squared_error: 0.0345\n",
      "Epoch 1: val_loss improved from inf to 0.09972, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 19s 296ms/step - loss: 0.1248 - mean_squared_error: 0.0345 - val_loss: 0.0997 - val_mean_squared_error: 0.0193\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0884 - mean_squared_error: 0.0151\n",
      "Epoch 2: val_loss improved from 0.09972 to 0.07853, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.0884 - mean_squared_error: 0.0151 - val_loss: 0.0785 - val_mean_squared_error: 0.0098\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.0131\n",
      "Epoch 3: val_loss improved from 0.07853 to 0.07526, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 5s 228ms/step - loss: 0.0832 - mean_squared_error: 0.0131 - val_loss: 0.0753 - val_mean_squared_error: 0.0109\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.0128\n",
      "Epoch 4: val_loss improved from 0.07526 to 0.07445, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 5s 235ms/step - loss: 0.0810 - mean_squared_error: 0.0128 - val_loss: 0.0744 - val_mean_squared_error: 0.0111\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0749 - mean_squared_error: 0.0111\n",
      "Epoch 5: val_loss did not improve from 0.07445\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.0749 - mean_squared_error: 0.0111 - val_loss: 0.0815 - val_mean_squared_error: 0.0131\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0577 - mean_squared_error: 0.0070\n",
      "Epoch 6: val_loss improved from 0.07445 to 0.04364, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 5s 247ms/step - loss: 0.0577 - mean_squared_error: 0.0070 - val_loss: 0.0436 - val_mean_squared_error: 0.0044\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0489 - mean_squared_error: 0.0053\n",
      "Epoch 7: val_loss did not improve from 0.04364\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.0489 - mean_squared_error: 0.0053 - val_loss: 0.0683 - val_mean_squared_error: 0.0075\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0446 - mean_squared_error: 0.0045\n",
      "Epoch 8: val_loss improved from 0.04364 to 0.04293, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size19_pool2_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "21/21 [==============================] - 5s 247ms/step - loss: 0.0446 - mean_squared_error: 0.0045 - val_loss: 0.0429 - val_mean_squared_error: 0.0035\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0422 - mean_squared_error: 0.0040\n",
      "Epoch 9: val_loss did not improve from 0.04293\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 0.0422 - mean_squared_error: 0.0040 - val_loss: 0.0490 - val_mean_squared_error: 0.0042\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0037\n",
      "Epoch 10: val_loss did not improve from 0.04293\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.0403 - mean_squared_error: 0.0037 - val_loss: 0.0594 - val_mean_squared_error: 0.0056\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0035\n",
      "Epoch 11: val_loss did not improve from 0.04293\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.0381 - mean_squared_error: 0.0035 - val_loss: 0.0488 - val_mean_squared_error: 0.0040\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###3 fold : val mae 0.04###\n",
      "mae0.83+-0.10\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.0138\n",
      "Epoch 1: val_loss improved from inf to 0.05614, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_0.hdf5\n",
      "83/83 [==============================] - 12s 47ms/step - loss: 0.0831 - mean_squared_error: 0.0138 - val_loss: 0.0561 - val_mean_squared_error: 0.0064\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0549 - mean_squared_error: 0.0063\n",
      "Epoch 2: val_loss did not improve from 0.05614\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0549 - mean_squared_error: 0.0063 - val_loss: 0.1280 - val_mean_squared_error: 0.0231\n",
      "Epoch 3/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0473 - mean_squared_error: 0.0049\n",
      "Epoch 3: val_loss improved from 0.05614 to 0.04630, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0471 - mean_squared_error: 0.0049 - val_loss: 0.0463 - val_mean_squared_error: 0.0049\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0445 - mean_squared_error: 0.0043\n",
      "Epoch 4: val_loss did not improve from 0.04630\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0445 - mean_squared_error: 0.0043 - val_loss: 0.0541 - val_mean_squared_error: 0.0067\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0037\n",
      "Epoch 5: val_loss did not improve from 0.04630\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0404 - mean_squared_error: 0.0037 - val_loss: 0.0679 - val_mean_squared_error: 0.0091\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0036\n",
      "Epoch 6: val_loss did not improve from 0.04630\n",
      "83/83 [==============================] - 3s 30ms/step - loss: 0.0393 - mean_squared_error: 0.0036 - val_loss: 0.0756 - val_mean_squared_error: 0.0130\n",
      "55/55 [==============================] - 1s 7ms/step\n",
      " ###0 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0813 - mean_squared_error: 0.0135\n",
      "Epoch 1: val_loss improved from inf to 0.04908, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_1.hdf5\n",
      "83/83 [==============================] - 12s 43ms/step - loss: 0.0813 - mean_squared_error: 0.0135 - val_loss: 0.0491 - val_mean_squared_error: 0.0048\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0533 - mean_squared_error: 0.0060\n",
      "Epoch 2: val_loss did not improve from 0.04908\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0533 - mean_squared_error: 0.0060 - val_loss: 0.0764 - val_mean_squared_error: 0.0099\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.0049\n",
      "Epoch 3: val_loss did not improve from 0.04908\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0478 - mean_squared_error: 0.0049 - val_loss: 0.0525 - val_mean_squared_error: 0.0057\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0041\n",
      "Epoch 4: val_loss did not improve from 0.04908\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0426 - mean_squared_error: 0.0041 - val_loss: 0.0708 - val_mean_squared_error: 0.0097\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###1 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.0137\n",
      "Epoch 1: val_loss improved from inf to 0.06580, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_2.hdf5\n",
      "83/83 [==============================] - 15s 46ms/step - loss: 0.0837 - mean_squared_error: 0.0137 - val_loss: 0.0658 - val_mean_squared_error: 0.0058\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0560 - mean_squared_error: 0.0065\n",
      "Epoch 2: val_loss improved from 0.06580 to 0.06159, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0560 - mean_squared_error: 0.0065 - val_loss: 0.0616 - val_mean_squared_error: 0.0067\n",
      "Epoch 3/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.0049\n",
      "Epoch 3: val_loss did not improve from 0.06159\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0472 - mean_squared_error: 0.0049 - val_loss: 0.1381 - val_mean_squared_error: 0.0245\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0432 - mean_squared_error: 0.0041\n",
      "Epoch 4: val_loss did not improve from 0.06159\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0432 - mean_squared_error: 0.0041 - val_loss: 0.0852 - val_mean_squared_error: 0.0129\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0037\n",
      "Epoch 5: val_loss improved from 0.06159 to 0.05914, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0403 - mean_squared_error: 0.0037 - val_loss: 0.0591 - val_mean_squared_error: 0.0073\n",
      "Epoch 6/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0034\n",
      "Epoch 6: val_loss improved from 0.05914 to 0.03690, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0390 - mean_squared_error: 0.0034 - val_loss: 0.0369 - val_mean_squared_error: 0.0035\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0034\n",
      "Epoch 7: val_loss did not improve from 0.03690\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0382 - mean_squared_error: 0.0034 - val_loss: 0.0798 - val_mean_squared_error: 0.0104\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0364 - mean_squared_error: 0.0032\n",
      "Epoch 8: val_loss did not improve from 0.03690\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0364 - mean_squared_error: 0.0032 - val_loss: 0.0421 - val_mean_squared_error: 0.0040\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0030\n",
      "Epoch 9: val_loss did not improve from 0.03690\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0354 - mean_squared_error: 0.0030 - val_loss: 0.0511 - val_mean_squared_error: 0.0055\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###2 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0846 - mean_squared_error: 0.0143\n",
      "Epoch 1: val_loss improved from inf to 0.06430, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_3.hdf5\n",
      "83/83 [==============================] - 13s 46ms/step - loss: 0.0846 - mean_squared_error: 0.0143 - val_loss: 0.0643 - val_mean_squared_error: 0.0060\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.0064\n",
      "Epoch 2: val_loss improved from 0.06430 to 0.05411, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0550 - mean_squared_error: 0.0064 - val_loss: 0.0541 - val_mean_squared_error: 0.0062\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.0051\n",
      "Epoch 3: val_loss did not improve from 0.05411\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0486 - mean_squared_error: 0.0051 - val_loss: 0.0952 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0452 - mean_squared_error: 0.0045\n",
      "Epoch 4: val_loss improved from 0.05411 to 0.05119, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size9_pool5_do0.1_tra3_head2_kdim16_fnn64/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.0451 - mean_squared_error: 0.0045 - val_loss: 0.0512 - val_mean_squared_error: 0.0059\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0426 - mean_squared_error: 0.0040\n",
      "Epoch 5: val_loss did not improve from 0.05119\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0426 - mean_squared_error: 0.0040 - val_loss: 0.0520 - val_mean_squared_error: 0.0059\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0036\n",
      "Epoch 6: val_loss did not improve from 0.05119\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0392 - mean_squared_error: 0.0036 - val_loss: 0.0557 - val_mean_squared_error: 0.0069\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0035\n",
      "Epoch 7: val_loss did not improve from 0.05119\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0386 - mean_squared_error: 0.0035 - val_loss: 0.1062 - val_mean_squared_error: 0.0196\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###3 fold : val mae 0.05###\n",
      "mae0.95+-0.11\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool2_do0.2_tra4_head8_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 01:41:42.361681: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.96GiB (rounded to 6400000000)requested by op model/multi_head_attention/softmax/Softmax\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-22 01:41:42.361850: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-22 01:41:42.361873: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 665, Chunks in use: 665. 166.2KiB allocated for chunks. 166.2KiB in use in bin. 51.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361885: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 38, Chunks in use: 37. 19.2KiB allocated for chunks. 18.5KiB in use in bin. 18.5KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361896: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 4.2KiB allocated for chunks. 4.2KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361907: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 117, Chunks in use: 117. 260.0KiB allocated for chunks. 260.0KiB in use in bin. 234.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361918: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 90, Chunks in use: 90. 412.8KiB allocated for chunks. 412.8KiB in use in bin. 360.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361929: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 63, Chunks in use: 62. 577.5KiB allocated for chunks. 568.2KiB in use in bin. 536.5KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361940: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 6, Chunks in use: 6. 139.8KiB allocated for chunks. 139.8KiB in use in bin. 102.2KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361951: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 9, Chunks in use: 9. 414.8KiB allocated for chunks. 414.8KiB in use in bin. 324.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361962: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 104.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361973: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 3, Chunks in use: 0. 690.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361983: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 10, Chunks in use: 0. 3.38MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.361992: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 2, Chunks in use: 0. 1.69MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362002: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 0. 6.99MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362012: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 0. 5.86MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362022: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 4, Chunks in use: 0. 24.20MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362034: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 4, Chunks in use: 3. 43.00MiB allocated for chunks. 29.60MiB in use in bin. 29.30MiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362045: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 4, Chunks in use: 4. 92.19MiB allocated for chunks. 92.19MiB in use in bin. 87.89MiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362056: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 4, Chunks in use: 4. 148.60MiB allocated for chunks. 148.60MiB in use in bin. 117.19MiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362067: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 4, Chunks in use: 4. 317.80MiB allocated for chunks. 317.80MiB in use in bin. 273.44MiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362077: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 142.73MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362089: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 12, Chunks in use: 9. 20.67GiB allocated for chunks. 17.17GiB in use in bin. 17.02GiB client-requested in use in bin.\n",
      "2023-09-22 01:41:42.362099: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 5.96GiB was 256.00MiB, Chunk State: \n",
      "2023-09-22 01:41:42.362117: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 273.48MiB | Requested Size: 78.12MiB | in_use: 0 | bin_num: 20, prev:   Size: 256B | Requested Size: 4B | in_use: 1 | bin_num: -1, next:   Size: 256B | Requested Size: 4B | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:41:42.362131: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 398.79MiB | Requested Size: 2.0KiB | in_use: 0 | bin_num: 20, prev:   Size: 1.18GiB | Requested Size: 1.18GiB | in_use: 1 | bin_num: -1, next:   Size: 256B | Requested Size: 4B | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:41:42.362142: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 2.84GiB | Requested Size: 256B | in_use: 0 | bin_num: 20, prev:   Size: 5.96GiB | Requested Size: 5.96GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:41:42.362154: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 23023321088\n",
      "2023-09-22 01:41:42.362166: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000000 of size 1280 next 1\n",
      "2023-09-22 01:41:42.362174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000500 of size 256 next 2\n",
      "2023-09-22 01:41:42.362182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000600 of size 256 next 3\n",
      "2023-09-22 01:41:42.362189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000700 of size 256 next 5\n",
      "2023-09-22 01:41:42.362197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000800 of size 256 next 6\n",
      "2023-09-22 01:41:42.362204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000900 of size 256 next 4\n",
      "2023-09-22 01:41:42.362211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000a00 of size 256 next 377\n",
      "2023-09-22 01:41:42.362219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000b00 of size 256 next 1338\n",
      "2023-09-22 01:41:42.362226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000c00 of size 256 next 1366\n",
      "2023-09-22 01:41:42.362233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000d00 of size 256 next 12\n",
      "2023-09-22 01:41:42.362241: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000e00 of size 256 next 13\n",
      "2023-09-22 01:41:42.362248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000f00 of size 256 next 14\n",
      "2023-09-22 01:41:42.362256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001000 of size 2048 next 1267\n",
      "2023-09-22 01:41:42.362266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001800 of size 2048 next 876\n",
      "2023-09-22 01:41:42.362274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002000 of size 4096 next 320\n",
      "2023-09-22 01:41:42.362281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003000 of size 4352 next 28\n",
      "2023-09-22 01:41:42.362289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004100 of size 256 next 29\n",
      "2023-09-22 01:41:42.362296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004200 of size 256 next 30\n",
      "2023-09-22 01:41:42.362303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004300 of size 256 next 61\n",
      "2023-09-22 01:41:42.362310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004400 of size 256 next 309\n",
      "2023-09-22 01:41:42.362318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004500 of size 256 next 563\n",
      "2023-09-22 01:41:42.362325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004600 of size 256 next 42\n",
      "2023-09-22 01:41:42.362332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004700 of size 256 next 37\n",
      "2023-09-22 01:41:42.362341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004800 of size 256 next 36\n",
      "2023-09-22 01:41:42.362348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004900 of size 2048 next 1604\n",
      "2023-09-22 01:41:42.362356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005100 of size 2048 next 805\n",
      "2023-09-22 01:41:42.362363: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005900 of size 2048 next 32\n",
      "2023-09-22 01:41:42.362370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006100 of size 256 next 31\n",
      "2023-09-22 01:41:42.362378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006200 of size 256 next 33\n",
      "2023-09-22 01:41:42.362385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006300 of size 256 next 1658\n",
      "2023-09-22 01:41:42.362398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006400 of size 256 next 1075\n",
      "2023-09-22 01:41:42.362406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006500 of size 256 next 1446\n",
      "2023-09-22 01:41:42.362414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006600 of size 256 next 1050\n",
      "2023-09-22 01:41:42.362424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006700 of size 256 next 911\n",
      "2023-09-22 01:41:42.362432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006800 of size 256 next 35\n",
      "2023-09-22 01:41:42.362442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006900 of size 256 next 45\n",
      "2023-09-22 01:41:42.362450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006a00 of size 256 next 48\n",
      "2023-09-22 01:41:42.362459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006b00 of size 256 next 49\n",
      "2023-09-22 01:41:42.362469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006c00 of size 8192 next 1262\n",
      "2023-09-22 01:41:42.362479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de008c00 of size 8192 next 612\n",
      "2023-09-22 01:41:42.362489: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ac00 of size 8192 next 1536\n",
      "2023-09-22 01:41:42.362499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00cc00 of size 21248 next 1646\n",
      "2023-09-22 01:41:42.362510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de011f00 of size 8448 next 330\n",
      "2023-09-22 01:41:42.362518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de014000 of size 8448 next 1305\n",
      "2023-09-22 01:41:42.362528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016100 of size 11264 next 69\n",
      "2023-09-22 01:41:42.362538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de018d00 of size 11264 next 519\n",
      "2023-09-22 01:41:42.362547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01b900 of size 8192 next 632\n",
      "2023-09-22 01:41:42.362555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01d900 of size 9472 next 134\n",
      "2023-09-22 01:41:42.362566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01fe00 of size 256 next 1035\n",
      "2023-09-22 01:41:42.362576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01ff00 of size 256 next 1587\n",
      "2023-09-22 01:41:42.362586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020000 of size 256 next 180\n",
      "2023-09-22 01:41:42.362596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020100 of size 256 next 504\n",
      "2023-09-22 01:41:42.362605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020200 of size 256 next 1599\n",
      "2023-09-22 01:41:42.362613: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020300 of size 256 next 398\n",
      "2023-09-22 01:41:42.362622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020400 of size 256 next 1704\n",
      "2023-09-22 01:41:42.362632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020500 of size 256 next 1356\n",
      "2023-09-22 01:41:42.362642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020600 of size 256 next 1636\n",
      "2023-09-22 01:41:42.362652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020700 of size 256 next 308\n",
      "2023-09-22 01:41:42.362660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020800 of size 256 next 685\n",
      "2023-09-22 01:41:42.362669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020900 of size 256 next 240\n",
      "2023-09-22 01:41:42.362677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020a00 of size 256 next 401\n",
      "2023-09-22 01:41:42.362684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020b00 of size 256 next 1065\n",
      "2023-09-22 01:41:42.362693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de020c00 of size 6144 next 314\n",
      "2023-09-22 01:41:42.362701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022400 of size 512 next 1486\n",
      "2023-09-22 01:41:42.362709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022600 of size 512 next 461\n",
      "2023-09-22 01:41:42.362718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022800 of size 256 next 854\n",
      "2023-09-22 01:41:42.362726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022900 of size 256 next 1522\n",
      "2023-09-22 01:41:42.362735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022a00 of size 256 next 968\n",
      "2023-09-22 01:41:42.362743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022b00 of size 256 next 1623\n",
      "2023-09-22 01:41:42.362753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de022c00 of size 4096 next 210\n",
      "2023-09-22 01:41:42.362763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de023c00 of size 4096 next 270\n",
      "2023-09-22 01:41:42.362773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de024c00 of size 4096 next 1288\n",
      "2023-09-22 01:41:42.362784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de025c00 of size 40704 next 105\n",
      "2023-09-22 01:41:42.362793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fb00 of size 256 next 103\n",
      "2023-09-22 01:41:42.362803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fc00 of size 256 next 104\n",
      "2023-09-22 01:41:42.362813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fd00 of size 256 next 107\n",
      "2023-09-22 01:41:42.362821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fe00 of size 256 next 110\n",
      "2023-09-22 01:41:42.362830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ff00 of size 256 next 115\n",
      "2023-09-22 01:41:42.362838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030000 of size 256 next 116\n",
      "2023-09-22 01:41:42.362845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030100 of size 256 next 117\n",
      "2023-09-22 01:41:42.362854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030200 of size 256 next 52\n",
      "2023-09-22 01:41:42.362864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030300 of size 256 next 415\n",
      "2023-09-22 01:41:42.362873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030400 of size 256 next 55\n",
      "2023-09-22 01:41:42.362883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030500 of size 256 next 646\n",
      "2023-09-22 01:41:42.362893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030600 of size 256 next 108\n",
      "2023-09-22 01:41:42.362902: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030700 of size 256 next 109\n",
      "2023-09-22 01:41:42.362912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030800 of size 1263840000 next 1227\n",
      "2023-09-22 01:41:42.362922: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f122957b300 of size 418161920 next 953\n",
      "2023-09-22 01:41:42.362931: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445800 of size 256 next 925\n",
      "2023-09-22 01:41:42.362942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445900 of size 30720000 next 445\n",
      "2023-09-22 01:41:42.362952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244191900 of size 34841344 next 894\n",
      "2023-09-22 01:41:42.362961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbc00 of size 256 next 695\n",
      "2023-09-22 01:41:42.362971: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbd00 of size 256 next 1266\n",
      "2023-09-22 01:41:42.362981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbe00 of size 2048 next 974\n",
      "2023-09-22 01:41:42.362991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cc600 of size 2048 next 620\n",
      "2023-09-22 01:41:42.363000: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cce00 of size 2048 next 574\n",
      "2023-09-22 01:41:42.363010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cd600 of size 2048 next 1169\n",
      "2023-09-22 01:41:42.363019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cde00 of size 3584 next 896\n",
      "2023-09-22 01:41:42.363031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cec00 of size 256 next 676\n",
      "2023-09-22 01:41:42.363041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ced00 of size 256 next 1122\n",
      "2023-09-22 01:41:42.363050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cee00 of size 2304 next 917\n",
      "2023-09-22 01:41:42.363059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cf700 of size 256 next 635\n",
      "2023-09-22 01:41:42.363069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cf800 of size 256 next 1693\n",
      "2023-09-22 01:41:42.363078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cf900 of size 256 next 1610\n",
      "2023-09-22 01:41:42.363087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cfa00 of size 256 next 348\n",
      "2023-09-22 01:41:42.363097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cfb00 of size 512 next 536\n",
      "2023-09-22 01:41:42.363107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cfd00 of size 512 next 419\n",
      "2023-09-22 01:41:42.363116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cff00 of size 512 next 1689\n",
      "2023-09-22 01:41:42.363125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0100 of size 256 next 1133\n",
      "2023-09-22 01:41:42.363134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0200 of size 256 next 849\n",
      "2023-09-22 01:41:42.363156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0300 of size 256 next 1257\n",
      "2023-09-22 01:41:42.363167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0400 of size 256 next 1584\n",
      "2023-09-22 01:41:42.363177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0500 of size 256 next 1677\n",
      "2023-09-22 01:41:42.363187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0600 of size 256 next 1120\n",
      "2023-09-22 01:41:42.363198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0700 of size 4096 next 294\n",
      "2023-09-22 01:41:42.363208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d1700 of size 8192 next 395\n",
      "2023-09-22 01:41:42.363218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d3700 of size 8192 next 969\n",
      "2023-09-22 01:41:42.363228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d5700 of size 8192 next 1459\n",
      "2023-09-22 01:41:42.363238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d7700 of size 4096 next 256\n",
      "2023-09-22 01:41:42.363248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d8700 of size 7168 next 357\n",
      "2023-09-22 01:41:42.363258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da300 of size 256 next 486\n",
      "2023-09-22 01:41:42.363267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da400 of size 256 next 1384\n",
      "2023-09-22 01:41:42.363277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da500 of size 256 next 547\n",
      "2023-09-22 01:41:42.363286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da600 of size 256 next 1705\n",
      "2023-09-22 01:41:42.363297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da700 of size 256 next 627\n",
      "2023-09-22 01:41:42.363306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da800 of size 256 next 802\n",
      "2023-09-22 01:41:42.363316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da900 of size 256 next 873\n",
      "2023-09-22 01:41:42.363327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462daa00 of size 2048 next 1457\n",
      "2023-09-22 01:41:42.363336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462db200 of size 2048 next 992\n",
      "2023-09-22 01:41:42.363345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dba00 of size 256 next 744\n",
      "2023-09-22 01:41:42.363353: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dbb00 of size 256 next 82\n",
      "2023-09-22 01:41:42.363362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dbc00 of size 256 next 1350\n",
      "2023-09-22 01:41:42.363371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dbd00 of size 256 next 443\n",
      "2023-09-22 01:41:42.363380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dbe00 of size 256 next 1607\n",
      "2023-09-22 01:41:42.363390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dbf00 of size 256 next 245\n",
      "2023-09-22 01:41:42.363399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462dc000 of size 256 next 1124\n",
      "2023-09-22 01:41:42.363410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12462dc100 of size 4219648 next 959\n",
      "2023-09-22 01:41:42.363419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2400 of size 256 next 1426\n",
      "2023-09-22 01:41:42.363429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2500 of size 21760 next 89\n",
      "2023-09-22 01:41:42.363438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e7a00 of size 256 next 483\n",
      "2023-09-22 01:41:42.363447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e7b00 of size 256 next 95\n",
      "2023-09-22 01:41:42.363457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e7c00 of size 13824 next 606\n",
      "2023-09-22 01:41:42.363466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eb200 of size 13824 next 379\n",
      "2023-09-22 01:41:42.363475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ee800 of size 14336 next 291\n",
      "2023-09-22 01:41:42.363485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2000 of size 256 next 880\n",
      "2023-09-22 01:41:42.363494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2100 of size 2048 next 1663\n",
      "2023-09-22 01:41:42.363504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2900 of size 2048 next 652\n",
      "2023-09-22 01:41:42.363514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3100 of size 4096 next 834\n",
      "2023-09-22 01:41:42.363524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4100 of size 5888 next 98\n",
      "2023-09-22 01:41:42.363533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5800 of size 256 next 385\n",
      "2023-09-22 01:41:42.363543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5900 of size 256 next 705\n",
      "2023-09-22 01:41:42.363552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5a00 of size 256 next 225\n",
      "2023-09-22 01:41:42.363562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5b00 of size 10556928 next 1155\n",
      "2023-09-22 01:41:42.363571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107100 of size 256 next 995\n",
      "2023-09-22 01:41:42.363581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107200 of size 2048 next 1320\n",
      "2023-09-22 01:41:42.363590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107a00 of size 2048 next 304\n",
      "2023-09-22 01:41:42.363601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247108200 of size 4096 next 1586\n",
      "2023-09-22 01:41:42.363612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247109200 of size 4608 next 746\n",
      "2023-09-22 01:41:42.363623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710a400 of size 4096 next 650\n",
      "2023-09-22 01:41:42.363633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710b400 of size 6656 next 686\n",
      "2023-09-22 01:41:42.363642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710ce00 of size 256 next 509\n",
      "2023-09-22 01:41:42.363651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710cf00 of size 256 next 126\n",
      "2023-09-22 01:41:42.363660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710d000 of size 256 next 1647\n",
      "2023-09-22 01:41:42.363668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710d100 of size 4864 next 663\n",
      "2023-09-22 01:41:42.363677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710e400 of size 256 next 1162\n",
      "2023-09-22 01:41:42.363688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710e500 of size 256 next 1272\n",
      "2023-09-22 01:41:42.363698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710e600 of size 256 next 1695\n",
      "2023-09-22 01:41:42.363708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710e700 of size 256 next 591\n",
      "2023-09-22 01:41:42.363717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710e800 of size 256 next 1638\n",
      "2023-09-22 01:41:42.363727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710e900 of size 256 next 193\n",
      "2023-09-22 01:41:42.363737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710ea00 of size 256 next 1434\n",
      "2023-09-22 01:41:42.363747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710eb00 of size 256 next 1017\n",
      "2023-09-22 01:41:42.363756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710ec00 of size 256 next 548\n",
      "2023-09-22 01:41:42.363766: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710ed00 of size 256 next 243\n",
      "2023-09-22 01:41:42.363775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710ee00 of size 256 next 975\n",
      "2023-09-22 01:41:42.363783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710ef00 of size 256 next 1374\n",
      "2023-09-22 01:41:42.363793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f000 of size 256 next 177\n",
      "2023-09-22 01:41:42.363802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f100 of size 256 next 437\n",
      "2023-09-22 01:41:42.363812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f200 of size 256 next 757\n",
      "2023-09-22 01:41:42.363821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f300 of size 256 next 1285\n",
      "2023-09-22 01:41:42.363831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f400 of size 256 next 468\n",
      "2023-09-22 01:41:42.363840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f500 of size 256 next 78\n",
      "2023-09-22 01:41:42.363850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f600 of size 256 next 728\n",
      "2023-09-22 01:41:42.363859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f700 of size 256 next 610\n",
      "2023-09-22 01:41:42.363869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f800 of size 256 next 53\n",
      "2023-09-22 01:41:42.363879: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f900 of size 256 next 1628\n",
      "2023-09-22 01:41:42.363888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710fa00 of size 256 next 996\n",
      "2023-09-22 01:41:42.363897: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710fb00 of size 256 next 238\n",
      "2023-09-22 01:41:42.363907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710fc00 of size 256 next 380\n",
      "2023-09-22 01:41:42.363916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710fd00 of size 256 next 1679\n",
      "2023-09-22 01:41:42.363925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710fe00 of size 256 next 1656\n",
      "2023-09-22 01:41:42.363935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710ff00 of size 256 next 1430\n",
      "2023-09-22 01:41:42.363945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110000 of size 256 next 448\n",
      "2023-09-22 01:41:42.363954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110100 of size 256 next 354\n",
      "2023-09-22 01:41:42.363963: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110200 of size 256 next 381\n",
      "2023-09-22 01:41:42.363973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110300 of size 256 next 232\n",
      "2023-09-22 01:41:42.363982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110400 of size 256 next 993\n",
      "2023-09-22 01:41:42.363992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110500 of size 256 next 1317\n",
      "2023-09-22 01:41:42.364001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110600 of size 256 next 20\n",
      "2023-09-22 01:41:42.364010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110700 of size 256 next 823\n",
      "2023-09-22 01:41:42.364020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110800 of size 256 next 549\n",
      "2023-09-22 01:41:42.364030: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110900 of size 256 next 1608\n",
      "2023-09-22 01:41:42.364039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110a00 of size 256 next 231\n",
      "2023-09-22 01:41:42.364049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110b00 of size 256 next 1637\n",
      "2023-09-22 01:41:42.364059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110c00 of size 256 next 568\n",
      "2023-09-22 01:41:42.364068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110d00 of size 256 next 1370\n",
      "2023-09-22 01:41:42.364077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110e00 of size 256 next 1633\n",
      "2023-09-22 01:41:42.364087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247110f00 of size 256 next 1625\n",
      "2023-09-22 01:41:42.364094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111000 of size 256 next 156\n",
      "2023-09-22 01:41:42.364103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111100 of size 256 next 16\n",
      "2023-09-22 01:41:42.364112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111200 of size 256 next 1226\n",
      "2023-09-22 01:41:42.364122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247111300 of size 4096 next 408\n",
      "2023-09-22 01:41:42.364131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247112300 of size 8192 next 456\n",
      "2023-09-22 01:41:42.364140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247114300 of size 8192 next 1063\n",
      "2023-09-22 01:41:42.364149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247116300 of size 8192 next 470\n",
      "2023-09-22 01:41:42.364159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247118300 of size 8192 next 1229\n",
      "2023-09-22 01:41:42.364169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711a300 of size 8192 next 94\n",
      "2023-09-22 01:41:42.364178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711c300 of size 4096 next 413\n",
      "2023-09-22 01:41:42.364187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711d300 of size 4096 next 1280\n",
      "2023-09-22 01:41:42.364198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711e300 of size 1024 next 366\n",
      "2023-09-22 01:41:42.364208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711e700 of size 1024 next 550\n",
      "2023-09-22 01:41:42.364217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711eb00 of size 256 next 1667\n",
      "2023-09-22 01:41:42.364227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711ec00 of size 512 next 587\n",
      "2023-09-22 01:41:42.364236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711ee00 of size 512 next 1383\n",
      "2023-09-22 01:41:42.364245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711f000 of size 512 next 1291\n",
      "2023-09-22 01:41:42.364255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711f200 of size 512 next 1517\n",
      "2023-09-22 01:41:42.364264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711f400 of size 512 next 405\n",
      "2023-09-22 01:41:42.364274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711f600 of size 512 next 102\n",
      "2023-09-22 01:41:42.364283: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711f800 of size 256 next 427\n",
      "2023-09-22 01:41:42.364292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711f900 of size 256 next 1556\n",
      "2023-09-22 01:41:42.364302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711fa00 of size 256 next 1688\n",
      "2023-09-22 01:41:42.364311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711fb00 of size 256 next 131\n",
      "2023-09-22 01:41:42.364320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711fc00 of size 256 next 85\n",
      "2023-09-22 01:41:42.364329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711fd00 of size 3328 next 382\n",
      "2023-09-22 01:41:42.364339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247120a00 of size 256 next 618\n",
      "2023-09-22 01:41:42.364348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247120b00 of size 256 next 524\n",
      "2023-09-22 01:41:42.364357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247120c00 of size 256 next 1415\n",
      "2023-09-22 01:41:42.364367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247120d00 of size 256 next 499\n",
      "2023-09-22 01:41:42.364377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247120e00 of size 256 next 954\n",
      "2023-09-22 01:41:42.364386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247120f00 of size 256 next 1149\n",
      "2023-09-22 01:41:42.364395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121000 of size 256 next 903\n",
      "2023-09-22 01:41:42.364403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121100 of size 256 next 67\n",
      "2023-09-22 01:41:42.364412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121200 of size 256 next 262\n",
      "2023-09-22 01:41:42.364421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121300 of size 256 next 261\n",
      "2023-09-22 01:41:42.364430: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121400 of size 256 next 658\n",
      "2023-09-22 01:41:42.364439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121500 of size 256 next 211\n",
      "2023-09-22 01:41:42.364449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121600 of size 256 next 557\n",
      "2023-09-22 01:41:42.364458: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121700 of size 256 next 1138\n",
      "2023-09-22 01:41:42.364468: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247121800 of size 8192 next 905\n",
      "2023-09-22 01:41:42.364477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247123800 of size 4096 next 1247\n",
      "2023-09-22 01:41:42.364487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247124800 of size 7936 next 1140\n",
      "2023-09-22 01:41:42.364496: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126700 of size 256 next 47\n",
      "2023-09-22 01:41:42.364505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126800 of size 4096 next 1156\n",
      "2023-09-22 01:41:42.364515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127800 of size 11264 next 696\n",
      "2023-09-22 01:41:42.364524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a400 of size 8192 next 234\n",
      "2023-09-22 01:41:42.364534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712c400 of size 8192 next 1458\n",
      "2023-09-22 01:41:42.364543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712e400 of size 15360 next 916\n",
      "2023-09-22 01:41:42.364552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247132000 of size 2048 next 397\n",
      "2023-09-22 01:41:42.364562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247132800 of size 2304 next 246\n",
      "2023-09-22 01:41:42.364571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247133100 of size 2048 next 949\n",
      "2023-09-22 01:41:42.364580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247133900 of size 2560 next 597\n",
      "2023-09-22 01:41:42.364590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247134300 of size 2048 next 472\n",
      "2023-09-22 01:41:42.364599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247134b00 of size 2048 next 266\n",
      "2023-09-22 01:41:42.364609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247135300 of size 2048 next 885\n",
      "2023-09-22 01:41:42.364618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247135b00 of size 2048 next 948\n",
      "2023-09-22 01:41:42.364627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247136300 of size 2048 next 1644\n",
      "2023-09-22 01:41:42.364637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247136b00 of size 2048 next 1532\n",
      "2023-09-22 01:41:42.364646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247137300 of size 2048 next 1423\n",
      "2023-09-22 01:41:42.364655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247137b00 of size 4096 next 795\n",
      "2023-09-22 01:41:42.364665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247138b00 of size 7424 next 181\n",
      "2023-09-22 01:41:42.364677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713a800 of size 256 next 857\n",
      "2023-09-22 01:41:42.364686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713a900 of size 256 next 579\n",
      "2023-09-22 01:41:42.364695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713aa00 of size 256 next 406\n",
      "2023-09-22 01:41:42.364705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713ab00 of size 256 next 370\n",
      "2023-09-22 01:41:42.364714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713ac00 of size 256 next 1141\n",
      "2023-09-22 01:41:42.364723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713ad00 of size 256 next 1233\n",
      "2023-09-22 01:41:42.364733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713ae00 of size 256 next 1045\n",
      "2023-09-22 01:41:42.364742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713af00 of size 256 next 1376\n",
      "2023-09-22 01:41:42.364751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713b000 of size 2048 next 340\n",
      "2023-09-22 01:41:42.364760: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713b800 of size 256 next 120\n",
      "2023-09-22 01:41:42.364770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713b900 of size 256 next 704\n",
      "2023-09-22 01:41:42.364779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713ba00 of size 256 next 1028\n",
      "2023-09-22 01:41:42.364788: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713bb00 of size 256 next 1433\n",
      "2023-09-22 01:41:42.364798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713bc00 of size 256 next 1572\n",
      "2023-09-22 01:41:42.364807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713bd00 of size 256 next 1640\n",
      "2023-09-22 01:41:42.364817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713be00 of size 256 next 1474\n",
      "2023-09-22 01:41:42.364826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713bf00 of size 256 next 361\n",
      "2023-09-22 01:41:42.364834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c000 of size 256 next 264\n",
      "2023-09-22 01:41:42.364843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c100 of size 256 next 1271\n",
      "2023-09-22 01:41:42.364852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c200 of size 256 next 219\n",
      "2023-09-22 01:41:42.364862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c300 of size 256 next 1660\n",
      "2023-09-22 01:41:42.364871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c400 of size 256 next 869\n",
      "2023-09-22 01:41:42.364881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c500 of size 256 next 292\n",
      "2023-09-22 01:41:42.364890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c600 of size 256 next 338\n",
      "2023-09-22 01:41:42.364900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c700 of size 256 next 450\n",
      "2023-09-22 01:41:42.364909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713c800 of size 4096 next 1248\n",
      "2023-09-22 01:41:42.364918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713d800 of size 4096 next 735\n",
      "2023-09-22 01:41:42.364928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713e800 of size 2048 next 1346\n",
      "2023-09-22 01:41:42.364937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f000 of size 256 next 154\n",
      "2023-09-22 01:41:42.364947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f100 of size 256 next 868\n",
      "2023-09-22 01:41:42.364955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f200 of size 256 next 1238\n",
      "2023-09-22 01:41:42.364964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f300 of size 256 next 66\n",
      "2023-09-22 01:41:42.364973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f400 of size 256 next 336\n",
      "2023-09-22 01:41:42.364982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f500 of size 256 next 1460\n",
      "2023-09-22 01:41:42.364991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f600 of size 256 next 782\n",
      "2023-09-22 01:41:42.365001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f700 of size 256 next 288\n",
      "2023-09-22 01:41:42.365010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713f800 of size 2560 next 129\n",
      "2023-09-22 01:41:42.365020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247140200 of size 2048 next 1188\n",
      "2023-09-22 01:41:42.365029: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247140a00 of size 2560 next 545\n",
      "2023-09-22 01:41:42.365038: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247141400 of size 2048 next 958\n",
      "2023-09-22 01:41:42.365048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247141c00 of size 2048 next 934\n",
      "2023-09-22 01:41:42.365058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247142400 of size 2048 next 133\n",
      "2023-09-22 01:41:42.365067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247142c00 of size 256 next 1109\n",
      "2023-09-22 01:41:42.365077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247142d00 of size 256 next 662\n",
      "2023-09-22 01:41:42.365086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247142e00 of size 256 next 1648\n",
      "2023-09-22 01:41:42.365095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247142f00 of size 256 next 1006\n",
      "2023-09-22 01:41:42.365104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143000 of size 256 next 987\n",
      "2023-09-22 01:41:42.365115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143100 of size 256 next 577\n",
      "2023-09-22 01:41:42.365124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143200 of size 256 next 1055\n",
      "2023-09-22 01:41:42.365134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143300 of size 256 next 1525\n",
      "2023-09-22 01:41:42.365143: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143400 of size 256 next 1582\n",
      "2023-09-22 01:41:42.365152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143500 of size 256 next 1553\n",
      "2023-09-22 01:41:42.365161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143600 of size 256 next 1672\n",
      "2023-09-22 01:41:42.365170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143700 of size 256 next 1313\n",
      "2023-09-22 01:41:42.365179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143800 of size 256 next 403\n",
      "2023-09-22 01:41:42.365189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143900 of size 256 next 1411\n",
      "2023-09-22 01:41:42.365198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143a00 of size 256 next 1691\n",
      "2023-09-22 01:41:42.365207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143b00 of size 256 next 1221\n",
      "2023-09-22 01:41:42.365217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143c00 of size 4096 next 561\n",
      "2023-09-22 01:41:42.365226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144c00 of size 256 next 161\n",
      "2023-09-22 01:41:42.365236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144d00 of size 256 next 1485\n",
      "2023-09-22 01:41:42.365245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144e00 of size 256 next 594\n",
      "2023-09-22 01:41:42.365255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144f00 of size 256 next 1683\n",
      "2023-09-22 01:41:42.365262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145000 of size 256 next 807\n",
      "2023-09-22 01:41:42.365271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145100 of size 256 next 781\n",
      "2023-09-22 01:41:42.365281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145200 of size 256 next 424\n",
      "2023-09-22 01:41:42.365291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145300 of size 256 next 513\n",
      "2023-09-22 01:41:42.365300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145400 of size 256 next 1382\n",
      "2023-09-22 01:41:42.365309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145500 of size 256 next 1016\n",
      "2023-09-22 01:41:42.365319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145600 of size 256 next 1005\n",
      "2023-09-22 01:41:42.365328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145700 of size 256 next 858\n",
      "2023-09-22 01:41:42.365338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145800 of size 256 next 1319\n",
      "2023-09-22 01:41:42.365347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145900 of size 256 next 168\n",
      "2023-09-22 01:41:42.365356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145a00 of size 256 next 898\n",
      "2023-09-22 01:41:42.365365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145b00 of size 256 next 608\n",
      "2023-09-22 01:41:42.365375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247145c00 of size 4096 next 1469\n",
      "2023-09-22 01:41:42.365384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247146c00 of size 6144 next 1170\n",
      "2023-09-22 01:41:42.365393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247148400 of size 2816 next 449\n",
      "2023-09-22 01:41:42.365402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1247148f00 of size 306944 next 163\n",
      "2023-09-22 01:41:42.365411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193e00 of size 256 next 123\n",
      "2023-09-22 01:41:42.365421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193f00 of size 256 next 1630\n",
      "2023-09-22 01:41:42.365430: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194000 of size 256 next 1208\n",
      "2023-09-22 01:41:42.365439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194100 of size 256 next 924\n",
      "2023-09-22 01:41:42.365449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194200 of size 256 next 984\n",
      "2023-09-22 01:41:42.365458: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194300 of size 256 next 453\n",
      "2023-09-22 01:41:42.365468: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194400 of size 256 next 989\n",
      "2023-09-22 01:41:42.365477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1247194500 of size 6516480 next 1614\n",
      "2023-09-22 01:41:42.365486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cb400 of size 3584 next 656\n",
      "2023-09-22 01:41:42.365495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc200 of size 512 next 1224\n",
      "2023-09-22 01:41:42.365505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc400 of size 512 next 521\n",
      "2023-09-22 01:41:42.365514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477cc600 of size 8192 next 19\n",
      "2023-09-22 01:41:42.365523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ce600 of size 8192 next 1519\n",
      "2023-09-22 01:41:42.365533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0600 of size 512 next 817\n",
      "2023-09-22 01:41:42.365542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0800 of size 512 next 1504\n",
      "2023-09-22 01:41:42.365551: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d0a00 of size 8192 next 538\n",
      "2023-09-22 01:41:42.365561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d2a00 of size 8192 next 79\n",
      "2023-09-22 01:41:42.365568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d4a00 of size 256 next 1080\n",
      "2023-09-22 01:41:42.365577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d4b00 of size 256 next 169\n",
      "2023-09-22 01:41:42.365586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d4c00 of size 256 next 1106\n",
      "2023-09-22 01:41:42.365596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d4d00 of size 256 next 1146\n",
      "2023-09-22 01:41:42.365605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d4e00 of size 256 next 299\n",
      "2023-09-22 01:41:42.365614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d4f00 of size 256 next 167\n",
      "2023-09-22 01:41:42.365624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d5000 of size 4096 next 1388\n",
      "2023-09-22 01:41:42.365634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d6000 of size 4096 next 1538\n",
      "2023-09-22 01:41:42.365642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d7000 of size 256 next 1003\n",
      "2023-09-22 01:41:42.365649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d7100 of size 256 next 81\n",
      "2023-09-22 01:41:42.365658: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d7200 of size 4096 next 260\n",
      "2023-09-22 01:41:42.365667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d8200 of size 4096 next 46\n",
      "2023-09-22 01:41:42.365677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9200 of size 256 next 1127\n",
      "2023-09-22 01:41:42.365686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9300 of size 256 next 1528\n",
      "2023-09-22 01:41:42.365695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9400 of size 256 next 677\n",
      "2023-09-22 01:41:42.365704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9500 of size 256 next 981\n",
      "2023-09-22 01:41:42.365713: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9600 of size 256 next 866\n",
      "2023-09-22 01:41:42.365722: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9700 of size 256 next 1095\n",
      "2023-09-22 01:41:42.365732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477d9800 of size 8192 next 702\n",
      "2023-09-22 01:41:42.365741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477db800 of size 8192 next 947\n",
      "2023-09-22 01:41:42.365750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477dd800 of size 512 next 762\n",
      "2023-09-22 01:41:42.365759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477dda00 of size 512 next 176\n",
      "2023-09-22 01:41:42.365768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ddc00 of size 8192 next 529\n",
      "2023-09-22 01:41:42.365778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477dfc00 of size 8192 next 230\n",
      "2023-09-22 01:41:42.365787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e1c00 of size 512 next 1041\n",
      "2023-09-22 01:41:42.365796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e1e00 of size 512 next 341\n",
      "2023-09-22 01:41:42.365805: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e2000 of size 8192 next 1559\n",
      "2023-09-22 01:41:42.365815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e4000 of size 8192 next 1337\n",
      "2023-09-22 01:41:42.365824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e6000 of size 512 next 1101\n",
      "2023-09-22 01:41:42.365833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e6200 of size 512 next 310\n",
      "2023-09-22 01:41:42.365843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e6400 of size 13056 next 918\n",
      "2023-09-22 01:41:42.365852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9700 of size 256 next 440\n",
      "2023-09-22 01:41:42.365861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9800 of size 256 next 999\n",
      "2023-09-22 01:41:42.365871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9900 of size 4096 next 1619\n",
      "2023-09-22 01:41:42.365880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ea900 of size 256 next 1706\n",
      "2023-09-22 01:41:42.365889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eaa00 of size 256 next 1417\n",
      "2023-09-22 01:41:42.365899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eab00 of size 256 next 1102\n",
      "2023-09-22 01:41:42.365908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eac00 of size 256 next 518\n",
      "2023-09-22 01:41:42.365917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ead00 of size 256 next 1401\n",
      "2023-09-22 01:41:42.365926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eae00 of size 256 next 537\n",
      "2023-09-22 01:41:42.365935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eaf00 of size 256 next 1563\n",
      "2023-09-22 01:41:42.365943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb000 of size 256 next 1018\n",
      "2023-09-22 01:41:42.365952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb100 of size 256 next 271\n",
      "2023-09-22 01:41:42.365961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb200 of size 256 next 1481\n",
      "2023-09-22 01:41:42.365970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb300 of size 256 next 1661\n",
      "2023-09-22 01:41:42.365980: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb400 of size 256 next 1639\n",
      "2023-09-22 01:41:42.365989: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb500 of size 256 next 1375\n",
      "2023-09-22 01:41:42.365998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb600 of size 256 next 730\n",
      "2023-09-22 01:41:42.366007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb700 of size 256 next 1597\n",
      "2023-09-22 01:41:42.366016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb800 of size 256 next 716\n",
      "2023-09-22 01:41:42.366025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eb900 of size 256 next 1340\n",
      "2023-09-22 01:41:42.366034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eba00 of size 256 next 283\n",
      "2023-09-22 01:41:42.366043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebb00 of size 256 next 1357\n",
      "2023-09-22 01:41:42.366052: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebc00 of size 256 next 185\n",
      "2023-09-22 01:41:42.366061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebd00 of size 256 next 1557\n",
      "2023-09-22 01:41:42.366070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebe00 of size 256 next 1022\n",
      "2023-09-22 01:41:42.366080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebf00 of size 256 next 1323\n",
      "2023-09-22 01:41:42.366089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec000 of size 256 next 332\n",
      "2023-09-22 01:41:42.366098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec100 of size 256 next 155\n",
      "2023-09-22 01:41:42.366108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec200 of size 256 next 1454\n",
      "2023-09-22 01:41:42.366117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec300 of size 256 next 1265\n",
      "2023-09-22 01:41:42.366126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec400 of size 256 next 1404\n",
      "2023-09-22 01:41:42.366135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec500 of size 512 next 1001\n",
      "2023-09-22 01:41:42.366145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec700 of size 256 next 1336\n",
      "2023-09-22 01:41:42.366153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec800 of size 256 next 1193\n",
      "2023-09-22 01:41:42.366164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ec900 of size 256 next 1439\n",
      "2023-09-22 01:41:42.366173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eca00 of size 256 next 1263\n",
      "2023-09-22 01:41:42.366183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecb00 of size 256 next 434\n",
      "2023-09-22 01:41:42.366192: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecc00 of size 256 next 306\n",
      "2023-09-22 01:41:42.366201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecd00 of size 256 next 979\n",
      "2023-09-22 01:41:42.366210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ece00 of size 256 next 1049\n",
      "2023-09-22 01:41:42.366220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecf00 of size 256 next 1315\n",
      "2023-09-22 01:41:42.366229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed000 of size 256 next 1367\n",
      "2023-09-22 01:41:42.366238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed100 of size 256 next 767\n",
      "2023-09-22 01:41:42.366245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12477ed200 of size 768 next 914\n",
      "2023-09-22 01:41:42.366254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed500 of size 256 next 570\n",
      "2023-09-22 01:41:42.366263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed600 of size 256 next 973\n",
      "2023-09-22 01:41:42.366272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ed700 of size 256 next 988\n",
      "2023-09-22 01:41:42.366282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12477ed800 of size 9472 next 1342\n",
      "2023-09-22 01:41:42.366291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477efd00 of size 256 next 1409\n",
      "2023-09-22 01:41:42.366300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12477efe00 of size 107264 next 247\n",
      "2023-09-22 01:41:42.366309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780a100 of size 2048 next 1151\n",
      "2023-09-22 01:41:42.366318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780a900 of size 2048 next 943\n",
      "2023-09-22 01:41:42.366327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b100 of size 256 next 1447\n",
      "2023-09-22 01:41:42.366337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b200 of size 256 next 886\n",
      "2023-09-22 01:41:42.366346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b300 of size 256 next 1438\n",
      "2023-09-22 01:41:42.366355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b400 of size 256 next 1472\n",
      "2023-09-22 01:41:42.366364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b500 of size 256 next 899\n",
      "2023-09-22 01:41:42.366373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b600 of size 256 next 277\n",
      "2023-09-22 01:41:42.366382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b700 of size 256 next 1701\n",
      "2023-09-22 01:41:42.366392: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780b800 of size 2304 next 1524\n",
      "2023-09-22 01:41:42.366401: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780c100 of size 4096 next 1209\n",
      "2023-09-22 01:41:42.366410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780d100 of size 6656 next 1396\n",
      "2023-09-22 01:41:42.366419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780eb00 of size 4096 next 197\n",
      "2023-09-22 01:41:42.366428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780fb00 of size 2048 next 439\n",
      "2023-09-22 01:41:42.366437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247810300 of size 2560 next 752\n",
      "2023-09-22 01:41:42.366446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247810d00 of size 4096 next 983\n",
      "2023-09-22 01:41:42.366455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247811d00 of size 256 next 542\n",
      "2023-09-22 01:41:42.366464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247811e00 of size 256 next 351\n",
      "2023-09-22 01:41:42.366474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247811f00 of size 256 next 976\n",
      "2023-09-22 01:41:42.366483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812000 of size 256 next 183\n",
      "2023-09-22 01:41:42.366492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812100 of size 256 next 293\n",
      "2023-09-22 01:41:42.366502: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812200 of size 256 next 852\n",
      "2023-09-22 01:41:42.366511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812300 of size 2048 next 791\n",
      "2023-09-22 01:41:42.366520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812b00 of size 256 next 1040\n",
      "2023-09-22 01:41:42.366529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812c00 of size 256 next 543\n",
      "2023-09-22 01:41:42.366538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812d00 of size 256 next 1643\n",
      "2023-09-22 01:41:42.366546: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812e00 of size 2304 next 818\n",
      "2023-09-22 01:41:42.366555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813700 of size 256 next 241\n",
      "2023-09-22 01:41:42.366564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813800 of size 256 next 1453\n",
      "2023-09-22 01:41:42.366573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813900 of size 256 next 1407\n",
      "2023-09-22 01:41:42.366582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813a00 of size 256 next 1144\n",
      "2023-09-22 01:41:42.366591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813b00 of size 256 next 1172\n",
      "2023-09-22 01:41:42.366601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813c00 of size 256 next 1019\n",
      "2023-09-22 01:41:42.366608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813d00 of size 256 next 84\n",
      "2023-09-22 01:41:42.366616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813e00 of size 256 next 43\n",
      "2023-09-22 01:41:42.366623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813f00 of size 256 next 1079\n",
      "2023-09-22 01:41:42.366630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814000 of size 256 next 622\n",
      "2023-09-22 01:41:42.366640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814100 of size 3072 next 619\n",
      "2023-09-22 01:41:42.366649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814d00 of size 256 next 58\n",
      "2023-09-22 01:41:42.366659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814e00 of size 256 next 1521\n",
      "2023-09-22 01:41:42.366668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814f00 of size 256 next 40\n",
      "2023-09-22 01:41:42.366678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815000 of size 256 next 1496\n",
      "2023-09-22 01:41:42.366687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815100 of size 256 next 1015\n",
      "2023-09-22 01:41:42.366697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815200 of size 256 next 877\n",
      "2023-09-22 01:41:42.366706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815300 of size 256 next 1395\n",
      "2023-09-22 01:41:42.366715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815400 of size 256 next 1368\n",
      "2023-09-22 01:41:42.366725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815500 of size 256 next 1708\n",
      "2023-09-22 01:41:42.366734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815600 of size 256 next 585\n",
      "2023-09-22 01:41:42.366743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815700 of size 256 next 275\n",
      "2023-09-22 01:41:42.366753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815800 of size 256 next 374\n",
      "2023-09-22 01:41:42.366762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815900 of size 256 next 1303\n",
      "2023-09-22 01:41:42.366771: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815a00 of size 256 next 853\n",
      "2023-09-22 01:41:42.366780: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815b00 of size 256 next 977\n",
      "2023-09-22 01:41:42.366790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815c00 of size 256 next 1478\n",
      "2023-09-22 01:41:42.366799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815d00 of size 256 next 1178\n",
      "2023-09-22 01:41:42.366807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815e00 of size 256 next 1578\n",
      "2023-09-22 01:41:42.366814: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815f00 of size 256 next 1682\n",
      "2023-09-22 01:41:42.366823: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816000 of size 256 next 1441\n",
      "2023-09-22 01:41:42.366832: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816100 of size 256 next 194\n",
      "2023-09-22 01:41:42.366841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816200 of size 256 next 1286\n",
      "2023-09-22 01:41:42.366851: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816300 of size 256 next 1501\n",
      "2023-09-22 01:41:42.366860: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816400 of size 256 next 1076\n",
      "2023-09-22 01:41:42.366870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816500 of size 256 next 1605\n",
      "2023-09-22 01:41:42.366879: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816600 of size 256 next 297\n",
      "2023-09-22 01:41:42.366888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816700 of size 256 next 1511\n",
      "2023-09-22 01:41:42.366898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816800 of size 256 next 460\n",
      "2023-09-22 01:41:42.366907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816900 of size 256 next 1250\n",
      "2023-09-22 01:41:42.366917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247816a00 of size 2048 next 1264\n",
      "2023-09-22 01:41:42.366926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247817200 of size 2048 next 1189\n",
      "2023-09-22 01:41:42.366936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247817a00 of size 3584 next 815\n",
      "2023-09-22 01:41:42.366945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247818800 of size 256 next 1445\n",
      "2023-09-22 01:41:42.366954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247818900 of size 256 next 1087\n",
      "2023-09-22 01:41:42.366964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247818a00 of size 256 next 1680\n",
      "2023-09-22 01:41:42.366973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247818b00 of size 256 next 151\n",
      "2023-09-22 01:41:42.366983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247818c00 of size 256 next 1400\n",
      "2023-09-22 01:41:42.366993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247818d00 of size 2816 next 73\n",
      "2023-09-22 01:41:42.367002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247819800 of size 5120 next 779\n",
      "2023-09-22 01:41:42.367011: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124781ac00 of size 4096 next 1203\n",
      "2023-09-22 01:41:42.367020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124781bc00 of size 4096 next 1516\n",
      "2023-09-22 01:41:42.367030: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124781cc00 of size 7168 next 64\n",
      "2023-09-22 01:41:42.367039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124781e800 of size 13824 next 1465\n",
      "2023-09-22 01:41:42.367049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247821e00 of size 23296 next 1213\n",
      "2023-09-22 01:41:42.367058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247827900 of size 52736 next 738\n",
      "2023-09-22 01:41:42.367067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247834700 of size 256 next 350\n",
      "2023-09-22 01:41:42.367077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247834800 of size 256 next 808\n",
      "2023-09-22 01:41:42.367086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1247834900 of size 1810688 next 555\n",
      "2023-09-22 01:41:42.367095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479eea00 of size 256 next 998\n",
      "2023-09-22 01:41:42.367104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479eeb00 of size 256 next 422\n",
      "2023-09-22 01:41:42.367112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479eec00 of size 256 next 776\n",
      "2023-09-22 01:41:42.367121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479eed00 of size 2304 next 1497\n",
      "2023-09-22 01:41:42.367130: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479ef600 of size 4096 next 640\n",
      "2023-09-22 01:41:42.367146: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f0600 of size 6400 next 1581\n",
      "2023-09-22 01:41:42.367154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f1f00 of size 256 next 1464\n",
      "2023-09-22 01:41:42.367164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2000 of size 256 next 1589\n",
      "2023-09-22 01:41:42.367174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2100 of size 36864 next 1134\n",
      "2023-09-22 01:41:42.367186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479fb100 of size 63488 next 114\n",
      "2023-09-22 01:41:42.367195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0a900 of size 256 next 1300\n",
      "2023-09-22 01:41:42.367206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0aa00 of size 6656 next 435\n",
      "2023-09-22 01:41:42.367216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0c400 of size 256 next 870\n",
      "2023-09-22 01:41:42.367225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0c500 of size 256 next 733\n",
      "2023-09-22 01:41:42.367235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0c600 of size 256 next 1345\n",
      "2023-09-22 01:41:42.367245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0c700 of size 256 next 217\n",
      "2023-09-22 01:41:42.367254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0c800 of size 256 next 1577\n",
      "2023-09-22 01:41:42.367263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0c900 of size 256 next 391\n",
      "2023-09-22 01:41:42.367273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0ca00 of size 256 next 1057\n",
      "2023-09-22 01:41:42.367282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0cb00 of size 2048 next 7\n",
      "2023-09-22 01:41:42.367292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0d300 of size 5632 next 1212\n",
      "2023-09-22 01:41:42.367301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0e900 of size 2048 next 119\n",
      "2023-09-22 01:41:42.367310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0f100 of size 2560 next 1451\n",
      "2023-09-22 01:41:42.367320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0fb00 of size 2048 next 967\n",
      "2023-09-22 01:41:42.367329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a10300 of size 2048 next 324\n",
      "2023-09-22 01:41:42.367338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a10b00 of size 4096 next 1116\n",
      "2023-09-22 01:41:42.367349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a11b00 of size 4096 next 1130\n",
      "2023-09-22 01:41:42.367359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a12b00 of size 4608 next 255\n",
      "2023-09-22 01:41:42.367368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a13d00 of size 4096 next 171\n",
      "2023-09-22 01:41:42.367377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a14d00 of size 4096 next 1475\n",
      "2023-09-22 01:41:42.367387: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a15d00 of size 4096 next 1199\n",
      "2023-09-22 01:41:42.367396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a16d00 of size 2048 next 202\n",
      "2023-09-22 01:41:42.367406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a17500 of size 2048 next 345\n",
      "2023-09-22 01:41:42.367415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a17d00 of size 2048 next 132\n",
      "2023-09-22 01:41:42.367424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a18500 of size 2560 next 690\n",
      "2023-09-22 01:41:42.367432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a18f00 of size 2048 next 713\n",
      "2023-09-22 01:41:42.367441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a19700 of size 2048 next 1066\n",
      "2023-09-22 01:41:42.367450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a19f00 of size 4096 next 1161\n",
      "2023-09-22 01:41:42.367460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1af00 of size 4864 next 1427\n",
      "2023-09-22 01:41:42.367469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c200 of size 256 next 153\n",
      "2023-09-22 01:41:42.367478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c300 of size 256 next 1024\n",
      "2023-09-22 01:41:42.367487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c400 of size 256 next 394\n",
      "2023-09-22 01:41:42.367497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c500 of size 256 next 369\n",
      "2023-09-22 01:41:42.367506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c600 of size 256 next 751\n",
      "2023-09-22 01:41:42.367515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c700 of size 256 next 1105\n",
      "2023-09-22 01:41:42.367525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c800 of size 256 next 135\n",
      "2023-09-22 01:41:42.367534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1c900 of size 256 next 1204\n",
      "2023-09-22 01:41:42.367543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1ca00 of size 2048 next 665\n",
      "2023-09-22 01:41:42.367552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1d200 of size 2560 next 777\n",
      "2023-09-22 01:41:42.367562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1dc00 of size 2048 next 1482\n",
      "2023-09-22 01:41:42.367571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1247a1e400 of size 306432 next 1048\n",
      "2023-09-22 01:41:42.367580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69100 of size 256 next 1393\n",
      "2023-09-22 01:41:42.367590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69200 of size 256 next 184\n",
      "2023-09-22 01:41:42.367600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1247a69300 of size 6689280 next 1295\n",
      "2023-09-22 01:41:42.367609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca500 of size 256 next 671\n",
      "2023-09-22 01:41:42.367618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca600 of size 256 next 1061\n",
      "2023-09-22 01:41:42.367628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca700 of size 256 next 1514\n",
      "2023-09-22 01:41:42.367638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca800 of size 81920000 next 158\n",
      "2023-09-22 01:41:42.367647: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f124ceea800 of size 149667584 next 514\n",
      "2023-09-22 01:41:42.367656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6700 of size 256 next 284\n",
      "2023-09-22 01:41:42.367666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6800 of size 256 next 796\n",
      "2023-09-22 01:41:42.367675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1255da6900 of size 1371392 next 673\n",
      "2023-09-22 01:41:42.367684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5600 of size 256 next 1259\n",
      "2023-09-22 01:41:42.367694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5700 of size 7936 next 520\n",
      "2023-09-22 01:41:42.367703: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7600 of size 256 next 214\n",
      "2023-09-22 01:41:42.367712: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7700 of size 256 next 1410\n",
      "2023-09-22 01:41:42.367721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7800 of size 256 next 1539\n",
      "2023-09-22 01:41:42.367730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7900 of size 256 next 344\n",
      "2023-09-22 01:41:42.367738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7a00 of size 256 next 723\n",
      "2023-09-22 01:41:42.367747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7b00 of size 256 next 1692\n",
      "2023-09-22 01:41:42.367756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7c00 of size 256 next 615\n",
      "2023-09-22 01:41:42.367765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7d00 of size 256 next 229\n",
      "2023-09-22 01:41:42.367775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7e00 of size 256 next 668\n",
      "2023-09-22 01:41:42.367784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7f00 of size 256 next 475\n",
      "2023-09-22 01:41:42.367793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8000 of size 256 next 1031\n",
      "2023-09-22 01:41:42.367803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8100 of size 256 next 603\n",
      "2023-09-22 01:41:42.367812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8200 of size 256 next 469\n",
      "2023-09-22 01:41:42.367821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8300 of size 256 next 436\n",
      "2023-09-22 01:41:42.367831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8400 of size 256 next 10\n",
      "2023-09-22 01:41:42.367841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8500 of size 256 next 799\n",
      "2023-09-22 01:41:42.367850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8600 of size 256 next 68\n",
      "2023-09-22 01:41:42.367859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8700 of size 256 next 664\n",
      "2023-09-22 01:41:42.367868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8800 of size 256 next 1560\n",
      "2023-09-22 01:41:42.367877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8900 of size 256 next 1330\n",
      "2023-09-22 01:41:42.367886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8a00 of size 256 next 523\n",
      "2023-09-22 01:41:42.367896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8b00 of size 256 next 1495\n",
      "2023-09-22 01:41:42.367905: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8c00 of size 256 next 1085\n",
      "2023-09-22 01:41:42.367915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8d00 of size 256 next 598\n",
      "2023-09-22 01:41:42.367924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8e00 of size 256 next 1355\n",
      "2023-09-22 01:41:42.367933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8f00 of size 256 next 267\n",
      "2023-09-22 01:41:42.367942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9000 of size 256 next 801\n",
      "2023-09-22 01:41:42.367952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9100 of size 256 next 616\n",
      "2023-09-22 01:41:42.367961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9200 of size 256 next 784\n",
      "2023-09-22 01:41:42.367970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9300 of size 256 next 1152\n",
      "2023-09-22 01:41:42.367980: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9400 of size 256 next 508\n",
      "2023-09-22 01:41:42.367989: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9500 of size 2048 next 931\n",
      "2023-09-22 01:41:42.367998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9d00 of size 2048 next 466\n",
      "2023-09-22 01:41:42.368007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa500 of size 2048 next 203\n",
      "2023-09-22 01:41:42.368017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efad00 of size 3072 next 1027\n",
      "2023-09-22 01:41:42.368026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb900 of size 256 next 624\n",
      "2023-09-22 01:41:42.368035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efba00 of size 256 next 715\n",
      "2023-09-22 01:41:42.368043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbb00 of size 256 next 1694\n",
      "2023-09-22 01:41:42.368052: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbc00 of size 256 next 365\n",
      "2023-09-22 01:41:42.368061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbd00 of size 256 next 1515\n",
      "2023-09-22 01:41:42.368071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbe00 of size 256 next 729\n",
      "2023-09-22 01:41:42.368080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbf00 of size 256 next 1190\n",
      "2023-09-22 01:41:42.368089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc000 of size 256 next 971\n",
      "2023-09-22 01:41:42.368098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc100 of size 256 next 1498\n",
      "2023-09-22 01:41:42.368108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc200 of size 256 next 1526\n",
      "2023-09-22 01:41:42.368117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc300 of size 3840 next 683\n",
      "2023-09-22 01:41:42.368126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd200 of size 256 next 1296\n",
      "2023-09-22 01:41:42.368136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd300 of size 24985600 next 1634\n",
      "2023-09-22 01:41:42.368145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1300 of size 256 next 780\n",
      "2023-09-22 01:41:42.368154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1400 of size 501639936 next 972\n",
      "2023-09-22 01:41:42.368163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537f00 of size 256 next 929\n",
      "2023-09-22 01:41:42.368172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538000 of size 256 next 940\n",
      "2023-09-22 01:41:42.368181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538100 of size 256 next 478\n",
      "2023-09-22 01:41:42.368190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538200 of size 256 next 900\n",
      "2023-09-22 01:41:42.368200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538300 of size 256 next 1473\n",
      "2023-09-22 01:41:42.368207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538400 of size 256 next 882\n",
      "2023-09-22 01:41:42.368215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538500 of size 256 next 1281\n",
      "2023-09-22 01:41:42.368224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538600 of size 256 next 1197\n",
      "2023-09-22 01:41:42.368234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538700 of size 256 next 814\n",
      "2023-09-22 01:41:42.368243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538800 of size 256 next 213\n",
      "2023-09-22 01:41:42.368253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538900 of size 2048 next 997\n",
      "2023-09-22 01:41:42.368262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539100 of size 2048 next 152\n",
      "2023-09-22 01:41:42.368272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539900 of size 3840 next 1179\n",
      "2023-09-22 01:41:42.368281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a800 of size 256 next 771\n",
      "2023-09-22 01:41:42.368291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f127553a900 of size 249344 next 1093\n",
      "2023-09-22 01:41:42.368300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577700 of size 256 next 1255\n",
      "2023-09-22 01:41:42.368311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1275577800 of size 852480 next 25\n",
      "2023-09-22 01:41:42.368320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275647a00 of size 256 next 1571\n",
      "2023-09-22 01:41:42.368329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1275647b00 of size 396544 next 474\n",
      "2023-09-22 01:41:42.368338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8800 of size 256 next 859\n",
      "2023-09-22 01:41:42.368348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8900 of size 256 next 24\n",
      "2023-09-22 01:41:42.368357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8a00 of size 2048 next 399\n",
      "2023-09-22 01:41:42.368366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9200 of size 2048 next 681\n",
      "2023-09-22 01:41:42.368376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9a00 of size 2048 next 1353\n",
      "2023-09-22 01:41:42.368385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aa200 of size 2048 next 26\n",
      "2023-09-22 01:41:42.368394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aaa00 of size 2048 next 787\n",
      "2023-09-22 01:41:42.368405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ab200 of size 2048 next 923\n",
      "2023-09-22 01:41:42.368415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aba00 of size 2048 next 444\n",
      "2023-09-22 01:41:42.368424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ac200 of size 256 next 994\n",
      "2023-09-22 01:41:42.368433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ac300 of size 256 next 302\n",
      "2023-09-22 01:41:42.368442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ac400 of size 3072 next 682\n",
      "2023-09-22 01:41:42.368452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad000 of size 256 next 836\n",
      "2023-09-22 01:41:42.368462: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad100 of size 256 next 659\n",
      "2023-09-22 01:41:42.368471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad200 of size 256 next 276\n",
      "2023-09-22 01:41:42.368480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad300 of size 256 next 531\n",
      "2023-09-22 01:41:42.368490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad400 of size 256 next 897\n",
      "2023-09-22 01:41:42.368500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad500 of size 256 next 93\n",
      "2023-09-22 01:41:42.368510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad600 of size 256 next 928\n",
      "2023-09-22 01:41:42.368518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad700 of size 421440000 next 1311\n",
      "2023-09-22 01:41:42.368527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f128e898100 of size 1315430912 next 863\n",
      "2023-09-22 01:41:42.368538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16300 of size 256 next 867\n",
      "2023-09-22 01:41:42.368547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16400 of size 4096 next 505\n",
      "2023-09-22 01:41:42.368557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17400 of size 2048 next 218\n",
      "2023-09-22 01:41:42.368566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17c00 of size 2048 next 824\n",
      "2023-09-22 01:41:42.368576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18400 of size 256 next 1490\n",
      "2023-09-22 01:41:42.368585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18500 of size 256 next 1111\n",
      "2023-09-22 01:41:42.368595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18600 of size 4096 next 358\n",
      "2023-09-22 01:41:42.368605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19600 of size 6144 next 748\n",
      "2023-09-22 01:41:42.368614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1ae00 of size 256 next 464\n",
      "2023-09-22 01:41:42.368623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1af00 of size 256 next 1183\n",
      "2023-09-22 01:41:42.368632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b000 of size 256 next 775\n",
      "2023-09-22 01:41:42.368641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b100 of size 256 next 893\n",
      "2023-09-22 01:41:42.368651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b200 of size 256 next 1037\n",
      "2023-09-22 01:41:42.368660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b300 of size 256 next 703\n",
      "2023-09-22 01:41:42.368670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b400 of size 256 next 164\n",
      "2023-09-22 01:41:42.368681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b500 of size 256 next 1231\n",
      "2023-09-22 01:41:42.368691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b600 of size 256 next 770\n",
      "2023-09-22 01:41:42.368702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b700 of size 256 next 1249\n",
      "2023-09-22 01:41:42.368711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b800 of size 256 next 321\n",
      "2023-09-22 01:41:42.368720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b900 of size 256 next 248\n",
      "2023-09-22 01:41:42.368729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1ba00 of size 256 next 1541\n",
      "2023-09-22 01:41:42.368738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1bb00 of size 256 next 1062\n",
      "2023-09-22 01:41:42.368748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1bc00 of size 256 next 920\n",
      "2023-09-22 01:41:42.368757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1bd00 of size 256 next 913\n",
      "2023-09-22 01:41:42.368766: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1be00 of size 256 next 1665\n",
      "2023-09-22 01:41:42.368775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1bf00 of size 256 next 420\n",
      "2023-09-22 01:41:42.368785: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c000 of size 256 next 328\n",
      "2023-09-22 01:41:42.368794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c100 of size 256 next 941\n",
      "2023-09-22 01:41:42.368804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c200 of size 256 next 1602\n",
      "2023-09-22 01:41:42.368813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c300 of size 256 next 347\n",
      "2023-09-22 01:41:42.368822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c400 of size 256 next 1543\n",
      "2023-09-22 01:41:42.368830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c500 of size 256 next 318\n",
      "2023-09-22 01:41:42.368839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c600 of size 256 next 236\n",
      "2023-09-22 01:41:42.368848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c700 of size 256 next 1256\n",
      "2023-09-22 01:41:42.368857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c800 of size 256 next 1373\n",
      "2023-09-22 01:41:42.368867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c900 of size 256 next 945\n",
      "2023-09-22 01:41:42.368876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1ca00 of size 256 next 1429\n",
      "2023-09-22 01:41:42.368885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1cb00 of size 256 next 1148\n",
      "2023-09-22 01:41:42.368894: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1cc00 of size 256 next 1206\n",
      "2023-09-22 01:41:42.368904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1cd00 of size 256 next 1070\n",
      "2023-09-22 01:41:42.368913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1ce00 of size 256 next 1000\n",
      "2023-09-22 01:41:42.368923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1cf00 of size 256 next 1700\n",
      "2023-09-22 01:41:42.368932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d000 of size 256 next 970\n",
      "2023-09-22 01:41:42.368941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d100 of size 256 next 423\n",
      "2023-09-22 01:41:42.368951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d200 of size 256 next 1216\n",
      "2023-09-22 01:41:42.368960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d300 of size 256 next 122\n",
      "2023-09-22 01:41:42.368969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d400 of size 256 next 148\n",
      "2023-09-22 01:41:42.368978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d500 of size 256 next 1287\n",
      "2023-09-22 01:41:42.368988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d600 of size 256 next 327\n",
      "2023-09-22 01:41:42.368997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1d700 of size 256 next 1488\n",
      "2023-09-22 01:41:42.369006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12dcf1d800 of size 414208 next 669\n",
      "2023-09-22 01:41:42.369015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82a00 of size 256 next 785\n",
      "2023-09-22 01:41:42.369025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82b00 of size 256 next 672\n",
      "2023-09-22 01:41:42.369034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82c00 of size 256 next 296\n",
      "2023-09-22 01:41:42.369044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82d00 of size 256 next 674\n",
      "2023-09-22 01:41:42.369053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82e00 of size 256 next 1014\n",
      "2023-09-22 01:41:42.369062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82f00 of size 256 next 15\n",
      "2023-09-22 01:41:42.369072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83000 of size 256 next 1466\n",
      "2023-09-22 01:41:42.369081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83100 of size 256 next 1678\n",
      "2023-09-22 01:41:42.369090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83200 of size 256 next 467\n",
      "2023-09-22 01:41:42.369099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83300 of size 256 next 792\n",
      "2023-09-22 01:41:42.369108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83400 of size 256 next 1073\n",
      "2023-09-22 01:41:42.369118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83500 of size 256 next 1128\n",
      "2023-09-22 01:41:42.369127: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83600 of size 256 next 891\n",
      "2023-09-22 01:41:42.369135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83700 of size 256 next 1132\n",
      "2023-09-22 01:41:42.369144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83800 of size 256 next 1230\n",
      "2023-09-22 01:41:42.369153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83900 of size 256 next 583\n",
      "2023-09-22 01:41:42.369162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83a00 of size 256 next 551\n",
      "2023-09-22 01:41:42.369172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83b00 of size 256 next 910\n",
      "2023-09-22 01:41:42.369181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12dcf83c00 of size 286769664 next 1082\n",
      "2023-09-22 01:41:42.369190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0ffe00 of size 256 next 407\n",
      "2023-09-22 01:41:42.369200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fff00 of size 256 next 826\n",
      "2023-09-22 01:41:42.369209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100000 of size 1024 next 1386\n",
      "2023-09-22 01:41:42.369218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100400 of size 256 next 955\n",
      "2023-09-22 01:41:42.369228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100500 of size 256 next 1595\n",
      "2023-09-22 01:41:42.369237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100600 of size 256 next 1558\n",
      "2023-09-22 01:41:42.369246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100700 of size 512 next 599\n",
      "2023-09-22 01:41:42.369256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100900 of size 512 next 1479\n",
      "2023-09-22 01:41:42.369265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100b00 of size 512 next 1537\n",
      "2023-09-22 01:41:42.369274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100d00 of size 256 next 1056\n",
      "2023-09-22 01:41:42.369285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100e00 of size 256 next 1168\n",
      "2023-09-22 01:41:42.369294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100f00 of size 256 next 611\n",
      "2023-09-22 01:41:42.369304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101000 of size 256 next 1279\n",
      "2023-09-22 01:41:42.369313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101100 of size 256 next 892\n",
      "2023-09-22 01:41:42.369322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee101200 of size 321280 next 263\n",
      "2023-09-22 01:41:42.369332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee14f900 of size 36864 next 645\n",
      "2023-09-22 01:41:42.369342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee158900 of size 58880 next 630\n",
      "2023-09-22 01:41:42.369351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee166f00 of size 6656 next 1645\n",
      "2023-09-22 01:41:42.369361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee168900 of size 256 next 1380\n",
      "2023-09-22 01:41:42.369370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee168a00 of size 307200 next 890\n",
      "2023-09-22 01:41:42.369380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1b3a00 of size 4096 next 564\n",
      "2023-09-22 01:41:42.369390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1b4a00 of size 36864 next 874\n",
      "2023-09-22 01:41:42.369399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1bda00 of size 36864 next 1316\n",
      "2023-09-22 01:41:42.369409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1c6a00 of size 2048 next 51\n",
      "2023-09-22 01:41:42.369418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1c7200 of size 3584 next 457\n",
      "2023-09-22 01:41:42.369427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1c8000 of size 2048 next 1192\n",
      "2023-09-22 01:41:42.369437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1c8800 of size 2560 next 1064\n",
      "2023-09-22 01:41:42.369445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1c9200 of size 2048 next 144\n",
      "2023-09-22 01:41:42.369454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1c9a00 of size 2560 next 273\n",
      "2023-09-22 01:41:42.369463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ca400 of size 2048 next 1341\n",
      "2023-09-22 01:41:42.369473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cac00 of size 256 next 1276\n",
      "2023-09-22 01:41:42.369482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cad00 of size 256 next 1029\n",
      "2023-09-22 01:41:42.369491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cae00 of size 256 next 1289\n",
      "2023-09-22 01:41:42.369501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1caf00 of size 256 next 1533\n",
      "2023-09-22 01:41:42.369510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cb000 of size 256 next 1068\n",
      "2023-09-22 01:41:42.369519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cb100 of size 256 next 1154\n",
      "2023-09-22 01:41:42.369529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cb200 of size 256 next 1405\n",
      "2023-09-22 01:41:42.369538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cb300 of size 256 next 487\n",
      "2023-09-22 01:41:42.369547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cb400 of size 2048 next 1273\n",
      "2023-09-22 01:41:42.369556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cbc00 of size 4096 next 1324\n",
      "2023-09-22 01:41:42.369566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ccc00 of size 4096 next 1261\n",
      "2023-09-22 01:41:42.369575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cdc00 of size 2048 next 212\n",
      "2023-09-22 01:41:42.369585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ce400 of size 2048 next 1236\n",
      "2023-09-22 01:41:42.369594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cec00 of size 4096 next 215\n",
      "2023-09-22 01:41:42.369604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1cfc00 of size 6144 next 1654\n",
      "2023-09-22 01:41:42.369614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d1400 of size 2048 next 532\n",
      "2023-09-22 01:41:42.369623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d1c00 of size 2560 next 1254\n",
      "2023-09-22 01:41:42.369633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d2600 of size 2048 next 60\n",
      "2023-09-22 01:41:42.369642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d2e00 of size 2560 next 540\n",
      "2023-09-22 01:41:42.369651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d3800 of size 2048 next 425\n",
      "2023-09-22 01:41:42.369661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d4000 of size 2048 next 1177\n",
      "2023-09-22 01:41:42.369670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d4800 of size 4096 next 301\n",
      "2023-09-22 01:41:42.369679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d5800 of size 6144 next 431\n",
      "2023-09-22 01:41:42.369689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d7000 of size 4096 next 1081\n",
      "2023-09-22 01:41:42.369696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d8000 of size 4608 next 700\n",
      "2023-09-22 01:41:42.369704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1d9200 of size 4096 next 1442\n",
      "2023-09-22 01:41:42.369711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1da200 of size 6656 next 1046\n",
      "2023-09-22 01:41:42.369719: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dbc00 of size 256 next 1072\n",
      "2023-09-22 01:41:42.369726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dbd00 of size 256 next 906\n",
      "2023-09-22 01:41:42.369734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dbe00 of size 256 next 1690\n",
      "2023-09-22 01:41:42.369741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dbf00 of size 2048 next 1269\n",
      "2023-09-22 01:41:42.369748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dc700 of size 256 next 1117\n",
      "2023-09-22 01:41:42.369756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dc800 of size 256 next 1318\n",
      "2023-09-22 01:41:42.369763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dc900 of size 256 next 1293\n",
      "2023-09-22 01:41:42.369771: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dca00 of size 2304 next 482\n",
      "2023-09-22 01:41:42.369778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dd300 of size 256 next 1021\n",
      "2023-09-22 01:41:42.369785: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dd400 of size 256 next 596\n",
      "2023-09-22 01:41:42.369793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dd500 of size 256 next 1697\n",
      "2023-09-22 01:41:42.369800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dd600 of size 256 next 1422\n",
      "2023-09-22 01:41:42.369808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dd700 of size 256 next 1598\n",
      "2023-09-22 01:41:42.369815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dd800 of size 256 next 1237\n",
      "2023-09-22 01:41:42.369822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dd900 of size 256 next 846\n",
      "2023-09-22 01:41:42.369830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dda00 of size 256 next 1698\n",
      "2023-09-22 01:41:42.369837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ddb00 of size 256 next 1544\n",
      "2023-09-22 01:41:42.369844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ddc00 of size 256 next 1004\n",
      "2023-09-22 01:41:42.369852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ddd00 of size 256 next 355\n",
      "2023-09-22 01:41:42.369863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1dde00 of size 256 next 1709\n",
      "2023-09-22 01:41:42.369873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ddf00 of size 256 next 709\n",
      "2023-09-22 01:41:42.369883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1de000 of size 256 next 196\n",
      "2023-09-22 01:41:42.369893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1de100 of size 256 next 960\n",
      "2023-09-22 01:41:42.369902: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1de200 of size 8192 next 495\n",
      "2023-09-22 01:41:42.369911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e0200 of size 256 next 329\n",
      "2023-09-22 01:41:42.369921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e0300 of size 256 next 1428\n",
      "2023-09-22 01:41:42.369930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e0400 of size 256 next 747\n",
      "2023-09-22 01:41:42.369939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e0500 of size 256 next 1191\n",
      "2023-09-22 01:41:42.369949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e0600 of size 256 next 711\n",
      "2023-09-22 01:41:42.369959: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e0700 of size 256 next 1675\n",
      "2023-09-22 01:41:42.369969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e0800 of size 4096 next 1137\n",
      "2023-09-22 01:41:42.369978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e1800 of size 4096 next 1421\n",
      "2023-09-22 01:41:42.369987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e2800 of size 256 next 8\n",
      "2023-09-22 01:41:42.369997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e2900 of size 256 next 139\n",
      "2023-09-22 01:41:42.370007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e2a00 of size 4096 next 1232\n",
      "2023-09-22 01:41:42.370017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e3a00 of size 4096 next 1470\n",
      "2023-09-22 01:41:42.370026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e4a00 of size 256 next 1239\n",
      "2023-09-22 01:41:42.370036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e4b00 of size 256 next 1042\n",
      "2023-09-22 01:41:42.370045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e4c00 of size 256 next 146\n",
      "2023-09-22 01:41:42.370055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e4d00 of size 256 next 1354\n",
      "2023-09-22 01:41:42.370064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e4e00 of size 256 next 554\n",
      "2023-09-22 01:41:42.370073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e4f00 of size 256 next 946\n",
      "2023-09-22 01:41:42.370083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e5000 of size 8192 next 768\n",
      "2023-09-22 01:41:42.370092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e7000 of size 8192 next 1244\n",
      "2023-09-22 01:41:42.370102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e9000 of size 512 next 1211\n",
      "2023-09-22 01:41:42.370111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e9200 of size 512 next 621\n",
      "2023-09-22 01:41:42.370121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e9400 of size 8192 next 1425\n",
      "2023-09-22 01:41:42.370131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1eb400 of size 8192 next 1292\n",
      "2023-09-22 01:41:42.370139: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ed400 of size 512 next 862\n",
      "2023-09-22 01:41:42.370148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ed600 of size 512 next 204\n",
      "2023-09-22 01:41:42.370157: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ed800 of size 8192 next 272\n",
      "2023-09-22 01:41:42.370166: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ef800 of size 8192 next 1477\n",
      "2023-09-22 01:41:42.370176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f1800 of size 512 next 1331\n",
      "2023-09-22 01:41:42.370185: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f1a00 of size 512 next 1702\n",
      "2023-09-22 01:41:42.370194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f1c00 of size 8192 next 1361\n",
      "2023-09-22 01:41:42.370204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f3c00 of size 8192 next 1335\n",
      "2023-09-22 01:41:42.370213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f5c00 of size 256 next 390\n",
      "2023-09-22 01:41:42.370223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f5d00 of size 256 next 1621\n",
      "2023-09-22 01:41:42.370232: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f5e00 of size 256 next 173\n",
      "2023-09-22 01:41:42.370241: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f5f00 of size 256 next 1668\n",
      "2023-09-22 01:41:42.370250: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f6000 of size 256 next 830\n",
      "2023-09-22 01:41:42.370260: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f6100 of size 256 next 964\n",
      "2023-09-22 01:41:42.370269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f6200 of size 4096 next 1181\n",
      "2023-09-22 01:41:42.370279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f7200 of size 4096 next 356\n",
      "2023-09-22 01:41:42.370288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f8200 of size 256 next 1283\n",
      "2023-09-22 01:41:42.370297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f8300 of size 256 next 670\n",
      "2023-09-22 01:41:42.370307: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f8400 of size 4096 next 655\n",
      "2023-09-22 01:41:42.370316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1f9400 of size 4096 next 965\n",
      "2023-09-22 01:41:42.370325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1fa400 of size 256 next 1038\n",
      "2023-09-22 01:41:42.370335: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1fa500 of size 256 next 1088\n",
      "2023-09-22 01:41:42.370344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1fa600 of size 256 next 507\n",
      "2023-09-22 01:41:42.370355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1fa700 of size 256 next 1210\n",
      "2023-09-22 01:41:42.370363: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1fa800 of size 256 next 1676\n",
      "2023-09-22 01:41:42.370370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1fa900 of size 256 next 1054\n",
      "2023-09-22 01:41:42.370379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1faa00 of size 6144 next 1535\n",
      "2023-09-22 01:41:42.370389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1fc200 of size 13824 next 455\n",
      "2023-09-22 01:41:42.370398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1ff800 of size 13824 next 1241\n",
      "2023-09-22 01:41:42.370408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee202e00 of size 13824 next 942\n",
      "2023-09-22 01:41:42.370418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee206400 of size 24064 next 485\n",
      "2023-09-22 01:41:42.370427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee20c200 of size 233472 next 1030\n",
      "2023-09-22 01:41:42.370436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee245200 of size 256 next 1596\n",
      "2023-09-22 01:41:42.370444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee245300 of size 1086976 next 159\n",
      "2023-09-22 01:41:42.370452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34e900 of size 256 next 125\n",
      "2023-09-22 01:41:42.370459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34ea00 of size 256 next 1662\n",
      "2023-09-22 01:41:42.370466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34eb00 of size 256 next 1402\n",
      "2023-09-22 01:41:42.370477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34ec00 of size 256 next 1245\n",
      "2023-09-22 01:41:42.370486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34ed00 of size 256 next 1378\n",
      "2023-09-22 01:41:42.370495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34ee00 of size 256 next 189\n",
      "2023-09-22 01:41:42.370505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34ef00 of size 2048 next 1158\n",
      "2023-09-22 01:41:42.370515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee34f700 of size 2816 next 1333\n",
      "2023-09-22 01:41:42.370524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee350200 of size 24576 next 933\n",
      "2023-09-22 01:41:42.370533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee356200 of size 4096 next 1562\n",
      "2023-09-22 01:41:42.370543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee357200 of size 13824 next 1622\n",
      "2023-09-22 01:41:42.370552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee35a800 of size 2048 next 1009\n",
      "2023-09-22 01:41:42.370561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee35b000 of size 2048 next 1351\n",
      "2023-09-22 01:41:42.370571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee35b800 of size 10240 next 1502\n",
      "2023-09-22 01:41:42.370580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee35e000 of size 4096 next 839\n",
      "2023-09-22 01:41:42.370589: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee35f000 of size 4608 next 1363\n",
      "2023-09-22 01:41:42.370599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee360200 of size 61440 next 684\n",
      "2023-09-22 01:41:42.370608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee36f200 of size 2048 next 1327\n",
      "2023-09-22 01:41:42.370617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee36fa00 of size 2304 next 838\n",
      "2023-09-22 01:41:42.370627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee370300 of size 2048 next 1176\n",
      "2023-09-22 01:41:42.370636: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee370b00 of size 2048 next 1379\n",
      "2023-09-22 01:41:42.370646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee371300 of size 3840 next 326\n",
      "2023-09-22 01:41:42.370655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee372200 of size 5120 next 651\n",
      "2023-09-22 01:41:42.370664: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee373600 of size 4096 next 844\n",
      "2023-09-22 01:41:42.370673: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee374600 of size 4096 next 178\n",
      "2023-09-22 01:41:42.370682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee375600 of size 1636864 next 239\n",
      "2023-09-22 01:41:42.370692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505000 of size 256 next 1150\n",
      "2023-09-22 01:41:42.370701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ee505100 of size 3652864 next 1601\n",
      "2023-09-22 01:41:42.370710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880e00 of size 256 next 1389\n",
      "2023-09-22 01:41:42.370720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880f00 of size 40960000 next 50\n",
      "2023-09-22 01:41:42.370729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f0f90f00 of size 40960000 next 546\n",
      "2023-09-22 01:41:42.370739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f36a0f00 of size 20480000 next 617\n",
      "2023-09-22 01:41:42.370747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4a28f00 of size 20480000 next 172\n",
      "2023-09-22 01:41:42.370756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5db0f00 of size 10240000 next 207\n",
      "2023-09-22 01:41:42.370768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f6774f00 of size 10240000 next 130\n",
      "2023-09-22 01:41:42.370777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f7138f00 of size 14051072 next 932\n",
      "2023-09-22 01:41:42.370786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f600 of size 256 next 101\n",
      "2023-09-22 01:41:42.370796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f700 of size 256 next 761\n",
      "2023-09-22 01:41:42.370806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f800 of size 39062528 next 657\n",
      "2023-09-22 01:41:42.370816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0400 of size 256 next 1326\n",
      "2023-09-22 01:41:42.370825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa3e0500 of size 487680 next 1583\n",
      "2023-09-22 01:41:42.370835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa457600 of size 2048 next 1339\n",
      "2023-09-22 01:41:42.370846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa457e00 of size 350976 next 1590\n",
      "2023-09-22 01:41:42.370857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ad900 of size 256 next 319\n",
      "2023-09-22 01:41:42.370867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ada00 of size 256 next 783\n",
      "2023-09-22 01:41:42.370878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa4adb00 of size 919808 next 1686\n",
      "2023-09-22 01:41:42.370888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e400 of size 256 next 1096\n",
      "2023-09-22 01:41:42.370898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e500 of size 256 next 252\n",
      "2023-09-22 01:41:42.370907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e600 of size 256 next 1674\n",
      "2023-09-22 01:41:42.370917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e700 of size 256 next 825\n",
      "2023-09-22 01:41:42.370926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa58e800 of size 1419520 next 1507\n",
      "2023-09-22 01:41:42.370935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9100 of size 256 next 1364\n",
      "2023-09-22 01:41:42.370945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9200 of size 256 next 699\n",
      "2023-09-22 01:41:42.370956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9300 of size 256 next 1471\n",
      "2023-09-22 01:41:42.370965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9400 of size 256 next 1078\n",
      "2023-09-22 01:41:42.370974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9500 of size 512 next 726\n",
      "2023-09-22 01:41:42.370984: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9700 of size 256 next 206\n",
      "2023-09-22 01:41:42.370993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa6e9800 of size 341504 next 1696\n",
      "2023-09-22 01:41:42.371003: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ce00 of size 256 next 106\n",
      "2023-09-22 01:41:42.371012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa73cf00 of size 2495232 next 584\n",
      "2023-09-22 01:41:42.371022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e200 of size 256 next 1164\n",
      "2023-09-22 01:41:42.371031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e300 of size 256 next 506\n",
      "2023-09-22 01:41:42.371041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e400 of size 256 next 1131\n",
      "2023-09-22 01:41:42.371050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e500 of size 256 next 1344\n",
      "2023-09-22 01:41:42.371059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e600 of size 256 next 1575\n",
      "2023-09-22 01:41:42.371067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e700 of size 256 next 265\n",
      "2023-09-22 01:41:42.371076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e800 of size 256 next 623\n",
      "2023-09-22 01:41:42.371085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99e900 of size 256 next 1579\n",
      "2023-09-22 01:41:42.371095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99ea00 of size 256 next 1642\n",
      "2023-09-22 01:41:42.371104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99eb00 of size 256 next 1461\n",
      "2023-09-22 01:41:42.371114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99ec00 of size 256 next 359\n",
      "2023-09-22 01:41:42.371126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99ed00 of size 256 next 1182\n",
      "2023-09-22 01:41:42.371161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99ee00 of size 256 next 962\n",
      "2023-09-22 01:41:42.371176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99ef00 of size 2048 next 492\n",
      "2023-09-22 01:41:42.371191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99f700 of size 3072 next 1205\n",
      "2023-09-22 01:41:42.371202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0300 of size 256 next 675\n",
      "2023-09-22 01:41:42.371215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0400 of size 8192 next 1215\n",
      "2023-09-22 01:41:42.371227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a2400 of size 8192 next 1166\n",
      "2023-09-22 01:41:42.371238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4400 of size 8192 next 1555\n",
      "2023-09-22 01:41:42.371251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a6400 of size 8192 next 465\n",
      "2023-09-22 01:41:42.371262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a8400 of size 8192 next 378\n",
      "2023-09-22 01:41:42.371274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9aa400 of size 8192 next 96\n",
      "2023-09-22 01:41:42.371285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ac400 of size 256 next 1673\n",
      "2023-09-22 01:41:42.371297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ac500 of size 256 next 300\n",
      "2023-09-22 01:41:42.371310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ac600 of size 256 next 811\n",
      "2023-09-22 01:41:42.371322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ac700 of size 256 next 1051\n",
      "2023-09-22 01:41:42.371336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ac800 of size 4096 next 511\n",
      "2023-09-22 01:41:42.371347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ad800 of size 4096 next 706\n",
      "2023-09-22 01:41:42.371359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ae800 of size 256 next 1135\n",
      "2023-09-22 01:41:42.371371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ae900 of size 256 next 1058\n",
      "2023-09-22 01:41:42.371384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9aea00 of size 4096 next 352\n",
      "2023-09-22 01:41:42.371396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9afa00 of size 4096 next 638\n",
      "2023-09-22 01:41:42.371408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0a00 of size 256 next 250\n",
      "2023-09-22 01:41:42.371420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0b00 of size 256 next 580\n",
      "2023-09-22 01:41:42.371433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0c00 of size 256 next 1554\n",
      "2023-09-22 01:41:42.371441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0d00 of size 256 next 1299\n",
      "2023-09-22 01:41:42.371448: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0e00 of size 256 next 1142\n",
      "2023-09-22 01:41:42.371455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0f00 of size 256 next 1314\n",
      "2023-09-22 01:41:42.371460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1000 of size 8192 next 1010\n",
      "2023-09-22 01:41:42.371466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b3000 of size 8192 next 864\n",
      "2023-09-22 01:41:42.371472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b5000 of size 512 next 843\n",
      "2023-09-22 01:41:42.371477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b5200 of size 512 next 1391\n",
      "2023-09-22 01:41:42.371482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b5400 of size 8192 next 386\n",
      "2023-09-22 01:41:42.371488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b7400 of size 11264 next 1270\n",
      "2023-09-22 01:41:42.371493: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ba000 of size 256 next 1034\n",
      "2023-09-22 01:41:42.371499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa9ba100 of size 307456 next 1531\n",
      "2023-09-22 01:41:42.371504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa05200 of size 256 next 769\n",
      "2023-09-22 01:41:42.371510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa05300 of size 256 next 845\n",
      "2023-09-22 01:41:42.371515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa05400 of size 256 next 822\n",
      "2023-09-22 01:41:42.371521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12faa05500 of size 224512 next 689\n",
      "2023-09-22 01:41:42.371527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c200 of size 256 next 383\n",
      "2023-09-22 01:41:42.371532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c300 of size 28160 next 1550\n",
      "2023-09-22 01:41:42.371538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43100 of size 256 next 1551\n",
      "2023-09-22 01:41:42.371545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43200 of size 448982784 next 162\n",
      "2023-09-22 01:41:42.371552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315672100 of size 2048 next 832\n",
      "2023-09-22 01:41:42.371558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315672900 of size 2048 next 755\n",
      "2023-09-22 01:41:42.371564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673100 of size 2048 next 21\n",
      "2023-09-22 01:41:42.371570: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673900 of size 256 next 581\n",
      "2023-09-22 01:41:42.371575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673a00 of size 512 next 634\n",
      "2023-09-22 01:41:42.371580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673c00 of size 512 next 242\n",
      "2023-09-22 01:41:42.371586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315673e00 of size 512 next 1687\n",
      "2023-09-22 01:41:42.371591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674000 of size 256 next 1039\n",
      "2023-09-22 01:41:42.371596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674100 of size 256 next 367\n",
      "2023-09-22 01:41:42.371602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674200 of size 256 next 200\n",
      "2023-09-22 01:41:42.371607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674300 of size 256 next 371\n",
      "2023-09-22 01:41:42.371611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674400 of size 256 next 201\n",
      "2023-09-22 01:41:42.371616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674500 of size 256 next 1508\n",
      "2023-09-22 01:41:42.371621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674600 of size 256 next 560\n",
      "2023-09-22 01:41:42.371625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674700 of size 256 next 572\n",
      "2023-09-22 01:41:42.371629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674800 of size 256 next 1298\n",
      "2023-09-22 01:41:42.371635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315674900 of size 4352 next 9\n",
      "2023-09-22 01:41:42.371639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315675a00 of size 8448 next 1593\n",
      "2023-09-22 01:41:42.371643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677b00 of size 256 next 628\n",
      "2023-09-22 01:41:42.371648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677c00 of size 256 next 92\n",
      "2023-09-22 01:41:42.371651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1315677d00 of size 7948800 next 754\n",
      "2023-09-22 01:41:42.371655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c700 of size 256 next 848\n",
      "2023-09-22 01:41:42.371660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c800 of size 256 next 136\n",
      "2023-09-22 01:41:42.371664: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c900 of size 81920000 next 517\n",
      "2023-09-22 01:41:42.371669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131ac2c900 of size 97466112 next 190\n",
      "2023-09-22 01:41:42.371674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920000 of size 256 next 1574\n",
      "2023-09-22 01:41:42.371677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920100 of size 71928064 next 112\n",
      "2023-09-22 01:41:42.371682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8a00 of size 256 next 687\n",
      "2023-09-22 01:41:42.371687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8b00 of size 256 next 692\n",
      "2023-09-22 01:41:42.371692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8c00 of size 256 next 1153\n",
      "2023-09-22 01:41:42.371696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8d00 of size 256 next 1573\n",
      "2023-09-22 01:41:42.371701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8e00 of size 256 next 86\n",
      "2023-09-22 01:41:42.371705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8f00 of size 256 next 493\n",
      "2023-09-22 01:41:42.371710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9000 of size 421440000 next 1369\n",
      "2023-09-22 01:41:42.371715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f133dfa3a00 of size 1263840000 next 861\n",
      "2023-09-22 01:41:42.371719: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13894ee500 of size 6400000000 next 251\n",
      "2023-09-22 01:41:42.371724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1506c72500 of size 6400000000 next 569\n",
      "2023-09-22 01:41:42.371729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f16843f6500 of size 3054279424 next 18446744073709551615\n",
      "2023-09-22 01:41:42.371734: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-09-22 01:41:42.371743: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 665 Chunks of size 256 totalling 166.2KiB\n",
      "2023-09-22 01:41:42.371749: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 37 Chunks of size 512 totalling 18.5KiB\n",
      "2023-09-22 01:41:42.371754: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 1024 totalling 3.0KiB\n",
      "2023-09-22 01:41:42.371758: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-09-22 01:41:42.371762: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 84 Chunks of size 2048 totalling 168.0KiB\n",
      "2023-09-22 01:41:42.371767: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 7 Chunks of size 2304 totalling 15.8KiB\n",
      "2023-09-22 01:41:42.371772: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 11 Chunks of size 2560 totalling 27.5KiB\n",
      "2023-09-22 01:41:42.371777: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 2816 totalling 8.2KiB\n",
      "2023-09-22 01:41:42.371782: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 3072 totalling 12.0KiB\n",
      "2023-09-22 01:41:42.371787: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3328 totalling 3.2KiB\n",
      "2023-09-22 01:41:42.371792: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 3584 totalling 14.0KiB\n",
      "2023-09-22 01:41:42.371797: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 3840 totalling 11.2KiB\n",
      "2023-09-22 01:41:42.371801: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 61 Chunks of size 4096 totalling 244.0KiB\n",
      "2023-09-22 01:41:42.371806: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 4352 totalling 8.5KiB\n",
      "2023-09-22 01:41:42.371811: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 4608 totalling 18.0KiB\n",
      "2023-09-22 01:41:42.371815: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 4864 totalling 9.5KiB\n",
      "2023-09-22 01:41:42.371820: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 5120 totalling 10.0KiB\n",
      "2023-09-22 01:41:42.371824: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 5632 totalling 5.5KiB\n",
      "2023-09-22 01:41:42.371828: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 5888 totalling 5.8KiB\n",
      "2023-09-22 01:41:42.371833: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 6144 totalling 36.0KiB\n",
      "2023-09-22 01:41:42.371838: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6400 totalling 6.2KiB\n",
      "2023-09-22 01:41:42.371842: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 6656 totalling 32.5KiB\n",
      "2023-09-22 01:41:42.371847: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 7168 totalling 14.0KiB\n",
      "2023-09-22 01:41:42.371851: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 7424 totalling 7.2KiB\n",
      "2023-09-22 01:41:42.371856: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 7936 totalling 15.5KiB\n",
      "2023-09-22 01:41:42.371860: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 43 Chunks of size 8192 totalling 344.0KiB\n",
      "2023-09-22 01:41:42.371865: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 8448 totalling 24.8KiB\n",
      "2023-09-22 01:41:42.371869: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9472 totalling 9.2KiB\n",
      "2023-09-22 01:41:42.371874: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2023-09-22 01:41:42.371878: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 11264 totalling 44.0KiB\n",
      "2023-09-22 01:41:42.371883: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 13056 totalling 12.8KiB\n",
      "2023-09-22 01:41:42.371888: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 7 Chunks of size 13824 totalling 94.5KiB\n",
      "2023-09-22 01:41:42.371892: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2023-09-22 01:41:42.371897: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15360 totalling 15.0KiB\n",
      "2023-09-22 01:41:42.371901: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 21248 totalling 20.8KiB\n",
      "2023-09-22 01:41:42.371906: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 21760 totalling 21.2KiB\n",
      "2023-09-22 01:41:42.371911: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 23296 totalling 22.8KiB\n",
      "2023-09-22 01:41:42.371914: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 24064 totalling 23.5KiB\n",
      "2023-09-22 01:41:42.371919: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 24576 totalling 24.0KiB\n",
      "2023-09-22 01:41:42.371924: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 28160 totalling 27.5KiB\n",
      "2023-09-22 01:41:42.371928: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 36864 totalling 144.0KiB\n",
      "2023-09-22 01:41:42.371933: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 40704 totalling 39.8KiB\n",
      "2023-09-22 01:41:42.371938: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 52736 totalling 51.5KiB\n",
      "2023-09-22 01:41:42.371943: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 58880 totalling 57.5KiB\n",
      "2023-09-22 01:41:42.371948: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 61440 totalling 60.0KiB\n",
      "2023-09-22 01:41:42.371955: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 63488 totalling 62.0KiB\n",
      "2023-09-22 01:41:42.371961: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 10240000 totalling 19.53MiB\n",
      "2023-09-22 01:41:42.371967: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10556928 totalling 10.07MiB\n",
      "2023-09-22 01:41:42.371973: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 20480000 totalling 39.06MiB\n",
      "2023-09-22 01:41:42.371978: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 24985600 totalling 23.83MiB\n",
      "2023-09-22 01:41:42.371983: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 30720000 totalling 29.30MiB\n",
      "2023-09-22 01:41:42.371988: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 34841344 totalling 33.23MiB\n",
      "2023-09-22 01:41:42.371993: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 39062528 totalling 37.25MiB\n",
      "2023-09-22 01:41:42.371997: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 40960000 totalling 78.12MiB\n",
      "2023-09-22 01:41:42.372002: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 71928064 totalling 68.60MiB\n",
      "2023-09-22 01:41:42.372007: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 81920000 totalling 156.25MiB\n",
      "2023-09-22 01:41:42.372012: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 97466112 totalling 92.95MiB\n",
      "2023-09-22 01:41:42.372016: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 421440000 totalling 803.83MiB\n",
      "2023-09-22 01:41:42.372021: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 448982784 totalling 428.18MiB\n",
      "2023-09-22 01:41:42.372026: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 501639936 totalling 478.40MiB\n",
      "2023-09-22 01:41:42.372030: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 1263840000 totalling 2.35GiB\n",
      "2023-09-22 01:41:42.372035: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1315430912 totalling 1.22GiB\n",
      "2023-09-22 01:41:42.372039: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 6400000000 totalling 11.92GiB\n",
      "2023-09-22 01:41:42.372044: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 17.75GiB\n",
      "2023-09-22 01:41:42.372048: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 23023321088 memory_limit_: 23023321088 available bytes: 0 curr_region_allocation_bytes_: 46046642176\n",
      "2023-09-22 01:41:42.372058: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     23023321088\n",
      "InUse:                     19055406336\n",
      "MaxInUse:                  21928617216\n",
      "NumAllocs:                    28142943\n",
      "MaxAllocSize:               6400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-22 01:41:42.372093: W tensorflow/tsl/framework/bfc_allocator.cc:492] ******_********************************************************************************_____________\n",
      "2023-09-22 01:41:42.372123: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at softmax_op_gpu.cu.cc:222 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,8,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'model/multi_head_attention/softmax/Softmax' defined at (most recent call last):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_3386617/1959657965.py\", line 121, in <module>\n",
      "      hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3},\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 526, in _compute_attention\n",
      "      attention_scores = self._masked_softmax(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 492, in _masked_softmax\n",
      "      return self._softmax(attention_scores, attention_mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/activation/softmax.py\", line 103, in call\n",
      "      return backend.softmax(inputs, axis=self.axis[0])\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/backend.py\", line 5416, in softmax\n",
      "      return tf.nn.softmax(x, axis=axis)\n",
      "Node: 'model/multi_head_attention/softmax/Softmax'\n",
      "OOM when allocating tensor with shape[128,8,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/multi_head_attention/softmax/Softmax}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_1538729]\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0802 - mean_squared_error: 0.0128\n",
      "Epoch 1: val_loss improved from inf to 0.05291, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 14s 48ms/step - loss: 0.0802 - mean_squared_error: 0.0128 - val_loss: 0.0529 - val_mean_squared_error: 0.0060\n",
      "Epoch 2/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0563 - mean_squared_error: 0.0066\n",
      "Epoch 2: val_loss did not improve from 0.05291\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 0.0564 - mean_squared_error: 0.0066 - val_loss: 0.0760 - val_mean_squared_error: 0.0108\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.0052\n",
      "Epoch 3: val_loss did not improve from 0.05291\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0498 - mean_squared_error: 0.0052 - val_loss: 0.0530 - val_mean_squared_error: 0.0060\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0045\n",
      "Epoch 4: val_loss did not improve from 0.05291\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0461 - mean_squared_error: 0.0045 - val_loss: 0.0721 - val_mean_squared_error: 0.0103\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###0 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.0130\n",
      "Epoch 1: val_loss improved from inf to 0.05925, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 11s 38ms/step - loss: 0.0806 - mean_squared_error: 0.0129 - val_loss: 0.0592 - val_mean_squared_error: 0.0080\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0558 - mean_squared_error: 0.0064\n",
      "Epoch 2: val_loss improved from 0.05925 to 0.05579, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 0.0558 - mean_squared_error: 0.0064 - val_loss: 0.0558 - val_mean_squared_error: 0.0063\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.0053\n",
      "Epoch 3: val_loss improved from 0.05579 to 0.04519, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0498 - mean_squared_error: 0.0053 - val_loss: 0.0452 - val_mean_squared_error: 0.0048\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.0047\n",
      "Epoch 4: val_loss did not improve from 0.04519\n",
      "83/83 [==============================] - 2s 30ms/step - loss: 0.0468 - mean_squared_error: 0.0047 - val_loss: 0.0757 - val_mean_squared_error: 0.0111\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0044\n",
      "Epoch 5: val_loss did not improve from 0.04519\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.0454 - mean_squared_error: 0.0044 - val_loss: 0.0580 - val_mean_squared_error: 0.0074\n",
      "Epoch 6/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0040\n",
      "Epoch 6: val_loss did not improve from 0.04519\n",
      "83/83 [==============================] - 3s 30ms/step - loss: 0.0427 - mean_squared_error: 0.0040 - val_loss: 0.0810 - val_mean_squared_error: 0.0121\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###1 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0822 - mean_squared_error: 0.0132\n",
      "Epoch 1: val_loss improved from inf to 0.06127, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 12s 41ms/step - loss: 0.0821 - mean_squared_error: 0.0132 - val_loss: 0.0613 - val_mean_squared_error: 0.0073\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.0067\n",
      "Epoch 2: val_loss improved from 0.06127 to 0.06079, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0569 - mean_squared_error: 0.0067 - val_loss: 0.0608 - val_mean_squared_error: 0.0078\n",
      "Epoch 3/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0503 - mean_squared_error: 0.0053\n",
      "Epoch 3: val_loss improved from 0.06079 to 0.05740, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0505 - mean_squared_error: 0.0053 - val_loss: 0.0574 - val_mean_squared_error: 0.0066\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0476 - mean_squared_error: 0.0048\n",
      "Epoch 4: val_loss improved from 0.05740 to 0.04660, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0475 - mean_squared_error: 0.0048 - val_loss: 0.0466 - val_mean_squared_error: 0.0053\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.0043\n",
      "Epoch 5: val_loss improved from 0.04660 to 0.04083, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 0.0447 - mean_squared_error: 0.0043 - val_loss: 0.0408 - val_mean_squared_error: 0.0040\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.0041\n",
      "Epoch 6: val_loss improved from 0.04083 to 0.03906, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0429 - mean_squared_error: 0.0041 - val_loss: 0.0391 - val_mean_squared_error: 0.0038\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0415 - mean_squared_error: 0.0038\n",
      "Epoch 7: val_loss did not improve from 0.03906\n",
      "83/83 [==============================] - 3s 30ms/step - loss: 0.0415 - mean_squared_error: 0.0038 - val_loss: 0.0395 - val_mean_squared_error: 0.0040\n",
      "Epoch 8/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0037\n",
      "Epoch 8: val_loss did not improve from 0.03906\n",
      "83/83 [==============================] - 3s 35ms/step - loss: 0.0405 - mean_squared_error: 0.0037 - val_loss: 0.0489 - val_mean_squared_error: 0.0052\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0036\n",
      "Epoch 9: val_loss did not improve from 0.03906\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0396 - mean_squared_error: 0.0036 - val_loss: 0.0393 - val_mean_squared_error: 0.0041\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###2 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0818 - mean_squared_error: 0.0133\n",
      "Epoch 1: val_loss improved from inf to 0.06586, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 15s 46ms/step - loss: 0.0818 - mean_squared_error: 0.0133 - val_loss: 0.0659 - val_mean_squared_error: 0.0091\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0574 - mean_squared_error: 0.0069\n",
      "Epoch 2: val_loss improved from 0.06586 to 0.04413, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 0.0574 - mean_squared_error: 0.0069 - val_loss: 0.0441 - val_mean_squared_error: 0.0047\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0508 - mean_squared_error: 0.0053\n",
      "Epoch 3: val_loss did not improve from 0.04413\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0508 - mean_squared_error: 0.0053 - val_loss: 0.0533 - val_mean_squared_error: 0.0057\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0461 - mean_squared_error: 0.0046\n",
      "Epoch 4: val_loss improved from 0.04413 to 0.03996, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 0.0461 - mean_squared_error: 0.0046 - val_loss: 0.0400 - val_mean_squared_error: 0.0039\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0432 - mean_squared_error: 0.0041\n",
      "Epoch 5: val_loss did not improve from 0.03996\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0432 - mean_squared_error: 0.0041 - val_loss: 0.0423 - val_mean_squared_error: 0.0041\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0423 - mean_squared_error: 0.0039\n",
      "Epoch 6: val_loss improved from 0.03996 to 0.03552, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt16_size9_pool5_do0.2_tra3_head2_kdim16_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.0423 - mean_squared_error: 0.0039 - val_loss: 0.0355 - val_mean_squared_error: 0.0030\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0415 - mean_squared_error: 0.0039\n",
      "Epoch 7: val_loss did not improve from 0.03552\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0415 - mean_squared_error: 0.0039 - val_loss: 0.0470 - val_mean_squared_error: 0.0042\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0037\n",
      "Epoch 8: val_loss did not improve from 0.03552\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0403 - mean_squared_error: 0.0037 - val_loss: 0.0410 - val_mean_squared_error: 0.0043\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0035\n",
      "Epoch 9: val_loss did not improve from 0.03552\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0390 - mean_squared_error: 0.0035 - val_loss: 0.0373 - val_mean_squared_error: 0.0031\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###3 fold : val mae 0.04###\n",
      "mae0.91+-0.13\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1178 - mean_squared_error: 0.0316\n",
      "Epoch 1: val_loss improved from inf to 0.10973, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 27s 169ms/step - loss: 0.1177 - mean_squared_error: 0.0315 - val_loss: 0.1097 - val_mean_squared_error: 0.0216\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0208\n",
      "Epoch 2: val_loss did not improve from 0.10973\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 0.1066 - mean_squared_error: 0.0208 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.10973\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss did not improve from 0.10973\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 2s 32ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1188 - mean_squared_error: 0.0318\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 30s 173ms/step - loss: 0.1186 - mean_squared_error: 0.0317 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10696 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10694\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10694\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10694 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 13s 160ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss did not improve from 0.10694\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10694 to 0.10694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 8: val_loss did not improve from 0.10694\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 9: val_loss did not improve from 0.10694\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 10/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 10: val_loss did not improve from 0.10694\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1206 - mean_squared_error: 0.0333\n",
      "Epoch 1: val_loss improved from inf to 0.10584, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 26s 164ms/step - loss: 0.1206 - mean_squared_error: 0.0332 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1080 - mean_squared_error: 0.0213\n",
      "Epoch 2: val_loss improved from 0.10584 to 0.10584, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 0.1080 - mean_squared_error: 0.0213 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0213\n",
      "Epoch 3: val_loss improved from 0.10584 to 0.10528, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 0.1078 - mean_squared_error: 0.0213 - val_loss: 0.1053 - val_mean_squared_error: 0.0203\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10528\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1055 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 5: val_loss did not improve from 0.10528\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1056 - val_mean_squared_error: 0.0204\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 6: val_loss did not improve from 0.10528\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1183 - mean_squared_error: 0.0312\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 26s 163ms/step - loss: 0.1183 - mean_squared_error: 0.0312 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10639 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 0.1076 - mean_squared_error: 0.0209 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.10638 to 0.10632, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10632\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10632 to 0.10631, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt64_size15_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 13s 160ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss did not improve from 0.10631\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 0.1076 - mean_squared_error: 0.0209 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 7: val_loss did not improve from 0.10631\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 0.1076 - mean_squared_error: 0.0209 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 8: val_loss did not improve from 0.10631\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.25+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1196 - mean_squared_error: 0.0318\n",
      "Epoch 1: val_loss improved from inf to 0.10063, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 16s 99ms/step - loss: 0.1196 - mean_squared_error: 0.0318 - val_loss: 0.1006 - val_mean_squared_error: 0.0196\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0203\n",
      "Epoch 2: val_loss improved from 0.10063 to 0.09792, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 66ms/step - loss: 0.1038 - mean_squared_error: 0.0203 - val_loss: 0.0979 - val_mean_squared_error: 0.0190\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0189\n",
      "Epoch 3: val_loss improved from 0.09792 to 0.08451, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.1002 - mean_squared_error: 0.0189 - val_loss: 0.0845 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0969 - mean_squared_error: 0.0179\n",
      "Epoch 4: val_loss improved from 0.08451 to 0.08043, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0969 - mean_squared_error: 0.0179 - val_loss: 0.0804 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0886 - mean_squared_error: 0.0154\n",
      "Epoch 5: val_loss improved from 0.08043 to 0.07868, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 0.0886 - mean_squared_error: 0.0154 - val_loss: 0.0787 - val_mean_squared_error: 0.0128\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0779 - mean_squared_error: 0.0121\n",
      "Epoch 6: val_loss improved from 0.07868 to 0.05956, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0778 - mean_squared_error: 0.0121 - val_loss: 0.0596 - val_mean_squared_error: 0.0070\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0670 - mean_squared_error: 0.0089\n",
      "Epoch 7: val_loss did not improve from 0.05956\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0670 - mean_squared_error: 0.0089 - val_loss: 0.1418 - val_mean_squared_error: 0.0336\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0601 - mean_squared_error: 0.0074\n",
      "Epoch 8: val_loss did not improve from 0.05956\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0601 - mean_squared_error: 0.0074 - val_loss: 0.0683 - val_mean_squared_error: 0.0105\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.0061\n",
      "Epoch 9: val_loss did not improve from 0.05956\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.0549 - mean_squared_error: 0.0061 - val_loss: 0.1648 - val_mean_squared_error: 0.0478\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###0 fold : val mae 0.06###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1193 - mean_squared_error: 0.0308\n",
      "Epoch 1: val_loss improved from inf to 0.09723, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 19s 99ms/step - loss: 0.1193 - mean_squared_error: 0.0308 - val_loss: 0.0972 - val_mean_squared_error: 0.0187\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1042 - mean_squared_error: 0.0203\n",
      "Epoch 2: val_loss improved from 0.09723 to 0.09234, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.1041 - mean_squared_error: 0.0203 - val_loss: 0.0923 - val_mean_squared_error: 0.0175\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0191\n",
      "Epoch 3: val_loss improved from 0.09234 to 0.09140, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.1001 - mean_squared_error: 0.0190 - val_loss: 0.0914 - val_mean_squared_error: 0.0170\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0895 - mean_squared_error: 0.0159\n",
      "Epoch 4: val_loss improved from 0.09140 to 0.08722, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0896 - mean_squared_error: 0.0160 - val_loss: 0.0872 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0804 - mean_squared_error: 0.0129\n",
      "Epoch 5: val_loss improved from 0.08722 to 0.05696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 0.0802 - mean_squared_error: 0.0128 - val_loss: 0.0570 - val_mean_squared_error: 0.0072\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0707 - mean_squared_error: 0.0100\n",
      "Epoch 6: val_loss improved from 0.05696 to 0.04470, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0708 - mean_squared_error: 0.0101 - val_loss: 0.0447 - val_mean_squared_error: 0.0046\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0638 - mean_squared_error: 0.0082\n",
      "Epoch 7: val_loss did not improve from 0.04470\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.0638 - mean_squared_error: 0.0082 - val_loss: 0.0776 - val_mean_squared_error: 0.0128\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.0067\n",
      "Epoch 8: val_loss did not improve from 0.04470\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 0.0573 - mean_squared_error: 0.0067 - val_loss: 0.1129 - val_mean_squared_error: 0.0249\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0529 - mean_squared_error: 0.0056\n",
      "Epoch 9: val_loss did not improve from 0.04470\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0529 - mean_squared_error: 0.0056 - val_loss: 0.1174 - val_mean_squared_error: 0.0275\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1242 - mean_squared_error: 0.0343\n",
      "Epoch 1: val_loss improved from inf to 0.09905, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 16s 94ms/step - loss: 0.1241 - mean_squared_error: 0.0343 - val_loss: 0.0990 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1048 - mean_squared_error: 0.0203\n",
      "Epoch 2: val_loss improved from 0.09905 to 0.09472, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 67ms/step - loss: 0.1048 - mean_squared_error: 0.0203 - val_loss: 0.0947 - val_mean_squared_error: 0.0181\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0190\n",
      "Epoch 3: val_loss improved from 0.09472 to 0.07902, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.1003 - mean_squared_error: 0.0191 - val_loss: 0.0790 - val_mean_squared_error: 0.0139\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0932 - mean_squared_error: 0.0170\n",
      "Epoch 4: val_loss improved from 0.07902 to 0.06290, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.0930 - mean_squared_error: 0.0169 - val_loss: 0.0629 - val_mean_squared_error: 0.0087\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0825 - mean_squared_error: 0.0138\n",
      "Epoch 5: val_loss improved from 0.06290 to 0.04386, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 69ms/step - loss: 0.0825 - mean_squared_error: 0.0138 - val_loss: 0.0439 - val_mean_squared_error: 0.0046\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0724 - mean_squared_error: 0.0108\n",
      "Epoch 6: val_loss did not improve from 0.04386\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.0725 - mean_squared_error: 0.0109 - val_loss: 0.0612 - val_mean_squared_error: 0.0085\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0637 - mean_squared_error: 0.0082\n",
      "Epoch 7: val_loss did not improve from 0.04386\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0637 - mean_squared_error: 0.0082 - val_loss: 0.0756 - val_mean_squared_error: 0.0115\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0611 - mean_squared_error: 0.0074\n",
      "Epoch 8: val_loss did not improve from 0.04386\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.0611 - mean_squared_error: 0.0074 - val_loss: 0.2341 - val_mean_squared_error: 0.0845\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###2 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1225 - mean_squared_error: 0.0325\n",
      "Epoch 1: val_loss improved from inf to 0.09766, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 16s 87ms/step - loss: 0.1224 - mean_squared_error: 0.0324 - val_loss: 0.0977 - val_mean_squared_error: 0.0189\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0200\n",
      "Epoch 2: val_loss improved from 0.09766 to 0.08065, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 3s 66ms/step - loss: 0.1029 - mean_squared_error: 0.0200 - val_loss: 0.0807 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0188\n",
      "Epoch 3: val_loss improved from 0.08065 to 0.07624, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0997 - mean_squared_error: 0.0188 - val_loss: 0.0762 - val_mean_squared_error: 0.0133\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0892 - mean_squared_error: 0.0156\n",
      "Epoch 4: val_loss improved from 0.07624 to 0.05363, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.0892 - mean_squared_error: 0.0156 - val_loss: 0.0536 - val_mean_squared_error: 0.0065\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.0128\n",
      "Epoch 5: val_loss improved from 0.05363 to 0.05197, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 3s 72ms/step - loss: 0.0800 - mean_squared_error: 0.0128 - val_loss: 0.0520 - val_mean_squared_error: 0.0059\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.0104\n",
      "Epoch 6: val_loss improved from 0.05197 to 0.04840, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size7_pool4_do0.5_tra4_head4_kdim16_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.0721 - mean_squared_error: 0.0104 - val_loss: 0.0484 - val_mean_squared_error: 0.0052\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0639 - mean_squared_error: 0.0082\n",
      "Epoch 7: val_loss did not improve from 0.04840\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.0639 - mean_squared_error: 0.0082 - val_loss: 0.0732 - val_mean_squared_error: 0.0121\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.0069\n",
      "Epoch 8: val_loss did not improve from 0.04840\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.0583 - mean_squared_error: 0.0069 - val_loss: 0.0955 - val_mean_squared_error: 0.0186\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0540 - mean_squared_error: 0.0059\n",
      "Epoch 9: val_loss did not improve from 0.04840\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.0540 - mean_squared_error: 0.0059 - val_loss: 0.1260 - val_mean_squared_error: 0.0288\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###3 fold : val mae 0.05###\n",
      "mae1.00+-0.11\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn2_filt16_size5_pool4_do0.1_tra5_head8_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 01:54:10.058387: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 765.38MiB (rounded to 802562048)requested by op model/multi_head_attention_4/einsum/Einsum\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-22 01:54:10.058624: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-22 01:54:10.058647: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 752, Chunks in use: 751. 188.0KiB allocated for chunks. 187.8KiB in use in bin. 88.8KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058659: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058671: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 95, Chunks in use: 95. 96.2KiB allocated for chunks. 96.2KiB in use in bin. 95.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058682: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 1, Chunks in use: 1. 3.8KiB allocated for chunks. 3.8KiB in use in bin. 3.8KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058693: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 239, Chunks in use: 239. 1.06MiB allocated for chunks. 1.06MiB in use in bin. 958.5KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058704: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 46, Chunks in use: 45. 388.2KiB allocated for chunks. 373.8KiB in use in bin. 360.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058715: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 9, Chunks in use: 9. 196.2KiB allocated for chunks. 196.2KiB in use in bin. 174.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058726: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 37, Chunks in use: 37. 1.21MiB allocated for chunks. 1.21MiB in use in bin. 1.11MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058736: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 19, Chunks in use: 19. 2.10MiB allocated for chunks. 2.10MiB in use in bin. 2.08MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058747: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 8, Chunks in use: 8. 1.39MiB allocated for chunks. 1.39MiB in use in bin. 896.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058757: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 14, Chunks in use: 14. 4.66MiB allocated for chunks. 4.66MiB in use in bin. 4.28MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058767: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 3, Chunks in use: 2. 2.13MiB allocated for chunks. 1.17MiB in use in bin. 626.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058777: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 0. 7.62MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058789: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 60, Chunks in use: 60. 128.66MiB allocated for chunks. 128.66MiB in use in bin. 120.00MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058799: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 9.78MiB allocated for chunks. 9.78MiB in use in bin. 9.78MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058811: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 5, Chunks in use: 4. 47.28MiB allocated for chunks. 39.12MiB in use in bin. 39.12MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058822: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 13, Chunks in use: 13. 258.43MiB allocated for chunks. 258.43MiB in use in bin. 254.16MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058832: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058842: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 26, Chunks in use: 25. 2.11GiB allocated for chunks. 2.03GiB in use in bin. 1.89GiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058857: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 5, Chunks in use: 4. 704.93MiB allocated for chunks. 559.09MiB in use in bin. 313.00MiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058868: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 28, Chunks in use: 27. 18.19GiB allocated for chunks. 17.75GiB in use in bin. 17.75GiB client-requested in use in bin.\n",
      "2023-09-22 01:54:10.058879: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 765.38MiB was 256.00MiB, Chunk State: \n",
      "2023-09-22 01:54:10.058894: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 448.58MiB | Requested Size: 128B | in_use: 0 | bin_num: 20, prev:   Size: 765.38MiB | Requested Size: 765.38MiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:54:10.058902: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 23023321088\n",
      "2023-09-22 01:54:10.058913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000000 of size 1280 next 1\n",
      "2023-09-22 01:54:10.058921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000500 of size 256 next 2\n",
      "2023-09-22 01:54:10.058929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000600 of size 256 next 3\n",
      "2023-09-22 01:54:10.058936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000700 of size 256 next 5\n",
      "2023-09-22 01:54:10.058944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000800 of size 256 next 6\n",
      "2023-09-22 01:54:10.058951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000900 of size 256 next 4\n",
      "2023-09-22 01:54:10.058959: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000a00 of size 256 next 1475\n",
      "2023-09-22 01:54:10.058966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000b00 of size 256 next 1209\n",
      "2023-09-22 01:54:10.058973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000c00 of size 256 next 886\n",
      "2023-09-22 01:54:10.058981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000d00 of size 256 next 12\n",
      "2023-09-22 01:54:10.058988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000e00 of size 256 next 13\n",
      "2023-09-22 01:54:10.058996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000f00 of size 256 next 14\n",
      "2023-09-22 01:54:10.059004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001000 of size 4096 next 1062\n",
      "2023-09-22 01:54:10.059013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002000 of size 4096 next 843\n",
      "2023-09-22 01:54:10.059021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003000 of size 4352 next 28\n",
      "2023-09-22 01:54:10.059035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004100 of size 256 next 29\n",
      "2023-09-22 01:54:10.059043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004200 of size 256 next 30\n",
      "2023-09-22 01:54:10.059051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004300 of size 256 next 61\n",
      "2023-09-22 01:54:10.059058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004400 of size 256 next 309\n",
      "2023-09-22 01:54:10.059069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004500 of size 256 next 563\n",
      "2023-09-22 01:54:10.059077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004600 of size 256 next 42\n",
      "2023-09-22 01:54:10.059084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004700 of size 256 next 37\n",
      "2023-09-22 01:54:10.059093: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004800 of size 256 next 36\n",
      "2023-09-22 01:54:10.059101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004900 of size 6144 next 32\n",
      "2023-09-22 01:54:10.059110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006100 of size 256 next 31\n",
      "2023-09-22 01:54:10.059118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006200 of size 256 next 33\n",
      "2023-09-22 01:54:10.059125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006300 of size 256 next 1038\n",
      "2023-09-22 01:54:10.059135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006400 of size 256 next 96\n",
      "2023-09-22 01:54:10.059168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006500 of size 256 next 587\n",
      "2023-09-22 01:54:10.059179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006600 of size 256 next 255\n",
      "2023-09-22 01:54:10.059190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006700 of size 256 next 911\n",
      "2023-09-22 01:54:10.059198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006800 of size 256 next 35\n",
      "2023-09-22 01:54:10.059205: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006900 of size 256 next 45\n",
      "2023-09-22 01:54:10.059216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006a00 of size 256 next 48\n",
      "2023-09-22 01:54:10.059226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006b00 of size 256 next 49\n",
      "2023-09-22 01:54:10.059238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006c00 of size 160512 next 1573\n",
      "2023-09-22 01:54:10.059246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02df00 of size 256 next 917\n",
      "2023-09-22 01:54:10.059258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e000 of size 256 next 330\n",
      "2023-09-22 01:54:10.059266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e100 of size 256 next 1242\n",
      "2023-09-22 01:54:10.059273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e200 of size 256 next 1094\n",
      "2023-09-22 01:54:10.059282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e300 of size 256 next 956\n",
      "2023-09-22 01:54:10.059294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e400 of size 256 next 1653\n",
      "2023-09-22 01:54:10.059302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e500 of size 256 next 1246\n",
      "2023-09-22 01:54:10.059311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e600 of size 256 next 1358\n",
      "2023-09-22 01:54:10.059320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e700 of size 256 next 536\n",
      "2023-09-22 01:54:10.059329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e800 of size 256 next 581\n",
      "2023-09-22 01:54:10.059339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02e900 of size 256 next 612\n",
      "2023-09-22 01:54:10.059348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ea00 of size 256 next 710\n",
      "2023-09-22 01:54:10.059357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02eb00 of size 256 next 1211\n",
      "2023-09-22 01:54:10.059366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ec00 of size 256 next 748\n",
      "2023-09-22 01:54:10.059375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ed00 of size 256 next 1110\n",
      "2023-09-22 01:54:10.059384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ee00 of size 256 next 1437\n",
      "2023-09-22 01:54:10.059393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ef00 of size 256 next 1214\n",
      "2023-09-22 01:54:10.059401: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f000 of size 256 next 1178\n",
      "2023-09-22 01:54:10.059410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f100 of size 256 next 165\n",
      "2023-09-22 01:54:10.059419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f200 of size 256 next 228\n",
      "2023-09-22 01:54:10.059428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f300 of size 256 next 120\n",
      "2023-09-22 01:54:10.059437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f400 of size 256 next 1579\n",
      "2023-09-22 01:54:10.059446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f500 of size 256 next 1236\n",
      "2023-09-22 01:54:10.059455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f600 of size 256 next 714\n",
      "2023-09-22 01:54:10.059464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f700 of size 256 next 504\n",
      "2023-09-22 01:54:10.059473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f800 of size 256 next 141\n",
      "2023-09-22 01:54:10.059482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02f900 of size 256 next 245\n",
      "2023-09-22 01:54:10.059491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fa00 of size 256 next 105\n",
      "2023-09-22 01:54:10.059500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fb00 of size 256 next 103\n",
      "2023-09-22 01:54:10.059510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fc00 of size 256 next 104\n",
      "2023-09-22 01:54:10.059519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fd00 of size 256 next 107\n",
      "2023-09-22 01:54:10.059527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fe00 of size 256 next 110\n",
      "2023-09-22 01:54:10.059536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ff00 of size 256 next 115\n",
      "2023-09-22 01:54:10.059545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030000 of size 256 next 116\n",
      "2023-09-22 01:54:10.059554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030100 of size 256 next 117\n",
      "2023-09-22 01:54:10.059563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030200 of size 256 next 1592\n",
      "2023-09-22 01:54:10.059572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030300 of size 256 next 1270\n",
      "2023-09-22 01:54:10.059581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030400 of size 256 next 1546\n",
      "2023-09-22 01:54:10.059590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030500 of size 256 next 646\n",
      "2023-09-22 01:54:10.059599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030600 of size 256 next 108\n",
      "2023-09-22 01:54:10.059608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030700 of size 256 next 109\n",
      "2023-09-22 01:54:10.059617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030800 of size 1263600128 next 846\n",
      "2023-09-22 01:54:10.059628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1229540a00 of size 82051072 next 1105\n",
      "2023-09-22 01:54:10.059635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122e380a00 of size 82051072 next 401\n",
      "2023-09-22 01:54:10.059644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12331c0a00 of size 82051072 next 998\n",
      "2023-09-22 01:54:10.059653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1238000a00 of size 82051072 next 68\n",
      "2023-09-22 01:54:10.059663: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f123ce40a00 of size 90197504 next 953\n",
      "2023-09-22 01:54:10.059672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445800 of size 256 next 925\n",
      "2023-09-22 01:54:10.059681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445900 of size 20480000 next 1692\n",
      "2023-09-22 01:54:10.059691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12437cd900 of size 20480000 next 301\n",
      "2023-09-22 01:54:10.059700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244b55900 of size 24601344 next 894\n",
      "2023-09-22 01:54:10.059711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbc00 of size 256 next 695\n",
      "2023-09-22 01:54:10.059721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbd00 of size 256 next 1266\n",
      "2023-09-22 01:54:10.059730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbe00 of size 4096 next 512\n",
      "2023-09-22 01:54:10.059740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cce00 of size 4608 next 802\n",
      "2023-09-22 01:54:10.059749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462ce000 of size 4096 next 807\n",
      "2023-09-22 01:54:10.059759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cf000 of size 5632 next 161\n",
      "2023-09-22 01:54:10.059768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d0600 of size 4096 next 343\n",
      "2023-09-22 01:54:10.059777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d1600 of size 4608 next 277\n",
      "2023-09-22 01:54:10.059787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d2800 of size 4096 next 935\n",
      "2023-09-22 01:54:10.059797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d3800 of size 5632 next 1447\n",
      "2023-09-22 01:54:10.059806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d4e00 of size 4096 next 337\n",
      "2023-09-22 01:54:10.059816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d5e00 of size 256 next 1517\n",
      "2023-09-22 01:54:10.059825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d5f00 of size 256 next 1470\n",
      "2023-09-22 01:54:10.059834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6000 of size 256 next 978\n",
      "2023-09-22 01:54:10.059843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6100 of size 256 next 993\n",
      "2023-09-22 01:54:10.059852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6200 of size 256 next 1069\n",
      "2023-09-22 01:54:10.059862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6300 of size 256 next 1086\n",
      "2023-09-22 01:54:10.059871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6400 of size 256 next 323\n",
      "2023-09-22 01:54:10.059880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6500 of size 256 next 1536\n",
      "2023-09-22 01:54:10.059889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6600 of size 256 next 1667\n",
      "2023-09-22 01:54:10.059898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6700 of size 256 next 666\n",
      "2023-09-22 01:54:10.059908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6800 of size 256 next 485\n",
      "2023-09-22 01:54:10.059917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6900 of size 256 next 912\n",
      "2023-09-22 01:54:10.059926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6a00 of size 256 next 1404\n",
      "2023-09-22 01:54:10.059935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6b00 of size 256 next 421\n",
      "2023-09-22 01:54:10.059944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6c00 of size 256 next 379\n",
      "2023-09-22 01:54:10.059952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6d00 of size 256 next 647\n",
      "2023-09-22 01:54:10.059961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6e00 of size 256 next 349\n",
      "2023-09-22 01:54:10.059970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d6f00 of size 256 next 183\n",
      "2023-09-22 01:54:10.059980: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d7000 of size 4096 next 178\n",
      "2023-09-22 01:54:10.059990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d8000 of size 5120 next 1531\n",
      "2023-09-22 01:54:10.059998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9400 of size 256 next 322\n",
      "2023-09-22 01:54:10.060007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9500 of size 256 next 1167\n",
      "2023-09-22 01:54:10.060016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9600 of size 256 next 1250\n",
      "2023-09-22 01:54:10.060025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9700 of size 256 next 460\n",
      "2023-09-22 01:54:10.060035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9800 of size 256 next 857\n",
      "2023-09-22 01:54:10.060044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9900 of size 256 next 1456\n",
      "2023-09-22 01:54:10.060053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9a00 of size 256 next 1021\n",
      "2023-09-22 01:54:10.060062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9b00 of size 256 next 265\n",
      "2023-09-22 01:54:10.060071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9c00 of size 256 next 623\n",
      "2023-09-22 01:54:10.060080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9d00 of size 256 next 145\n",
      "2023-09-22 01:54:10.060089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9e00 of size 256 next 564\n",
      "2023-09-22 01:54:10.060098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462d9f00 of size 256 next 1614\n",
      "2023-09-22 01:54:10.060107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da000 of size 256 next 85\n",
      "2023-09-22 01:54:10.060117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da100 of size 256 next 1457\n",
      "2023-09-22 01:54:10.060126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462da200 of size 2097152 next 1338\n",
      "2023-09-22 01:54:10.060136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464da200 of size 2130432 next 959\n",
      "2023-09-22 01:54:10.060145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2400 of size 256 next 1426\n",
      "2023-09-22 01:54:10.060154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2500 of size 4096 next 195\n",
      "2023-09-22 01:54:10.060164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e3500 of size 4096 next 371\n",
      "2023-09-22 01:54:10.060173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e4500 of size 5632 next 613\n",
      "2023-09-22 01:54:10.060182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e5b00 of size 4096 next 1440\n",
      "2023-09-22 01:54:10.060191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6b00 of size 4608 next 1612\n",
      "2023-09-22 01:54:10.060200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e7d00 of size 4096 next 571\n",
      "2023-09-22 01:54:10.060210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e8d00 of size 4096 next 1558\n",
      "2023-09-22 01:54:10.060220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e9d00 of size 4608 next 1433\n",
      "2023-09-22 01:54:10.060229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466eaf00 of size 4608 next 146\n",
      "2023-09-22 01:54:10.060238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ec100 of size 4096 next 1463\n",
      "2023-09-22 01:54:10.060247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ed100 of size 5632 next 1480\n",
      "2023-09-22 01:54:10.060257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ee700 of size 4096 next 1277\n",
      "2023-09-22 01:54:10.060268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ef700 of size 4608 next 602\n",
      "2023-09-22 01:54:10.060279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f0900 of size 5888 next 291\n",
      "2023-09-22 01:54:10.060290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2000 of size 256 next 880\n",
      "2023-09-22 01:54:10.060300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2100 of size 4096 next 979\n",
      "2023-09-22 01:54:10.060309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3100 of size 4096 next 133\n",
      "2023-09-22 01:54:10.060320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4100 of size 5888 next 98\n",
      "2023-09-22 01:54:10.060330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5800 of size 256 next 385\n",
      "2023-09-22 01:54:10.060341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5900 of size 256 next 705\n",
      "2023-09-22 01:54:10.060351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5a00 of size 256 next 225\n",
      "2023-09-22 01:54:10.060360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5b00 of size 2097152 next 664\n",
      "2023-09-22 01:54:10.060370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12468f5b00 of size 2097152 next 789\n",
      "2023-09-22 01:54:10.060380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246af5b00 of size 2097152 next 615\n",
      "2023-09-22 01:54:10.060389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246cf5b00 of size 2097152 next 15\n",
      "2023-09-22 01:54:10.060398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246ef5b00 of size 2168320 next 1155\n",
      "2023-09-22 01:54:10.060408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107100 of size 256 next 995\n",
      "2023-09-22 01:54:10.060417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107200 of size 128256 next 1140\n",
      "2023-09-22 01:54:10.060429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126700 of size 256 next 47\n",
      "2023-09-22 01:54:10.060438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126800 of size 4096 next 247\n",
      "2023-09-22 01:54:10.060446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127800 of size 4096 next 79\n",
      "2023-09-22 01:54:10.060454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128800 of size 4864 next 1451\n",
      "2023-09-22 01:54:10.060463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129b00 of size 256 next 677\n",
      "2023-09-22 01:54:10.060472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129c00 of size 256 next 148\n",
      "2023-09-22 01:54:10.060482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129d00 of size 256 next 374\n",
      "2023-09-22 01:54:10.060491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129e00 of size 256 next 1136\n",
      "2023-09-22 01:54:10.060500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129f00 of size 256 next 814\n",
      "2023-09-22 01:54:10.060510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a000 of size 256 next 813\n",
      "2023-09-22 01:54:10.060519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a100 of size 256 next 258\n",
      "2023-09-22 01:54:10.060529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a200 of size 256 next 1269\n",
      "2023-09-22 01:54:10.060538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a300 of size 256 next 1553\n",
      "2023-09-22 01:54:10.060547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a400 of size 256 next 839\n",
      "2023-09-22 01:54:10.060557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a500 of size 256 next 1461\n",
      "2023-09-22 01:54:10.060566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a600 of size 256 next 1396\n",
      "2023-09-22 01:54:10.060576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a700 of size 256 next 1002\n",
      "2023-09-22 01:54:10.060586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a800 of size 256 next 901\n",
      "2023-09-22 01:54:10.060595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a900 of size 256 next 686\n",
      "2023-09-22 01:54:10.060605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712aa00 of size 256 next 297\n",
      "2023-09-22 01:54:10.060614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712ab00 of size 256 next 1195\n",
      "2023-09-22 01:54:10.060624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712ac00 of size 256 next 1356\n",
      "2023-09-22 01:54:10.060633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712ad00 of size 256 next 900\n",
      "2023-09-22 01:54:10.060642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712ae00 of size 256 next 91\n",
      "2023-09-22 01:54:10.060652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712af00 of size 256 next 823\n",
      "2023-09-22 01:54:10.060661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b000 of size 256 next 1599\n",
      "2023-09-22 01:54:10.060670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b100 of size 256 next 153\n",
      "2023-09-22 01:54:10.060680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b200 of size 256 next 942\n",
      "2023-09-22 01:54:10.060689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b300 of size 256 next 795\n",
      "2023-09-22 01:54:10.060699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b400 of size 256 next 1375\n",
      "2023-09-22 01:54:10.060708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b500 of size 256 next 155\n",
      "2023-09-22 01:54:10.060718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b600 of size 256 next 1485\n",
      "2023-09-22 01:54:10.060727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b700 of size 256 next 738\n",
      "2023-09-22 01:54:10.060737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b800 of size 32768 next 450\n",
      "2023-09-22 01:54:10.060746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247133800 of size 32768 next 800\n",
      "2023-09-22 01:54:10.060754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124713b800 of size 32768 next 509\n",
      "2023-09-22 01:54:10.060763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247143800 of size 3840 next 1262\n",
      "2023-09-22 01:54:10.060773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144700 of size 256 next 1382\n",
      "2023-09-22 01:54:10.060782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144800 of size 256 next 1063\n",
      "2023-09-22 01:54:10.060792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144900 of size 256 next 572\n",
      "2023-09-22 01:54:10.060801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144a00 of size 256 next 1244\n",
      "2023-09-22 01:54:10.060811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144b00 of size 256 next 728\n",
      "2023-09-22 01:54:10.060820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144c00 of size 256 next 938\n",
      "2023-09-22 01:54:10.060829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247144d00 of size 5120 next 873\n",
      "2023-09-22 01:54:10.060839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247146100 of size 5120 next 1100\n",
      "2023-09-22 01:54:10.060849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247147500 of size 256 next 931\n",
      "2023-09-22 01:54:10.060858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247147600 of size 256 next 1245\n",
      "2023-09-22 01:54:10.060868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247147700 of size 256 next 1226\n",
      "2023-09-22 01:54:10.060879: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247147800 of size 256 next 1058\n",
      "2023-09-22 01:54:10.060889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247147900 of size 256 next 1561\n",
      "2023-09-22 01:54:10.060899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247147a00 of size 256 next 1025\n",
      "2023-09-22 01:54:10.060909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247147b00 of size 25856 next 1577\n",
      "2023-09-22 01:54:10.060919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124714e000 of size 114688 next 707\n",
      "2023-09-22 01:54:10.060929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124716a000 of size 171520 next 163\n",
      "2023-09-22 01:54:10.060938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193e00 of size 256 next 123\n",
      "2023-09-22 01:54:10.060947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193f00 of size 256 next 1630\n",
      "2023-09-22 01:54:10.060957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194000 of size 256 next 192\n",
      "2023-09-22 01:54:10.060966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194100 of size 256 next 670\n",
      "2023-09-22 01:54:10.060975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194200 of size 256 next 66\n",
      "2023-09-22 01:54:10.060985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194300 of size 256 next 453\n",
      "2023-09-22 01:54:10.060994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194400 of size 256 next 989\n",
      "2023-09-22 01:54:10.061005: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194500 of size 8192 next 1235\n",
      "2023-09-22 01:54:10.061015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247196500 of size 8192 next 283\n",
      "2023-09-22 01:54:10.061028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247198500 of size 16384 next 473\n",
      "2023-09-22 01:54:10.061039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124719c500 of size 49664 next 1460\n",
      "2023-09-22 01:54:10.061048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a8700 of size 256 next 1067\n",
      "2023-09-22 01:54:10.061058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a8800 of size 1024 next 1473\n",
      "2023-09-22 01:54:10.061068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a8c00 of size 1024 next 1654\n",
      "2023-09-22 01:54:10.061075: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a9000 of size 1024 next 1339\n",
      "2023-09-22 01:54:10.061085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a9400 of size 1024 next 200\n",
      "2023-09-22 01:54:10.061095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a9800 of size 1024 next 1030\n",
      "2023-09-22 01:54:10.061105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471a9c00 of size 6912 next 1009\n",
      "2023-09-22 01:54:10.061115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ab700 of size 4096 next 1391\n",
      "2023-09-22 01:54:10.061124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ac700 of size 4096 next 680\n",
      "2023-09-22 01:54:10.061133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ad700 of size 4096 next 396\n",
      "2023-09-22 01:54:10.061144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471ae700 of size 4096 next 898\n",
      "2023-09-22 01:54:10.061154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471af700 of size 2346752 next 1397\n",
      "2023-09-22 01:54:10.061163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473ec600 of size 256 next 1633\n",
      "2023-09-22 01:54:10.061172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473ec700 of size 4176128 next 9\n",
      "2023-09-22 01:54:10.061181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e8000 of size 256 next 609\n",
      "2023-09-22 01:54:10.061191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e8100 of size 5632 next 918\n",
      "2023-09-22 01:54:10.061200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9700 of size 256 next 440\n",
      "2023-09-22 01:54:10.061210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9800 of size 256 next 999\n",
      "2023-09-22 01:54:10.061219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9900 of size 4096 next 987\n",
      "2023-09-22 01:54:10.061229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ea900 of size 4608 next 1576\n",
      "2023-09-22 01:54:10.061238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ebb00 of size 4096 next 1077\n",
      "2023-09-22 01:54:10.061248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477ecb00 of size 4608 next 360\n",
      "2023-09-22 01:54:10.061257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477edd00 of size 4096 next 569\n",
      "2023-09-22 01:54:10.061267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477eed00 of size 5632 next 1166\n",
      "2023-09-22 01:54:10.061278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f0300 of size 4096 next 688\n",
      "2023-09-22 01:54:10.061288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f1300 of size 4608 next 621\n",
      "2023-09-22 01:54:10.061297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f2500 of size 4096 next 817\n",
      "2023-09-22 01:54:10.061307: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f3500 of size 6656 next 1619\n",
      "2023-09-22 01:54:10.061316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f4f00 of size 256 next 1621\n",
      "2023-09-22 01:54:10.061325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f5000 of size 256 next 1501\n",
      "2023-09-22 01:54:10.061335: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f5100 of size 256 next 315\n",
      "2023-09-22 01:54:10.061344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f5200 of size 256 next 207\n",
      "2023-09-22 01:54:10.061354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f5300 of size 1024 next 114\n",
      "2023-09-22 01:54:10.061363: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f5700 of size 1024 next 373\n",
      "2023-09-22 01:54:10.061373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f5b00 of size 1024 next 1146\n",
      "2023-09-22 01:54:10.061382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f5f00 of size 1024 next 908\n",
      "2023-09-22 01:54:10.061391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f6300 of size 1024 next 427\n",
      "2023-09-22 01:54:10.061401: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f6700 of size 1024 next 862\n",
      "2023-09-22 01:54:10.061411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f6b00 of size 256 next 1388\n",
      "2023-09-22 01:54:10.061421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f6c00 of size 256 next 729\n",
      "2023-09-22 01:54:10.061430: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f6d00 of size 256 next 219\n",
      "2023-09-22 01:54:10.061440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f6e00 of size 256 next 356\n",
      "2023-09-22 01:54:10.061450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f6f00 of size 256 next 318\n",
      "2023-09-22 01:54:10.061460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7000 of size 256 next 329\n",
      "2023-09-22 01:54:10.061469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7100 of size 256 next 971\n",
      "2023-09-22 01:54:10.061479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7200 of size 256 next 505\n",
      "2023-09-22 01:54:10.061488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7300 of size 256 next 803\n",
      "2023-09-22 01:54:10.061498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7400 of size 256 next 204\n",
      "2023-09-22 01:54:10.061507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7500 of size 256 next 906\n",
      "2023-09-22 01:54:10.061517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7600 of size 256 next 905\n",
      "2023-09-22 01:54:10.061527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7700 of size 256 next 944\n",
      "2023-09-22 01:54:10.061537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7800 of size 256 next 1050\n",
      "2023-09-22 01:54:10.061546: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7900 of size 256 next 1503\n",
      "2023-09-22 01:54:10.061555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7a00 of size 256 next 328\n",
      "2023-09-22 01:54:10.061564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7b00 of size 256 next 1394\n",
      "2023-09-22 01:54:10.061574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7c00 of size 256 next 118\n",
      "2023-09-22 01:54:10.061583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7d00 of size 256 next 411\n",
      "2023-09-22 01:54:10.061593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7e00 of size 256 next 271\n",
      "2023-09-22 01:54:10.061602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f7f00 of size 256 next 860\n",
      "2023-09-22 01:54:10.061612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f8000 of size 256 next 1346\n",
      "2023-09-22 01:54:10.061621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f8100 of size 256 next 1613\n",
      "2023-09-22 01:54:10.061630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f8200 of size 256 next 16\n",
      "2023-09-22 01:54:10.061640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f8300 of size 256 next 1311\n",
      "2023-09-22 01:54:10.061650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f8400 of size 256 next 1317\n",
      "2023-09-22 01:54:10.061659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f8500 of size 256 next 1293\n",
      "2023-09-22 01:54:10.061667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f8600 of size 4096 next 1348\n",
      "2023-09-22 01:54:10.061676: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f9600 of size 4096 next 1091\n",
      "2023-09-22 01:54:10.061685: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477fa600 of size 4096 next 600\n",
      "2023-09-22 01:54:10.061695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477fb600 of size 4096 next 893\n",
      "2023-09-22 01:54:10.061704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477fc600 of size 4096 next 1516\n",
      "2023-09-22 01:54:10.061714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477fd600 of size 256 next 1206\n",
      "2023-09-22 01:54:10.061723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477fd700 of size 256 next 1278\n",
      "2023-09-22 01:54:10.061733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12477fd800 of size 2049792 next 1581\n",
      "2023-09-22 01:54:10.061742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f1f00 of size 256 next 1464\n",
      "2023-09-22 01:54:10.061751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2000 of size 256 next 1589\n",
      "2023-09-22 01:54:10.061760: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2100 of size 114688 next 856\n",
      "2023-09-22 01:54:10.061770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0e100 of size 114688 next 495\n",
      "2023-09-22 01:54:10.061779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a2a100 of size 32768 next 1481\n",
      "2023-09-22 01:54:10.061788: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a32100 of size 32768 next 1363\n",
      "2023-09-22 01:54:10.061798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a3a100 of size 16384 next 1010\n",
      "2023-09-22 01:54:10.061807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a3e100 of size 1024 next 1703\n",
      "2023-09-22 01:54:10.061816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a3e500 of size 1024 next 181\n",
      "2023-09-22 01:54:10.061825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a3e900 of size 8192 next 896\n",
      "2023-09-22 01:54:10.061835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a40900 of size 8192 next 1306\n",
      "2023-09-22 01:54:10.061845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a42900 of size 8192 next 1182\n",
      "2023-09-22 01:54:10.061854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a44900 of size 8192 next 1498\n",
      "2023-09-22 01:54:10.061864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a46900 of size 8192 next 1647\n",
      "2023-09-22 01:54:10.061874: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a48900 of size 8192 next 719\n",
      "2023-09-22 01:54:10.061884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4a900 of size 1024 next 549\n",
      "2023-09-22 01:54:10.061893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4ad00 of size 1024 next 1439\n",
      "2023-09-22 01:54:10.061903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4b100 of size 1024 next 854\n",
      "2023-09-22 01:54:10.061912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4b500 of size 1024 next 864\n",
      "2023-09-22 01:54:10.061921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4b900 of size 1024 next 151\n",
      "2023-09-22 01:54:10.061930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4bd00 of size 1024 next 345\n",
      "2023-09-22 01:54:10.061940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4c100 of size 32768 next 781\n",
      "2023-09-22 01:54:10.061949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54100 of size 40448 next 1390\n",
      "2023-09-22 01:54:10.061959: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5df00 of size 256 next 1529\n",
      "2023-09-22 01:54:10.061968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e000 of size 256 next 1707\n",
      "2023-09-22 01:54:10.061975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e100 of size 256 next 861\n",
      "2023-09-22 01:54:10.061985: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e200 of size 256 next 1652\n",
      "2023-09-22 01:54:10.061994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e300 of size 256 next 1504\n",
      "2023-09-22 01:54:10.062003: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e400 of size 256 next 99\n",
      "2023-09-22 01:54:10.062012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e500 of size 256 next 1706\n",
      "2023-09-22 01:54:10.062022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e600 of size 256 next 844\n",
      "2023-09-22 01:54:10.062031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e700 of size 256 next 1631\n",
      "2023-09-22 01:54:10.062041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e800 of size 256 next 739\n",
      "2023-09-22 01:54:10.062050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5e900 of size 256 next 866\n",
      "2023-09-22 01:54:10.062059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5ea00 of size 256 next 1300\n",
      "2023-09-22 01:54:10.062068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5eb00 of size 256 next 1677\n",
      "2023-09-22 01:54:10.062078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5ec00 of size 4096 next 243\n",
      "2023-09-22 01:54:10.062087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5fc00 of size 4864 next 139\n",
      "2023-09-22 01:54:10.062097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60f00 of size 256 next 274\n",
      "2023-09-22 01:54:10.062107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61000 of size 256 next 1555\n",
      "2023-09-22 01:54:10.062117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61100 of size 256 next 1568\n",
      "2023-09-22 01:54:10.062126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61200 of size 256 next 1583\n",
      "2023-09-22 01:54:10.062135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61300 of size 256 next 1459\n",
      "2023-09-22 01:54:10.062144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61400 of size 256 next 1133\n",
      "2023-09-22 01:54:10.062153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61500 of size 256 next 149\n",
      "2023-09-22 01:54:10.062163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61600 of size 256 next 259\n",
      "2023-09-22 01:54:10.062172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61700 of size 256 next 489\n",
      "2023-09-22 01:54:10.062181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61800 of size 256 next 525\n",
      "2023-09-22 01:54:10.062191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61900 of size 256 next 205\n",
      "2023-09-22 01:54:10.062200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61a00 of size 256 next 410\n",
      "2023-09-22 01:54:10.062209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61b00 of size 256 next 1297\n",
      "2023-09-22 01:54:10.062218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61c00 of size 256 next 279\n",
      "2023-09-22 01:54:10.062228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61d00 of size 256 next 1665\n",
      "2023-09-22 01:54:10.062237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61e00 of size 256 next 1168\n",
      "2023-09-22 01:54:10.062246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61f00 of size 4864 next 769\n",
      "2023-09-22 01:54:10.062255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a63200 of size 8192 next 358\n",
      "2023-09-22 01:54:10.062265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a65200 of size 16128 next 1048\n",
      "2023-09-22 01:54:10.062276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69100 of size 256 next 1393\n",
      "2023-09-22 01:54:10.062284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69200 of size 256 next 184\n",
      "2023-09-22 01:54:10.062293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69300 of size 2097152 next 1224\n",
      "2023-09-22 01:54:10.062303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247c69300 of size 2211840 next 423\n",
      "2023-09-22 01:54:10.062313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e85300 of size 114688 next 1385\n",
      "2023-09-22 01:54:10.062322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ea1300 of size 114688 next 965\n",
      "2023-09-22 01:54:10.062332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ebd300 of size 2150912 next 1295\n",
      "2023-09-22 01:54:10.062341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca500 of size 256 next 671\n",
      "2023-09-22 01:54:10.062350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca600 of size 256 next 1061\n",
      "2023-09-22 01:54:10.062360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca700 of size 256 next 1514\n",
      "2023-09-22 01:54:10.062369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca800 of size 82051072 next 1124\n",
      "2023-09-22 01:54:10.062379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124cf0a800 of size 149536512 next 514\n",
      "2023-09-22 01:54:10.062388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6700 of size 256 next 284\n",
      "2023-09-22 01:54:10.062397: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6800 of size 256 next 796\n",
      "2023-09-22 01:54:10.062407: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6900 of size 114688 next 21\n",
      "2023-09-22 01:54:10.062415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255dc2900 of size 131072 next 535\n",
      "2023-09-22 01:54:10.062422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255de2900 of size 320512 next 397\n",
      "2023-09-22 01:54:10.062432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e30d00 of size 320512 next 1119\n",
      "2023-09-22 01:54:10.062441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e7f100 of size 484608 next 673\n",
      "2023-09-22 01:54:10.062451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5600 of size 256 next 1259\n",
      "2023-09-22 01:54:10.062460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5700 of size 7936 next 520\n",
      "2023-09-22 01:54:10.062469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7600 of size 256 next 214\n",
      "2023-09-22 01:54:10.062478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7700 of size 4096 next 69\n",
      "2023-09-22 01:54:10.062488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8700 of size 4096 next 923\n",
      "2023-09-22 01:54:10.062497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9700 of size 4096 next 744\n",
      "2023-09-22 01:54:10.062507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa700 of size 4608 next 1027\n",
      "2023-09-22 01:54:10.062516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb900 of size 256 next 624\n",
      "2023-09-22 01:54:10.062526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efba00 of size 6144 next 683\n",
      "2023-09-22 01:54:10.062535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd200 of size 256 next 1296\n",
      "2023-09-22 01:54:10.062545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd300 of size 2097152 next 256\n",
      "2023-09-22 01:54:10.062554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12560fd300 of size 2097152 next 537\n",
      "2023-09-22 01:54:10.062564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12562fd300 of size 2097152 next 1538\n",
      "2023-09-22 01:54:10.062573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12564fd300 of size 2097152 next 372\n",
      "2023-09-22 01:54:10.062582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12566fd300 of size 2097152 next 1176\n",
      "2023-09-22 01:54:10.062591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12568fd300 of size 2097152 next 853\n",
      "2023-09-22 01:54:10.062601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1256afd300 of size 2097152 next 1502\n",
      "2023-09-22 01:54:10.062610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1256cfd300 of size 2097152 next 1162\n",
      "2023-09-22 01:54:10.062619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1256efd300 of size 2097152 next 1307\n",
      "2023-09-22 01:54:10.062628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12570fd300 of size 2097152 next 38\n",
      "2023-09-22 01:54:10.062638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12572fd300 of size 2097152 next 400\n",
      "2023-09-22 01:54:10.062648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12574fd300 of size 4096 next 428\n",
      "2023-09-22 01:54:10.062657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12574fe300 of size 4096 next 756\n",
      "2023-09-22 01:54:10.062666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12574ff300 of size 4608 next 402\n",
      "2023-09-22 01:54:10.062675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500500 of size 256 next 1120\n",
      "2023-09-22 01:54:10.062685: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500600 of size 256 next 527\n",
      "2023-09-22 01:54:10.062694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500700 of size 256 next 1370\n",
      "2023-09-22 01:54:10.062703: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500800 of size 256 next 1015\n",
      "2023-09-22 01:54:10.062712: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500900 of size 256 next 1234\n",
      "2023-09-22 01:54:10.062720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500a00 of size 256 next 1022\n",
      "2023-09-22 01:54:10.062729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500b00 of size 256 next 231\n",
      "2023-09-22 01:54:10.062739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500c00 of size 256 next 679\n",
      "2023-09-22 01:54:10.062748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500d00 of size 256 next 380\n",
      "2023-09-22 01:54:10.062758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500e00 of size 256 next 1708\n",
      "2023-09-22 01:54:10.062767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257500f00 of size 256 next 1402\n",
      "2023-09-22 01:54:10.062777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257501000 of size 256 next 1222\n",
      "2023-09-22 01:54:10.062786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257501100 of size 256 next 950\n",
      "2023-09-22 01:54:10.062796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257501200 of size 256 next 874\n",
      "2023-09-22 01:54:10.062805: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257501300 of size 4096 next 777\n",
      "2023-09-22 01:54:10.062815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257502300 of size 4096 next 665\n",
      "2023-09-22 01:54:10.062824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257503300 of size 4096 next 1476\n",
      "2023-09-22 01:54:10.062833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257504300 of size 256 next 451\n",
      "2023-09-22 01:54:10.062843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257504400 of size 256 next 299\n",
      "2023-09-22 01:54:10.062852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257504500 of size 4352 next 872\n",
      "2023-09-22 01:54:10.062863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257505600 of size 256 next 128\n",
      "2023-09-22 01:54:10.062872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257505700 of size 256 next 1330\n",
      "2023-09-22 01:54:10.062882: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257505800 of size 6400 next 1469\n",
      "2023-09-22 01:54:10.062893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507100 of size 256 next 584\n",
      "2023-09-22 01:54:10.062903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507200 of size 256 next 1164\n",
      "2023-09-22 01:54:10.062912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507300 of size 256 next 1290\n",
      "2023-09-22 01:54:10.062922: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507400 of size 256 next 1170\n",
      "2023-09-22 01:54:10.062932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507500 of size 256 next 1029\n",
      "2023-09-22 01:54:10.062941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507600 of size 256 next 424\n",
      "2023-09-22 01:54:10.062951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507700 of size 256 next 67\n",
      "2023-09-22 01:54:10.062960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507800 of size 256 next 547\n",
      "2023-09-22 01:54:10.062969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507900 of size 256 next 125\n",
      "2023-09-22 01:54:10.062979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507a00 of size 256 next 449\n",
      "2023-09-22 01:54:10.062988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507b00 of size 256 next 159\n",
      "2023-09-22 01:54:10.062997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507c00 of size 256 next 327\n",
      "2023-09-22 01:54:10.063007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507d00 of size 256 next 1488\n",
      "2023-09-22 01:54:10.063016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507e00 of size 256 next 1662\n",
      "2023-09-22 01:54:10.063026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257507f00 of size 256 next 974\n",
      "2023-09-22 01:54:10.063033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508000 of size 256 next 1287\n",
      "2023-09-22 01:54:10.063042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508100 of size 256 next 261\n",
      "2023-09-22 01:54:10.063052: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508200 of size 256 next 1700\n",
      "2023-09-22 01:54:10.063061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508300 of size 256 next 1151\n",
      "2023-09-22 01:54:10.063070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508400 of size 256 next 54\n",
      "2023-09-22 01:54:10.063079: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508500 of size 256 next 1000\n",
      "2023-09-22 01:54:10.063089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508600 of size 256 next 1429\n",
      "2023-09-22 01:54:10.063099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508700 of size 256 next 1148\n",
      "2023-09-22 01:54:10.063108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508800 of size 256 next 593\n",
      "2023-09-22 01:54:10.063117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508900 of size 256 next 1566\n",
      "2023-09-22 01:54:10.063127: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508a00 of size 256 next 945\n",
      "2023-09-22 01:54:10.063136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508b00 of size 256 next 779\n",
      "2023-09-22 01:54:10.063150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508c00 of size 256 next 620\n",
      "2023-09-22 01:54:10.063159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508d00 of size 256 next 241\n",
      "2023-09-22 01:54:10.063169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257508e00 of size 4096 next 233\n",
      "2023-09-22 01:54:10.063179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257509e00 of size 256 next 1298\n",
      "2023-09-22 01:54:10.063190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257509f00 of size 256 next 260\n",
      "2023-09-22 01:54:10.063200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a000 of size 256 next 10\n",
      "2023-09-22 01:54:10.063211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a100 of size 256 next 1102\n",
      "2023-09-22 01:54:10.063221: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a200 of size 256 next 855\n",
      "2023-09-22 01:54:10.063230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a300 of size 256 next 212\n",
      "2023-09-22 01:54:10.063240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a400 of size 256 next 1351\n",
      "2023-09-22 01:54:10.063250: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a500 of size 256 next 1596\n",
      "2023-09-22 01:54:10.063259: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a600 of size 256 next 154\n",
      "2023-09-22 01:54:10.063268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a700 of size 256 next 1340\n",
      "2023-09-22 01:54:10.063278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a800 of size 256 next 272\n",
      "2023-09-22 01:54:10.063287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750a900 of size 256 next 820\n",
      "2023-09-22 01:54:10.063297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750aa00 of size 256 next 102\n",
      "2023-09-22 01:54:10.063306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750ab00 of size 256 next 302\n",
      "2023-09-22 01:54:10.063315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750ac00 of size 256 next 1419\n",
      "2023-09-22 01:54:10.063325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750ad00 of size 256 next 158\n",
      "2023-09-22 01:54:10.063334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750ae00 of size 4096 next 508\n",
      "2023-09-22 01:54:10.063344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750be00 of size 4096 next 821\n",
      "2023-09-22 01:54:10.063351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750ce00 of size 4096 next 254\n",
      "2023-09-22 01:54:10.063361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750de00 of size 4096 next 1334\n",
      "2023-09-22 01:54:10.063370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125750ee00 of size 7680 next 617\n",
      "2023-09-22 01:54:10.063379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257510c00 of size 114688 next 363\n",
      "2023-09-22 01:54:10.063390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125752cc00 of size 155648 next 927\n",
      "2023-09-22 01:54:10.063399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257552c00 of size 4096 next 1569\n",
      "2023-09-22 01:54:10.063409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257553c00 of size 4608 next 1542\n",
      "2023-09-22 01:54:10.063418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257554e00 of size 5632 next 419\n",
      "2023-09-22 01:54:10.063427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257556400 of size 4096 next 1530\n",
      "2023-09-22 01:54:10.063437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257557400 of size 4608 next 94\n",
      "2023-09-22 01:54:10.063446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257558600 of size 4096 next 1693\n",
      "2023-09-22 01:54:10.063456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257559600 of size 5632 next 775\n",
      "2023-09-22 01:54:10.063465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ac00 of size 256 next 1407\n",
      "2023-09-22 01:54:10.063475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ad00 of size 256 next 399\n",
      "2023-09-22 01:54:10.063484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ae00 of size 256 next 34\n",
      "2023-09-22 01:54:10.063494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755af00 of size 256 next 1181\n",
      "2023-09-22 01:54:10.063503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b000 of size 256 next 521\n",
      "2023-09-22 01:54:10.063512: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b100 of size 256 next 1098\n",
      "2023-09-22 01:54:10.063522: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b200 of size 256 next 1494\n",
      "2023-09-22 01:54:10.063531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b300 of size 256 next 645\n",
      "2023-09-22 01:54:10.063541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b400 of size 256 next 1144\n",
      "2023-09-22 01:54:10.063550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b500 of size 256 next 89\n",
      "2023-09-22 01:54:10.063559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b600 of size 256 next 1661\n",
      "2023-09-22 01:54:10.063568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b700 of size 256 next 1655\n",
      "2023-09-22 01:54:10.063578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b800 of size 256 next 546\n",
      "2023-09-22 01:54:10.063587: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755b900 of size 256 next 1409\n",
      "2023-09-22 01:54:10.063597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ba00 of size 256 next 630\n",
      "2023-09-22 01:54:10.063606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755bb00 of size 256 next 187\n",
      "2023-09-22 01:54:10.063616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755bc00 of size 256 next 324\n",
      "2023-09-22 01:54:10.063625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755bd00 of size 256 next 232\n",
      "2023-09-22 01:54:10.063634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755be00 of size 4096 next 1183\n",
      "2023-09-22 01:54:10.063644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ce00 of size 4096 next 542\n",
      "2023-09-22 01:54:10.063653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755de00 of size 4608 next 1239\n",
      "2023-09-22 01:54:10.063661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f125755f000 of size 1516288 next 1634\n",
      "2023-09-22 01:54:10.063670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1300 of size 256 next 780\n",
      "2023-09-22 01:54:10.063679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1400 of size 82051072 next 1489\n",
      "2023-09-22 01:54:10.063689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125c511400 of size 82051072 next 1056\n",
      "2023-09-22 01:54:10.063697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1261351400 of size 20512768 next 1383\n",
      "2023-09-22 01:54:10.063705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12626e1400 of size 82051072 next 496\n",
      "2023-09-22 01:54:10.063713: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1267521400 of size 82051072 next 1107\n",
      "2023-09-22 01:54:10.063723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f126c361400 of size 152922880 next 972\n",
      "2023-09-22 01:54:10.063732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537f00 of size 256 next 929\n",
      "2023-09-22 01:54:10.063742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538000 of size 256 next 940\n",
      "2023-09-22 01:54:10.063751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538100 of size 4096 next 53\n",
      "2023-09-22 01:54:10.063761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539100 of size 5888 next 1179\n",
      "2023-09-22 01:54:10.063770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a800 of size 256 next 771\n",
      "2023-09-22 01:54:10.063779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a900 of size 8192 next 933\n",
      "2023-09-22 01:54:10.063789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553c900 of size 8192 next 1075\n",
      "2023-09-22 01:54:10.063798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553e900 of size 8192 next 1511\n",
      "2023-09-22 01:54:10.063807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275540900 of size 8192 next 1333\n",
      "2023-09-22 01:54:10.063817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275542900 of size 32768 next 882\n",
      "2023-09-22 01:54:10.063826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127554a900 of size 32768 next 1059\n",
      "2023-09-22 01:54:10.063835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275552900 of size 256 next 1004\n",
      "2023-09-22 01:54:10.063845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275552a00 of size 1024 next 1400\n",
      "2023-09-22 01:54:10.063855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275552e00 of size 1024 next 415\n",
      "2023-09-22 01:54:10.063864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275553200 of size 1024 next 262\n",
      "2023-09-22 01:54:10.063873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275553600 of size 8192 next 367\n",
      "2023-09-22 01:54:10.063883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275555600 of size 8192 next 637\n",
      "2023-09-22 01:54:10.063893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275557600 of size 8192 next 355\n",
      "2023-09-22 01:54:10.063902: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275559600 of size 1024 next 1190\n",
      "2023-09-22 01:54:10.063911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275559a00 of size 1024 next 952\n",
      "2023-09-22 01:54:10.063921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275559e00 of size 1024 next 217\n",
      "2023-09-22 01:54:10.063932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555a200 of size 256 next 186\n",
      "2023-09-22 01:54:10.063941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555a300 of size 1024 next 1128\n",
      "2023-09-22 01:54:10.063950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555a700 of size 1024 next 1143\n",
      "2023-09-22 01:54:10.063960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555ab00 of size 1024 next 924\n",
      "2023-09-22 01:54:10.063969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555af00 of size 1024 next 986\n",
      "2023-09-22 01:54:10.063978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555b300 of size 1024 next 1565\n",
      "2023-09-22 01:54:10.063988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555b700 of size 1024 next 446\n",
      "2023-09-22 01:54:10.063997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555bb00 of size 256 next 1423\n",
      "2023-09-22 01:54:10.064005: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555bc00 of size 1024 next 78\n",
      "2023-09-22 01:54:10.064014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555c000 of size 1280 next 1213\n",
      "2023-09-22 01:54:10.064024: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555c500 of size 4096 next 1053\n",
      "2023-09-22 01:54:10.064033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555d500 of size 4096 next 395\n",
      "2023-09-22 01:54:10.064043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555e500 of size 5632 next 1387\n",
      "2023-09-22 01:54:10.064052: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127555fb00 of size 4096 next 1487\n",
      "2023-09-22 01:54:10.064061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275560b00 of size 4096 next 306\n",
      "2023-09-22 01:54:10.064070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275561b00 of size 4096 next 40\n",
      "2023-09-22 01:54:10.064080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275562b00 of size 4096 next 348\n",
      "2023-09-22 01:54:10.064089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275563b00 of size 4096 next 1512\n",
      "2023-09-22 01:54:10.064098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275564b00 of size 4096 next 1342\n",
      "2023-09-22 01:54:10.064108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275565b00 of size 6656 next 1651\n",
      "2023-09-22 01:54:10.064117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275567500 of size 5632 next 298\n",
      "2023-09-22 01:54:10.064126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275568b00 of size 4096 next 644\n",
      "2023-09-22 01:54:10.064135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275569b00 of size 4608 next 1241\n",
      "2023-09-22 01:54:10.064145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556ad00 of size 4096 next 973\n",
      "2023-09-22 01:54:10.064154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556bd00 of size 5632 next 1264\n",
      "2023-09-22 01:54:10.064163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556d300 of size 4096 next 580\n",
      "2023-09-22 01:54:10.064172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556e300 of size 4608 next 1479\n",
      "2023-09-22 01:54:10.064182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127556f500 of size 4096 next 526\n",
      "2023-09-22 01:54:10.064191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275570500 of size 4608 next 143\n",
      "2023-09-22 01:54:10.064200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275571700 of size 4096 next 1084\n",
      "2023-09-22 01:54:10.064210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275572700 of size 4608 next 762\n",
      "2023-09-22 01:54:10.064219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275573900 of size 4096 next 701\n",
      "2023-09-22 01:54:10.064228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275574900 of size 4096 next 1510\n",
      "2023-09-22 01:54:10.064237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275575900 of size 4096 next 97\n",
      "2023-09-22 01:54:10.064247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275576900 of size 256 next 1373\n",
      "2023-09-22 01:54:10.064257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275576a00 of size 256 next 1257\n",
      "2023-09-22 01:54:10.064266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275576b00 of size 256 next 1261\n",
      "2023-09-22 01:54:10.064275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275576c00 of size 256 next 1227\n",
      "2023-09-22 01:54:10.064284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275576d00 of size 256 next 757\n",
      "2023-09-22 01:54:10.064293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275576e00 of size 256 next 1458\n",
      "2023-09-22 01:54:10.064302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275576f00 of size 256 next 1425\n",
      "2023-09-22 01:54:10.064310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577000 of size 256 next 1090\n",
      "2023-09-22 01:54:10.064319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577100 of size 256 next 445\n",
      "2023-09-22 01:54:10.064329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577200 of size 256 next 1304\n",
      "2023-09-22 01:54:10.064338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577300 of size 256 next 398\n",
      "2023-09-22 01:54:10.064347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577400 of size 256 next 828\n",
      "2023-09-22 01:54:10.064357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577500 of size 256 next 405\n",
      "2023-09-22 01:54:10.064366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577600 of size 256 next 1093\n",
      "2023-09-22 01:54:10.064375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577700 of size 256 next 1255\n",
      "2023-09-22 01:54:10.064385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577800 of size 320512 next 1188\n",
      "2023-09-22 01:54:10.064394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c5c00 of size 320512 next 934\n",
      "2023-09-22 01:54:10.064404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275614000 of size 608256 next 474\n",
      "2023-09-22 01:54:10.064413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8800 of size 256 next 859\n",
      "2023-09-22 01:54:10.064422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8900 of size 256 next 24\n",
      "2023-09-22 01:54:10.064431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8a00 of size 4096 next 44\n",
      "2023-09-22 01:54:10.064441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9a00 of size 4096 next 418\n",
      "2023-09-22 01:54:10.064450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aaa00 of size 4096 next 870\n",
      "2023-09-22 01:54:10.064460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aba00 of size 5632 next 682\n",
      "2023-09-22 01:54:10.064469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad000 of size 256 next 836\n",
      "2023-09-22 01:54:10.064478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad100 of size 256 next 659\n",
      "2023-09-22 01:54:10.064487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad200 of size 256 next 276\n",
      "2023-09-22 01:54:10.064497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad300 of size 256 next 531\n",
      "2023-09-22 01:54:10.064506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad400 of size 256 next 897\n",
      "2023-09-22 01:54:10.064515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad500 of size 256 next 93\n",
      "2023-09-22 01:54:10.064526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad600 of size 256 next 928\n",
      "2023-09-22 01:54:10.064536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad700 of size 656408576 next 909\n",
      "2023-09-22 01:54:10.064545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f129c8ad700 of size 656408576 next 513\n",
      "2023-09-22 01:54:10.064554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c3aad700 of size 82051072 next 1607\n",
      "2023-09-22 01:54:10.064563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c88ed700 of size 82051072 next 1657\n",
      "2023-09-22 01:54:10.064573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cd72d700 of size 82051072 next 391\n",
      "2023-09-22 01:54:10.064582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12d256d700 of size 82051072 next 1158\n",
      "2023-09-22 01:54:10.064590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12d73ad700 of size 95849472 next 863\n",
      "2023-09-22 01:54:10.064598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16300 of size 256 next 867\n",
      "2023-09-22 01:54:10.064606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16400 of size 4096 next 140\n",
      "2023-09-22 01:54:10.064613: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17400 of size 4096 next 824\n",
      "2023-09-22 01:54:10.064623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18400 of size 256 next 1490\n",
      "2023-09-22 01:54:10.064632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18500 of size 256 next 1111\n",
      "2023-09-22 01:54:10.064641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18600 of size 114688 next 518\n",
      "2023-09-22 01:54:10.064651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf34600 of size 114688 next 336\n",
      "2023-09-22 01:54:10.064660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf50600 of size 205824 next 669\n",
      "2023-09-22 01:54:10.064670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82a00 of size 256 next 785\n",
      "2023-09-22 01:54:10.064679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82b00 of size 256 next 672\n",
      "2023-09-22 01:54:10.064688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82c00 of size 256 next 296\n",
      "2023-09-22 01:54:10.064698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82d00 of size 256 next 674\n",
      "2023-09-22 01:54:10.064707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82e00 of size 256 next 1208\n",
      "2023-09-22 01:54:10.064716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82f00 of size 256 next 1698\n",
      "2023-09-22 01:54:10.064725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83000 of size 256 next 331\n",
      "2023-09-22 01:54:10.064735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83100 of size 256 next 1678\n",
      "2023-09-22 01:54:10.064744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83200 of size 256 next 467\n",
      "2023-09-22 01:54:10.064754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83300 of size 256 next 792\n",
      "2023-09-22 01:54:10.064763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83400 of size 256 next 492\n",
      "2023-09-22 01:54:10.064772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83500 of size 256 next 1676\n",
      "2023-09-22 01:54:10.064781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83600 of size 256 next 1428\n",
      "2023-09-22 01:54:10.064791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83700 of size 256 next 394\n",
      "2023-09-22 01:54:10.064800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83800 of size 256 next 1519\n",
      "2023-09-22 01:54:10.064809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83900 of size 256 next 413\n",
      "2023-09-22 01:54:10.064819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83a00 of size 256 next 551\n",
      "2023-09-22 01:54:10.064828: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83b00 of size 256 next 910\n",
      "2023-09-22 01:54:10.064837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83c00 of size 20512768 next 1539\n",
      "2023-09-22 01:54:10.064847: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12de313c00 of size 10256384 next 369\n",
      "2023-09-22 01:54:10.064859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12decdbc00 of size 20512768 next 650\n",
      "2023-09-22 01:54:10.064868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e006bc00 of size 20512768 next 326\n",
      "2023-09-22 01:54:10.064878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e13fbc00 of size 10256384 next 949\n",
      "2023-09-22 01:54:10.064887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e1dc3c00 of size 20512768 next 1709\n",
      "2023-09-22 01:54:10.064896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e3153c00 of size 144402432 next 389\n",
      "2023-09-22 01:54:10.064904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0a400 of size 256 next 1301\n",
      "2023-09-22 01:54:10.064913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0a500 of size 256 next 730\n",
      "2023-09-22 01:54:10.064923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0a600 of size 7424 next 1229\n",
      "2023-09-22 01:54:10.064932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0c300 of size 256 next 100\n",
      "2023-09-22 01:54:10.064941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0c400 of size 256 next 598\n",
      "2023-09-22 01:54:10.064950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0c500 of size 256 next 652\n",
      "2023-09-22 01:54:10.064960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0c600 of size 256 next 1054\n",
      "2023-09-22 01:54:10.064969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0c700 of size 256 next 879\n",
      "2023-09-22 01:54:10.064979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0c800 of size 256 next 1074\n",
      "2023-09-22 01:54:10.064989: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0c900 of size 256 next 966\n",
      "2023-09-22 01:54:10.064998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0ca00 of size 256 next 166\n",
      "2023-09-22 01:54:10.065008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0cb00 of size 256 next 1690\n",
      "2023-09-22 01:54:10.065017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0cc00 of size 256 next 1156\n",
      "2023-09-22 01:54:10.065026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0cd00 of size 256 next 1668\n",
      "2023-09-22 01:54:10.065035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0ce00 of size 256 next 869\n",
      "2023-09-22 01:54:10.065045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0cf00 of size 256 next 8\n",
      "2023-09-22 01:54:10.065054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0d000 of size 256 next 1080\n",
      "2023-09-22 01:54:10.065063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0d100 of size 256 next 668\n",
      "2023-09-22 01:54:10.065073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0d200 of size 256 next 778\n",
      "2023-09-22 01:54:10.065082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0d300 of size 4096 next 1106\n",
      "2023-09-22 01:54:10.065092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb0e300 of size 7680 next 287\n",
      "2023-09-22 01:54:10.065101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebb10100 of size 2097152 next 1572\n",
      "2023-09-22 01:54:10.065110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebd10100 of size 2097152 next 84\n",
      "2023-09-22 01:54:10.065120: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ebf10100 of size 2097152 next 169\n",
      "2023-09-22 01:54:10.065129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ec110100 of size 2097152 next 1087\n",
      "2023-09-22 01:54:10.065139: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ec310100 of size 2097152 next 1445\n",
      "2023-09-22 01:54:10.065148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ec510100 of size 2097152 next 1430\n",
      "2023-09-22 01:54:10.065158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ec710100 of size 2097152 next 1068\n",
      "2023-09-22 01:54:10.065167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ec910100 of size 2097152 next 487\n",
      "2023-09-22 01:54:10.065176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ecb10100 of size 2097152 next 469\n",
      "2023-09-22 01:54:10.065185: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ecd10100 of size 2097152 next 1134\n",
      "2023-09-22 01:54:10.065195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ecf10100 of size 5128192 next 263\n",
      "2023-09-22 01:54:10.065205: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed3f4100 of size 5128192 next 270\n",
      "2023-09-22 01:54:10.065213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12ed8d8100 of size 8551680 next 1082\n",
      "2023-09-22 01:54:10.065222: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0ffe00 of size 256 next 407\n",
      "2023-09-22 01:54:10.065229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fff00 of size 256 next 826\n",
      "2023-09-22 01:54:10.065237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100000 of size 4096 next 611\n",
      "2023-09-22 01:54:10.065247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101000 of size 256 next 1279\n",
      "2023-09-22 01:54:10.065256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101100 of size 256 next 892\n",
      "2023-09-22 01:54:10.065266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101200 of size 320512 next 240\n",
      "2023-09-22 01:54:10.065275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee14f600 of size 617728 next 1288\n",
      "2023-09-22 01:54:10.065284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e6300 of size 256 next 1637\n",
      "2023-09-22 01:54:10.065294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e6400 of size 256 next 1322\n",
      "2023-09-22 01:54:10.065303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e6500 of size 256 next 554\n",
      "2023-09-22 01:54:10.065312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e6600 of size 256 next 742\n",
      "2023-09-22 01:54:10.065322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e6700 of size 256 next 975\n",
      "2023-09-22 01:54:10.065331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e6800 of size 256 next 1122\n",
      "2023-09-22 01:54:10.065341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1e6900 of size 3161088 next 649\n",
      "2023-09-22 01:54:10.065350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ea500 of size 256 next 384\n",
      "2023-09-22 01:54:10.065360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ea600 of size 256 next 425\n",
      "2023-09-22 01:54:10.065369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ea700 of size 256 next 852\n",
      "2023-09-22 01:54:10.065378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ea800 of size 256 next 1472\n",
      "2023-09-22 01:54:10.065388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ea900 of size 256 next 1421\n",
      "2023-09-22 01:54:10.065398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eaa00 of size 256 next 477\n",
      "2023-09-22 01:54:10.065408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eab00 of size 256 next 268\n",
      "2023-09-22 01:54:10.065417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eac00 of size 256 next 1258\n",
      "2023-09-22 01:54:10.065426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ead00 of size 256 next 1585\n",
      "2023-09-22 01:54:10.065436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eae00 of size 256 next 1500\n",
      "2023-09-22 01:54:10.065445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eaf00 of size 256 next 1247\n",
      "2023-09-22 01:54:10.065454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eb000 of size 256 next 914\n",
      "2023-09-22 01:54:10.065464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eb100 of size 256 next 370\n",
      "2023-09-22 01:54:10.065473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eb200 of size 256 next 1689\n",
      "2023-09-22 01:54:10.065483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eb300 of size 256 next 185\n",
      "2023-09-22 01:54:10.065492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4eb400 of size 4096 next 1218\n",
      "2023-09-22 01:54:10.065501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ec400 of size 4096 next 1026\n",
      "2023-09-22 01:54:10.065511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ed400 of size 4096 next 577\n",
      "2023-09-22 01:54:10.065520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ee400 of size 4096 next 198\n",
      "2023-09-22 01:54:10.065529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ef400 of size 4352 next 1386\n",
      "2023-09-22 01:54:10.065537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f0500 of size 256 next 1369\n",
      "2023-09-22 01:54:10.065546: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f0600 of size 4096 next 1509\n",
      "2023-09-22 01:54:10.065556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f1600 of size 6400 next 236\n",
      "2023-09-22 01:54:10.065565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f2f00 of size 256 next 1506\n",
      "2023-09-22 01:54:10.065575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3000 of size 256 next 1444\n",
      "2023-09-22 01:54:10.065584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3100 of size 256 next 858\n",
      "2023-09-22 01:54:10.065593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3200 of size 256 next 1153\n",
      "2023-09-22 01:54:10.065602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3300 of size 256 next 267\n",
      "2023-09-22 01:54:10.065612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3400 of size 256 next 622\n",
      "2023-09-22 01:54:10.065621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3500 of size 256 next 1644\n",
      "2023-09-22 01:54:10.065630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3600 of size 256 next 608\n",
      "2023-09-22 01:54:10.065639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3700 of size 256 next 1076\n",
      "2023-09-22 01:54:10.065648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3800 of size 256 next 26\n",
      "2023-09-22 01:54:10.065658: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3900 of size 256 next 797\n",
      "2023-09-22 01:54:10.065667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3a00 of size 256 next 885\n",
      "2023-09-22 01:54:10.065677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3b00 of size 256 next 755\n",
      "2023-09-22 01:54:10.065686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3c00 of size 256 next 266\n",
      "2023-09-22 01:54:10.065695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3d00 of size 256 next 997\n",
      "2023-09-22 01:54:10.065704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3e00 of size 256 next 55\n",
      "2023-09-22 01:54:10.065714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3f00 of size 256 next 1672\n",
      "2023-09-22 01:54:10.065723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4000 of size 256 next 603\n",
      "2023-09-22 01:54:10.065732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4100 of size 256 next 832\n",
      "2023-09-22 01:54:10.065741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4200 of size 256 next 475\n",
      "2023-09-22 01:54:10.065750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4300 of size 1024 next 1031\n",
      "2023-09-22 01:54:10.065759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4700 of size 256 next 715\n",
      "2023-09-22 01:54:10.065769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4800 of size 256 next 1525\n",
      "2023-09-22 01:54:10.065779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4900 of size 256 next 1117\n",
      "2023-09-22 01:54:10.065788: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4a00 of size 256 next 1152\n",
      "2023-09-22 01:54:10.065797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4b00 of size 256 next 692\n",
      "2023-09-22 01:54:10.065807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4c00 of size 14336 next 409\n",
      "2023-09-22 01:54:10.065817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f8400 of size 29440 next 497\n",
      "2023-09-22 01:54:10.065826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ff700 of size 256 next 963\n",
      "2023-09-22 01:54:10.065835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ff800 of size 256 next 436\n",
      "2023-09-22 01:54:10.065843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4ff900 of size 4096 next 218\n",
      "2023-09-22 01:54:10.065852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee500900 of size 7168 next 747\n",
      "2023-09-22 01:54:10.065863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee502500 of size 4096 next 1626\n",
      "2023-09-22 01:54:10.065873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee503500 of size 6912 next 239\n",
      "2023-09-22 01:54:10.065882: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505000 of size 256 next 1150\n",
      "2023-09-22 01:54:10.065891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505100 of size 3652864 next 1601\n",
      "2023-09-22 01:54:10.065900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880e00 of size 256 next 1389\n",
      "2023-09-22 01:54:10.065910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880f00 of size 101744896 next 1547\n",
      "2023-09-22 01:54:10.065919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4989000 of size 4096 next 404\n",
      "2023-09-22 01:54:10.065928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498a000 of size 4096 next 1349\n",
      "2023-09-22 01:54:10.065937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498b000 of size 4096 next 517\n",
      "2023-09-22 01:54:10.065947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498c000 of size 4096 next 433\n",
      "2023-09-22 01:54:10.065956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498d000 of size 4096 next 1664\n",
      "2023-09-22 01:54:10.065965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e000 of size 256 next 557\n",
      "2023-09-22 01:54:10.065974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e100 of size 256 next 1177\n",
      "2023-09-22 01:54:10.065983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e200 of size 256 next 119\n",
      "2023-09-22 01:54:10.065993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e300 of size 256 next 1355\n",
      "2023-09-22 01:54:10.066002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e400 of size 256 next 1442\n",
      "2023-09-22 01:54:10.066012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e500 of size 256 next 435\n",
      "2023-09-22 01:54:10.066021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e600 of size 256 next 344\n",
      "2023-09-22 01:54:10.066031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e700 of size 256 next 1648\n",
      "2023-09-22 01:54:10.066040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e800 of size 256 next 684\n",
      "2023-09-22 01:54:10.066050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e900 of size 256 next 1028\n",
      "2023-09-22 01:54:10.066059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498ea00 of size 256 next 1410\n",
      "2023-09-22 01:54:10.066068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498eb00 of size 256 next 838\n",
      "2023-09-22 01:54:10.066078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498ec00 of size 256 next 1200\n",
      "2023-09-22 01:54:10.066087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498ed00 of size 256 next 597\n",
      "2023-09-22 01:54:10.066096: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498ee00 of size 256 next 1131\n",
      "2023-09-22 01:54:10.066105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498ef00 of size 256 next 506\n",
      "2023-09-22 01:54:10.066115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f000 of size 256 next 1688\n",
      "2023-09-22 01:54:10.066124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f100 of size 256 next 129\n",
      "2023-09-22 01:54:10.066133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f200 of size 256 next 954\n",
      "2023-09-22 01:54:10.066143: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f300 of size 256 next 1415\n",
      "2023-09-22 01:54:10.066150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f400 of size 256 next 733\n",
      "2023-09-22 01:54:10.066159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f500 of size 256 next 429\n",
      "2023-09-22 01:54:10.066169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f600 of size 256 next 281\n",
      "2023-09-22 01:54:10.066178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f498f700 of size 256 next 766\n",
      "2023-09-22 01:54:10.066187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f800 of size 256 next 361\n",
      "2023-09-22 01:54:10.066197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f900 of size 256 next 663\n",
      "2023-09-22 01:54:10.066207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498fa00 of size 256 next 532\n",
      "2023-09-22 01:54:10.066214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f498fb00 of size 14848 next 234\n",
      "2023-09-22 01:54:10.066222: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4993500 of size 40192 next 530\n",
      "2023-09-22 01:54:10.066230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f499d200 of size 2097152 next 1192\n",
      "2023-09-22 01:54:10.066239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4b9d200 of size 2097152 next 461\n",
      "2023-09-22 01:54:10.066249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4d9d200 of size 2097152 next 264\n",
      "2023-09-22 01:54:10.066259: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4f9d200 of size 2166272 next 712\n",
      "2023-09-22 01:54:10.066268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ae000 of size 256 next 150\n",
      "2023-09-22 01:54:10.066277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ae100 of size 21504 next 753\n",
      "2023-09-22 01:54:10.066287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51b3500 of size 4096 next 201\n",
      "2023-09-22 01:54:10.066296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51b4500 of size 4608 next 1282\n",
      "2023-09-22 01:54:10.066306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51b5700 of size 4096 next 1557\n",
      "2023-09-22 01:54:10.066315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51b6700 of size 4608 next 1005\n",
      "2023-09-22 01:54:10.066324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51b7900 of size 4096 next 1046\n",
      "2023-09-22 01:54:10.066333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51b8900 of size 5632 next 1006\n",
      "2023-09-22 01:54:10.066342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51b9f00 of size 256 next 50\n",
      "2023-09-22 01:54:10.066351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba000 of size 256 next 23\n",
      "2023-09-22 01:54:10.066361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba100 of size 256 next 990\n",
      "2023-09-22 01:54:10.066370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba200 of size 256 next 568\n",
      "2023-09-22 01:54:10.066379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba300 of size 256 next 1679\n",
      "2023-09-22 01:54:10.066389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba400 of size 256 next 1584\n",
      "2023-09-22 01:54:10.066398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba500 of size 256 next 314\n",
      "2023-09-22 01:54:10.066408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba600 of size 256 next 770\n",
      "2023-09-22 01:54:10.066417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba700 of size 256 next 1632\n",
      "2023-09-22 01:54:10.066426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba800 of size 256 next 639\n",
      "2023-09-22 01:54:10.066437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ba900 of size 256 next 1695\n",
      "2023-09-22 01:54:10.066446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51baa00 of size 256 next 1137\n",
      "2023-09-22 01:54:10.066454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bab00 of size 256 next 845\n",
      "2023-09-22 01:54:10.066463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bac00 of size 256 next 591\n",
      "2023-09-22 01:54:10.066472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bad00 of size 256 next 156\n",
      "2023-09-22 01:54:10.066482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bae00 of size 256 next 541\n",
      "2023-09-22 01:54:10.066491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51baf00 of size 6144 next 1563\n",
      "2023-09-22 01:54:10.066500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bc700 of size 256 next 948\n",
      "2023-09-22 01:54:10.066510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bc800 of size 256 next 134\n",
      "2023-09-22 01:54:10.066519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bc900 of size 256 next 171\n",
      "2023-09-22 01:54:10.066528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bca00 of size 256 next 73\n",
      "2023-09-22 01:54:10.066537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bcb00 of size 256 next 1281\n",
      "2023-09-22 01:54:10.066547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bcc00 of size 256 next 1272\n",
      "2023-09-22 01:54:10.066556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bcd00 of size 256 next 566\n",
      "2023-09-22 01:54:10.066565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bce00 of size 256 next 784\n",
      "2023-09-22 01:54:10.066575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bcf00 of size 256 next 357\n",
      "2023-09-22 01:54:10.066584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bd000 of size 256 next 1477\n",
      "2023-09-22 01:54:10.066593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bd100 of size 256 next 851\n",
      "2023-09-22 01:54:10.066603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bd200 of size 256 next 500\n",
      "2023-09-22 01:54:10.066612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bd300 of size 4096 next 248\n",
      "2023-09-22 01:54:10.066621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51be300 of size 4096 next 1526\n",
      "2023-09-22 01:54:10.066631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51bf300 of size 4096 next 523\n",
      "2023-09-22 01:54:10.066640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c0300 of size 4096 next 1556\n",
      "2023-09-22 01:54:10.066650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1300 of size 256 next 83\n",
      "2023-09-22 01:54:10.066659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1400 of size 256 next 173\n",
      "2023-09-22 01:54:10.066668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1500 of size 256 next 1420\n",
      "2023-09-22 01:54:10.066677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1600 of size 256 next 1367\n",
      "2023-09-22 01:54:10.066686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1700 of size 256 next 1044\n",
      "2023-09-22 01:54:10.066696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1800 of size 256 next 1508\n",
      "2023-09-22 01:54:10.066705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1900 of size 256 next 570\n",
      "2023-09-22 01:54:10.066714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1a00 of size 256 next 1191\n",
      "2023-09-22 01:54:10.066724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1b00 of size 256 next 196\n",
      "2023-09-22 01:54:10.066733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1c00 of size 256 next 1368\n",
      "2023-09-22 01:54:10.066742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1d00 of size 256 next 1598\n",
      "2023-09-22 01:54:10.066752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1e00 of size 256 next 1465\n",
      "2023-09-22 01:54:10.066759: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c1f00 of size 256 next 1610\n",
      "2023-09-22 01:54:10.066768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c2000 of size 256 next 132\n",
      "2023-09-22 01:54:10.066777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c2100 of size 256 next 377\n",
      "2023-09-22 01:54:10.066787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c2200 of size 256 next 1212\n",
      "2023-09-22 01:54:10.066796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c2300 of size 256 next 816\n",
      "2023-09-22 01:54:10.066805: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c2400 of size 256 next 52\n",
      "2023-09-22 01:54:10.066815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c2500 of size 21504 next 1095\n",
      "2023-09-22 01:54:10.066824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c7900 of size 4096 next 18\n",
      "2023-09-22 01:54:10.066833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c8900 of size 4096 next 560\n",
      "2023-09-22 01:54:10.066842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51c9900 of size 4096 next 1280\n",
      "2023-09-22 01:54:10.066852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ca900 of size 4096 next 1434\n",
      "2023-09-22 01:54:10.066861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51cb900 of size 4096 next 916\n",
      "2023-09-22 01:54:10.066870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51cc900 of size 4096 next 1638\n",
      "2023-09-22 01:54:10.066880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51cd900 of size 4352 next 447\n",
      "2023-09-22 01:54:10.066889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51cea00 of size 4096 next 1675\n",
      "2023-09-22 01:54:10.066898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51cfa00 of size 7168 next 731\n",
      "2023-09-22 01:54:10.066907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51d1600 of size 256 next 822\n",
      "2023-09-22 01:54:10.066917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51d1700 of size 114688 next 1680\n",
      "2023-09-22 01:54:10.066926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ed700 of size 256 next 1482\n",
      "2023-09-22 01:54:10.066935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ed800 of size 256 next 443\n",
      "2023-09-22 01:54:10.066945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ed900 of size 32768 next 811\n",
      "2023-09-22 01:54:10.066954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51f5900 of size 32768 next 1292\n",
      "2023-09-22 01:54:10.066964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51fd900 of size 1024 next 1687\n",
      "2023-09-22 01:54:10.066973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51fdd00 of size 1024 next 164\n",
      "2023-09-22 01:54:10.066982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51fe100 of size 1024 next 936\n",
      "2023-09-22 01:54:10.066992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51fe500 of size 1024 next 871\n",
      "2023-09-22 01:54:10.067001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51fe900 of size 1024 next 130\n",
      "2023-09-22 01:54:10.067010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51fed00 of size 1024 next 981\n",
      "2023-09-22 01:54:10.067019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f51ff100 of size 8192 next 877\n",
      "2023-09-22 01:54:10.067028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5201100 of size 8192 next 1453\n",
      "2023-09-22 01:54:10.067038: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5203100 of size 8192 next 1454\n",
      "2023-09-22 01:54:10.067047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5205100 of size 8192 next 1327\n",
      "2023-09-22 01:54:10.067056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5207100 of size 8192 next 1199\n",
      "2023-09-22 01:54:10.067064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5209100 of size 8192 next 1418\n",
      "2023-09-22 01:54:10.067071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f520b100 of size 1024 next 1073\n",
      "2023-09-22 01:54:10.067079: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f520b500 of size 1024 next 849\n",
      "2023-09-22 01:54:10.067087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f520b900 of size 1024 next 1663\n",
      "2023-09-22 01:54:10.067098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f520bd00 of size 1024 next 180\n",
      "2023-09-22 01:54:10.067106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f520c100 of size 1024 next 122\n",
      "2023-09-22 01:54:10.067115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f520c500 of size 1024 next 1161\n",
      "2023-09-22 01:54:10.067125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f520c900 of size 32768 next 801\n",
      "2023-09-22 01:54:10.067135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5214900 of size 32768 next 1291\n",
      "2023-09-22 01:54:10.067160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f521c900 of size 256 next 237\n",
      "2023-09-22 01:54:10.067170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f521ca00 of size 256 next 1474\n",
      "2023-09-22 01:54:10.067180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f521cb00 of size 32768 next 1313\n",
      "2023-09-22 01:54:10.067190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5224b00 of size 32768 next 1588\n",
      "2023-09-22 01:54:10.067201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f522cb00 of size 1024 next 616\n",
      "2023-09-22 01:54:10.067210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f522cf00 of size 1024 next 782\n",
      "2023-09-22 01:54:10.067220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f522d300 of size 1024 next 1705\n",
      "2023-09-22 01:54:10.067230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f522d700 of size 1024 next 221\n",
      "2023-09-22 01:54:10.067239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f522db00 of size 1024 next 1495\n",
      "2023-09-22 01:54:10.067248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f522df00 of size 1024 next 548\n",
      "2023-09-22 01:54:10.067258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f522e300 of size 8192 next 606\n",
      "2023-09-22 01:54:10.067267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5230300 of size 8192 next 1114\n",
      "2023-09-22 01:54:10.067276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5232300 of size 8192 next 594\n",
      "2023-09-22 01:54:10.067286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5234300 of size 8192 next 555\n",
      "2023-09-22 01:54:10.067295: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5236300 of size 8192 next 1286\n",
      "2023-09-22 01:54:10.067304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5238300 of size 8192 next 904\n",
      "2023-09-22 01:54:10.067313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f523a300 of size 1024 next 996\n",
      "2023-09-22 01:54:10.067323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f523a700 of size 1024 next 1319\n",
      "2023-09-22 01:54:10.067332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f523ab00 of size 1024 next 723\n",
      "2023-09-22 01:54:10.067342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f523af00 of size 1024 next 559\n",
      "2023-09-22 01:54:10.067351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f523b300 of size 1024 next 1640\n",
      "2023-09-22 01:54:10.067361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f523b700 of size 1024 next 478\n",
      "2023-09-22 01:54:10.067370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f523bb00 of size 32768 next 776\n",
      "2023-09-22 01:54:10.067379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5243b00 of size 32768 next 667\n",
      "2023-09-22 01:54:10.067388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f524bb00 of size 256 next 1544\n",
      "2023-09-22 01:54:10.067396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f524bc00 of size 256 next 1343\n",
      "2023-09-22 01:54:10.067404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f524bd00 of size 32768 next 1210\n",
      "2023-09-22 01:54:10.067411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5253d00 of size 32768 next 203\n",
      "2023-09-22 01:54:10.067419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525bd00 of size 1024 next 1064\n",
      "2023-09-22 01:54:10.067428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525c100 of size 1024 next 444\n",
      "2023-09-22 01:54:10.067438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525c500 of size 1024 next 1578\n",
      "2023-09-22 01:54:10.067447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525c900 of size 1024 next 703\n",
      "2023-09-22 01:54:10.067456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525cd00 of size 1024 next 273\n",
      "2023-09-22 01:54:10.067466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525d100 of size 1024 next 1268\n",
      "2023-09-22 01:54:10.067475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525d500 of size 8192 next 818\n",
      "2023-09-22 01:54:10.067484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f525f500 of size 8192 next 543\n",
      "2023-09-22 01:54:10.067494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5261500 of size 8192 next 1040\n",
      "2023-09-22 01:54:10.067503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5263500 of size 8192 next 1037\n",
      "2023-09-22 01:54:10.067512: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5265500 of size 8192 next 751\n",
      "2023-09-22 01:54:10.067522: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5267500 of size 8192 next 1013\n",
      "2023-09-22 01:54:10.067531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5269500 of size 1024 next 579\n",
      "2023-09-22 01:54:10.067541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5269900 of size 1024 next 406\n",
      "2023-09-22 01:54:10.067550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5269d00 of size 1024 next 787\n",
      "2023-09-22 01:54:10.067559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f526a100 of size 1024 next 43\n",
      "2023-09-22 01:54:10.067569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f526a500 of size 1024 next 381\n",
      "2023-09-22 01:54:10.067578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f526a900 of size 1024 next 1350\n",
      "2023-09-22 01:54:10.067588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f526ad00 of size 47872 next 386\n",
      "2023-09-22 01:54:10.067597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5276800 of size 256 next 1608\n",
      "2023-09-22 01:54:10.067606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5276900 of size 21504 next 1283\n",
      "2023-09-22 01:54:10.067616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f527bd00 of size 40192 next 1417\n",
      "2023-09-22 01:54:10.067625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5285a00 of size 320512 next 1149\n",
      "2023-09-22 01:54:10.067634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f52d3e00 of size 320512 next 1256\n",
      "2023-09-22 01:54:10.067644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5322200 of size 320512 next 1681\n",
      "2023-09-22 01:54:10.067653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5370600 of size 347392 next 967\n",
      "2023-09-22 01:54:10.067662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f53c5300 of size 4096 next 1018\n",
      "2023-09-22 01:54:10.067672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f53c6300 of size 2146304 next 1359\n",
      "2023-09-22 01:54:10.067683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55d2300 of size 256 next 1522\n",
      "2023-09-22 01:54:10.067692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55d2400 of size 256 next 1649\n",
      "2023-09-22 01:54:10.067700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55d2500 of size 4096 next 341\n",
      "2023-09-22 01:54:10.067709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55d3500 of size 21504 next 1331\n",
      "2023-09-22 01:54:10.067718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55d8900 of size 35840 next 946\n",
      "2023-09-22 01:54:10.067728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55e1500 of size 256 next 1372\n",
      "2023-09-22 01:54:10.067737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55e1600 of size 256 next 921\n",
      "2023-09-22 01:54:10.067746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55e1700 of size 256 next 788\n",
      "2023-09-22 01:54:10.067755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55e1800 of size 4096 next 1685\n",
      "2023-09-22 01:54:10.067765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55e2800 of size 7424 next 1112\n",
      "2023-09-22 01:54:10.067774: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55e4500 of size 4096 next 434\n",
      "2023-09-22 01:54:10.067783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f55e5500 of size 1354496 next 220\n",
      "2023-09-22 01:54:10.067793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5730000 of size 256 next 1570\n",
      "2023-09-22 01:54:10.067802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5730100 of size 256 next 951\n",
      "2023-09-22 01:54:10.067811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5730200 of size 256 next 1616\n",
      "2023-09-22 01:54:10.067821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5730300 of size 7424 next 87\n",
      "2023-09-22 01:54:10.067830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5732000 of size 4096 next 157\n",
      "2023-09-22 01:54:10.067839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5733000 of size 4096 next 625\n",
      "2023-09-22 01:54:10.067849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734000 of size 256 next 1552\n",
      "2023-09-22 01:54:10.067858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734100 of size 256 next 362\n",
      "2023-09-22 01:54:10.067868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734200 of size 256 next 1065\n",
      "2023-09-22 01:54:10.067877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734300 of size 256 next 313\n",
      "2023-09-22 01:54:10.067886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734400 of size 256 next 1142\n",
      "2023-09-22 01:54:10.067895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734500 of size 256 next 1097\n",
      "2023-09-22 01:54:10.067905: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734600 of size 256 next 1541\n",
      "2023-09-22 01:54:10.067914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734700 of size 256 next 167\n",
      "2023-09-22 01:54:10.067923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734800 of size 256 next 1491\n",
      "2023-09-22 01:54:10.067933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734900 of size 256 next 251\n",
      "2023-09-22 01:54:10.067942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734a00 of size 256 next 1066\n",
      "2023-09-22 01:54:10.067951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734b00 of size 256 next 1138\n",
      "2023-09-22 01:54:10.067961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734c00 of size 256 next 1341\n",
      "2023-09-22 01:54:10.067970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734d00 of size 256 next 562\n",
      "2023-09-22 01:54:10.067979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734e00 of size 256 next 1108\n",
      "2023-09-22 01:54:10.067989: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5734f00 of size 256 next 903\n",
      "2023-09-22 01:54:10.067997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5735000 of size 4096 next 253\n",
      "2023-09-22 01:54:10.068002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5736000 of size 4096 next 382\n",
      "2023-09-22 01:54:10.068009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5737000 of size 20480000 next 790\n",
      "2023-09-22 01:54:10.068014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f6abf000 of size 20841984 next 932\n",
      "2023-09-22 01:54:10.068019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f600 of size 256 next 101\n",
      "2023-09-22 01:54:10.068023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f700 of size 256 next 761\n",
      "2023-09-22 01:54:10.068027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f800 of size 2097152 next 1422\n",
      "2023-09-22 01:54:10.068031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f809f800 of size 2097152 next 126\n",
      "2023-09-22 01:54:10.068036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f829f800 of size 2097152 next 1051\n",
      "2023-09-22 01:54:10.068040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f849f800 of size 2097152 next 1318\n",
      "2023-09-22 01:54:10.068044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f869f800 of size 2097152 next 1305\n",
      "2023-09-22 01:54:10.068048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f889f800 of size 2097152 next 498\n",
      "2023-09-22 01:54:10.068052: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f8a9f800 of size 2097152 next 1303\n",
      "2023-09-22 01:54:10.068057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f8c9f800 of size 2097152 next 1702\n",
      "2023-09-22 01:54:10.068061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f8e9f800 of size 2097152 next 1543\n",
      "2023-09-22 01:54:10.068065: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f909f800 of size 2097152 next 1548\n",
      "2023-09-22 01:54:10.068069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f929f800 of size 2097152 next 1376\n",
      "2023-09-22 01:54:10.068073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f949f800 of size 2097152 next 610\n",
      "2023-09-22 01:54:10.068077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f969f800 of size 2097152 next 1314\n",
      "2023-09-22 01:54:10.068081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f989f800 of size 2097152 next 582\n",
      "2023-09-22 01:54:10.068085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9a9f800 of size 2097152 next 791\n",
      "2023-09-22 01:54:10.068090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9c9f800 of size 2097152 next 1174\n",
      "2023-09-22 01:54:10.068094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f9e9f800 of size 2097152 next 1335\n",
      "2023-09-22 01:54:10.068099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa09f800 of size 3410944 next 657\n",
      "2023-09-22 01:54:10.068103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0400 of size 256 next 1326\n",
      "2023-09-22 01:54:10.068107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0500 of size 320512 next 713\n",
      "2023-09-22 01:54:10.068111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa42e900 of size 520192 next 1590\n",
      "2023-09-22 01:54:10.068115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ad900 of size 256 next 319\n",
      "2023-09-22 01:54:10.068119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ada00 of size 256 next 783\n",
      "2023-09-22 01:54:10.068124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4adb00 of size 114688 next 420\n",
      "2023-09-22 01:54:10.068128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4c9b00 of size 114688 next 1070\n",
      "2023-09-22 01:54:10.068132: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e5b00 of size 32768 next 1398\n",
      "2023-09-22 01:54:10.068136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4edb00 of size 256 next 1132\n",
      "2023-09-22 01:54:10.068140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4edc00 of size 256 next 466\n",
      "2023-09-22 01:54:10.068144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4edd00 of size 32768 next 82\n",
      "2023-09-22 01:54:10.068148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4f5d00 of size 32768 next 1057\n",
      "2023-09-22 01:54:10.068153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fdd00 of size 1024 next 320\n",
      "2023-09-22 01:54:10.068157: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fe100 of size 1024 next 634\n",
      "2023-09-22 01:54:10.068161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fe500 of size 1024 next 1085\n",
      "2023-09-22 01:54:10.068165: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fe900 of size 1024 next 1682\n",
      "2023-09-22 01:54:10.068169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fed00 of size 1024 next 638\n",
      "2023-09-22 01:54:10.068173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ff100 of size 1024 next 619\n",
      "2023-09-22 01:54:10.068177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ff500 of size 8192 next 422\n",
      "2023-09-22 01:54:10.068182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa501500 of size 8192 next 834\n",
      "2023-09-22 01:54:10.068186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa503500 of size 8192 next 1024\n",
      "2023-09-22 01:54:10.068190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa505500 of size 8192 next 815\n",
      "2023-09-22 01:54:10.068195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa507500 of size 8192 next 338\n",
      "2023-09-22 01:54:10.068199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa509500 of size 8192 next 1289\n",
      "2023-09-22 01:54:10.068203: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa50b500 of size 1024 next 960\n",
      "2023-09-22 01:54:10.068208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa50b900 of size 1024 next 1273\n",
      "2023-09-22 01:54:10.068212: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa50bd00 of size 1024 next 984\n",
      "2023-09-22 01:54:10.068216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa50c100 of size 1024 next 1694\n",
      "2023-09-22 01:54:10.068220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa50c500 of size 1024 next 1691\n",
      "2023-09-22 01:54:10.068224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa50c900 of size 1024 next 1656\n",
      "2023-09-22 01:54:10.068229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa50cd00 of size 32768 next 1276\n",
      "2023-09-22 01:54:10.068234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa514d00 of size 32768 next 1271\n",
      "2023-09-22 01:54:10.068239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa51cd00 of size 256 next 876\n",
      "2023-09-22 01:54:10.068244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa51ce00 of size 256 next 1189\n",
      "2023-09-22 01:54:10.068248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa51cf00 of size 32768 next 658\n",
      "2023-09-22 01:54:10.068252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa524f00 of size 32768 next 193\n",
      "2023-09-22 01:54:10.068256: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa52cf00 of size 1024 next 95\n",
      "2023-09-22 01:54:10.068261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa52d300 of size 1024 next 1231\n",
      "2023-09-22 01:54:10.068265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa52d700 of size 1024 next 152\n",
      "2023-09-22 01:54:10.068269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa52db00 of size 1024 next 1014\n",
      "2023-09-22 01:54:10.068273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa52df00 of size 1024 next 403\n",
      "2023-09-22 01:54:10.068277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa52e300 of size 1024 next 1230\n",
      "2023-09-22 01:54:10.068281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa52e700 of size 32768 next 941\n",
      "2023-09-22 01:54:10.068285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa536700 of size 32768 next 627\n",
      "2023-09-22 01:54:10.068289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53e700 of size 256 next 1017\n",
      "2023-09-22 01:54:10.068294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53e800 of size 256 next 1697\n",
      "2023-09-22 01:54:10.068298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53e900 of size 256 next 640\n",
      "2023-09-22 01:54:10.068302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53ea00 of size 256 next 1645\n",
      "2023-09-22 01:54:10.068306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53eb00 of size 256 next 468\n",
      "2023-09-22 01:54:10.068310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53ec00 of size 256 next 1602\n",
      "2023-09-22 01:54:10.068314: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53ed00 of size 256 next 805\n",
      "2023-09-22 01:54:10.068319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53ee00 of size 256 next 1079\n",
      "2023-09-22 01:54:10.068323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53ef00 of size 324864 next 1686\n",
      "2023-09-22 01:54:10.068327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e400 of size 256 next 1096\n",
      "2023-09-22 01:54:10.068331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e500 of size 256 next 252\n",
      "2023-09-22 01:54:10.068335: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e600 of size 256 next 1674\n",
      "2023-09-22 01:54:10.068340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e700 of size 256 next 825\n",
      "2023-09-22 01:54:10.068344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa58e800 of size 1419520 next 1507\n",
      "2023-09-22 01:54:10.068348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9100 of size 256 next 1364\n",
      "2023-09-22 01:54:10.068352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9200 of size 256 next 699\n",
      "2023-09-22 01:54:10.068357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9300 of size 256 next 1471\n",
      "2023-09-22 01:54:10.068361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9400 of size 256 next 1078\n",
      "2023-09-22 01:54:10.068365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9500 of size 256 next 1260\n",
      "2023-09-22 01:54:10.068369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9600 of size 256 next 726\n",
      "2023-09-22 01:54:10.068373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9700 of size 256 next 206\n",
      "2023-09-22 01:54:10.068378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9800 of size 114688 next 1237\n",
      "2023-09-22 01:54:10.068382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa705800 of size 122880 next 992\n",
      "2023-09-22 01:54:10.068386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723800 of size 256 next 1642\n",
      "2023-09-22 01:54:10.068391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723900 of size 256 next 194\n",
      "2023-09-22 01:54:10.068395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723a00 of size 256 next 347\n",
      "2023-09-22 01:54:10.068399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723b00 of size 256 next 558\n",
      "2023-09-22 01:54:10.068403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723c00 of size 256 next 439\n",
      "2023-09-22 01:54:10.068408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723d00 of size 256 next 288\n",
      "2023-09-22 01:54:10.068412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723e00 of size 256 next 332\n",
      "2023-09-22 01:54:10.068416: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa723f00 of size 256 next 913\n",
      "2023-09-22 01:54:10.068419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724000 of size 256 next 249\n",
      "2023-09-22 01:54:10.068424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724100 of size 256 next 80\n",
      "2023-09-22 01:54:10.068428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724200 of size 256 next 1353\n",
      "2023-09-22 01:54:10.068432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724300 of size 256 next 1023\n",
      "2023-09-22 01:54:10.068436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724400 of size 256 next 706\n",
      "2023-09-22 01:54:10.068441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724500 of size 256 next 583\n",
      "2023-09-22 01:54:10.068445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724600 of size 256 next 694\n",
      "2023-09-22 01:54:10.068449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724700 of size 256 next 711\n",
      "2023-09-22 01:54:10.068453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa724800 of size 4096 next 585\n",
      "2023-09-22 01:54:10.068457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa725800 of size 4096 next 390\n",
      "2023-09-22 01:54:10.068461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726800 of size 256 next 1594\n",
      "2023-09-22 01:54:10.068466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726900 of size 256 next 1427\n",
      "2023-09-22 01:54:10.068470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726a00 of size 256 next 472\n",
      "2023-09-22 01:54:10.068474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726b00 of size 256 next 1615\n",
      "2023-09-22 01:54:10.068478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726c00 of size 256 next 58\n",
      "2023-09-22 01:54:10.068482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726d00 of size 256 next 448\n",
      "2023-09-22 01:54:10.068487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726e00 of size 256 next 1623\n",
      "2023-09-22 01:54:10.068491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa726f00 of size 256 next 1684\n",
      "2023-09-22 01:54:10.068495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727000 of size 256 next 168\n",
      "2023-09-22 01:54:10.068499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727100 of size 256 next 1323\n",
      "2023-09-22 01:54:10.068504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727200 of size 256 next 691\n",
      "2023-09-22 01:54:10.068508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727300 of size 256 next 81\n",
      "2023-09-22 01:54:10.068512: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727400 of size 256 next 502\n",
      "2023-09-22 01:54:10.068516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727500 of size 256 next 1448\n",
      "2023-09-22 01:54:10.068520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727600 of size 256 next 481\n",
      "2023-09-22 01:54:10.068524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727700 of size 256 next 988\n",
      "2023-09-22 01:54:10.068528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727800 of size 256 next 737\n",
      "2023-09-22 01:54:10.068533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727900 of size 256 next 735\n",
      "2023-09-22 01:54:10.068538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727a00 of size 256 next 1560\n",
      "2023-09-22 01:54:10.068543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727b00 of size 256 next 293\n",
      "2023-09-22 01:54:10.068548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727c00 of size 256 next 976\n",
      "2023-09-22 01:54:10.068551: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727d00 of size 256 next 943\n",
      "2023-09-22 01:54:10.068555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727e00 of size 256 next 725\n",
      "2023-09-22 01:54:10.068559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa727f00 of size 256 next 721\n",
      "2023-09-22 01:54:10.068563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728000 of size 256 next 718\n",
      "2023-09-22 01:54:10.068567: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728100 of size 256 next 1595\n",
      "2023-09-22 01:54:10.068572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728200 of size 256 next 71\n",
      "2023-09-22 01:54:10.068575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728300 of size 256 next 1127\n",
      "2023-09-22 01:54:10.068578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728400 of size 256 next 561\n",
      "2023-09-22 01:54:10.068582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728500 of size 256 next 533\n",
      "2023-09-22 01:54:10.068585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728600 of size 256 next 464\n",
      "2023-09-22 01:54:10.068589: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728700 of size 256 next 1315\n",
      "2023-09-22 01:54:10.068594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa728800 of size 4096 next 955\n",
      "2023-09-22 01:54:10.068598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa729800 of size 4096 next 1284\n",
      "2023-09-22 01:54:10.068602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa72a800 of size 7680 next 994\n",
      "2023-09-22 01:54:10.068607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa72c600 of size 4096 next 441\n",
      "2023-09-22 01:54:10.068610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa72d600 of size 4096 next 172\n",
      "2023-09-22 01:54:10.068614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa72e600 of size 4096 next 1154\n",
      "2023-09-22 01:54:10.068619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa72f600 of size 4608 next 351\n",
      "2023-09-22 01:54:10.068623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa730800 of size 4608 next 1172\n",
      "2023-09-22 01:54:10.068627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa731a00 of size 4096 next 1329\n",
      "2023-09-22 01:54:10.068631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa732a00 of size 4608 next 1406\n",
      "2023-09-22 01:54:10.068635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa733c00 of size 4096 next 614\n",
      "2023-09-22 01:54:10.068639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa734c00 of size 5632 next 676\n",
      "2023-09-22 01:54:10.068644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa736200 of size 4096 next 135\n",
      "2023-09-22 01:54:10.068648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa737200 of size 4608 next 1604\n",
      "2023-09-22 01:54:10.068652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa738400 of size 4096 next 1466\n",
      "2023-09-22 01:54:10.068656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa739400 of size 5632 next 1446\n",
      "2023-09-22 01:54:10.068660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73aa00 of size 4096 next 685\n",
      "2023-09-22 01:54:10.068665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ba00 of size 5120 next 1696\n",
      "2023-09-22 01:54:10.068669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ce00 of size 256 next 106\n",
      "2023-09-22 01:54:10.068673: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12fa73cf00 of size 1648640 next 1016\n",
      "2023-09-22 01:54:10.068677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa8cf700 of size 256 next 354\n",
      "2023-09-22 01:54:10.068681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa8cf800 of size 114688 next 1497\n",
      "2023-09-22 01:54:10.068685: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa8eb800 of size 213248 next 830\n",
      "2023-09-22 01:54:10.068689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa91f900 of size 4096 next 696\n",
      "2023-09-22 01:54:10.068694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa920900 of size 4096 next 538\n",
      "2023-09-22 01:54:10.068698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa921900 of size 4096 next 1232\n",
      "2023-09-22 01:54:10.068702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa922900 of size 4096 next 1587\n",
      "2023-09-22 01:54:10.068707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa923900 of size 4096 next 1533\n",
      "2023-09-22 01:54:10.068710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa924900 of size 256 next 1157\n",
      "2023-09-22 01:54:10.068715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa924a00 of size 4096 next 210\n",
      "2023-09-22 01:54:10.068719: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa925a00 of size 4608 next 1324\n",
      "2023-09-22 01:54:10.068723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa926c00 of size 4096 next 1316\n",
      "2023-09-22 01:54:10.068727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa927c00 of size 5632 next 1582\n",
      "2023-09-22 01:54:10.068731: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa929200 of size 4096 next 1528\n",
      "2023-09-22 01:54:10.068736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92a200 of size 4608 next 878\n",
      "2023-09-22 01:54:10.068740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92b400 of size 4096 next 1169\n",
      "2023-09-22 01:54:10.068744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92c400 of size 1024 next 174\n",
      "2023-09-22 01:54:10.068748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92c800 of size 1024 next 1639\n",
      "2023-09-22 01:54:10.068752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92cc00 of size 1024 next 1354\n",
      "2023-09-22 01:54:10.068756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92d000 of size 256 next 471\n",
      "2023-09-22 01:54:10.068761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92d100 of size 1280 next 1001\n",
      "2023-09-22 01:54:10.068765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92d600 of size 4096 next 709\n",
      "2023-09-22 01:54:10.068769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92e600 of size 4608 next 490\n",
      "2023-09-22 01:54:10.068773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa92f800 of size 4096 next 1103\n",
      "2023-09-22 01:54:10.068778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa930800 of size 5632 next 1554\n",
      "2023-09-22 01:54:10.068782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa931e00 of size 4096 next 1116\n",
      "2023-09-22 01:54:10.068786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa932e00 of size 4096 next 1413\n",
      "2023-09-22 01:54:10.068790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa933e00 of size 4096 next 1193\n",
      "2023-09-22 01:54:10.068794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa934e00 of size 7424 next 1223\n",
      "2023-09-22 01:54:10.068799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa936b00 of size 4352 next 675\n",
      "2023-09-22 01:54:10.068803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa937c00 of size 256 next 229\n",
      "2023-09-22 01:54:10.068807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa937d00 of size 256 next 868\n",
      "2023-09-22 01:54:10.068812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa937e00 of size 7424 next 1267\n",
      "2023-09-22 01:54:10.068816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa939b00 of size 4096 next 743\n",
      "2023-09-22 01:54:10.068820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa93ab00 of size 4096 next 1411\n",
      "2023-09-22 01:54:10.068824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa93bb00 of size 114688 next 482\n",
      "2023-09-22 01:54:10.068828: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa957b00 of size 114688 next 1135\n",
      "2023-09-22 01:54:10.068832: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa973b00 of size 256 next 375\n",
      "2023-09-22 01:54:10.068837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa973c00 of size 256 next 1535\n",
      "2023-09-22 01:54:10.068841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa973d00 of size 256 next 1197\n",
      "2023-09-22 01:54:10.068845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa973e00 of size 256 next 1171\n",
      "2023-09-22 01:54:10.068849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa973f00 of size 256 next 292\n",
      "2023-09-22 01:54:10.068853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa974000 of size 256 next 437\n",
      "2023-09-22 01:54:10.068857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa974100 of size 6400 next 359\n",
      "2023-09-22 01:54:10.068861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa975a00 of size 256 next 238\n",
      "2023-09-22 01:54:10.068865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa975b00 of size 256 next 1332\n",
      "2023-09-22 01:54:10.068870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa975c00 of size 256 next 599\n",
      "2023-09-22 01:54:10.068874: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa975d00 of size 256 next 20\n",
      "2023-09-22 01:54:10.068878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa975e00 of size 256 next 662\n",
      "2023-09-22 01:54:10.068882: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa975f00 of size 256 next 693\n",
      "2023-09-22 01:54:10.068886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976000 of size 256 next 1088\n",
      "2023-09-22 01:54:10.068891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976100 of size 1536 next 176\n",
      "2023-09-22 01:54:10.068896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976700 of size 256 next 810\n",
      "2023-09-22 01:54:10.068901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976800 of size 256 next 1660\n",
      "2023-09-22 01:54:10.068905: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976900 of size 256 next 1055\n",
      "2023-09-22 01:54:10.068909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976a00 of size 256 next 215\n",
      "2023-09-22 01:54:10.068914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976b00 of size 256 next 1361\n",
      "2023-09-22 01:54:10.068918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976c00 of size 256 next 1020\n",
      "2023-09-22 01:54:10.068922: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976d00 of size 256 next 507\n",
      "2023-09-22 01:54:10.068926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976e00 of size 256 next 177\n",
      "2023-09-22 01:54:10.068930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa976f00 of size 256 next 295\n",
      "2023-09-22 01:54:10.068934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa977000 of size 256 next 578\n",
      "2023-09-22 01:54:10.068939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa977100 of size 256 next 1109\n",
      "2023-09-22 01:54:10.068943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa977200 of size 256 next 1643\n",
      "2023-09-22 01:54:10.068947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa977300 of size 256 next 350\n",
      "2023-09-22 01:54:10.068952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa977400 of size 256 next 484\n",
      "2023-09-22 01:54:10.068956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa977500 of size 8192 next 1275\n",
      "2023-09-22 01:54:10.068960: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa979500 of size 8192 next 1035\n",
      "2023-09-22 01:54:10.068964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97b500 of size 8192 next 304\n",
      "2023-09-22 01:54:10.068969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97d500 of size 1024 next 799\n",
      "2023-09-22 01:54:10.068973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97d900 of size 256 next 716\n",
      "2023-09-22 01:54:10.068977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97da00 of size 256 next 550\n",
      "2023-09-22 01:54:10.068982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97db00 of size 256 next 1352\n",
      "2023-09-22 01:54:10.068988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97dc00 of size 256 next 1562\n",
      "2023-09-22 01:54:10.068992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97dd00 of size 256 next 479\n",
      "2023-09-22 01:54:10.068996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97de00 of size 5888 next 808\n",
      "2023-09-22 01:54:10.069001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa97f500 of size 32768 next 250\n",
      "2023-09-22 01:54:10.069006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa987500 of size 32768 next 365\n",
      "2023-09-22 01:54:10.069011: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa98f500 of size 32768 next 310\n",
      "2023-09-22 01:54:10.069015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa997500 of size 34304 next 202\n",
      "2023-09-22 01:54:10.069019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99fb00 of size 256 next 56\n",
      "2023-09-22 01:54:10.069023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99fc00 of size 256 next 1310\n",
      "2023-09-22 01:54:10.069028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99fd00 of size 256 next 1254\n",
      "2023-09-22 01:54:10.069032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99fe00 of size 256 next 655\n",
      "2023-09-22 01:54:10.069036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa99ff00 of size 256 next 1624\n",
      "2023-09-22 01:54:10.069040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0000 of size 256 next 77\n",
      "2023-09-22 01:54:10.069045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0100 of size 256 next 1185\n",
      "2023-09-22 01:54:10.069049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0200 of size 256 next 431\n",
      "2023-09-22 01:54:10.069053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0300 of size 256 next 804\n",
      "2023-09-22 01:54:10.069057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0400 of size 256 next 1493\n",
      "2023-09-22 01:54:10.069061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0500 of size 256 next 333\n",
      "2023-09-22 01:54:10.069065: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0600 of size 256 next 1618\n",
      "2023-09-22 01:54:10.069069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0700 of size 256 next 1673\n",
      "2023-09-22 01:54:10.069074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0800 of size 256 next 494\n",
      "2023-09-22 01:54:10.069078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0900 of size 256 next 22\n",
      "2023-09-22 01:54:10.069082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0a00 of size 256 next 601\n",
      "2023-09-22 01:54:10.069086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0b00 of size 256 next 574\n",
      "2023-09-22 01:54:10.069091: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0c00 of size 256 next 1586\n",
      "2023-09-22 01:54:10.069095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0d00 of size 256 next 1345\n",
      "2023-09-22 01:54:10.069099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0e00 of size 256 next 708\n",
      "2023-09-22 01:54:10.069103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a0f00 of size 256 next 1336\n",
      "2023-09-22 01:54:10.069107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1000 of size 256 next 1204\n",
      "2023-09-22 01:54:10.069112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1100 of size 256 next 456\n",
      "2023-09-22 01:54:10.069116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1200 of size 256 next 1003\n",
      "2023-09-22 01:54:10.069120: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1300 of size 256 next 947\n",
      "2023-09-22 01:54:10.069124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1400 of size 256 next 528\n",
      "2023-09-22 01:54:10.069129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1500 of size 256 next 1399\n",
      "2023-09-22 01:54:10.069132: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1600 of size 256 next 1019\n",
      "2023-09-22 01:54:10.069136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1700 of size 256 next 1496\n",
      "2023-09-22 01:54:10.069140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1800 of size 256 next 970\n",
      "2023-09-22 01:54:10.069144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1900 of size 256 next 919\n",
      "2023-09-22 01:54:10.069149: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1a00 of size 256 next 1265\n",
      "2023-09-22 01:54:10.069153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1b00 of size 4096 next 230\n",
      "2023-09-22 01:54:10.069157: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a2b00 of size 4096 next 480\n",
      "2023-09-22 01:54:10.069161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a3b00 of size 256 next 1622\n",
      "2023-09-22 01:54:10.069165: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a3c00 of size 256 next 491\n",
      "2023-09-22 01:54:10.069170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a3d00 of size 256 next 636\n",
      "2023-09-22 01:54:10.069174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a3e00 of size 256 next 1118\n",
      "2023-09-22 01:54:10.069178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a3f00 of size 256 next 632\n",
      "2023-09-22 01:54:10.069183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4000 of size 256 next 1666\n",
      "2023-09-22 01:54:10.069187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4100 of size 256 next 1129\n",
      "2023-09-22 01:54:10.069191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4200 of size 256 next 1238\n",
      "2023-09-22 01:54:10.069195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4300 of size 256 next 977\n",
      "2023-09-22 01:54:10.069200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4400 of size 256 next 1337\n",
      "2023-09-22 01:54:10.069204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4500 of size 256 next 46\n",
      "2023-09-22 01:54:10.069208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4600 of size 256 next 1320\n",
      "2023-09-22 01:54:10.069213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4700 of size 256 next 483\n",
      "2023-09-22 01:54:10.069217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4800 of size 256 next 408\n",
      "2023-09-22 01:54:10.069221: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4900 of size 256 next 1532\n",
      "2023-09-22 01:54:10.069226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4a00 of size 256 next 899\n",
      "2023-09-22 01:54:10.069230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a4b00 of size 4096 next 1559\n",
      "2023-09-22 01:54:10.069234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a5b00 of size 4096 next 1347\n",
      "2023-09-22 01:54:10.069239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a6b00 of size 26880 next 767\n",
      "2023-09-22 01:54:10.069243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ad400 of size 256 next 1468\n",
      "2023-09-22 01:54:10.069247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ad500 of size 256 next 294\n",
      "2023-09-22 01:54:10.069251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ad600 of size 256 next 1299\n",
      "2023-09-22 01:54:10.069255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ad700 of size 4096 next 1567\n",
      "2023-09-22 01:54:10.069259: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9ae700 of size 4096 next 704\n",
      "2023-09-22 01:54:10.069264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9af700 of size 4352 next 242\n",
      "2023-09-22 01:54:10.069268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0800 of size 256 next 1130\n",
      "2023-09-22 01:54:10.069271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0900 of size 256 next 1395\n",
      "2023-09-22 01:54:10.069276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0a00 of size 256 next 656\n",
      "2023-09-22 01:54:10.069280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0b00 of size 256 next 1221\n",
      "2023-09-22 01:54:10.069284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0c00 of size 256 next 1366\n",
      "2023-09-22 01:54:10.069288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0d00 of size 256 next 1597\n",
      "2023-09-22 01:54:10.069292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0e00 of size 256 next 1401\n",
      "2023-09-22 01:54:10.069296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b0f00 of size 256 next 1658\n",
      "2023-09-22 01:54:10.069301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1000 of size 256 next 556\n",
      "2023-09-22 01:54:10.069305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1100 of size 256 next 681\n",
      "2023-09-22 01:54:10.069309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1200 of size 256 next 340\n",
      "2023-09-22 01:54:10.069313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1300 of size 256 next 19\n",
      "2023-09-22 01:54:10.069318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1400 of size 256 next 197\n",
      "2023-09-22 01:54:10.069322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1500 of size 256 next 1628\n",
      "2023-09-22 01:54:10.069326: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1600 of size 256 next 1101\n",
      "2023-09-22 01:54:10.069330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1700 of size 256 next 211\n",
      "2023-09-22 01:54:10.069335: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b1800 of size 5632 next 64\n",
      "2023-09-22 01:54:10.069339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b2e00 of size 4096 next 76\n",
      "2023-09-22 01:54:10.069343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b3e00 of size 7168 next 511\n",
      "2023-09-22 01:54:10.069347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b5a00 of size 256 next 1405\n",
      "2023-09-22 01:54:10.069351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b5b00 of size 256 next 962\n",
      "2023-09-22 01:54:10.069356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b5c00 of size 256 next 378\n",
      "2023-09-22 01:54:10.069360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9b5d00 of size 114688 next 1357\n",
      "2023-09-22 01:54:10.069364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9d1d00 of size 228352 next 829\n",
      "2023-09-22 01:54:10.069369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa09900 of size 4096 next 1521\n",
      "2023-09-22 01:54:10.069373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa0a900 of size 4096 next 457\n",
      "2023-09-22 01:54:10.069377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa0b900 of size 4096 next 891\n",
      "2023-09-22 01:54:10.069381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa0c900 of size 7936 next 1321\n",
      "2023-09-22 01:54:10.069385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa0e800 of size 186880 next 689\n",
      "2023-09-22 01:54:10.069390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c200 of size 256 next 383\n",
      "2023-09-22 01:54:10.069394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c300 of size 4096 next 1515\n",
      "2023-09-22 01:54:10.069398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3d300 of size 4096 next 321\n",
      "2023-09-22 01:54:10.069402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3e300 of size 4096 next 1007\n",
      "2023-09-22 01:54:10.069406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3f300 of size 4096 next 246\n",
      "2023-09-22 01:54:10.069410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40300 of size 4096 next 1416\n",
      "2023-09-22 01:54:10.069414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41300 of size 7680 next 1550\n",
      "2023-09-22 01:54:10.069418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43100 of size 256 next 1551\n",
      "2023-09-22 01:54:10.069422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43200 of size 82051072 next 524\n",
      "2023-09-22 01:54:10.069427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ff883200 of size 82051072 next 890\n",
      "2023-09-22 01:54:10.069431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13046c3200 of size 20512768 next 618\n",
      "2023-09-22 01:54:10.069435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1305a53200 of size 82051072 next 1248\n",
      "2023-09-22 01:54:10.069439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130a893200 of size 82051072 next 1147\n",
      "2023-09-22 01:54:10.069443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130f6d3200 of size 100288768 next 1593\n",
      "2023-09-22 01:54:10.069448: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677b00 of size 256 next 628\n",
      "2023-09-22 01:54:10.069452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677c00 of size 256 next 92\n",
      "2023-09-22 01:54:10.069456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677d00 of size 3604480 next 841\n",
      "2023-09-22 01:54:10.069460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13159e7d00 of size 256 next 366\n",
      "2023-09-22 01:54:10.069465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13159e7e00 of size 320512 next 833\n",
      "2023-09-22 01:54:10.069469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1315a36200 of size 1010688 next 162\n",
      "2023-09-22 01:54:10.069473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315b2ce00 of size 256 next 1285\n",
      "2023-09-22 01:54:10.069477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315b2cf00 of size 3012608 next 754\n",
      "2023-09-22 01:54:10.069482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c700 of size 256 next 848\n",
      "2023-09-22 01:54:10.069486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c800 of size 256 next 136\n",
      "2023-09-22 01:54:10.069490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c900 of size 81920000 next 1441\n",
      "2023-09-22 01:54:10.069496: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131ac2c900 of size 97466112 next 190\n",
      "2023-09-22 01:54:10.069500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920000 of size 256 next 1574\n",
      "2023-09-22 01:54:10.069505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920100 of size 71928064 next 112\n",
      "2023-09-22 01:54:10.069509: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8a00 of size 256 next 687\n",
      "2023-09-22 01:54:10.069513: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8b00 of size 256 next 1374\n",
      "2023-09-22 01:54:10.069517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8c00 of size 256 next 920\n",
      "2023-09-22 01:54:10.069521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8d00 of size 256 next 63\n",
      "2023-09-22 01:54:10.069526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8e00 of size 256 next 86\n",
      "2023-09-22 01:54:10.069530: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8f00 of size 256 next 493\n",
      "2023-09-22 01:54:10.069534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9000 of size 656408576 next 213\n",
      "2023-09-22 01:54:10.069538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f134bfb9000 of size 656408576 next 1205\n",
      "2023-09-22 01:54:10.069542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13731b9000 of size 656408576 next 1605\n",
      "2023-09-22 01:54:10.069547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f139a3b9000 of size 656408576 next 455\n",
      "2023-09-22 01:54:10.069550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13c15b9000 of size 146153472 next 188\n",
      "2023-09-22 01:54:10.069554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13ca11b000 of size 802562048 next 690\n",
      "2023-09-22 01:54:10.069559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13f9e7d000 of size 656408576 next 51\n",
      "2023-09-22 01:54:10.069563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f142107d000 of size 656408576 next 189\n",
      "2023-09-22 01:54:10.069567: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f144827d000 of size 656408576 next 308\n",
      "2023-09-22 01:54:10.069571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f146f47d000 of size 656408576 next 746\n",
      "2023-09-22 01:54:10.069576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f149667d000 of size 146153472 next 1704\n",
      "2023-09-22 01:54:10.069580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f149f1df000 of size 802562048 next 1379\n",
      "2023-09-22 01:54:10.069584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14cef41000 of size 656408576 next 1575\n",
      "2023-09-22 01:54:10.069588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14f6141000 of size 656408576 next 1625\n",
      "2023-09-22 01:54:10.069592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f151d341000 of size 656408576 next 958\n",
      "2023-09-22 01:54:10.069597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1544541000 of size 656408576 next 545\n",
      "2023-09-22 01:54:10.069601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f156b741000 of size 20512768 next 1344\n",
      "2023-09-22 01:54:10.069605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f156cad1000 of size 10256384 next 499\n",
      "2023-09-22 01:54:10.069610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f156d499000 of size 115384320 next 1384\n",
      "2023-09-22 01:54:10.069614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15742a3000 of size 802562048 next 486\n",
      "2023-09-22 01:54:10.069618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15a4005000 of size 656408576 next 131\n",
      "2023-09-22 01:54:10.069622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15cb205000 of size 656408576 next 1438\n",
      "2023-09-22 01:54:10.069626: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15f2405000 of size 656408576 next 717\n",
      "2023-09-22 01:54:10.069631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1619605000 of size 656408576 next 1113\n",
      "2023-09-22 01:54:10.069635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1640805000 of size 20512768 next 1646\n",
      "2023-09-22 01:54:10.069639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1641b95000 of size 10256384 next 1617\n",
      "2023-09-22 01:54:10.069643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f164255d000 of size 115384320 next 1308\n",
      "2023-09-22 01:54:10.069647: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1649367000 of size 802562048 next 1081\n",
      "2023-09-22 01:54:10.069652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16790c9000 of size 656408576 next 1072\n",
      "2023-09-22 01:54:10.069656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16a02c9000 of size 656408576 next 1478\n",
      "2023-09-22 01:54:10.069660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16c74c9000 of size 656408576 next 1683\n",
      "2023-09-22 01:54:10.069664: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16ee6c9000 of size 802562048 next 827\n",
      "2023-09-22 01:54:10.069669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f171e42b000 of size 470372352 next 18446744073709551615\n",
      "2023-09-22 01:54:10.069673: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-09-22 01:54:10.069679: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 751 Chunks of size 256 totalling 187.8KiB\n",
      "2023-09-22 01:54:10.069684: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 91 Chunks of size 1024 totalling 91.0KiB\n",
      "2023-09-22 01:54:10.069689: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 1280 totalling 3.8KiB\n",
      "2023-09-22 01:54:10.069693: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1536 totalling 1.5KiB\n",
      "2023-09-22 01:54:10.069698: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2023-09-22 01:54:10.069703: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 153 Chunks of size 4096 totalling 612.0KiB\n",
      "2023-09-22 01:54:10.069708: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 4352 totalling 25.5KiB\n",
      "2023-09-22 01:54:10.069712: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 27 Chunks of size 4608 totalling 121.5KiB\n",
      "2023-09-22 01:54:10.069717: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 4864 totalling 14.2KiB\n",
      "2023-09-22 01:54:10.069722: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 5120 totalling 20.0KiB\n",
      "2023-09-22 01:54:10.069726: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 18 Chunks of size 5632 totalling 99.0KiB\n",
      "2023-09-22 01:54:10.069731: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 5888 totalling 23.0KiB\n",
      "2023-09-22 01:54:10.069736: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 6144 totalling 18.0KiB\n",
      "2023-09-22 01:54:10.069740: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 6400 totalling 18.8KiB\n",
      "2023-09-22 01:54:10.069744: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 6656 totalling 13.0KiB\n",
      "2023-09-22 01:54:10.069748: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 6912 totalling 13.5KiB\n",
      "2023-09-22 01:54:10.069752: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 7168 totalling 21.0KiB\n",
      "2023-09-22 01:54:10.069756: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 7424 totalling 36.2KiB\n",
      "2023-09-22 01:54:10.069760: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 7680 totalling 30.0KiB\n",
      "2023-09-22 01:54:10.069765: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 7936 totalling 15.5KiB\n",
      "2023-09-22 01:54:10.069769: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 43 Chunks of size 8192 totalling 344.0KiB\n",
      "2023-09-22 01:54:10.069774: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2023-09-22 01:54:10.069778: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 16128 totalling 15.8KiB\n",
      "2023-09-22 01:54:10.069782: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 16384 totalling 32.0KiB\n",
      "2023-09-22 01:54:10.069787: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 21504 totalling 84.0KiB\n",
      "2023-09-22 01:54:10.069791: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 25856 totalling 25.2KiB\n",
      "2023-09-22 01:54:10.069796: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 26880 totalling 26.2KiB\n",
      "2023-09-22 01:54:10.069801: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 29440 totalling 28.8KiB\n",
      "2023-09-22 01:54:10.069805: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 30 Chunks of size 32768 totalling 960.0KiB\n",
      "2023-09-22 01:54:10.069810: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 34304 totalling 33.5KiB\n",
      "2023-09-22 01:54:10.069815: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 35840 totalling 35.0KiB\n",
      "2023-09-22 01:54:10.069819: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 40192 totalling 78.5KiB\n",
      "2023-09-22 01:54:10.069824: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 40448 totalling 39.5KiB\n",
      "2023-09-22 01:54:10.069829: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 47872 totalling 46.8KiB\n",
      "2023-09-22 01:54:10.069833: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 49664 totalling 48.5KiB\n",
      "2023-09-22 01:54:10.069838: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 17 Chunks of size 114688 totalling 1.86MiB\n",
      "2023-09-22 01:54:10.069842: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 122880 totalling 120.0KiB\n",
      "2023-09-22 01:54:10.069847: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 128256 totalling 125.2KiB\n",
      "2023-09-22 01:54:10.069852: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2023-09-22 01:54:10.069856: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 155648 totalling 152.0KiB\n",
      "2023-09-22 01:54:10.069861: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 160512 totalling 156.8KiB\n",
      "2023-09-22 01:54:10.069866: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 171520 totalling 167.5KiB\n",
      "2023-09-22 01:54:10.069871: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 186880 totalling 182.5KiB\n",
      "2023-09-22 01:54:10.069875: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 205824 totalling 201.0KiB\n",
      "2023-09-22 01:54:10.069880: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 213248 totalling 208.2KiB\n",
      "2023-09-22 01:54:10.069885: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 228352 totalling 223.0KiB\n",
      "2023-09-22 01:54:10.069889: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 10 Chunks of size 320512 totalling 3.06MiB\n",
      "2023-09-22 01:54:10.069894: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 324864 totalling 317.2KiB\n",
      "2023-09-22 01:54:10.069898: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 347392 totalling 339.2KiB\n",
      "2023-09-22 01:54:10.069903: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 484608 totalling 473.2KiB\n",
      "2023-09-22 01:54:10.069907: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 520192 totalling 508.0KiB\n",
      "2023-09-22 01:54:10.069912: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 608256 totalling 594.0KiB\n",
      "2023-09-22 01:54:10.069917: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 617728 totalling 603.2KiB\n",
      "2023-09-22 01:54:10.069921: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 47 Chunks of size 2097152 totalling 94.00MiB\n",
      "2023-09-22 01:54:10.069926: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2130432 totalling 2.03MiB\n",
      "2023-09-22 01:54:10.069930: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2146304 totalling 2.05MiB\n",
      "2023-09-22 01:54:10.069935: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2150912 totalling 2.05MiB\n",
      "2023-09-22 01:54:10.069939: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2166272 totalling 2.07MiB\n",
      "2023-09-22 01:54:10.069944: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2168320 totalling 2.07MiB\n",
      "2023-09-22 01:54:10.069948: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2211840 totalling 2.11MiB\n",
      "2023-09-22 01:54:10.069953: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2346752 totalling 2.24MiB\n",
      "2023-09-22 01:54:10.069957: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3012608 totalling 2.87MiB\n",
      "2023-09-22 01:54:10.069962: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3161088 totalling 3.01MiB\n",
      "2023-09-22 01:54:10.069966: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3410944 totalling 3.25MiB\n",
      "2023-09-22 01:54:10.069971: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3604480 totalling 3.44MiB\n",
      "2023-09-22 01:54:10.069975: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3652864 totalling 3.48MiB\n",
      "2023-09-22 01:54:10.069980: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4176128 totalling 3.98MiB\n",
      "2023-09-22 01:54:10.069984: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 5128192 totalling 9.78MiB\n",
      "2023-09-22 01:54:10.069989: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 10256384 totalling 39.12MiB\n",
      "2023-09-22 01:54:10.069994: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 20480000 totalling 58.59MiB\n",
      "2023-09-22 01:54:10.069999: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 20512768 totalling 156.50MiB\n",
      "2023-09-22 01:54:10.070003: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 20841984 totalling 19.88MiB\n",
      "2023-09-22 01:54:10.070008: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 24601344 totalling 23.46MiB\n",
      "2023-09-22 01:54:10.070013: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 71928064 totalling 68.60MiB\n",
      "2023-09-22 01:54:10.070017: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 81920000 totalling 78.12MiB\n",
      "2023-09-22 01:54:10.070022: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 16 Chunks of size 82051072 totalling 1.22GiB\n",
      "2023-09-22 01:54:10.070027: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 90197504 totalling 86.02MiB\n",
      "2023-09-22 01:54:10.070031: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 95849472 totalling 91.41MiB\n",
      "2023-09-22 01:54:10.070036: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 97466112 totalling 92.95MiB\n",
      "2023-09-22 01:54:10.070041: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 100288768 totalling 95.64MiB\n",
      "2023-09-22 01:54:10.070045: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 101744896 totalling 97.03MiB\n",
      "2023-09-22 01:54:10.070049: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 115384320 totalling 220.08MiB\n",
      "2023-09-22 01:54:10.070053: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 144402432 totalling 137.71MiB\n",
      "2023-09-22 01:54:10.070058: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 146153472 totalling 278.77MiB\n",
      "2023-09-22 01:54:10.070062: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 149536512 totalling 142.61MiB\n",
      "2023-09-22 01:54:10.070067: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 21 Chunks of size 656408576 totalling 12.84GiB\n",
      "2023-09-22 01:54:10.070072: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 802562048 totalling 3.74GiB\n",
      "2023-09-22 01:54:10.070076: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1263600128 totalling 1.18GiB\n",
      "2023-09-22 01:54:10.070081: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 20.77GiB\n",
      "2023-09-22 01:54:10.070085: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 23023321088 memory_limit_: 23023321088 available bytes: 0 curr_region_allocation_bytes_: 46046642176\n",
      "2023-09-22 01:54:10.070093: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     23023321088\n",
      "InUse:                     22300408576\n",
      "MaxInUse:                  22300408832\n",
      "NumAllocs:                    32811084\n",
      "MaxAllocSize:               6400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-22 01:54:10.070125: W tensorflow/tsl/framework/bfc_allocator.cc:492] **************************************************************************************************__\n",
      "2023-09-22 01:54:10.070151: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at einsum_op_impl.h:598 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[256,8,313,313] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'model/multi_head_attention_4/einsum/Einsum' defined at (most recent call last):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_3386617/1959657965.py\", line 121, in <module>\n",
      "      hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3},\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 524, in _compute_attention\n",
      "      attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
      "Node: 'model/multi_head_attention_4/einsum/Einsum'\n",
      "OOM when allocating tensor with shape[256,8,313,313] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/multi_head_attention_4/einsum/Einsum}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_1768781]\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0211\n",
      "Epoch 1: val_loss improved from inf to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 19s 128ms/step - loss: 0.1070 - mean_squared_error: 0.0211 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss improved from 0.11003 to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.11003 to 0.11001, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1165 - mean_squared_error: 0.0285\n",
      "Epoch 4: val_loss improved from 0.11001 to 0.10173, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1166 - mean_squared_error: 0.0285 - val_loss: 0.1017 - val_mean_squared_error: 0.0198\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 5: val_loss improved from 0.10173 to 0.09289, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.0929 - val_mean_squared_error: 0.0177\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0986 - mean_squared_error: 0.0183\n",
      "Epoch 6: val_loss did not improve from 0.09289\n",
      "42/42 [==============================] - 4s 92ms/step - loss: 0.0984 - mean_squared_error: 0.0183 - val_loss: 0.7693 - val_mean_squared_error: 0.6013\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0820 - mean_squared_error: 0.0131\n",
      "Epoch 7: val_loss did not improve from 0.09289\n",
      "42/42 [==============================] - 4s 96ms/step - loss: 0.0820 - mean_squared_error: 0.0131 - val_loss: 0.7816 - val_mean_squared_error: 0.6205\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0783 - mean_squared_error: 0.0118\n",
      "Epoch 8: val_loss did not improve from 0.09289\n",
      "42/42 [==============================] - 4s 92ms/step - loss: 0.0782 - mean_squared_error: 0.0118 - val_loss: 0.7221 - val_mean_squared_error: 0.5310\n",
      "55/55 [==============================] - 2s 14ms/step\n",
      " ###0 fold : val mae 0.10###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0212\n",
      "Epoch 1: val_loss improved from inf to 0.10695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 22s 120ms/step - loss: 0.1079 - mean_squared_error: 0.0212 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10695 to 0.10693, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0222\n",
      "Epoch 3: val_loss improved from 0.10693 to 0.10635, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1101 - mean_squared_error: 0.0222 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10635\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss did not improve from 0.10635\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss did not improve from 0.10635\n",
      "42/42 [==============================] - 4s 103ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0214\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 19s 121ms/step - loss: 0.1083 - mean_squared_error: 0.0214 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.10585 to 0.10584, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss improved from 0.10584 to 0.10571, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10571 to 0.10567, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 99ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 5: val_loss improved from 0.10567 to 0.10567, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 6: val_loss improved from 0.10567 to 0.10562, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 99ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1056 - val_mean_squared_error: 0.0204\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 7: val_loss improved from 0.10562 to 0.10551, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1055 - val_mean_squared_error: 0.0203\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 8: val_loss improved from 0.10551 to 0.10523, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1052 - val_mean_squared_error: 0.0203\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 9: val_loss improved from 0.10523 to 0.10379, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1038 - val_mean_squared_error: 0.0200\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0189\n",
      "Epoch 10: val_loss did not improve from 0.10379\n",
      "42/42 [==============================] - 4s 92ms/step - loss: 0.1007 - mean_squared_error: 0.0189 - val_loss: 0.4009 - val_mean_squared_error: 0.1699\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.0133\n",
      "Epoch 11: val_loss did not improve from 0.10379\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 0.0829 - mean_squared_error: 0.0132 - val_loss: 0.3130 - val_mean_squared_error: 0.1072\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0792 - mean_squared_error: 0.0117\n",
      "Epoch 12: val_loss did not improve from 0.10379\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 0.0790 - mean_squared_error: 0.0117 - val_loss: 0.1935 - val_mean_squared_error: 0.0461\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 1: val_loss improved from inf to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 20s 146ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10638 to 0.10637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 5s 111ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10637 to 0.10610, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt64_size9_pool4_do0.1_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1061 - val_mean_squared_error: 0.0207\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1143 - mean_squared_error: 0.0253\n",
      "Epoch 5: val_loss did not improve from 0.10610\n",
      "42/42 [==============================] - 4s 95ms/step - loss: 0.1143 - mean_squared_error: 0.0253 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss did not improve from 0.10610\n",
      "42/42 [==============================] - 4s 93ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.10610\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.16+-0.14\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt64_size11_pool2_do0.1_tra3_head4_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 01:58:01.570527: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.98GiB (rounded to 3200000000)requested by op model/multi_head_attention_2/einsum/Einsum\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-22 01:58:01.570940: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-22 01:58:01.570969: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 394, Chunks in use: 393. 98.5KiB allocated for chunks. 98.2KiB in use in bin. 47.2KiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.570988: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 337, Chunks in use: 337. 172.0KiB allocated for chunks. 172.0KiB in use in bin. 168.5KiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571004: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571021: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 27, Chunks in use: 27. 56.0KiB allocated for chunks. 56.0KiB in use in bin. 54.0KiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571035: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 136, Chunks in use: 136. 577.2KiB allocated for chunks. 577.2KiB in use in bin. 546.9KiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571049: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571064: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 30, Chunks in use: 30. 601.5KiB allocated for chunks. 601.5KiB in use in bin. 566.1KiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571079: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 116, Chunks in use: 116. 4.11MiB allocated for chunks. 4.11MiB in use in bin. 3.62MiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571090: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571104: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 16, Chunks in use: 15. 2.75MiB allocated for chunks. 2.58MiB in use in bin. 2.14MiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571117: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 42, Chunks in use: 42. 11.21MiB allocated for chunks. 11.21MiB in use in bin. 9.91MiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.571132: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 188, Chunks in use: 188. 103.49MiB allocated for chunks. 103.49MiB in use in bin. 94.88MiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573083: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.62MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573120: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573135: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573150: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 7, Chunks in use: 0. 83.53MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573165: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 5, Chunks in use: 5. 110.57MiB allocated for chunks. 110.57MiB in use in bin. 97.66MiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573179: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 5, Chunks in use: 4. 228.83MiB allocated for chunks. 179.77MiB in use in bin. 126.95MiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573197: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 18, Chunks in use: 18. 1.50GiB allocated for chunks. 1.50GiB in use in bin. 1.37GiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573214: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 3. 789.56MiB allocated for chunks. 635.80MiB in use in bin. 468.75MiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573228: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 22, Chunks in use: 20. 18.64GiB allocated for chunks. 16.29GiB in use in bin. 16.05GiB client-requested in use in bin.\n",
      "2023-09-22 01:58:01.573242: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 2.98GiB was 256.00MiB, Chunk State: \n",
      "2023-09-22 01:58:01.573266: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 290.18MiB | Requested Size: 256B | in_use: 0 | bin_num: 20, prev:   Size: 78.12MiB | Requested Size: 78.12MiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:58:01.573290: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 2.06GiB | Requested Size: 4.0KiB | in_use: 0 | bin_num: 20, prev:   Size: 312.50MiB | Requested Size: 312.50MiB | in_use: 1 | bin_num: -1, next:   Size: 2.98GiB | Requested Size: 2.98GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 01:58:01.573301: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 23023321088\n",
      "2023-09-22 01:58:01.573317: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000000 of size 1280 next 1\n",
      "2023-09-22 01:58:01.573331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000500 of size 256 next 2\n",
      "2023-09-22 01:58:01.573342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000600 of size 256 next 3\n",
      "2023-09-22 01:58:01.573352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000700 of size 256 next 5\n",
      "2023-09-22 01:58:01.573362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000800 of size 256 next 6\n",
      "2023-09-22 01:58:01.573373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000900 of size 256 next 4\n",
      "2023-09-22 01:58:01.573385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000a00 of size 256 next 1237\n",
      "2023-09-22 01:58:01.573396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000b00 of size 256 next 1023\n",
      "2023-09-22 01:58:01.573407: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000c00 of size 512 next 12\n",
      "2023-09-22 01:58:01.573418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000e00 of size 256 next 13\n",
      "2023-09-22 01:58:01.573429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000f00 of size 256 next 14\n",
      "2023-09-22 01:58:01.573440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001000 of size 4096 next 170\n",
      "2023-09-22 01:58:01.573467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002000 of size 4096 next 1527\n",
      "2023-09-22 01:58:01.573477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003000 of size 512 next 1167\n",
      "2023-09-22 01:58:01.573488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003200 of size 512 next 1653\n",
      "2023-09-22 01:58:01.573499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003400 of size 512 next 275\n",
      "2023-09-22 01:58:01.573510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003600 of size 512 next 1124\n",
      "2023-09-22 01:58:01.573539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003800 of size 512 next 1716\n",
      "2023-09-22 01:58:01.573550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003a00 of size 512 next 10\n",
      "2023-09-22 01:58:01.573568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003c00 of size 256 next 267\n",
      "2023-09-22 01:58:01.573586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003d00 of size 256 next 621\n",
      "2023-09-22 01:58:01.573616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003e00 of size 768 next 28\n",
      "2023-09-22 01:58:01.573626: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004100 of size 256 next 29\n",
      "2023-09-22 01:58:01.573637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004200 of size 256 next 30\n",
      "2023-09-22 01:58:01.573647: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004300 of size 256 next 61\n",
      "2023-09-22 01:58:01.573658: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004400 of size 256 next 309\n",
      "2023-09-22 01:58:01.573668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004500 of size 256 next 563\n",
      "2023-09-22 01:58:01.573679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004600 of size 256 next 42\n",
      "2023-09-22 01:58:01.573690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004700 of size 256 next 37\n",
      "2023-09-22 01:58:01.573700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004800 of size 256 next 36\n",
      "2023-09-22 01:58:01.573711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004900 of size 256 next 442\n",
      "2023-09-22 01:58:01.573721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004a00 of size 256 next 893\n",
      "2023-09-22 01:58:01.573729: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004b00 of size 512 next 405\n",
      "2023-09-22 01:58:01.573737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004d00 of size 768 next 1479\n",
      "2023-09-22 01:58:01.573746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005000 of size 256 next 52\n",
      "2023-09-22 01:58:01.573753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005100 of size 256 next 1512\n",
      "2023-09-22 01:58:01.573762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005200 of size 256 next 1299\n",
      "2023-09-22 01:58:01.573770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005300 of size 256 next 1744\n",
      "2023-09-22 01:58:01.573778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005400 of size 256 next 496\n",
      "2023-09-22 01:58:01.573785: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005500 of size 256 next 1739\n",
      "2023-09-22 01:58:01.573795: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005600 of size 512 next 1427\n",
      "2023-09-22 01:58:01.573802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005800 of size 256 next 1680\n",
      "2023-09-22 01:58:01.573810: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005900 of size 256 next 472\n",
      "2023-09-22 01:58:01.573819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005a00 of size 512 next 625\n",
      "2023-09-22 01:58:01.573827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005c00 of size 512 next 1552\n",
      "2023-09-22 01:58:01.573836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005e00 of size 768 next 32\n",
      "2023-09-22 01:58:01.573844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006100 of size 256 next 31\n",
      "2023-09-22 01:58:01.573851: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006200 of size 256 next 33\n",
      "2023-09-22 01:58:01.573860: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006300 of size 256 next 97\n",
      "2023-09-22 01:58:01.573868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006400 of size 256 next 148\n",
      "2023-09-22 01:58:01.573877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006500 of size 256 next 374\n",
      "2023-09-22 01:58:01.573884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006600 of size 256 next 16\n",
      "2023-09-22 01:58:01.573892: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006700 of size 256 next 911\n",
      "2023-09-22 01:58:01.573901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006800 of size 256 next 35\n",
      "2023-09-22 01:58:01.573908: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006900 of size 256 next 45\n",
      "2023-09-22 01:58:01.573916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006a00 of size 256 next 48\n",
      "2023-09-22 01:58:01.573923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006b00 of size 256 next 49\n",
      "2023-09-22 01:58:01.573933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006c00 of size 32768 next 1186\n",
      "2023-09-22 01:58:01.573946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ec00 of size 32768 next 363\n",
      "2023-09-22 01:58:01.573956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016c00 of size 55808 next 118\n",
      "2023-09-22 01:58:01.573966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de024600 of size 46336 next 105\n",
      "2023-09-22 01:58:01.573976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fb00 of size 256 next 103\n",
      "2023-09-22 01:58:01.573986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fc00 of size 256 next 104\n",
      "2023-09-22 01:58:01.573994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fd00 of size 256 next 107\n",
      "2023-09-22 01:58:01.574005: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fe00 of size 256 next 110\n",
      "2023-09-22 01:58:01.574014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ff00 of size 256 next 115\n",
      "2023-09-22 01:58:01.574024: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030000 of size 256 next 116\n",
      "2023-09-22 01:58:01.574034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030100 of size 256 next 117\n",
      "2023-09-22 01:58:01.574044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030200 of size 256 next 662\n",
      "2023-09-22 01:58:01.574054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030300 of size 256 next 1677\n",
      "2023-09-22 01:58:01.574064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030400 of size 256 next 862\n",
      "2023-09-22 01:58:01.574073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030500 of size 256 next 646\n",
      "2023-09-22 01:58:01.574083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030600 of size 256 next 108\n",
      "2023-09-22 01:58:01.574093: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030700 of size 256 next 109\n",
      "2023-09-22 01:58:01.574103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030800 of size 1272900352 next 1221\n",
      "2023-09-22 01:58:01.574114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1229e1f300 of size 33280 next 1130\n",
      "2023-09-22 01:58:01.574124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1229e27500 of size 256 next 706\n",
      "2023-09-22 01:58:01.574134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1229e27600 of size 256 next 71\n",
      "2023-09-22 01:58:01.574144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1229e27700 of size 48128 next 1582\n",
      "2023-09-22 01:58:01.574155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1229e33300 of size 409019648 next 953\n",
      "2023-09-22 01:58:01.574165: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445800 of size 256 next 925\n",
      "2023-09-22 01:58:01.574175: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445900 of size 256 next 426\n",
      "2023-09-22 01:58:01.574185: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445a00 of size 256 next 111\n",
      "2023-09-22 01:58:01.574194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445b00 of size 256 next 809\n",
      "2023-09-22 01:58:01.574205: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445c00 of size 256 next 1209\n",
      "2023-09-22 01:58:01.574215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445d00 of size 256 next 961\n",
      "2023-09-22 01:58:01.574225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445e00 of size 524288 next 302\n",
      "2023-09-22 01:58:01.574235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12424c5e00 of size 532480 next 635\n",
      "2023-09-22 01:58:01.574249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242547e00 of size 524288 next 817\n",
      "2023-09-22 01:58:01.574260: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12425c7e00 of size 662016 next 289\n",
      "2023-09-22 01:58:01.574270: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242669800 of size 180224 next 830\n",
      "2023-09-22 01:58:01.574281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242695800 of size 344064 next 1669\n",
      "2023-09-22 01:58:01.574291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12426e9800 of size 532480 next 393\n",
      "2023-09-22 01:58:01.574302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124276b800 of size 524288 next 1711\n",
      "2023-09-22 01:58:01.574312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12427eb800 of size 532480 next 608\n",
      "2023-09-22 01:58:01.574322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124286d800 of size 524288 next 399\n",
      "2023-09-22 01:58:01.574332: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12428ed800 of size 601088 next 595\n",
      "2023-09-22 01:58:01.574342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242980400 of size 32768 next 710\n",
      "2023-09-22 01:58:01.574352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242988400 of size 33280 next 1731\n",
      "2023-09-22 01:58:01.574363: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242990600 of size 32768 next 1732\n",
      "2023-09-22 01:58:01.574373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242998600 of size 36864 next 580\n",
      "2023-09-22 01:58:01.574383: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12429a1600 of size 256 next 1742\n",
      "2023-09-22 01:58:01.574393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12429a1700 of size 256 next 1745\n",
      "2023-09-22 01:58:01.574403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12429a1800 of size 10354688 next 248\n",
      "2023-09-22 01:58:01.574413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1243381800 of size 524288 next 185\n",
      "2023-09-22 01:58:01.574424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1243401800 of size 770048 next 1685\n",
      "2023-09-22 01:58:01.574434: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12434bd800 of size 13453824 next 142\n",
      "2023-09-22 01:58:01.574444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192200 of size 256 next 1452\n",
      "2023-09-22 01:58:01.574454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192300 of size 256 next 586\n",
      "2023-09-22 01:58:01.574464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192400 of size 256 next 1467\n",
      "2023-09-22 01:58:01.574474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192500 of size 256 next 865\n",
      "2023-09-22 01:58:01.574484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192600 of size 256 next 1201\n",
      "2023-09-22 01:58:01.574493: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192700 of size 256 next 772\n",
      "2023-09-22 01:58:01.574504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192800 of size 256 next 1126\n",
      "2023-09-22 01:58:01.574513: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192900 of size 256 next 417\n",
      "2023-09-22 01:58:01.574523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192a00 of size 256 next 741\n",
      "2023-09-22 01:58:01.574533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192b00 of size 256 next 806\n",
      "2023-09-22 01:58:01.574543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192c00 of size 256 next 280\n",
      "2023-09-22 01:58:01.574553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192d00 of size 256 next 342\n",
      "2023-09-22 01:58:01.574563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192e00 of size 256 next 364\n",
      "2023-09-22 01:58:01.574573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244192f00 of size 256 next 1194\n",
      "2023-09-22 01:58:01.574583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193000 of size 256 next 734\n",
      "2023-09-22 01:58:01.574592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193100 of size 256 next 1525\n",
      "2023-09-22 01:58:01.574602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193200 of size 256 next 463\n",
      "2023-09-22 01:58:01.574612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193300 of size 256 next 889\n",
      "2023-09-22 01:58:01.574622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193400 of size 256 next 57\n",
      "2023-09-22 01:58:01.574632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193500 of size 256 next 1611\n",
      "2023-09-22 01:58:01.574642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193600 of size 256 next 305\n",
      "2023-09-22 01:58:01.574652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193700 of size 256 next 60\n",
      "2023-09-22 01:58:01.574662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193800 of size 256 next 1431\n",
      "2023-09-22 01:58:01.574672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193900 of size 256 next 510\n",
      "2023-09-22 01:58:01.574682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193a00 of size 256 next 1450\n",
      "2023-09-22 01:58:01.574691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193b00 of size 256 next 227\n",
      "2023-09-22 01:58:01.574701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193c00 of size 256 next 739\n",
      "2023-09-22 01:58:01.574711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193d00 of size 256 next 840\n",
      "2023-09-22 01:58:01.574721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193e00 of size 256 next 1184\n",
      "2023-09-22 01:58:01.574731: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244193f00 of size 256 next 257\n",
      "2023-09-22 01:58:01.574741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244194000 of size 256 next 303\n",
      "2023-09-22 01:58:01.574751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244194100 of size 512 next 414\n",
      "2023-09-22 01:58:01.574761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244194300 of size 4096 next 182\n",
      "2023-09-22 01:58:01.574771: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244195300 of size 512 next 1104\n",
      "2023-09-22 01:58:01.574781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244195500 of size 512 next 715\n",
      "2023-09-22 01:58:01.574791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244195700 of size 512 next 1012\n",
      "2023-09-22 01:58:01.574801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244195900 of size 256 next 1438\n",
      "2023-09-22 01:58:01.574811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244195a00 of size 2304 next 749\n",
      "2023-09-22 01:58:01.574821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244196300 of size 4096 next 875\n",
      "2023-09-22 01:58:01.574831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244197300 of size 6400 next 589\n",
      "2023-09-22 01:58:01.574844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1244198c00 of size 24592384 next 1508\n",
      "2023-09-22 01:58:01.574854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124590cc00 of size 524288 next 1147\n",
      "2023-09-22 01:58:01.574865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124598cc00 of size 770048 next 1109\n",
      "2023-09-22 01:58:01.574876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245a48c00 of size 524288 next 490\n",
      "2023-09-22 01:58:01.574886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ac8c00 of size 662016 next 1169\n",
      "2023-09-22 01:58:01.574896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245b6a600 of size 524288 next 156\n",
      "2023-09-22 01:58:01.574906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245bea600 of size 532480 next 1172\n",
      "2023-09-22 01:58:01.574916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245c6c600 of size 524288 next 245\n",
      "2023-09-22 01:58:01.574926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245cec600 of size 532480 next 668\n",
      "2023-09-22 01:58:01.574936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245d6e600 of size 524288 next 1166\n",
      "2023-09-22 01:58:01.574946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245dee600 of size 601088 next 451\n",
      "2023-09-22 01:58:01.574956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e81200 of size 32768 next 770\n",
      "2023-09-22 01:58:01.574966: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e89200 of size 4096 next 332\n",
      "2023-09-22 01:58:01.574976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e8a200 of size 4096 next 135\n",
      "2023-09-22 01:58:01.574986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e8b200 of size 4096 next 1115\n",
      "2023-09-22 01:58:01.574996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e8c200 of size 4096 next 1446\n",
      "2023-09-22 01:58:01.575006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e8d200 of size 4096 next 1177\n",
      "2023-09-22 01:58:01.575016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e8e200 of size 4096 next 1337\n",
      "2023-09-22 01:58:01.575026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e8f200 of size 4096 next 1317\n",
      "2023-09-22 01:58:01.575036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e90200 of size 5632 next 898\n",
      "2023-09-22 01:58:01.575046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e91800 of size 512 next 1265\n",
      "2023-09-22 01:58:01.575056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e91a00 of size 512 next 1397\n",
      "2023-09-22 01:58:01.575067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e91c00 of size 16384 next 927\n",
      "2023-09-22 01:58:01.575077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e95c00 of size 16384 next 1009\n",
      "2023-09-22 01:58:01.575087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245e99c00 of size 34816 next 748\n",
      "2023-09-22 01:58:01.575097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2400 of size 256 next 1501\n",
      "2023-09-22 01:58:01.575107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2500 of size 256 next 1170\n",
      "2023-09-22 01:58:01.575117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2600 of size 256 next 409\n",
      "2023-09-22 01:58:01.575127: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2700 of size 256 next 497\n",
      "2023-09-22 01:58:01.575137: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2800 of size 512 next 329\n",
      "2023-09-22 01:58:01.575157: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2a00 of size 512 next 313\n",
      "2023-09-22 01:58:01.575167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2c00 of size 512 next 949\n",
      "2023-09-22 01:58:01.575177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2e00 of size 256 next 121\n",
      "2023-09-22 01:58:01.575187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea2f00 of size 512 next 688\n",
      "2023-09-22 01:58:01.575198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea3100 of size 512 next 500\n",
      "2023-09-22 01:58:01.575208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea3300 of size 512 next 1662\n",
      "2023-09-22 01:58:01.575218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea3500 of size 2816 next 1706\n",
      "2023-09-22 01:58:01.575229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4000 of size 256 next 1002\n",
      "2023-09-22 01:58:01.575239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4100 of size 256 next 901\n",
      "2023-09-22 01:58:01.575249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4200 of size 256 next 229\n",
      "2023-09-22 01:58:01.575259: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4300 of size 256 next 1596\n",
      "2023-09-22 01:58:01.575269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4400 of size 256 next 1626\n",
      "2023-09-22 01:58:01.575279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4500 of size 256 next 212\n",
      "2023-09-22 01:58:01.575290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4600 of size 256 next 1351\n",
      "2023-09-22 01:58:01.575300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4700 of size 256 next 79\n",
      "2023-09-22 01:58:01.575310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4800 of size 256 next 547\n",
      "2023-09-22 01:58:01.575320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4900 of size 256 next 855\n",
      "2023-09-22 01:58:01.575330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4a00 of size 256 next 1091\n",
      "2023-09-22 01:58:01.575340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4b00 of size 256 next 1102\n",
      "2023-09-22 01:58:01.575350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4c00 of size 256 next 1348\n",
      "2023-09-22 01:58:01.575360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4d00 of size 512 next 1298\n",
      "2023-09-22 01:58:01.575370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea4f00 of size 256 next 441\n",
      "2023-09-22 01:58:01.575380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea5000 of size 256 next 1006\n",
      "2023-09-22 01:58:01.575390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea5100 of size 256 next 861\n",
      "2023-09-22 01:58:01.575400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea5200 of size 256 next 294\n",
      "2023-09-22 01:58:01.575410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea5300 of size 256 next 521\n",
      "2023-09-22 01:58:01.575420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea5400 of size 256 next 1261\n",
      "2023-09-22 01:58:01.575431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ea5500 of size 262144 next 177\n",
      "2023-09-22 01:58:01.575441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245ee5500 of size 262144 next 518\n",
      "2023-09-22 01:58:01.575451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245f25500 of size 262144 next 87\n",
      "2023-09-22 01:58:01.575461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245f65500 of size 262144 next 1369\n",
      "2023-09-22 01:58:01.575471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245fa5500 of size 262144 next 1676\n",
      "2023-09-22 01:58:01.575481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1245fe5500 of size 262144 next 1356\n",
      "2023-09-22 01:58:01.575491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246025500 of size 262144 next 1518\n",
      "2023-09-22 01:58:01.575501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246065500 of size 262144 next 913\n",
      "2023-09-22 01:58:01.575511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12460a5500 of size 262144 next 96\n",
      "2023-09-22 01:58:01.575521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12460e5500 of size 262144 next 1425\n",
      "2023-09-22 01:58:01.575532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246125500 of size 262144 next 590\n",
      "2023-09-22 01:58:01.575542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246165500 of size 262144 next 213\n",
      "2023-09-22 01:58:01.575552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12461a5500 of size 262144 next 347\n",
      "2023-09-22 01:58:01.575562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12461e5500 of size 262144 next 814\n",
      "2023-09-22 01:58:01.575572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246225500 of size 262144 next 1472\n",
      "2023-09-22 01:58:01.575582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246265500 of size 419584 next 894\n",
      "2023-09-22 01:58:01.575592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbc00 of size 256 next 695\n",
      "2023-09-22 01:58:01.575602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbd00 of size 256 next 1266\n",
      "2023-09-22 01:58:01.575612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbe00 of size 524288 next 1628\n",
      "2023-09-22 01:58:01.575623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124634be00 of size 524288 next 884\n",
      "2023-09-22 01:58:01.575633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463cbe00 of size 524288 next 1725\n",
      "2023-09-22 01:58:01.575643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124644be00 of size 524288 next 387\n",
      "2023-09-22 01:58:01.575653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464cbe00 of size 524288 next 19\n",
      "2023-09-22 01:58:01.575663: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124654be00 of size 589824 next 852\n",
      "2023-09-22 01:58:01.575676: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465dbe00 of size 32768 next 656\n",
      "2023-09-22 01:58:01.575687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e3e00 of size 512 next 1217\n",
      "2023-09-22 01:58:01.575697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4000 of size 512 next 837\n",
      "2023-09-22 01:58:01.575707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4200 of size 512 next 1372\n",
      "2023-09-22 01:58:01.575717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4400 of size 512 next 143\n",
      "2023-09-22 01:58:01.575727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4600 of size 512 next 1365\n",
      "2023-09-22 01:58:01.575737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4800 of size 512 next 1623\n",
      "2023-09-22 01:58:01.575747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4a00 of size 512 next 1545\n",
      "2023-09-22 01:58:01.575757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4c00 of size 512 next 762\n",
      "2023-09-22 01:58:01.575767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e4e00 of size 4096 next 80\n",
      "2023-09-22 01:58:01.575777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e5e00 of size 4096 next 578\n",
      "2023-09-22 01:58:01.575787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e6e00 of size 4096 next 1576\n",
      "2023-09-22 01:58:01.575797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e7e00 of size 4096 next 519\n",
      "2023-09-22 01:58:01.575807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e8e00 of size 4096 next 1095\n",
      "2023-09-22 01:58:01.575817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465e9e00 of size 4096 next 605\n",
      "2023-09-22 01:58:01.575827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465eae00 of size 4096 next 694\n",
      "2023-09-22 01:58:01.575837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465ebe00 of size 32768 next 711\n",
      "2023-09-22 01:58:01.575847: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465f3e00 of size 32768 next 1585\n",
      "2023-09-22 01:58:01.575857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465fbe00 of size 242688 next 83\n",
      "2023-09-22 01:58:01.575868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246637200 of size 32768 next 1211\n",
      "2023-09-22 01:58:01.575878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124663f200 of size 27648 next 546\n",
      "2023-09-22 01:58:01.575888: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246645e00 of size 16384 next 1573\n",
      "2023-09-22 01:58:01.575899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246649e00 of size 17408 next 391\n",
      "2023-09-22 01:58:01.575909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124664e200 of size 33792 next 459\n",
      "2023-09-22 01:58:01.575920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246656600 of size 52224 next 348\n",
      "2023-09-22 01:58:01.575930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246663200 of size 147456 next 40\n",
      "2023-09-22 01:58:01.575941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246687200 of size 159488 next 1658\n",
      "2023-09-22 01:58:01.575951: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ae100 of size 32768 next 351\n",
      "2023-09-22 01:58:01.575961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466b6100 of size 48128 next 1157\n",
      "2023-09-22 01:58:01.575972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466c1d00 of size 32768 next 1127\n",
      "2023-09-22 01:58:01.575982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466c9d00 of size 32768 next 299\n",
      "2023-09-22 01:58:01.575992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466d1d00 of size 32768 next 1101\n",
      "2023-09-22 01:58:01.576002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466d9d00 of size 34560 next 959\n",
      "2023-09-22 01:58:01.576015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2400 of size 256 next 1426\n",
      "2023-09-22 01:58:01.576025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2500 of size 16384 next 721\n",
      "2023-09-22 01:58:01.576035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e6500 of size 16384 next 1331\n",
      "2023-09-22 01:58:01.576046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466ea500 of size 31488 next 291\n",
      "2023-09-22 01:58:01.576056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2000 of size 256 next 880\n",
      "2023-09-22 01:58:01.576066: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2100 of size 4096 next 1233\n",
      "2023-09-22 01:58:01.576076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3100 of size 4096 next 260\n",
      "2023-09-22 01:58:01.576086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4100 of size 5888 next 98\n",
      "2023-09-22 01:58:01.576096: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5800 of size 256 next 385\n",
      "2023-09-22 01:58:01.576106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5900 of size 256 next 705\n",
      "2023-09-22 01:58:01.576116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5a00 of size 256 next 225\n",
      "2023-09-22 01:58:01.576126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12466f5b00 of size 10556928 next 1155\n",
      "2023-09-22 01:58:01.576136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107100 of size 256 next 995\n",
      "2023-09-22 01:58:01.576146: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107200 of size 32768 next 160\n",
      "2023-09-22 01:58:01.576156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f200 of size 48128 next 617\n",
      "2023-09-22 01:58:01.576167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124711ae00 of size 47360 next 1140\n",
      "2023-09-22 01:58:01.576177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126700 of size 256 next 47\n",
      "2023-09-22 01:58:01.576187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126800 of size 4096 next 1484\n",
      "2023-09-22 01:58:01.576197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127800 of size 4096 next 1717\n",
      "2023-09-22 01:58:01.576207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128800 of size 4096 next 1153\n",
      "2023-09-22 01:58:01.576218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129800 of size 6144 next 823\n",
      "2023-09-22 01:58:01.576228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b000 of size 256 next 832\n",
      "2023-09-22 01:58:01.576238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b100 of size 256 next 153\n",
      "2023-09-22 01:58:01.576248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b200 of size 147456 next 390\n",
      "2023-09-22 01:58:01.576258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124714f200 of size 281600 next 163\n",
      "2023-09-22 01:58:01.576268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193e00 of size 256 next 123\n",
      "2023-09-22 01:58:01.576278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193f00 of size 256 next 1630\n",
      "2023-09-22 01:58:01.576288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194000 of size 256 next 566\n",
      "2023-09-22 01:58:01.576298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194100 of size 256 next 1062\n",
      "2023-09-22 01:58:01.576308: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194200 of size 512 next 453\n",
      "2023-09-22 01:58:01.576318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194400 of size 256 next 989\n",
      "2023-09-22 01:58:01.576328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194500 of size 524288 next 613\n",
      "2023-09-22 01:58:01.576339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247214500 of size 660480 next 1698\n",
      "2023-09-22 01:58:01.576349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12472b5900 of size 524288 next 146\n",
      "2023-09-22 01:58:01.576359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247335900 of size 532480 next 340\n",
      "2023-09-22 01:58:01.576369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473b7900 of size 524288 next 1328\n",
      "2023-09-22 01:58:01.576379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247437900 of size 532480 next 1287\n",
      "2023-09-22 01:58:01.576389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474b9900 of size 524288 next 1463\n",
      "2023-09-22 01:58:01.576399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247539900 of size 532480 next 879\n",
      "2023-09-22 01:58:01.576409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12475bb900 of size 524288 next 1407\n",
      "2023-09-22 01:58:01.576419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124763b900 of size 662016 next 1223\n",
      "2023-09-22 01:58:01.576429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12476dd300 of size 524288 next 921\n",
      "2023-09-22 01:58:01.576440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124775d300 of size 574464 next 918\n",
      "2023-09-22 01:58:01.576450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9700 of size 256 next 440\n",
      "2023-09-22 01:58:01.576460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9800 of size 256 next 999\n",
      "2023-09-22 01:58:01.576470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9900 of size 27648 next 1135\n",
      "2023-09-22 01:58:01.576480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477f0500 of size 54016 next 1278\n",
      "2023-09-22 01:58:01.576493: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477fd800 of size 32768 next 939\n",
      "2023-09-22 01:58:01.576503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247805800 of size 32768 next 1688\n",
      "2023-09-22 01:58:01.576513: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780d800 of size 4096 next 1715\n",
      "2023-09-22 01:58:01.576524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780e800 of size 4096 next 584\n",
      "2023-09-22 01:58:01.576534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124780f800 of size 4096 next 1713\n",
      "2023-09-22 01:58:01.576544: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247810800 of size 4096 next 1670\n",
      "2023-09-22 01:58:01.576554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247811800 of size 4096 next 1520\n",
      "2023-09-22 01:58:01.576564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247812800 of size 2048 next 522\n",
      "2023-09-22 01:58:01.576574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813000 of size 2048 next 1642\n",
      "2023-09-22 01:58:01.576584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813800 of size 512 next 1125\n",
      "2023-09-22 01:58:01.576594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813a00 of size 512 next 1134\n",
      "2023-09-22 01:58:01.576605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813c00 of size 512 next 292\n",
      "2023-09-22 01:58:01.576615: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247813e00 of size 512 next 1391\n",
      "2023-09-22 01:58:01.576626: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814000 of size 512 next 270\n",
      "2023-09-22 01:58:01.576636: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814200 of size 256 next 483\n",
      "2023-09-22 01:58:01.576646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814300 of size 256 next 1225\n",
      "2023-09-22 01:58:01.576656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814400 of size 512 next 1324\n",
      "2023-09-22 01:58:01.576666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814600 of size 512 next 251\n",
      "2023-09-22 01:58:01.576676: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814800 of size 512 next 1461\n",
      "2023-09-22 01:58:01.576686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814a00 of size 512 next 139\n",
      "2023-09-22 01:58:01.576696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814c00 of size 512 next 1195\n",
      "2023-09-22 01:58:01.576706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247814e00 of size 512 next 725\n",
      "2023-09-22 01:58:01.576716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815000 of size 2048 next 25\n",
      "2023-09-22 01:58:01.576726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247815800 of size 32768 next 1513\n",
      "2023-09-22 01:58:01.576736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124781d800 of size 32768 next 1253\n",
      "2023-09-22 01:58:01.576746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247825800 of size 32768 next 847\n",
      "2023-09-22 01:58:01.576756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124782d800 of size 32768 next 1243\n",
      "2023-09-22 01:58:01.576767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247835800 of size 512 next 360\n",
      "2023-09-22 01:58:01.576777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247835a00 of size 512 next 504\n",
      "2023-09-22 01:58:01.576787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247835c00 of size 512 next 756\n",
      "2023-09-22 01:58:01.576797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247835e00 of size 512 next 1198\n",
      "2023-09-22 01:58:01.576807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247836000 of size 512 next 920\n",
      "2023-09-22 01:58:01.576817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247836200 of size 512 next 636\n",
      "2023-09-22 01:58:01.576827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247836400 of size 512 next 858\n",
      "2023-09-22 01:58:01.576837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247836600 of size 512 next 166\n",
      "2023-09-22 01:58:01.576847: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247836800 of size 4096 next 1435\n",
      "2023-09-22 01:58:01.576857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247837800 of size 4096 next 1094\n",
      "2023-09-22 01:58:01.576867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247838800 of size 4096 next 1733\n",
      "2023-09-22 01:58:01.576877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247839800 of size 4096 next 757\n",
      "2023-09-22 01:58:01.576887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124783a800 of size 4096 next 1671\n",
      "2023-09-22 01:58:01.576897: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124783b800 of size 4096 next 1610\n",
      "2023-09-22 01:58:01.576907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124783c800 of size 4096 next 1121\n",
      "2023-09-22 01:58:01.576918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124783d800 of size 32768 next 1571\n",
      "2023-09-22 01:58:01.576928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247845800 of size 32768 next 1159\n",
      "2023-09-22 01:58:01.576938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124784d800 of size 32768 next 812\n",
      "2023-09-22 01:58:01.576948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247855800 of size 32768 next 982\n",
      "2023-09-22 01:58:01.576958: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124785d800 of size 4096 next 1718\n",
      "2023-09-22 01:58:01.576968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124785e800 of size 4096 next 768\n",
      "2023-09-22 01:58:01.576978: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124785f800 of size 4096 next 1681\n",
      "2023-09-22 01:58:01.576988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247860800 of size 4096 next 350\n",
      "2023-09-22 01:58:01.576998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247861800 of size 512 next 1045\n",
      "2023-09-22 01:58:01.577008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247861a00 of size 512 next 1719\n",
      "2023-09-22 01:58:01.577018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247861c00 of size 512 next 1181\n",
      "2023-09-22 01:58:01.577028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247861e00 of size 512 next 571\n",
      "2023-09-22 01:58:01.577038: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247862000 of size 512 next 236\n",
      "2023-09-22 01:58:01.577048: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247862200 of size 512 next 1098\n",
      "2023-09-22 01:58:01.577058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247862400 of size 512 next 412\n",
      "2023-09-22 01:58:01.577068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247862600 of size 512 next 747\n",
      "2023-09-22 01:58:01.577078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247862800 of size 4096 next 868\n",
      "2023-09-22 01:58:01.577088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247863800 of size 4096 next 713\n",
      "2023-09-22 01:58:01.577098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247864800 of size 4096 next 700\n",
      "2023-09-22 01:58:01.577108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247865800 of size 32768 next 732\n",
      "2023-09-22 01:58:01.577118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124786d800 of size 32768 next 1187\n",
      "2023-09-22 01:58:01.577128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247875800 of size 4096 next 1636\n",
      "2023-09-22 01:58:01.577138: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247876800 of size 4096 next 1049\n",
      "2023-09-22 01:58:01.577148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247877800 of size 4096 next 922\n",
      "2023-09-22 01:58:01.577158: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247878800 of size 512 next 1105\n",
      "2023-09-22 01:58:01.577168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247878a00 of size 512 next 1592\n",
      "2023-09-22 01:58:01.577178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247878c00 of size 512 next 1110\n",
      "2023-09-22 01:58:01.577189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247878e00 of size 512 next 1451\n",
      "2023-09-22 01:58:01.577199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247879000 of size 512 next 797\n",
      "2023-09-22 01:58:01.577209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247879200 of size 512 next 397\n",
      "2023-09-22 01:58:01.577219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247879400 of size 512 next 1432\n",
      "2023-09-22 01:58:01.577228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247879600 of size 512 next 607\n",
      "2023-09-22 01:58:01.577239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247879800 of size 4096 next 416\n",
      "2023-09-22 01:58:01.577249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124787a800 of size 4096 next 131\n",
      "2023-09-22 01:58:01.577259: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124787b800 of size 4096 next 465\n",
      "2023-09-22 01:58:01.577269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124787c800 of size 4096 next 1704\n",
      "2023-09-22 01:58:01.577279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124787d800 of size 524288 next 1240\n",
      "2023-09-22 01:58:01.577289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12478fd800 of size 1001216 next 1581\n",
      "2023-09-22 01:58:01.577299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f1f00 of size 256 next 1464\n",
      "2023-09-22 01:58:01.577309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2000 of size 256 next 1589\n",
      "2023-09-22 01:58:01.577319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2100 of size 32768 next 1071\n",
      "2023-09-22 01:58:01.577329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479fa100 of size 32768 next 886\n",
      "2023-09-22 01:58:01.577339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a02100 of size 32768 next 34\n",
      "2023-09-22 01:58:01.577349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a0a100 of size 32768 next 286\n",
      "2023-09-22 01:58:01.577359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a12100 of size 4096 next 288\n",
      "2023-09-22 01:58:01.577369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a13100 of size 4096 next 197\n",
      "2023-09-22 01:58:01.577379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a14100 of size 4096 next 778\n",
      "2023-09-22 01:58:01.577389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a15100 of size 4096 next 1480\n",
      "2023-09-22 01:58:01.577399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a16100 of size 4096 next 775\n",
      "2023-09-22 01:58:01.577409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a17100 of size 4096 next 709\n",
      "2023-09-22 01:58:01.577419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a18100 of size 4096 next 828\n",
      "2023-09-22 01:58:01.577429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a19100 of size 512 next 883\n",
      "2023-09-22 01:58:01.577439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a19300 of size 512 next 1494\n",
      "2023-09-22 01:58:01.577449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a19500 of size 512 next 618\n",
      "2023-09-22 01:58:01.577459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a19700 of size 512 next 1558\n",
      "2023-09-22 01:58:01.577469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a19900 of size 2048 next 1650\n",
      "2023-09-22 01:58:01.577480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1a100 of size 44032 next 1368\n",
      "2023-09-22 01:58:01.577490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a24d00 of size 32768 next 1056\n",
      "2023-09-22 01:58:01.577500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a2cd00 of size 33280 next 231\n",
      "2023-09-22 01:58:01.577510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a34f00 of size 32768 next 1737\n",
      "2023-09-22 01:58:01.577520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a3cf00 of size 63488 next 1293\n",
      "2023-09-22 01:58:01.577531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a4c700 of size 32768 next 100\n",
      "2023-09-22 01:58:01.577541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54700 of size 256 next 727\n",
      "2023-09-22 01:58:01.577551: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54800 of size 256 next 1185\n",
      "2023-09-22 01:58:01.577561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54900 of size 256 next 336\n",
      "2023-09-22 01:58:01.577571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54a00 of size 256 next 1067\n",
      "2023-09-22 01:58:01.577581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54b00 of size 256 next 763\n",
      "2023-09-22 01:58:01.577591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54c00 of size 256 next 1633\n",
      "2023-09-22 01:58:01.577601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54d00 of size 512 next 844\n",
      "2023-09-22 01:58:01.577610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a54f00 of size 512 next 647\n",
      "2023-09-22 01:58:01.577620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a55100 of size 512 next 1679\n",
      "2023-09-22 01:58:01.577630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a55300 of size 512 next 1332\n",
      "2023-09-22 01:58:01.577641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a55500 of size 40960 next 1149\n",
      "2023-09-22 01:58:01.577651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a5f500 of size 4096 next 1256\n",
      "2023-09-22 01:58:01.577661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60500 of size 256 next 1722\n",
      "2023-09-22 01:58:01.577671: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60600 of size 256 next 598\n",
      "2023-09-22 01:58:01.577681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60700 of size 512 next 652\n",
      "2023-09-22 01:58:01.577691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60900 of size 512 next 973\n",
      "2023-09-22 01:58:01.577701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60b00 of size 512 next 1728\n",
      "2023-09-22 01:58:01.577711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60d00 of size 512 next 1074\n",
      "2023-09-22 01:58:01.577721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a60f00 of size 512 next 1668\n",
      "2023-09-22 01:58:01.577732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61100 of size 512 next 909\n",
      "2023-09-22 01:58:01.577742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61300 of size 256 next 375\n",
      "2023-09-22 01:58:01.577752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61400 of size 256 next 1008\n",
      "2023-09-22 01:58:01.577762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a61500 of size 4096 next 179\n",
      "2023-09-22 01:58:01.577772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a62500 of size 5120 next 249\n",
      "2023-09-22 01:58:01.577783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a63900 of size 512 next 210\n",
      "2023-09-22 01:58:01.577793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a63b00 of size 512 next 987\n",
      "2023-09-22 01:58:01.577803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a63d00 of size 512 next 1597\n",
      "2023-09-22 01:58:01.577813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a63f00 of size 256 next 1264\n",
      "2023-09-22 01:58:01.577823: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64000 of size 256 next 857\n",
      "2023-09-22 01:58:01.577833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64100 of size 512 next 1456\n",
      "2023-09-22 01:58:01.577843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64300 of size 512 next 681\n",
      "2023-09-22 01:58:01.577853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64500 of size 512 next 1154\n",
      "2023-09-22 01:58:01.577863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64700 of size 512 next 1401\n",
      "2023-09-22 01:58:01.577873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64900 of size 512 next 1395\n",
      "2023-09-22 01:58:01.577883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64b00 of size 256 next 701\n",
      "2023-09-22 01:58:01.577893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64c00 of size 256 next 464\n",
      "2023-09-22 01:58:01.577903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64d00 of size 512 next 1366\n",
      "2023-09-22 01:58:01.577913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a64f00 of size 512 next 1402\n",
      "2023-09-22 01:58:01.577923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a65100 of size 512 next 1316\n",
      "2023-09-22 01:58:01.577934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a65300 of size 256 next 1116\n",
      "2023-09-22 01:58:01.577944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a65400 of size 256 next 238\n",
      "2023-09-22 01:58:01.577954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a65500 of size 256 next 23\n",
      "2023-09-22 01:58:01.577964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a65600 of size 2048 next 1476\n",
      "2023-09-22 01:58:01.577974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a65e00 of size 2048 next 1485\n",
      "2023-09-22 01:58:01.577984: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a66600 of size 512 next 1065\n",
      "2023-09-22 01:58:01.577994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a66800 of size 512 next 533\n",
      "2023-09-22 01:58:01.578004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a66a00 of size 512 next 233\n",
      "2023-09-22 01:58:01.578014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a66c00 of size 256 next 1151\n",
      "2023-09-22 01:58:01.578024: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a66d00 of size 512 next 502\n",
      "2023-09-22 01:58:01.578034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a66f00 of size 256 next 81\n",
      "2023-09-22 01:58:01.578044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67000 of size 256 next 810\n",
      "2023-09-22 01:58:01.578054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67100 of size 256 next 507\n",
      "2023-09-22 01:58:01.578064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67200 of size 256 next 456\n",
      "2023-09-22 01:58:01.578074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67300 of size 256 next 1020\n",
      "2023-09-22 01:58:01.578084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67400 of size 256 next 1361\n",
      "2023-09-22 01:58:01.578094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67500 of size 256 next 1411\n",
      "2023-09-22 01:58:01.578104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67600 of size 256 next 482\n",
      "2023-09-22 01:58:01.578114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67700 of size 256 next 388\n",
      "2023-09-22 01:58:01.578124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67800 of size 256 next 349\n",
      "2023-09-22 01:58:01.578134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67900 of size 256 next 183\n",
      "2023-09-22 01:58:01.578144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67a00 of size 768 next 1272\n",
      "2023-09-22 01:58:01.578154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67d00 of size 256 next 357\n",
      "2023-09-22 01:58:01.578164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67e00 of size 256 next 1477\n",
      "2023-09-22 01:58:01.578174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67f00 of size 256 next 622\n",
      "2023-09-22 01:58:01.578184: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68000 of size 256 next 1311\n",
      "2023-09-22 01:58:01.578193: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68100 of size 256 next 788\n",
      "2023-09-22 01:58:01.578203: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68200 of size 256 next 974\n",
      "2023-09-22 01:58:01.578213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68300 of size 256 next 484\n",
      "2023-09-22 01:58:01.578223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68400 of size 256 next 912\n",
      "2023-09-22 01:58:01.578233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68500 of size 512 next 218\n",
      "2023-09-22 01:58:01.578243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68700 of size 512 next 173\n",
      "2023-09-22 01:58:01.578253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68900 of size 256 next 1612\n",
      "2023-09-22 01:58:01.578263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68a00 of size 256 next 1044\n",
      "2023-09-22 01:58:01.578273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68b00 of size 256 next 577\n",
      "2023-09-22 01:58:01.578283: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68c00 of size 256 next 1465\n",
      "2023-09-22 01:58:01.578293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68d00 of size 512 next 1535\n",
      "2023-09-22 01:58:01.578303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68f00 of size 512 next 1048\n",
      "2023-09-22 01:58:01.578313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69100 of size 256 next 1393\n",
      "2023-09-22 01:58:01.578323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69200 of size 256 next 184\n",
      "2023-09-22 01:58:01.578333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69300 of size 524288 next 1500\n",
      "2023-09-22 01:58:01.578343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ae9300 of size 532480 next 583\n",
      "2023-09-22 01:58:01.578354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b6b300 of size 524288 next 1587\n",
      "2023-09-22 01:58:01.578364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247beb300 of size 532480 next 194\n",
      "2023-09-22 01:58:01.578374: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247c6d300 of size 524288 next 1615\n",
      "2023-09-22 01:58:01.578384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ced300 of size 662016 next 1644\n",
      "2023-09-22 01:58:01.578394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247d8ed00 of size 524288 next 1320\n",
      "2023-09-22 01:58:01.578404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e0ed00 of size 532480 next 69\n",
      "2023-09-22 01:58:01.578414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e90d00 of size 524288 next 765\n",
      "2023-09-22 01:58:01.578424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247f10d00 of size 532480 next 516\n",
      "2023-09-22 01:58:01.578434: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247f92d00 of size 524288 next 977\n",
      "2023-09-22 01:58:01.578444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1248012d00 of size 751616 next 1295\n",
      "2023-09-22 01:58:01.578454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca500 of size 256 next 671\n",
      "2023-09-22 01:58:01.578464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca600 of size 256 next 1061\n",
      "2023-09-22 01:58:01.578474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca700 of size 256 next 1514\n",
      "2023-09-22 01:58:01.578485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca800 of size 231587584 next 514\n",
      "2023-09-22 01:58:01.578497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6700 of size 256 next 284\n",
      "2023-09-22 01:58:01.578507: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6800 of size 256 next 796\n",
      "2023-09-22 01:58:01.578517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6900 of size 524288 next 1441\n",
      "2023-09-22 01:58:01.578528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e26900 of size 847104 next 673\n",
      "2023-09-22 01:58:01.578538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5600 of size 256 next 1259\n",
      "2023-09-22 01:58:01.578548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5700 of size 7936 next 520\n",
      "2023-09-22 01:58:01.578558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7600 of size 256 next 214\n",
      "2023-09-22 01:58:01.578568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7700 of size 512 next 1227\n",
      "2023-09-22 01:58:01.578579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7900 of size 512 next 26\n",
      "2023-09-22 01:58:01.578587: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7b00 of size 512 next 1081\n",
      "2023-09-22 01:58:01.578596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7d00 of size 512 next 501\n",
      "2023-09-22 01:58:01.578606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7f00 of size 512 next 1386\n",
      "2023-09-22 01:58:01.578616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8100 of size 512 next 1367\n",
      "2023-09-22 01:58:01.578625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8300 of size 512 next 1625\n",
      "2023-09-22 01:58:01.578635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8500 of size 512 next 125\n",
      "2023-09-22 01:58:01.578645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8700 of size 512 next 1285\n",
      "2023-09-22 01:58:01.578655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8900 of size 512 next 362\n",
      "2023-09-22 01:58:01.578665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8b00 of size 512 next 1440\n",
      "2023-09-22 01:58:01.578675: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8d00 of size 512 next 558\n",
      "2023-09-22 01:58:01.578685: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8f00 of size 512 next 1736\n",
      "2023-09-22 01:58:01.578695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9100 of size 512 next 1406\n",
      "2023-09-22 01:58:01.578705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9300 of size 512 next 807\n",
      "2023-09-22 01:58:01.578715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9500 of size 512 next 697\n",
      "2023-09-22 01:58:01.578725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9700 of size 4096 next 449\n",
      "2023-09-22 01:58:01.578735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa700 of size 4608 next 1027\n",
      "2023-09-22 01:58:01.578745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb900 of size 256 next 624\n",
      "2023-09-22 01:58:01.578755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efba00 of size 512 next 1232\n",
      "2023-09-22 01:58:01.578765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbc00 of size 512 next 1740\n",
      "2023-09-22 01:58:01.578775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efbe00 of size 512 next 538\n",
      "2023-09-22 01:58:01.578786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc000 of size 512 next 1380\n",
      "2023-09-22 01:58:01.578796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc200 of size 512 next 890\n",
      "2023-09-22 01:58:01.578806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc400 of size 512 next 1250\n",
      "2023-09-22 01:58:01.578816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc600 of size 512 next 1738\n",
      "2023-09-22 01:58:01.578826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc800 of size 512 next 1041\n",
      "2023-09-22 01:58:01.578835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efca00 of size 512 next 679\n",
      "2023-09-22 01:58:01.578845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efcc00 of size 512 next 455\n",
      "2023-09-22 01:58:01.578855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efce00 of size 512 next 158\n",
      "2023-09-22 01:58:01.578865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd000 of size 256 next 196\n",
      "2023-09-22 01:58:01.578875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd100 of size 256 next 683\n",
      "2023-09-22 01:58:01.578885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd200 of size 256 next 1296\n",
      "2023-09-22 01:58:01.578895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd300 of size 524288 next 89\n",
      "2023-09-22 01:58:01.578906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255f7d300 of size 932096 next 562\n",
      "2023-09-22 01:58:01.578916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1256060c00 of size 21999104 next 1409\n",
      "2023-09-22 01:58:01.578926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ba00 of size 256 next 630\n",
      "2023-09-22 01:58:01.578936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755bb00 of size 4096 next 1175\n",
      "2023-09-22 01:58:01.578946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755cb00 of size 4096 next 44\n",
      "2023-09-22 01:58:01.578957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755db00 of size 529664 next 524\n",
      "2023-09-22 01:58:01.578967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12575df000 of size 992000 next 1634\n",
      "2023-09-22 01:58:01.578977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1300 of size 256 next 780\n",
      "2023-09-22 01:58:01.578987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1400 of size 524288 next 485\n",
      "2023-09-22 01:58:01.578997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257751400 of size 524288 next 1392\n",
      "2023-09-22 01:58:01.579007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12577d1400 of size 524288 next 767\n",
      "2023-09-22 01:58:01.579017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257851400 of size 524288 next 1729\n",
      "2023-09-22 01:58:01.579027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12578d1400 of size 524288 next 1505\n",
      "2023-09-22 01:58:01.579037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257951400 of size 524288 next 1449\n",
      "2023-09-22 01:58:01.579047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12579d1400 of size 524288 next 1347\n",
      "2023-09-22 01:58:01.579058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257a51400 of size 527360 next 1099\n",
      "2023-09-22 01:58:01.579071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257ad2000 of size 524288 next 421\n",
      "2023-09-22 01:58:01.579081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b52000 of size 532480 next 326\n",
      "2023-09-22 01:58:01.579091: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257bd4000 of size 524288 next 235\n",
      "2023-09-22 01:58:01.579101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257c54000 of size 532480 next 1355\n",
      "2023-09-22 01:58:01.579111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257cd6000 of size 524288 next 942\n",
      "2023-09-22 01:58:01.579121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257d56000 of size 532480 next 300\n",
      "2023-09-22 01:58:01.579131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257dd8000 of size 524288 next 654\n",
      "2023-09-22 01:58:01.579162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257e58000 of size 662016 next 1692\n",
      "2023-09-22 01:58:01.579173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257ef9a00 of size 524288 next 1050\n",
      "2023-09-22 01:58:01.579184: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257f79a00 of size 532480 next 1207\n",
      "2023-09-22 01:58:01.579194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257ffba00 of size 524288 next 369\n",
      "2023-09-22 01:58:01.579204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125807ba00 of size 532480 next 454\n",
      "2023-09-22 01:58:01.579215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12580fda00 of size 524288 next 820\n",
      "2023-09-22 01:58:01.579225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125817da00 of size 532480 next 1483\n",
      "2023-09-22 01:58:01.579235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12581ffa00 of size 524288 next 1546\n",
      "2023-09-22 01:58:01.579245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125827fa00 of size 662016 next 1564\n",
      "2023-09-22 01:58:01.579254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1258321400 of size 524288 next 254\n",
      "2023-09-22 01:58:01.579264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12583a1400 of size 524288 next 1216\n",
      "2023-09-22 01:58:01.579274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1258421400 of size 524288 next 851\n",
      "2023-09-22 01:58:01.579284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12584a1400 of size 524288 next 1346\n",
      "2023-09-22 01:58:01.579294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1258521400 of size 524288 next 226\n",
      "2023-09-22 01:58:01.579304: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585a1400 of size 32768 next 798\n",
      "2023-09-22 01:58:01.579314: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585a9400 of size 256 next 1659\n",
      "2023-09-22 01:58:01.579324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585a9500 of size 256 next 242\n",
      "2023-09-22 01:58:01.579334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585a9600 of size 512 next 1247\n",
      "2023-09-22 01:58:01.579344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585a9800 of size 512 next 359\n",
      "2023-09-22 01:58:01.579354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585a9a00 of size 46592 next 758\n",
      "2023-09-22 01:58:01.579364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5000 of size 256 next 39\n",
      "2023-09-22 01:58:01.579374: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5100 of size 256 next 660\n",
      "2023-09-22 01:58:01.579384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5200 of size 256 next 740\n",
      "2023-09-22 01:58:01.579394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5300 of size 256 next 1408\n",
      "2023-09-22 01:58:01.579404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5400 of size 256 next 1605\n",
      "2023-09-22 01:58:01.579413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5500 of size 256 next 1444\n",
      "2023-09-22 01:58:01.579423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5600 of size 256 next 88\n",
      "2023-09-22 01:58:01.579433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5700 of size 512 next 376\n",
      "2023-09-22 01:58:01.579443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5900 of size 512 next 127\n",
      "2023-09-22 01:58:01.579453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5b00 of size 512 next 760\n",
      "2023-09-22 01:58:01.579463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5d00 of size 512 next 1410\n",
      "2023-09-22 01:58:01.579473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5f00 of size 512 next 1145\n",
      "2023-09-22 01:58:01.579483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b6100 of size 512 next 1695\n",
      "2023-09-22 01:58:01.579493: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b6300 of size 512 next 1196\n",
      "2023-09-22 01:58:01.579503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b6500 of size 512 next 316\n",
      "2023-09-22 01:58:01.579513: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b6700 of size 512 next 1424\n",
      "2023-09-22 01:58:01.579522: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b6900 of size 512 next 438\n",
      "2023-09-22 01:58:01.579532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b6b00 of size 512 next 285\n",
      "2023-09-22 01:58:01.579542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b6d00 of size 768 next 335\n",
      "2023-09-22 01:58:01.579552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b7000 of size 256 next 764\n",
      "2023-09-22 01:58:01.579562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b7100 of size 4096 next 1661\n",
      "2023-09-22 01:58:01.579572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b8100 of size 4096 next 693\n",
      "2023-09-22 01:58:01.579582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b9100 of size 4096 next 731\n",
      "2023-09-22 01:58:01.579592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585ba100 of size 4096 next 295\n",
      "2023-09-22 01:58:01.579602: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585bb100 of size 4096 next 50\n",
      "2023-09-22 01:58:01.579612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585bc100 of size 4096 next 1088\n",
      "2023-09-22 01:58:01.579622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585bd100 of size 4096 next 1283\n",
      "2023-09-22 01:58:01.579632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585be100 of size 4096 next 199\n",
      "2023-09-22 01:58:01.579642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585bf100 of size 32768 next 575\n",
      "2023-09-22 01:58:01.579652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585c7100 of size 57088 next 643\n",
      "2023-09-22 01:58:01.579662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585d5000 of size 485895936 next 972\n",
      "2023-09-22 01:58:01.579673: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537f00 of size 256 next 929\n",
      "2023-09-22 01:58:01.579683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538000 of size 256 next 940\n",
      "2023-09-22 01:58:01.579693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538100 of size 4096 next 195\n",
      "2023-09-22 01:58:01.579702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539100 of size 5888 next 1179\n",
      "2023-09-22 01:58:01.579712: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a800 of size 256 next 771\n",
      "2023-09-22 01:58:01.579722: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a900 of size 32768 next 155\n",
      "2023-09-22 01:58:01.579733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275542900 of size 32768 next 1727\n",
      "2023-09-22 01:58:01.579743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127554a900 of size 55808 next 377\n",
      "2023-09-22 01:58:01.579753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275558300 of size 32768 next 460\n",
      "2023-09-22 01:58:01.579763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275560300 of size 32768 next 1360\n",
      "2023-09-22 01:58:01.579773: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275568300 of size 62464 next 1093\n",
      "2023-09-22 01:58:01.579783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577700 of size 256 next 1255\n",
      "2023-09-22 01:58:01.579793: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577800 of size 524288 next 557\n",
      "2023-09-22 01:58:01.579803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755f7800 of size 147456 next 1388\n",
      "2023-09-22 01:58:01.579814: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127561b800 of size 577536 next 474\n",
      "2023-09-22 01:58:01.579824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8800 of size 256 next 859\n",
      "2023-09-22 01:58:01.579834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8900 of size 256 next 24\n",
      "2023-09-22 01:58:01.579844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8a00 of size 512 next 223\n",
      "2023-09-22 01:58:01.579854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8c00 of size 512 next 447\n",
      "2023-09-22 01:58:01.579864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8e00 of size 512 next 1412\n",
      "2023-09-22 01:58:01.579874: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9000 of size 512 next 1239\n",
      "2023-09-22 01:58:01.579884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9200 of size 512 next 1258\n",
      "2023-09-22 01:58:01.579893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9400 of size 512 next 1675\n",
      "2023-09-22 01:58:01.579903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9600 of size 512 next 1076\n",
      "2023-09-22 01:58:01.579913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9800 of size 512 next 102\n",
      "2023-09-22 01:58:01.579923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9a00 of size 4096 next 752\n",
      "2023-09-22 01:58:01.579933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aaa00 of size 4096 next 1220\n",
      "2023-09-22 01:58:01.579943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aba00 of size 5632 next 682\n",
      "2023-09-22 01:58:01.579953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad000 of size 256 next 836\n",
      "2023-09-22 01:58:01.579964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad100 of size 256 next 659\n",
      "2023-09-22 01:58:01.579974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad200 of size 256 next 276\n",
      "2023-09-22 01:58:01.579986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad300 of size 256 next 531\n",
      "2023-09-22 01:58:01.579997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad400 of size 256 next 897\n",
      "2023-09-22 01:58:01.580009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad500 of size 256 next 93\n",
      "2023-09-22 01:58:01.580021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad600 of size 256 next 928\n",
      "2023-09-22 01:58:01.580033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad700 of size 81920000 next 988\n",
      "2023-09-22 01:58:01.580045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127a4cd700 of size 81920000 next 323\n",
      "2023-09-22 01:58:01.580055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127f2ed700 of size 81920000 next 1470\n",
      "2023-09-22 01:58:01.580062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f128410d700 of size 81920000 next 1007\n",
      "2023-09-22 01:58:01.580067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1288f2d700 of size 327680000 next 168\n",
      "2023-09-22 01:58:01.580071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f129c7ad700 of size 327680000 next 1069\n",
      "2023-09-22 01:58:01.580076: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12b002d700 of size 436527616 next 41\n",
      "2023-09-22 01:58:01.580084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ca07b900 of size 32768 next 1202\n",
      "2023-09-22 01:58:01.580088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ca083900 of size 48128 next 216\n",
      "2023-09-22 01:58:01.580092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ca08f500 of size 524288 next 366\n",
      "2023-09-22 01:58:01.580097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ca10f500 of size 524288 next 819\n",
      "2023-09-22 01:58:01.580101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ca18f500 of size 524288 next 736\n",
      "2023-09-22 01:58:01.580105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ca20f500 of size 524288 next 604\n",
      "2023-09-22 01:58:01.580110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ca28f500 of size 41451520 next 831\n",
      "2023-09-22 01:58:01.580114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cca17500 of size 48384 next 46\n",
      "2023-09-22 01:58:01.580118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cca23200 of size 524288 next 1604\n",
      "2023-09-22 01:58:01.580122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ccaa3200 of size 850944 next 1129\n",
      "2023-09-22 01:58:01.580127: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ccb72e00 of size 256 next 491\n",
      "2023-09-22 01:58:01.580131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ccb72f00 of size 256 next 632\n",
      "2023-09-22 01:58:01.580135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ccb73000 of size 81920000 next 1323\n",
      "2023-09-22 01:58:01.580140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12d1993000 of size 81920000 next 321\n",
      "2023-09-22 01:58:01.580144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12d67b3000 of size 108409600 next 863\n",
      "2023-09-22 01:58:01.580148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16300 of size 256 next 867\n",
      "2023-09-22 01:58:01.580152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16400 of size 4096 next 1519\n",
      "2023-09-22 01:58:01.580156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17400 of size 4096 next 824\n",
      "2023-09-22 01:58:01.580161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18400 of size 256 next 1490\n",
      "2023-09-22 01:58:01.580165: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18500 of size 256 next 1111\n",
      "2023-09-22 01:58:01.580169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18600 of size 147456 next 985\n",
      "2023-09-22 01:58:01.580173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf3c600 of size 287744 next 669\n",
      "2023-09-22 01:58:01.580178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82a00 of size 256 next 785\n",
      "2023-09-22 01:58:01.580182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82b00 of size 256 next 672\n",
      "2023-09-22 01:58:01.580186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82c00 of size 256 next 296\n",
      "2023-09-22 01:58:01.580190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82d00 of size 256 next 674\n",
      "2023-09-22 01:58:01.580194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82e00 of size 768 next 448\n",
      "2023-09-22 01:58:01.580198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83100 of size 256 next 1678\n",
      "2023-09-22 01:58:01.580202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83200 of size 256 next 467\n",
      "2023-09-22 01:58:01.580205: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83300 of size 256 next 792\n",
      "2023-09-22 01:58:01.580209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83400 of size 256 next 1183\n",
      "2023-09-22 01:58:01.580212: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83500 of size 256 next 219\n",
      "2023-09-22 01:58:01.580215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83600 of size 256 next 872\n",
      "2023-09-22 01:58:01.580219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83700 of size 256 next 268\n",
      "2023-09-22 01:58:01.580222: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83800 of size 256 next 790\n",
      "2023-09-22 01:58:01.580225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83900 of size 256 next 585\n",
      "2023-09-22 01:58:01.580229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83a00 of size 256 next 551\n",
      "2023-09-22 01:58:01.580232: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83b00 of size 256 next 910\n",
      "2023-09-22 01:58:01.580236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83c00 of size 81920000 next 419\n",
      "2023-09-22 01:58:01.580239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e1da3c00 of size 81920000 next 1542\n",
      "2023-09-22 01:58:01.580243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e6bc3c00 of size 104645888 next 1709\n",
      "2023-09-22 01:58:01.580246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ecf90100 of size 147456 next 1028\n",
      "2023-09-22 01:58:01.580250: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ecfb4100 of size 147456 next 1362\n",
      "2023-09-22 01:58:01.580253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ecfd8100 of size 229376 next 827\n",
      "2023-09-22 01:58:01.580257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed010100 of size 524288 next 124\n",
      "2023-09-22 01:58:01.580260: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed090100 of size 532480 next 534\n",
      "2023-09-22 01:58:01.580263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed112100 of size 524288 next 17\n",
      "2023-09-22 01:58:01.580267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed192100 of size 532480 next 983\n",
      "2023-09-22 01:58:01.580270: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed214100 of size 524288 next 1378\n",
      "2023-09-22 01:58:01.580274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed294100 of size 532480 next 1381\n",
      "2023-09-22 01:58:01.580277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed316100 of size 524288 next 1274\n",
      "2023-09-22 01:58:01.580280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed396100 of size 659456 next 175\n",
      "2023-09-22 01:58:01.580288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed437100 of size 524288 next 311\n",
      "2023-09-22 01:58:01.580291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4b7100 of size 32768 next 208\n",
      "2023-09-22 01:58:01.580295: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4bf100 of size 32768 next 368\n",
      "2023-09-22 01:58:01.580298: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4c7100 of size 32768 next 1011\n",
      "2023-09-22 01:58:01.580302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4cf100 of size 32768 next 1478\n",
      "2023-09-22 01:58:01.580305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4d7100 of size 27648 next 1648\n",
      "2023-09-22 01:58:01.580309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4ddd00 of size 27648 next 1414\n",
      "2023-09-22 01:58:01.580312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4e4900 of size 16384 next 1260\n",
      "2023-09-22 01:58:01.580316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4e8900 of size 16384 next 1193\n",
      "2023-09-22 01:58:01.580319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4ec900 of size 21248 next 63\n",
      "2023-09-22 01:58:01.580323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4f1c00 of size 33792 next 1229\n",
      "2023-09-22 01:58:01.580326: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed4fa000 of size 59648 next 642\n",
      "2023-09-22 01:58:01.580330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed508900 of size 32768 next 1613\n",
      "2023-09-22 01:58:01.580333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed510900 of size 49152 next 312\n",
      "2023-09-22 01:58:01.580337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed51c900 of size 32768 next 1112\n",
      "2023-09-22 01:58:01.580341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed524900 of size 41472 next 1665\n",
      "2023-09-22 01:58:01.580344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed52eb00 of size 4096 next 1699\n",
      "2023-09-22 01:58:01.580348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed52fb00 of size 2048 next 1734\n",
      "2023-09-22 01:58:01.580351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed530300 of size 2048 next 1701\n",
      "2023-09-22 01:58:01.580355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed530b00 of size 2048 next 1054\n",
      "2023-09-22 01:58:01.580358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed531300 of size 2048 next 1420\n",
      "2023-09-22 01:58:01.580361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed531b00 of size 4096 next 1534\n",
      "2023-09-22 01:58:01.580365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed532b00 of size 4096 next 1152\n",
      "2023-09-22 01:58:01.580368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed533b00 of size 4096 next 1724\n",
      "2023-09-22 01:58:01.580372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed534b00 of size 6656 next 356\n",
      "2023-09-22 01:58:01.580375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed536500 of size 4096 next 129\n",
      "2023-09-22 01:58:01.580379: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed537500 of size 7168 next 1263\n",
      "2023-09-22 01:58:01.580382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed539100 of size 524288 next 325\n",
      "2023-09-22 01:58:01.580386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed5b9100 of size 532480 next 720\n",
      "2023-09-22 01:58:01.580389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed63b100 of size 524288 next 488\n",
      "2023-09-22 01:58:01.580393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed6bb100 of size 532480 next 937\n",
      "2023-09-22 01:58:01.580396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed73d100 of size 524288 next 1228\n",
      "2023-09-22 01:58:01.580399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed7bd100 of size 524288 next 452\n",
      "2023-09-22 01:58:01.580403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed83d100 of size 662016 next 1540\n",
      "2023-09-22 01:58:01.580406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed8deb00 of size 532480 next 1249\n",
      "2023-09-22 01:58:01.580410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed960b00 of size 524288 next 1524\n",
      "2023-09-22 01:58:01.580413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ed9e0b00 of size 524288 next 629\n",
      "2023-09-22 01:58:01.580417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12eda60b00 of size 532480 next 486\n",
      "2023-09-22 01:58:01.580420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edae2b00 of size 532480 next 307\n",
      "2023-09-22 01:58:01.580423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edb64b00 of size 524288 next 1034\n",
      "2023-09-22 01:58:01.580427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edbe4b00 of size 524288 next 113\n",
      "2023-09-22 01:58:01.580430: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edc64b00 of size 662016 next 1443\n",
      "2023-09-22 01:58:01.580434: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edd06500 of size 524288 next 1033\n",
      "2023-09-22 01:58:01.580437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edd86500 of size 532480 next 515\n",
      "2023-09-22 01:58:01.580440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ede08500 of size 524288 next 1123\n",
      "2023-09-22 01:58:01.580444: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ede88500 of size 532480 next 1606\n",
      "2023-09-22 01:58:01.580447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edf0a500 of size 524288 next 1089\n",
      "2023-09-22 01:58:01.580451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12edf8a500 of size 532480 next 1173\n",
      "2023-09-22 01:58:01.580454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee00c500 of size 997632 next 1082\n",
      "2023-09-22 01:58:01.580457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0ffe00 of size 256 next 407\n",
      "2023-09-22 01:58:01.580461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fff00 of size 256 next 826\n",
      "2023-09-22 01:58:01.580464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100000 of size 512 next 1667\n",
      "2023-09-22 01:58:01.580468: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100200 of size 256 next 666\n",
      "2023-09-22 01:58:01.580471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100300 of size 256 next 1164\n",
      "2023-09-22 01:58:01.580474: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100400 of size 256 next 1290\n",
      "2023-09-22 01:58:01.580478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100500 of size 256 next 1475\n",
      "2023-09-22 01:58:01.580481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100600 of size 256 next 1469\n",
      "2023-09-22 01:58:01.580485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100700 of size 256 next 677\n",
      "2023-09-22 01:58:01.580488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100800 of size 256 next 1536\n",
      "2023-09-22 01:58:01.580491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100900 of size 256 next 1404\n",
      "2023-09-22 01:58:01.580495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100a00 of size 256 next 297\n",
      "2023-09-22 01:58:01.580498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100b00 of size 256 next 1029\n",
      "2023-09-22 01:58:01.580501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100c00 of size 256 next 424\n",
      "2023-09-22 01:58:01.580505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100d00 of size 256 next 944\n",
      "2023-09-22 01:58:01.580508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100e00 of size 512 next 611\n",
      "2023-09-22 01:58:01.580511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101000 of size 256 next 1279\n",
      "2023-09-22 01:58:01.580515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101100 of size 256 next 892\n",
      "2023-09-22 01:58:01.580518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101200 of size 524288 next 1638\n",
      "2023-09-22 01:58:01.580522: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee181200 of size 524288 next 1735\n",
      "2023-09-22 01:58:01.580525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee201200 of size 524288 next 535\n",
      "2023-09-22 01:58:01.580528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee281200 of size 524288 next 298\n",
      "2023-09-22 01:58:01.580532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee301200 of size 524288 next 644\n",
      "2023-09-22 01:58:01.580535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee381200 of size 524288 next 1218\n",
      "2023-09-22 01:58:01.580539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee401200 of size 990720 next 1506\n",
      "2023-09-22 01:58:01.580544: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3000 of size 256 next 603\n",
      "2023-09-22 01:58:01.580548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3100 of size 256 next 475\n",
      "2023-09-22 01:58:01.580551: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3200 of size 256 next 997\n",
      "2023-09-22 01:58:01.580555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3300 of size 256 next 266\n",
      "2023-09-22 01:58:01.580558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3400 of size 256 next 755\n",
      "2023-09-22 01:58:01.580561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3500 of size 256 next 885\n",
      "2023-09-22 01:58:01.580565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3600 of size 256 next 684\n",
      "2023-09-22 01:58:01.580568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3700 of size 256 next 964\n",
      "2023-09-22 01:58:01.580571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3800 of size 512 next 1462\n",
      "2023-09-22 01:58:01.580575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3a00 of size 512 next 1031\n",
      "2023-09-22 01:58:01.580578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3c00 of size 256 next 188\n",
      "2023-09-22 01:58:01.580581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3d00 of size 256 next 1599\n",
      "2023-09-22 01:58:01.580585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3e00 of size 512 next 1072\n",
      "2023-09-22 01:58:01.580588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4000 of size 256 next 774\n",
      "2023-09-22 01:58:01.580591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4100 of size 512 next 1721\n",
      "2023-09-22 01:58:01.580595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4300 of size 768 next 717\n",
      "2023-09-22 01:58:01.580598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4600 of size 512 next 191\n",
      "2023-09-22 01:58:01.580601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4800 of size 512 next 458\n",
      "2023-09-22 01:58:01.580605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4a00 of size 512 next 692\n",
      "2023-09-22 01:58:01.580609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4c00 of size 32768 next 663\n",
      "2023-09-22 01:58:01.580612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4fcc00 of size 33792 next 239\n",
      "2023-09-22 01:58:01.580615: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505000 of size 256 next 1150\n",
      "2023-09-22 01:58:01.580619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505100 of size 524288 next 1652\n",
      "2023-09-22 01:58:01.580622: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee585100 of size 524288 next 1608\n",
      "2023-09-22 01:58:01.580625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee605100 of size 524288 next 1405\n",
      "2023-09-22 01:58:01.580629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee685100 of size 262144 next 318\n",
      "2023-09-22 01:58:01.580632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee6c5100 of size 262144 next 784\n",
      "2023-09-22 01:58:01.580636: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee705100 of size 262144 next 602\n",
      "2023-09-22 01:58:01.580639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee745100 of size 262144 next 1442\n",
      "2023-09-22 01:58:01.580642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee785100 of size 262144 next 1171\n",
      "2023-09-22 01:58:01.580646: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c5100 of size 262144 next 402\n",
      "2023-09-22 01:58:01.580649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee805100 of size 507136 next 1601\n",
      "2023-09-22 01:58:01.580653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880e00 of size 256 next 1389\n",
      "2023-09-22 01:58:01.580656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880f00 of size 101765376 next 1664\n",
      "2023-09-22 01:58:01.580660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498e000 of size 4096 next 1107\n",
      "2023-09-22 01:58:01.580663: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f498f000 of size 4096 next 722\n",
      "2023-09-22 01:58:01.580667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4990000 of size 4608 next 1617\n",
      "2023-09-22 01:58:01.580670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4991200 of size 512 next 907\n",
      "2023-09-22 01:58:01.580674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4991400 of size 512 next 633\n",
      "2023-09-22 01:58:01.580677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4991600 of size 512 next 648\n",
      "2023-09-22 01:58:01.580680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4991800 of size 512 next 888\n",
      "2023-09-22 01:58:01.580684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4991a00 of size 512 next 1042\n",
      "2023-09-22 01:58:01.580687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4991c00 of size 512 next 1489\n",
      "2023-09-22 01:58:01.580690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4991e00 of size 512 next 1600\n",
      "2023-09-22 01:58:01.580694: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4992000 of size 512 next 794\n",
      "2023-09-22 01:58:01.580697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4992200 of size 512 next 833\n",
      "2023-09-22 01:58:01.580700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4992400 of size 4352 next 234\n",
      "2023-09-22 01:58:01.580704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4993500 of size 262144 next 1655\n",
      "2023-09-22 01:58:01.580707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f49d3500 of size 262144 next 1726\n",
      "2023-09-22 01:58:01.580711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4a13500 of size 262144 next 263\n",
      "2023-09-22 01:58:01.580714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4a53500 of size 262144 next 215\n",
      "2023-09-22 01:58:01.580718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4a93500 of size 262144 next 11\n",
      "2023-09-22 01:58:01.580721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4ad3500 of size 262144 next 1714\n",
      "2023-09-22 01:58:01.580724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4b13500 of size 262144 next 1491\n",
      "2023-09-22 01:58:01.580728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4b53500 of size 262144 next 413\n",
      "2023-09-22 01:58:01.580731: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4b93500 of size 262144 next 476\n",
      "2023-09-22 01:58:01.580735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd3500 of size 16384 next 1019\n",
      "2023-09-22 01:58:01.580738: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7500 of size 256 next 1521\n",
      "2023-09-22 01:58:01.580741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7600 of size 256 next 457\n",
      "2023-09-22 01:58:01.580745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7700 of size 256 next 528\n",
      "2023-09-22 01:58:01.580748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7800 of size 256 next 1559\n",
      "2023-09-22 01:58:01.580752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7900 of size 256 next 891\n",
      "2023-09-22 01:58:01.580755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7a00 of size 256 next 587\n",
      "2023-09-22 01:58:01.580758: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7b00 of size 256 next 255\n",
      "2023-09-22 01:58:01.580762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7c00 of size 256 next 1003\n",
      "2023-09-22 01:58:01.580765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7d00 of size 256 next 1148\n",
      "2023-09-22 01:58:01.580768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7e00 of size 256 next 593\n",
      "2023-09-22 01:58:01.580772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd7f00 of size 256 next 947\n",
      "2023-09-22 01:58:01.580775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8000 of size 256 next 843\n",
      "2023-09-22 01:58:01.580779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8100 of size 256 next 1458\n",
      "2023-09-22 01:58:01.580782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8200 of size 256 next 979\n",
      "2023-09-22 01:58:01.580785: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8300 of size 256 next 133\n",
      "2023-09-22 01:58:01.580789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8400 of size 256 next 1322\n",
      "2023-09-22 01:58:01.580792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8500 of size 256 next 554\n",
      "2023-09-22 01:58:01.580795: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8600 of size 256 next 1496\n",
      "2023-09-22 01:58:01.580799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8700 of size 256 next 398\n",
      "2023-09-22 01:58:01.580802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8800 of size 256 next 742\n",
      "2023-09-22 01:58:01.580806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8900 of size 256 next 975\n",
      "2023-09-22 01:58:01.580809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8a00 of size 256 next 1349\n",
      "2023-09-22 01:58:01.580812: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8b00 of size 256 next 517\n",
      "2023-09-22 01:58:01.580816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8c00 of size 256 next 1583\n",
      "2023-09-22 01:58:01.580819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8d00 of size 256 next 1459\n",
      "2023-09-22 01:58:01.580822: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8e00 of size 256 next 923\n",
      "2023-09-22 01:58:01.580826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8f00 of size 512 next 744\n",
      "2023-09-22 01:58:01.580829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9100 of size 256 next 1428\n",
      "2023-09-22 01:58:01.580833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9200 of size 256 next 394\n",
      "2023-09-22 01:58:01.580836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9300 of size 256 next 609\n",
      "2023-09-22 01:58:01.580839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9400 of size 256 next 274\n",
      "2023-09-22 01:58:01.580843: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9500 of size 256 next 418\n",
      "2023-09-22 01:58:01.580846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9600 of size 256 next 870\n",
      "2023-09-22 01:58:01.580850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9700 of size 256 next 228\n",
      "2023-09-22 01:58:01.580853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9800 of size 256 next 120\n",
      "2023-09-22 01:58:01.580856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9900 of size 256 next 1122\n",
      "2023-09-22 01:58:01.580860: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9a00 of size 256 next 1342\n",
      "2023-09-22 01:58:01.580863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9b00 of size 256 next 1651\n",
      "2023-09-22 01:58:01.580867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9c00 of size 256 next 141\n",
      "2023-09-22 01:58:01.580870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9d00 of size 256 next 804\n",
      "2023-09-22 01:58:01.580873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9e00 of size 256 next 1493\n",
      "2023-09-22 01:58:01.580877: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd9f00 of size 256 next 1594\n",
      "2023-09-22 01:58:01.580880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bda000 of size 256 next 1448\n",
      "2023-09-22 01:58:01.580883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bda100 of size 256 next 481\n",
      "2023-09-22 01:58:01.580887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bda200 of size 256 next 1517\n",
      "2023-09-22 01:58:01.580890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bda300 of size 256 next 1282\n",
      "2023-09-22 01:58:01.580893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f4bda400 of size 256 next 950\n",
      "2023-09-22 01:58:01.580897: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bda500 of size 256 next 874\n",
      "2023-09-22 01:58:01.580900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bda600 of size 256 next 1522\n",
      "2023-09-22 01:58:01.580903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f4bda700 of size 177152 next 1618\n",
      "2023-09-22 01:58:01.580907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4c05b00 of size 256 next 1673\n",
      "2023-09-22 01:58:01.580910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4c05c00 of size 256 next 1022\n",
      "2023-09-22 01:58:01.580914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4c05d00 of size 640000 next 1416\n",
      "2023-09-22 01:58:01.580917: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4ca2100 of size 640000 next 1310\n",
      "2023-09-22 01:58:01.580921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4d3e500 of size 640000 next 963\n",
      "2023-09-22 01:58:01.580924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4dda900 of size 640000 next 436\n",
      "2023-09-22 01:58:01.580928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4e76d00 of size 640000 next 1086\n",
      "2023-09-22 01:58:01.580931: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4f13100 of size 640000 next 337\n",
      "2023-09-22 01:58:01.580934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4faf500 of size 640000 next 753\n",
      "2023-09-22 01:58:01.580938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f504b900 of size 640000 next 201\n",
      "2023-09-22 01:58:01.580941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f50e7d00 of size 1694976 next 1417\n",
      "2023-09-22 01:58:01.580945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5285a00 of size 524288 next 339\n",
      "2023-09-22 01:58:01.580948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5305a00 of size 784640 next 967\n",
      "2023-09-22 01:58:01.580952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f53c5300 of size 524288 next 698\n",
      "2023-09-22 01:58:01.580955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5445300 of size 524288 next 1746\n",
      "2023-09-22 01:58:01.580958: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f54c5300 of size 524288 next 119\n",
      "2023-09-22 01:58:01.580962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5545300 of size 655872 next 434\n",
      "2023-09-22 01:58:01.580965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f55e5500 of size 524288 next 505\n",
      "2023-09-22 01:58:01.580969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5665500 of size 830208 next 220\n",
      "2023-09-22 01:58:01.580972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5730000 of size 524288 next 382\n",
      "2023-09-22 01:58:01.580976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f57b0000 of size 561152 next 430\n",
      "2023-09-22 01:58:01.580983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5839000 of size 524288 next 1371\n",
      "2023-09-22 01:58:01.580986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f58b9000 of size 532480 next 678\n",
      "2023-09-22 01:58:01.580990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f593b000 of size 524288 next 631\n",
      "2023-09-22 01:58:01.580993: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f59bb000 of size 601088 next 544\n",
      "2023-09-22 01:58:01.580996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a4dc00 of size 32768 next 1163\n",
      "2023-09-22 01:58:01.581000: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a55c00 of size 512 next 341\n",
      "2023-09-22 01:58:01.581003: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a55e00 of size 512 next 20\n",
      "2023-09-22 01:58:01.581007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56000 of size 512 next 680\n",
      "2023-09-22 01:58:01.581010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56200 of size 512 next 396\n",
      "2023-09-22 01:58:01.581014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56400 of size 512 next 675\n",
      "2023-09-22 01:58:01.581017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56600 of size 512 next 845\n",
      "2023-09-22 01:58:01.581020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56800 of size 512 next 27\n",
      "2023-09-22 01:58:01.581024: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56a00 of size 512 next 685\n",
      "2023-09-22 01:58:01.581027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56c00 of size 512 next 860\n",
      "2023-09-22 01:58:01.581031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a56e00 of size 512 next 1466\n",
      "2023-09-22 01:58:01.581034: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a57000 of size 512 next 1077\n",
      "2023-09-22 01:58:01.581037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a57200 of size 512 next 822\n",
      "2023-09-22 01:58:01.581041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a57400 of size 512 next 1528\n",
      "2023-09-22 01:58:01.581044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a57600 of size 512 next 541\n",
      "2023-09-22 01:58:01.581047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a57800 of size 4096 next 743\n",
      "2023-09-22 01:58:01.581051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a58800 of size 4096 next 1584\n",
      "2023-09-22 01:58:01.581054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a59800 of size 4096 next 1632\n",
      "2023-09-22 01:58:01.581058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5a800 of size 2048 next 795\n",
      "2023-09-22 01:58:01.581061: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5b000 of size 512 next 159\n",
      "2023-09-22 01:58:01.581064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5b200 of size 512 next 1503\n",
      "2023-09-22 01:58:01.581068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5b400 of size 256 next 204\n",
      "2023-09-22 01:58:01.581071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5b500 of size 768 next 154\n",
      "2023-09-22 01:58:01.581074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5b800 of size 4096 next 1137\n",
      "2023-09-22 01:58:01.581078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5c800 of size 5632 next 1603\n",
      "2023-09-22 01:58:01.581081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a5de00 of size 32768 next 991\n",
      "2023-09-22 01:58:01.581085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a65e00 of size 36864 next 224\n",
      "2023-09-22 01:58:01.581088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a6ee00 of size 256 next 573\n",
      "2023-09-22 01:58:01.581091: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a6ef00 of size 256 next 1549\n",
      "2023-09-22 01:58:01.581095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f5a6f000 of size 256 next 930\n",
      "2023-09-22 01:58:01.581098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12f5a6f100 of size 11770368 next 161\n",
      "2023-09-22 01:58:01.581102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f65a8b00 of size 512 next 1329\n",
      "2023-09-22 01:58:01.581105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f65a8d00 of size 26175744 next 932\n",
      "2023-09-22 01:58:01.581109: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f600 of size 256 next 101\n",
      "2023-09-22 01:58:01.581112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f700 of size 256 next 761\n",
      "2023-09-22 01:58:01.581116: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f800 of size 39062528 next 657\n",
      "2023-09-22 01:58:01.581119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0400 of size 256 next 1326\n",
      "2023-09-22 01:58:01.581122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0500 of size 6912 next 1580\n",
      "2023-09-22 01:58:01.581126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2000 of size 512 next 567\n",
      "2023-09-22 01:58:01.581130: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2200 of size 512 next 916\n",
      "2023-09-22 01:58:01.581133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2400 of size 512 next 1141\n",
      "2023-09-22 01:58:01.581136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2600 of size 512 next 651\n",
      "2023-09-22 01:58:01.581140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2800 of size 512 next 144\n",
      "2023-09-22 01:58:01.581143: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2a00 of size 512 next 137\n",
      "2023-09-22 01:58:01.581146: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2c00 of size 512 next 1415\n",
      "2023-09-22 01:58:01.581150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e2e00 of size 512 next 592\n",
      "2023-09-22 01:58:01.581153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3000 of size 512 next 733\n",
      "2023-09-22 01:58:01.581156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3200 of size 512 next 1394\n",
      "2023-09-22 01:58:01.581160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3400 of size 512 next 1158\n",
      "2023-09-22 01:58:01.581163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3600 of size 512 next 328\n",
      "2023-09-22 01:58:01.581167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3800 of size 512 next 1575\n",
      "2023-09-22 01:58:01.581170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3a00 of size 512 next 1579\n",
      "2023-09-22 01:58:01.581173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3c00 of size 512 next 1236\n",
      "2023-09-22 01:58:01.581177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e3e00 of size 512 next 1720\n",
      "2023-09-22 01:58:01.581180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4000 of size 512 next 1113\n",
      "2023-09-22 01:58:01.581184: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4200 of size 512 next 1142\n",
      "2023-09-22 01:58:01.581187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4400 of size 512 next 432\n",
      "2023-09-22 01:58:01.581191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4600 of size 512 next 499\n",
      "2023-09-22 01:58:01.581194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4800 of size 512 next 1097\n",
      "2023-09-22 01:58:01.581197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4a00 of size 512 next 994\n",
      "2023-09-22 01:58:01.581201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4c00 of size 512 next 1541\n",
      "2023-09-22 01:58:01.581204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e4e00 of size 512 next 90\n",
      "2023-09-22 01:58:01.581207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5000 of size 512 next 1708\n",
      "2023-09-22 01:58:01.581211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5200 of size 512 next 1052\n",
      "2023-09-22 01:58:01.581214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5400 of size 512 next 1554\n",
      "2023-09-22 01:58:01.581218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5600 of size 512 next 903\n",
      "2023-09-22 01:58:01.581221: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5800 of size 768 next 1384\n",
      "2023-09-22 01:58:01.581224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5b00 of size 512 next 766\n",
      "2023-09-22 01:58:01.581228: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5d00 of size 512 next 353\n",
      "2023-09-22 01:58:01.581231: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e5f00 of size 512 next 1403\n",
      "2023-09-22 01:58:01.581235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6100 of size 512 next 147\n",
      "2023-09-22 01:58:01.581238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6300 of size 512 next 934\n",
      "2023-09-22 01:58:01.581241: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6500 of size 512 next 969\n",
      "2023-09-22 01:58:01.581245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6700 of size 512 next 1252\n",
      "2023-09-22 01:58:01.581248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6900 of size 512 next 7\n",
      "2023-09-22 01:58:01.581252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6b00 of size 512 next 1039\n",
      "2023-09-22 01:58:01.581255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6d00 of size 512 next 1344\n",
      "2023-09-22 01:58:01.581258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e6f00 of size 5632 next 1117\n",
      "2023-09-22 01:58:01.581262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8500 of size 512 next 1108\n",
      "2023-09-22 01:58:01.581265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8700 of size 512 next 371\n",
      "2023-09-22 01:58:01.581269: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8900 of size 256 next 1300\n",
      "2023-09-22 01:58:01.581272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8a00 of size 256 next 1238\n",
      "2023-09-22 01:58:01.581275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8b00 of size 256 next 66\n",
      "2023-09-22 01:58:01.581279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8c00 of size 256 next 570\n",
      "2023-09-22 01:58:01.581282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8d00 of size 256 next 1690\n",
      "2023-09-22 01:58:01.581286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8e00 of size 256 next 408\n",
      "2023-09-22 01:58:01.581289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e8f00 of size 256 next 1666\n",
      "2023-09-22 01:58:01.581293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9000 of size 256 next 600\n",
      "2023-09-22 01:58:01.581296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9100 of size 256 next 1001\n",
      "2023-09-22 01:58:01.581300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9200 of size 256 next 437\n",
      "2023-09-22 01:58:01.581303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9300 of size 256 next 1321\n",
      "2023-09-22 01:58:01.581306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9400 of size 256 next 344\n",
      "2023-09-22 01:58:01.581310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9500 of size 256 next 614\n",
      "2023-09-22 01:58:01.581313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9600 of size 256 next 1156\n",
      "2023-09-22 01:58:01.581317: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9700 of size 256 next 439\n",
      "2023-09-22 01:58:01.581320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9800 of size 256 next 793\n",
      "2023-09-22 01:58:01.581323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9900 of size 256 next 1336\n",
      "2023-09-22 01:58:01.581327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9a00 of size 512 next 1526\n",
      "2023-09-22 01:58:01.581330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9c00 of size 512 next 167\n",
      "2023-09-22 01:58:01.581334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e9e00 of size 768 next 1523\n",
      "2023-09-22 01:58:01.581337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3ea100 of size 287744 next 1205\n",
      "2023-09-22 01:58:01.581340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa430500 of size 27648 next 1309\n",
      "2023-09-22 01:58:01.581344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa437100 of size 27648 next 1083\n",
      "2023-09-22 01:58:01.581347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa43dd00 of size 27648 next 957\n",
      "2023-09-22 01:58:01.581351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa444900 of size 35840 next 1180\n",
      "2023-09-22 01:58:01.581354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa44d500 of size 4096 next 1492\n",
      "2023-09-22 01:58:01.581358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa44e500 of size 4096 next 641\n",
      "2023-09-22 01:58:01.581361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa44f500 of size 4096 next 1043\n",
      "2023-09-22 01:58:01.581365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa450500 of size 4096 next 653\n",
      "2023-09-22 01:58:01.581368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa451500 of size 4096 next 470\n",
      "2023-09-22 01:58:01.581371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa452500 of size 4096 next 958\n",
      "2023-09-22 01:58:01.581375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa453500 of size 4096 next 308\n",
      "2023-09-22 01:58:01.581378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454500 of size 512 next 290\n",
      "2023-09-22 01:58:01.581381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454700 of size 512 next 1747\n",
      "2023-09-22 01:58:01.581385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454900 of size 256 next 244\n",
      "2023-09-22 01:58:01.581388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454a00 of size 256 next 1345\n",
      "2023-09-22 01:58:01.581391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454b00 of size 256 next 708\n",
      "2023-09-22 01:58:01.581395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454c00 of size 256 next 702\n",
      "2023-09-22 01:58:01.581398: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454d00 of size 512 next 540\n",
      "2023-09-22 01:58:01.581402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454f00 of size 512 next 816\n",
      "2023-09-22 01:58:01.581405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa455100 of size 768 next 539\n",
      "2023-09-22 01:58:01.581408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa455400 of size 256 next 565\n",
      "2023-09-22 01:58:01.581412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa455500 of size 4096 next 1641\n",
      "2023-09-22 01:58:01.581415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa456500 of size 4096 next 75\n",
      "2023-09-22 01:58:01.581419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa457500 of size 4096 next 1627\n",
      "2023-09-22 01:58:01.581422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa458500 of size 4096 next 462\n",
      "2023-09-22 01:58:01.581425: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa459500 of size 4096 next 1032\n",
      "2023-09-22 01:58:01.581429: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa45a500 of size 4096 next 902\n",
      "2023-09-22 01:58:01.581432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa45b500 of size 4096 next 401\n",
      "2023-09-22 01:58:01.581435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa45c500 of size 32768 next 750\n",
      "2023-09-22 01:58:01.581439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa464500 of size 32768 next 650\n",
      "2023-09-22 01:58:01.581442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa46c500 of size 267264 next 1590\n",
      "2023-09-22 01:58:01.581446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ad900 of size 256 next 319\n",
      "2023-09-22 01:58:01.581449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ada00 of size 256 next 783\n",
      "2023-09-22 01:58:01.581452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4adb00 of size 32768 next 1036\n",
      "2023-09-22 01:58:01.581456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4b5b00 of size 32768 next 729\n",
      "2023-09-22 01:58:01.581460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4bdb00 of size 32768 next 77\n",
      "2023-09-22 01:58:01.581463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4c5b00 of size 32768 next 900\n",
      "2023-09-22 01:58:01.581466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4cdb00 of size 16384 next 526\n",
      "2023-09-22 01:58:01.581470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d1b00 of size 16384 next 1631\n",
      "2023-09-22 01:58:01.581473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d5b00 of size 2048 next 714\n",
      "2023-09-22 01:58:01.581477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d6300 of size 2048 next 1532\n",
      "2023-09-22 01:58:01.581480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d6b00 of size 2048 next 272\n",
      "2023-09-22 01:58:01.581483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d7300 of size 2048 next 850\n",
      "2023-09-22 01:58:01.581487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d7b00 of size 2048 next 1341\n",
      "2023-09-22 01:58:01.581490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d8300 of size 512 next 1433\n",
      "2023-09-22 01:58:01.581494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d8500 of size 512 next 919\n",
      "2023-09-22 01:58:01.581497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d8700 of size 512 next 198\n",
      "2023-09-22 01:58:01.581501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d8900 of size 512 next 1118\n",
      "2023-09-22 01:58:01.581504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d8b00 of size 512 next 1622\n",
      "2023-09-22 01:58:01.581508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d8d00 of size 512 next 1598\n",
      "2023-09-22 01:58:01.581511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4d8f00 of size 16384 next 829\n",
      "2023-09-22 01:58:01.581514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4dcf00 of size 16384 next 599\n",
      "2023-09-22 01:58:01.581518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e0f00 of size 256 next 346\n",
      "2023-09-22 01:58:01.581521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e1000 of size 256 next 1197\n",
      "2023-09-22 01:58:01.581525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e1100 of size 16384 next 1241\n",
      "2023-09-22 01:58:01.581528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e5100 of size 16384 next 67\n",
      "2023-09-22 01:58:01.581532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e9100 of size 512 next 1080\n",
      "2023-09-22 01:58:01.581535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e9300 of size 512 next 1340\n",
      "2023-09-22 01:58:01.581538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e9500 of size 512 next 1643\n",
      "2023-09-22 01:58:01.581542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e9700 of size 512 next 480\n",
      "2023-09-22 01:58:01.581545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e9900 of size 512 next 878\n",
      "2023-09-22 01:58:01.581549: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e9b00 of size 512 next 1374\n",
      "2023-09-22 01:58:01.581552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4e9d00 of size 2048 next 54\n",
      "2023-09-22 01:58:01.581555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ea500 of size 2048 next 1038\n",
      "2023-09-22 01:58:01.581559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ead00 of size 2048 next 738\n",
      "2023-09-22 01:58:01.581562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4eb500 of size 2048 next 626\n",
      "2023-09-22 01:58:01.581565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ebd00 of size 2048 next 386\n",
      "2023-09-22 01:58:01.581569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ec500 of size 2048 next 1204\n",
      "2023-09-22 01:58:01.581572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ecd00 of size 512 next 869\n",
      "2023-09-22 01:58:01.581576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ecf00 of size 512 next 1144\n",
      "2023-09-22 01:58:01.581579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ed100 of size 512 next 331\n",
      "2023-09-22 01:58:01.581582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ed300 of size 512 next 1280\n",
      "2023-09-22 01:58:01.581586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ed500 of size 512 next 676\n",
      "2023-09-22 01:58:01.581589: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ed700 of size 512 next 1103\n",
      "2023-09-22 01:58:01.581593: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ed900 of size 16384 next 58\n",
      "2023-09-22 01:58:01.581596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4f1900 of size 16384 next 378\n",
      "2023-09-22 01:58:01.581599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4f5900 of size 256 next 1353\n",
      "2023-09-22 01:58:01.581603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4f5a00 of size 256 next 1357\n",
      "2023-09-22 01:58:01.581606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4f5b00 of size 16384 next 334\n",
      "2023-09-22 01:58:01.581610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4f9b00 of size 16384 next 192\n",
      "2023-09-22 01:58:01.581613: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fdb00 of size 512 next 670\n",
      "2023-09-22 01:58:01.581616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fdd00 of size 512 next 1330\n",
      "2023-09-22 01:58:01.581620: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fdf00 of size 512 next 1208\n",
      "2023-09-22 01:58:01.581623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fe100 of size 512 next 1315\n",
      "2023-09-22 01:58:01.581626: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fe300 of size 512 next 955\n",
      "2023-09-22 01:58:01.581630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fe500 of size 512 next 1399\n",
      "2023-09-22 01:58:01.581633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4fe700 of size 29696 next 172\n",
      "2023-09-22 01:58:01.581637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa505b00 of size 234496 next 1079\n",
      "2023-09-22 01:58:01.581641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa53ef00 of size 55296 next 55\n",
      "2023-09-22 01:58:01.581648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa54c700 of size 27648 next 1672\n",
      "2023-09-22 01:58:01.581652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa553300 of size 512 next 1248\n",
      "2023-09-22 01:58:01.581655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa553500 of size 512 next 596\n",
      "2023-09-22 01:58:01.581659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa553700 of size 512 next 1219\n",
      "2023-09-22 01:58:01.581662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa553900 of size 512 next 1635\n",
      "2023-09-22 01:58:01.581665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa553b00 of size 512 next 65\n",
      "2023-09-22 01:58:01.581669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa553d00 of size 512 next 968\n",
      "2023-09-22 01:58:01.581672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa553f00 of size 512 next 59\n",
      "2023-09-22 01:58:01.581676: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa554100 of size 512 next 1092\n",
      "2023-09-22 01:58:01.581679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa554300 of size 512 next 1657\n",
      "2023-09-22 01:58:01.581683: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa554500 of size 512 next 1131\n",
      "2023-09-22 01:58:01.581686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa554700 of size 512 next 1060\n",
      "2023-09-22 01:58:01.581690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa554900 of size 768 next 545\n",
      "2023-09-22 01:58:01.581693: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa554c00 of size 512 next 1379\n",
      "2023-09-22 01:58:01.581696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa554e00 of size 512 next 51\n",
      "2023-09-22 01:58:01.581700: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555000 of size 512 next 1591\n",
      "2023-09-22 01:58:01.581703: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555200 of size 512 next 1499\n",
      "2023-09-22 01:58:01.581706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555400 of size 512 next 1139\n",
      "2023-09-22 01:58:01.581710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555600 of size 512 next 503\n",
      "2023-09-22 01:58:01.581713: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555800 of size 512 next 773\n",
      "2023-09-22 01:58:01.581717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555a00 of size 512 next 895\n",
      "2023-09-22 01:58:01.581720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555c00 of size 512 next 72\n",
      "2023-09-22 01:58:01.581723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa555e00 of size 512 next 1607\n",
      "2023-09-22 01:58:01.581727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa556000 of size 4096 next 746\n",
      "2023-09-22 01:58:01.581730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557000 of size 512 next 269\n",
      "2023-09-22 01:58:01.581733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557200 of size 512 next 980\n",
      "2023-09-22 01:58:01.581737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557400 of size 512 next 661\n",
      "2023-09-22 01:58:01.581740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557600 of size 512 next 506\n",
      "2023-09-22 01:58:01.581743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557800 of size 512 next 70\n",
      "2023-09-22 01:58:01.581747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557a00 of size 512 next 317\n",
      "2023-09-22 01:58:01.581750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557c00 of size 512 next 1294\n",
      "2023-09-22 01:58:01.581753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa557e00 of size 512 next 1302\n",
      "2023-09-22 01:58:01.581757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558000 of size 512 next 597\n",
      "2023-09-22 01:58:01.581760: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558200 of size 512 next 411\n",
      "2023-09-22 01:58:01.581764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558400 of size 256 next 271\n",
      "2023-09-22 01:58:01.581767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558500 of size 512 next 513\n",
      "2023-09-22 01:58:01.581770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558700 of size 256 next 240\n",
      "2023-09-22 01:58:01.581774: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558800 of size 256 next 68\n",
      "2023-09-22 01:58:01.581777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558900 of size 512 next 759\n",
      "2023-09-22 01:58:01.581780: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558b00 of size 768 next 838\n",
      "2023-09-22 01:58:01.581784: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558e00 of size 256 next 690\n",
      "2023-09-22 01:58:01.581787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558f00 of size 256 next 1200\n",
      "2023-09-22 01:58:01.581791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559000 of size 256 next 435\n",
      "2023-09-22 01:58:01.581794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559100 of size 256 next 392\n",
      "2023-09-22 01:58:01.581797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559200 of size 512 next 140\n",
      "2023-09-22 01:58:01.581801: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559400 of size 512 next 998\n",
      "2023-09-22 01:58:01.581804: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559600 of size 512 next 1516\n",
      "2023-09-22 01:58:01.581807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559800 of size 512 next 18\n",
      "2023-09-22 01:58:01.581811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559a00 of size 512 next 724\n",
      "2023-09-22 01:58:01.581814: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559c00 of size 512 next 552\n",
      "2023-09-22 01:58:01.581818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559e00 of size 512 next 1165\n",
      "2023-09-22 01:58:01.581821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a000 of size 512 next 1712\n",
      "2023-09-22 01:58:01.581824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a200 of size 512 next 1375\n",
      "2023-09-22 01:58:01.581828: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a400 of size 512 next 1537\n",
      "2023-09-22 01:58:01.581831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a600 of size 512 next 1683\n",
      "2023-09-22 01:58:01.581835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a800 of size 512 next 588\n",
      "2023-09-22 01:58:01.581838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55aa00 of size 256 next 301\n",
      "2023-09-22 01:58:01.581841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55ab00 of size 256 next 138\n",
      "2023-09-22 01:58:01.581845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55ac00 of size 5888 next 745\n",
      "2023-09-22 01:58:01.581848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c300 of size 512 next 532\n",
      "2023-09-22 01:58:01.581852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c500 of size 512 next 281\n",
      "2023-09-22 01:58:01.581855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c700 of size 512 next 962\n",
      "2023-09-22 01:58:01.581858: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c900 of size 512 next 990\n",
      "2023-09-22 01:58:01.581862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55cb00 of size 768 next 1308\n",
      "2023-09-22 01:58:01.581865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55ce00 of size 256 next 1090\n",
      "2023-09-22 01:58:01.581869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55cf00 of size 256 next 1497\n",
      "2023-09-22 01:58:01.581872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55d000 of size 256 next 354\n",
      "2023-09-22 01:58:01.581875: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55d100 of size 256 next 529\n",
      "2023-09-22 01:58:01.581879: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55d200 of size 256 next 62\n",
      "2023-09-22 01:58:01.581882: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55d300 of size 4096 next 926\n",
      "2023-09-22 01:58:01.581885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55e300 of size 4096 next 1215\n",
      "2023-09-22 01:58:01.581889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55f300 of size 512 next 1119\n",
      "2023-09-22 01:58:01.581892: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55f500 of size 512 next 915\n",
      "2023-09-22 01:58:01.581896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55f700 of size 512 next 971\n",
      "2023-09-22 01:58:01.581899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55f900 of size 512 next 803\n",
      "2023-09-22 01:58:01.581903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55fb00 of size 512 next 21\n",
      "2023-09-22 01:58:01.581906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55fd00 of size 512 next 887\n",
      "2023-09-22 01:58:01.581909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55ff00 of size 512 next 1270\n",
      "2023-09-22 01:58:01.581913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa560100 of size 512 next 278\n",
      "2023-09-22 01:58:01.581916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa560300 of size 4096 next 1455\n",
      "2023-09-22 01:58:01.581920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa561300 of size 4096 next 1312\n",
      "2023-09-22 01:58:01.581923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa562300 of size 4096 next 1203\n",
      "2023-09-22 01:58:01.581926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa563300 of size 4096 next 1160\n",
      "2023-09-22 01:58:01.581930: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa564300 of size 512 next 905\n",
      "2023-09-22 01:58:01.581933: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa564500 of size 512 next 906\n",
      "2023-09-22 01:58:01.581937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa564700 of size 3072 next 187\n",
      "2023-09-22 01:58:01.581940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa565300 of size 4096 next 232\n",
      "2023-09-22 01:58:01.581944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa566300 of size 4096 next 1646\n",
      "2023-09-22 01:58:01.581947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa567300 of size 2048 next 91\n",
      "2023-09-22 01:58:01.581950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa567b00 of size 2048 next 1533\n",
      "2023-09-22 01:58:01.581954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa568300 of size 4096 next 1267\n",
      "2023-09-22 01:58:01.581957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa569300 of size 4096 next 1620\n",
      "2023-09-22 01:58:01.581961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa56a300 of size 4096 next 954\n",
      "2023-09-22 01:58:01.581964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa56b300 of size 4096 next 1047\n",
      "2023-09-22 01:58:01.581968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa56c300 of size 4096 next 1251\n",
      "2023-09-22 01:58:01.581971: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa56d300 of size 4096 next 352\n",
      "2023-09-22 01:58:01.581975: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa56e300 of size 53248 next 361\n",
      "2023-09-22 01:58:01.581979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa57b300 of size 32768 next 189\n",
      "2023-09-22 01:58:01.581982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa583300 of size 45312 next 1686\n",
      "2023-09-22 01:58:01.581986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e400 of size 256 next 1096\n",
      "2023-09-22 01:58:01.581989: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e500 of size 256 next 252\n",
      "2023-09-22 01:58:01.581992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e600 of size 256 next 1674\n",
      "2023-09-22 01:58:01.581996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e700 of size 256 next 825\n",
      "2023-09-22 01:58:01.581999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e800 of size 524288 next 881\n",
      "2023-09-22 01:58:01.582003: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa60e800 of size 895232 next 1507\n",
      "2023-09-22 01:58:01.582006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9100 of size 256 next 1364\n",
      "2023-09-22 01:58:01.582009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9200 of size 256 next 699\n",
      "2023-09-22 01:58:01.582013: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9300 of size 256 next 1471\n",
      "2023-09-22 01:58:01.582016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9400 of size 256 next 1078\n",
      "2023-09-22 01:58:01.582019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9500 of size 512 next 726\n",
      "2023-09-22 01:58:01.582023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9700 of size 256 next 206\n",
      "2023-09-22 01:58:01.582026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9800 of size 32768 next 1741\n",
      "2023-09-22 01:58:01.582030: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6f1800 of size 32768 next 1743\n",
      "2023-09-22 01:58:01.582033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6f9800 of size 32768 next 1387\n",
      "2023-09-22 01:58:01.582036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa701800 of size 243200 next 1696\n",
      "2023-09-22 01:58:01.582040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ce00 of size 256 next 106\n",
      "2023-09-22 01:58:01.582043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73cf00 of size 32768 next 53\n",
      "2023-09-22 01:58:01.582047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa744f00 of size 32768 next 1288\n",
      "2023-09-22 01:58:01.582050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa74cf00 of size 32768 next 1730\n",
      "2023-09-22 01:58:01.582054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa754f00 of size 32768 next 324\n",
      "2023-09-22 01:58:01.582057: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa75cf00 of size 32768 next 696\n",
      "2023-09-22 01:58:01.582060: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa764f00 of size 32768 next 243\n",
      "2023-09-22 01:58:01.582064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa76cf00 of size 32768 next 842\n",
      "2023-09-22 01:58:01.582067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa774f00 of size 32768 next 1277\n",
      "2023-09-22 01:58:01.582070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa77cf00 of size 32768 next 1066\n",
      "2023-09-22 01:58:01.582074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa784f00 of size 32768 next 1138\n",
      "2023-09-22 01:58:01.582077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa78cf00 of size 32768 next 379\n",
      "2023-09-22 01:58:01.582080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa794f00 of size 32768 next 492\n",
      "2023-09-22 01:58:01.582084: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa79cf00 of size 32768 next 1509\n",
      "2023-09-22 01:58:01.582087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa7a4f00 of size 32768 next 645\n",
      "2023-09-22 01:58:01.582091: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa7acf00 of size 32768 next 946\n",
      "2023-09-22 01:58:01.582094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa7b4f00 of size 557056 next 1188\n",
      "2023-09-22 01:58:01.582098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa83cf00 of size 147456 next 1609\n",
      "2023-09-22 01:58:01.582101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa860f00 of size 147456 next 1325\n",
      "2023-09-22 01:58:01.582105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa884f00 of size 236544 next 1377\n",
      "2023-09-22 01:58:01.582108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa8beb00 of size 32768 next 1214\n",
      "2023-09-22 01:58:01.582112: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa8c6b00 of size 35840 next 1016\n",
      "2023-09-22 01:58:01.582115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa8cf700 of size 262144 next 856\n",
      "2023-09-22 01:58:01.582119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa90f700 of size 262144 next 495\n",
      "2023-09-22 01:58:01.582122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa94f700 of size 262144 next 241\n",
      "2023-09-22 01:58:01.582125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa98f700 of size 262144 next 620\n",
      "2023-09-22 01:58:01.582129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9cf700 of size 445184 next 689\n",
      "2023-09-22 01:58:01.582137: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c200 of size 256 next 383\n",
      "2023-09-22 01:58:01.582140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c300 of size 512 next 1191\n",
      "2023-09-22 01:58:01.582144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c500 of size 512 next 1304\n",
      "2023-09-22 01:58:01.582147: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c700 of size 512 next 445\n",
      "2023-09-22 01:58:01.582151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c900 of size 512 next 1486\n",
      "2023-09-22 01:58:01.582154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3cb00 of size 512 next 1556\n",
      "2023-09-22 01:58:01.582157: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3cd00 of size 512 next 1026\n",
      "2023-09-22 01:58:01.582161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3cf00 of size 512 next 523\n",
      "2023-09-22 01:58:01.582164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3d100 of size 512 next 1136\n",
      "2023-09-22 01:58:01.582168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3d300 of size 4096 next 1723\n",
      "2023-09-22 01:58:01.582171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3e300 of size 4096 next 786\n",
      "2023-09-22 01:58:01.582175: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3f300 of size 4096 next 209\n",
      "2023-09-22 01:58:01.582178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40300 of size 4096 next 1437\n",
      "2023-09-22 01:58:01.582182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41300 of size 7680 next 1550\n",
      "2023-09-22 01:58:01.582185: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43100 of size 256 next 1551\n",
      "2023-09-22 01:58:01.582188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12faa43200 of size 15564800 next 576\n",
      "2023-09-22 01:58:01.582192: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fb91b200 of size 48384 next 591\n",
      "2023-09-22 01:58:01.582195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fb926f00 of size 524288 next 1413\n",
      "2023-09-22 01:58:01.582199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fb9a6f00 of size 850944 next 639\n",
      "2023-09-22 01:58:01.582202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fba76b00 of size 256 next 1396\n",
      "2023-09-22 01:58:01.582205: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fba76c00 of size 256 next 1619\n",
      "2023-09-22 01:58:01.582209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fba76d00 of size 524288 next 569\n",
      "2023-09-22 01:58:01.582212: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fbaf6d00 of size 524288 next 992\n",
      "2023-09-22 01:58:01.582216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fbb76d00 of size 255714560 next 314\n",
      "2023-09-22 01:58:01.582219: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130af55200 of size 32768 next 914\n",
      "2023-09-22 01:58:01.582223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130af5d200 of size 48128 next 568\n",
      "2023-09-22 01:58:01.582226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130af68e00 of size 32768 next 1621\n",
      "2023-09-22 01:58:01.582230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130af70e00 of size 256 next 315\n",
      "2023-09-22 01:58:01.582233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130af70f00 of size 32768 next 1460\n",
      "2023-09-22 01:58:01.582237: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130af78f00 of size 65280 next 866\n",
      "2023-09-22 01:58:01.582240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130af88e00 of size 44442624 next 8\n",
      "2023-09-22 01:58:01.582244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130d9eb200 of size 524288 next 966\n",
      "2023-09-22 01:58:01.582247: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130da6b200 of size 770048 next 1434\n",
      "2023-09-22 01:58:01.582251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130db27200 of size 22691328 next 553\n",
      "2023-09-22 01:58:01.582254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130f0cb000 of size 524288 next 1629\n",
      "2023-09-22 01:58:01.582258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f130f14b000 of size 106089216 next 1593\n",
      "2023-09-22 01:58:01.582261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677b00 of size 256 next 628\n",
      "2023-09-22 01:58:01.582265: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677c00 of size 256 next 92\n",
      "2023-09-22 01:58:01.582268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677d00 of size 524288 next 1383\n",
      "2023-09-22 01:58:01.582271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13156f7d00 of size 524288 next 74\n",
      "2023-09-22 01:58:01.582275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315777d00 of size 524288 next 560\n",
      "2023-09-22 01:58:01.582278: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13157f7d00 of size 524288 next 1436\n",
      "2023-09-22 01:58:01.582281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315877d00 of size 524288 next 132\n",
      "2023-09-22 01:58:01.582285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158f7d00 of size 524288 next 1710\n",
      "2023-09-22 01:58:01.582288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315977d00 of size 983296 next 429\n",
      "2023-09-22 01:58:01.582292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315a67e00 of size 806912 next 162\n",
      "2023-09-22 01:58:01.582299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315b2ce00 of size 524288 next 1419\n",
      "2023-09-22 01:58:01.582303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315bace00 of size 524288 next 821\n",
      "2023-09-22 01:58:01.582306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315c2ce00 of size 524288 next 686\n",
      "2023-09-22 01:58:01.582309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315cace00 of size 524288 next 956\n",
      "2023-09-22 01:58:01.582313: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d2ce00 of size 915712 next 754\n",
      "2023-09-22 01:58:01.582316: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c700 of size 256 next 848\n",
      "2023-09-22 01:58:01.582320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c800 of size 256 next 136\n",
      "2023-09-22 01:58:01.582323: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c900 of size 179386112 next 190\n",
      "2023-09-22 01:58:01.582327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920000 of size 256 next 1574\n",
      "2023-09-22 01:58:01.582330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920100 of size 20480000 next 511\n",
      "2023-09-22 01:58:01.582334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1321ca8100 of size 51448064 next 112\n",
      "2023-09-22 01:58:01.582337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8a00 of size 256 next 687\n",
      "2023-09-22 01:58:01.582340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8b00 of size 256 next 1567\n",
      "2023-09-22 01:58:01.582344: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8c00 of size 256 next 1212\n",
      "2023-09-22 01:58:01.582347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8d00 of size 256 next 1510\n",
      "2023-09-22 01:58:01.582351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8e00 of size 256 next 86\n",
      "2023-09-22 01:58:01.582354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8f00 of size 256 next 493\n",
      "2023-09-22 01:58:01.582357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1324db9000 of size 10354688 next 1242\n",
      "2023-09-22 01:58:01.582361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1325799000 of size 524288 next 835\n",
      "2023-09-22 01:58:01.582364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1325819000 of size 770048 next 395\n",
      "2023-09-22 01:58:01.582368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13258d5000 of size 81920000 next 1254\n",
      "2023-09-22 01:58:01.582371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f132a6f5000 of size 81920000 next 230\n",
      "2023-09-22 01:58:01.582375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f132f515000 of size 120266752 next 211\n",
      "2023-09-22 01:58:01.582378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13367c7000 of size 524288 next 1084\n",
      "2023-09-22 01:58:01.582382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1336847000 of size 524288 next 556\n",
      "2023-09-22 01:58:01.582385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13368c7000 of size 63545344 next 222\n",
      "2023-09-22 01:58:01.582388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f133a561000 of size 770048 next 1168\n",
      "2023-09-22 01:58:01.582392: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f133a61d000 of size 15532032 next 157\n",
      "2023-09-22 01:58:01.582395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f133b4ed000 of size 524288 next 1539\n",
      "2023-09-22 01:58:01.582399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f133b56d000 of size 327680000 next 691\n",
      "2023-09-22 01:58:01.582402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f134eded000 of size 327680000 next 1515\n",
      "2023-09-22 01:58:01.582406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f136266d000 of size 327680000 next 704\n",
      "2023-09-22 01:58:01.582409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1375eed000 of size 81920000 next 76\n",
      "2023-09-22 01:58:01.582412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f137ad0d000 of size 81920000 next 477\n",
      "2023-09-22 01:58:01.582416: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f137fb2d000 of size 161223936 next 282\n",
      "2023-09-22 01:58:01.582419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13894ee500 of size 1263840000 next 176\n",
      "2023-09-22 01:58:01.582423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13d4a39000 of size 421200128 next 899\n",
      "2023-09-22 01:58:01.582427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13edbe9100 of size 327680000 next 1005\n",
      "2023-09-22 01:58:01.582431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1401469100 of size 327680000 next 380\n",
      "2023-09-22 01:58:01.582435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1414ce9100 of size 327680000 next 1046\n",
      "2023-09-22 01:58:01.582439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1428569100 of size 2216960000 next 246\n",
      "2023-09-22 01:58:01.582443: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14ac7ab100 of size 3200000000 next 1684\n",
      "2023-09-22 01:58:01.582449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f156b36d100 of size 3200000000 next 978\n",
      "2023-09-22 01:58:01.582453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1629f2f100 of size 3200000000 next 993\n",
      "2023-09-22 01:58:01.582457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16e8af1100 of size 327680000 next 1557\n",
      "2023-09-22 01:58:01.582462: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16fc371100 of size 327680000 next 64\n",
      "2023-09-22 01:58:01.582466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f170fbf1100 of size 327680000 next 841\n",
      "2023-09-22 01:58:01.582469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1723471100 of size 81920000 next 1222\n",
      "2023-09-22 01:58:01.582472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1728291100 of size 304279296 next 18446744073709551615\n",
      "2023-09-22 01:58:01.582476: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-09-22 01:58:01.582482: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 393 Chunks of size 256 totalling 98.2KiB\n",
      "2023-09-22 01:58:01.582487: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 323 Chunks of size 512 totalling 161.5KiB\n",
      "2023-09-22 01:58:01.582491: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 14 Chunks of size 768 totalling 10.5KiB\n",
      "2023-09-22 01:58:01.582497: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-09-22 01:58:01.582501: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 24 Chunks of size 2048 totalling 48.0KiB\n",
      "2023-09-22 01:58:01.582505: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2304 totalling 2.2KiB\n",
      "2023-09-22 01:58:01.582509: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2816 totalling 2.8KiB\n",
      "2023-09-22 01:58:01.582513: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 3072 totalling 3.0KiB\n",
      "2023-09-22 01:58:01.582517: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 118 Chunks of size 4096 totalling 472.0KiB\n",
      "2023-09-22 01:58:01.582520: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4352 totalling 4.2KiB\n",
      "2023-09-22 01:58:01.582524: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 4608 totalling 9.0KiB\n",
      "2023-09-22 01:58:01.582528: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 5120 totalling 5.0KiB\n",
      "2023-09-22 01:58:01.582532: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 5632 totalling 22.0KiB\n",
      "2023-09-22 01:58:01.582536: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 5888 totalling 17.2KiB\n",
      "2023-09-22 01:58:01.582540: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6144 totalling 6.0KiB\n",
      "2023-09-22 01:58:01.582546: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6400 totalling 6.2KiB\n",
      "2023-09-22 01:58:01.582549: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6656 totalling 6.5KiB\n",
      "2023-09-22 01:58:01.582553: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6912 totalling 6.8KiB\n",
      "2023-09-22 01:58:01.582557: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 7168 totalling 7.0KiB\n",
      "2023-09-22 01:58:01.582561: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 7680 totalling 7.5KiB\n",
      "2023-09-22 01:58:01.582564: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 7936 totalling 7.8KiB\n",
      "2023-09-22 01:58:01.582568: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 18 Chunks of size 16384 totalling 288.0KiB\n",
      "2023-09-22 01:58:01.582572: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 17408 totalling 17.0KiB\n",
      "2023-09-22 01:58:01.582576: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 21248 totalling 20.8KiB\n",
      "2023-09-22 01:58:01.582580: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 27648 totalling 216.0KiB\n",
      "2023-09-22 01:58:01.582587: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 29696 totalling 29.0KiB\n",
      "2023-09-22 01:58:01.582591: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 31488 totalling 30.8KiB\n",
      "2023-09-22 01:58:01.582594: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 78 Chunks of size 32768 totalling 2.44MiB\n",
      "2023-09-22 01:58:01.582598: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 33280 totalling 97.5KiB\n",
      "2023-09-22 01:58:01.582602: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 33792 totalling 99.0KiB\n",
      "2023-09-22 01:58:01.582606: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 34560 totalling 33.8KiB\n",
      "2023-09-22 01:58:01.582610: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 34816 totalling 34.0KiB\n",
      "2023-09-22 01:58:01.582614: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 35840 totalling 70.0KiB\n",
      "2023-09-22 01:58:01.582618: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 36864 totalling 72.0KiB\n",
      "2023-09-22 01:58:01.582622: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 40960 totalling 40.0KiB\n",
      "2023-09-22 01:58:01.582626: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 41472 totalling 40.5KiB\n",
      "2023-09-22 01:58:01.582630: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 44032 totalling 43.0KiB\n",
      "2023-09-22 01:58:01.582633: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 45312 totalling 44.2KiB\n",
      "2023-09-22 01:58:01.582637: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 46336 totalling 45.2KiB\n",
      "2023-09-22 01:58:01.582641: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 46592 totalling 45.5KiB\n",
      "2023-09-22 01:58:01.582645: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 47360 totalling 46.2KiB\n",
      "2023-09-22 01:58:01.582649: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 48128 totalling 235.0KiB\n",
      "2023-09-22 01:58:01.582653: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 48384 totalling 94.5KiB\n",
      "2023-09-22 01:58:01.582657: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 49152 totalling 48.0KiB\n",
      "2023-09-22 01:58:01.582661: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 52224 totalling 51.0KiB\n",
      "2023-09-22 01:58:01.582667: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 53248 totalling 52.0KiB\n",
      "2023-09-22 01:58:01.582671: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 54016 totalling 52.8KiB\n",
      "2023-09-22 01:58:01.582675: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 55296 totalling 54.0KiB\n",
      "2023-09-22 01:58:01.582679: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 55808 totalling 109.0KiB\n",
      "2023-09-22 01:58:01.582683: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 57088 totalling 55.8KiB\n",
      "2023-09-22 01:58:01.582687: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 59648 totalling 58.2KiB\n",
      "2023-09-22 01:58:01.582691: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 62464 totalling 61.0KiB\n",
      "2023-09-22 01:58:01.582697: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 63488 totalling 62.0KiB\n",
      "2023-09-22 01:58:01.582701: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 65280 totalling 63.8KiB\n",
      "2023-09-22 01:58:01.582705: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 147456 totalling 1.12MiB\n",
      "2023-09-22 01:58:01.582709: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 159488 totalling 155.8KiB\n",
      "2023-09-22 01:58:01.582712: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 180224 totalling 176.0KiB\n",
      "2023-09-22 01:58:01.582716: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 229376 totalling 224.0KiB\n",
      "2023-09-22 01:58:01.582722: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 234496 totalling 229.0KiB\n",
      "2023-09-22 01:58:01.582726: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 236544 totalling 231.0KiB\n",
      "2023-09-22 01:58:01.582730: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 242688 totalling 237.0KiB\n",
      "2023-09-22 01:58:01.582734: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 243200 totalling 237.5KiB\n",
      "2023-09-22 01:58:01.582738: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 34 Chunks of size 262144 totalling 8.50MiB\n",
      "2023-09-22 01:58:01.582742: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 267264 totalling 261.0KiB\n",
      "2023-09-22 01:58:01.582747: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 281600 totalling 275.0KiB\n",
      "2023-09-22 01:58:01.582751: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 287744 totalling 562.0KiB\n",
      "2023-09-22 01:58:01.582755: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 344064 totalling 336.0KiB\n",
      "2023-09-22 01:58:01.582759: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 419584 totalling 409.8KiB\n",
      "2023-09-22 01:58:01.582763: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 445184 totalling 434.8KiB\n",
      "2023-09-22 01:58:01.582767: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 507136 totalling 495.2KiB\n",
      "2023-09-22 01:58:01.582771: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 109 Chunks of size 524288 totalling 54.50MiB\n",
      "2023-09-22 01:58:01.582775: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 527360 totalling 515.0KiB\n",
      "2023-09-22 01:58:01.582779: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 529664 totalling 517.2KiB\n",
      "2023-09-22 01:58:01.582783: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 30 Chunks of size 532480 totalling 15.23MiB\n",
      "2023-09-22 01:58:01.582787: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 557056 totalling 544.0KiB\n",
      "2023-09-22 01:58:01.582791: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 561152 totalling 548.0KiB\n",
      "2023-09-22 01:58:01.582794: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 574464 totalling 561.0KiB\n",
      "2023-09-22 01:58:01.582798: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 577536 totalling 564.0KiB\n",
      "2023-09-22 01:58:01.582802: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2023-09-22 01:58:01.582806: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 601088 totalling 1.72MiB\n",
      "2023-09-22 01:58:01.582810: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 640000 totalling 4.88MiB\n",
      "2023-09-22 01:58:01.582814: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 655872 totalling 640.5KiB\n",
      "2023-09-22 01:58:01.582818: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 659456 totalling 644.0KiB\n",
      "2023-09-22 01:58:01.582824: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 660480 totalling 645.0KiB\n",
      "2023-09-22 01:58:01.582828: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 662016 totalling 5.05MiB\n",
      "2023-09-22 01:58:01.582832: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 751616 totalling 734.0KiB\n",
      "2023-09-22 01:58:01.582835: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 770048 totalling 3.67MiB\n",
      "2023-09-22 01:58:01.582839: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 784640 totalling 766.2KiB\n",
      "2023-09-22 01:58:01.582843: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 806912 totalling 788.0KiB\n",
      "2023-09-22 01:58:01.582847: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 830208 totalling 810.8KiB\n",
      "2023-09-22 01:58:01.582851: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 847104 totalling 827.2KiB\n",
      "2023-09-22 01:58:01.582857: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 850944 totalling 1.62MiB\n",
      "2023-09-22 01:58:01.582861: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 895232 totalling 874.2KiB\n",
      "2023-09-22 01:58:01.582864: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 915712 totalling 894.2KiB\n",
      "2023-09-22 01:58:01.582868: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 932096 totalling 910.2KiB\n",
      "2023-09-22 01:58:01.582872: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 983296 totalling 960.2KiB\n",
      "2023-09-22 01:58:01.582876: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 990720 totalling 967.5KiB\n",
      "2023-09-22 01:58:01.582880: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 992000 totalling 968.8KiB\n",
      "2023-09-22 01:58:01.582884: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 997632 totalling 974.2KiB\n",
      "2023-09-22 01:58:01.582888: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1001216 totalling 977.8KiB\n",
      "2023-09-22 01:58:01.582892: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 20480000 totalling 19.53MiB\n",
      "2023-09-22 01:58:01.582896: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 21999104 totalling 20.98MiB\n",
      "2023-09-22 01:58:01.582900: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 22691328 totalling 21.64MiB\n",
      "2023-09-22 01:58:01.582904: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 24592384 totalling 23.45MiB\n",
      "2023-09-22 01:58:01.582908: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 26175744 totalling 24.96MiB\n",
      "2023-09-22 01:58:01.582911: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 39062528 totalling 37.25MiB\n",
      "2023-09-22 01:58:01.582917: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 41451520 totalling 39.53MiB\n",
      "2023-09-22 01:58:01.582921: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 44442624 totalling 42.38MiB\n",
      "2023-09-22 01:58:01.582925: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 63545344 totalling 60.60MiB\n",
      "2023-09-22 01:58:01.582929: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 13 Chunks of size 81920000 totalling 1015.62MiB\n",
      "2023-09-22 01:58:01.582933: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 101765376 totalling 97.05MiB\n",
      "2023-09-22 01:58:01.582939: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 104645888 totalling 99.80MiB\n",
      "2023-09-22 01:58:01.582943: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 106089216 totalling 101.17MiB\n",
      "2023-09-22 01:58:01.582947: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 108409600 totalling 103.39MiB\n",
      "2023-09-22 01:58:01.582951: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 120266752 totalling 114.70MiB\n",
      "2023-09-22 01:58:01.582955: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 179386112 totalling 171.08MiB\n",
      "2023-09-22 01:58:01.582961: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 231587584 totalling 220.86MiB\n",
      "2023-09-22 01:58:01.582965: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 255714560 totalling 243.87MiB\n",
      "2023-09-22 01:58:01.582968: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 11 Chunks of size 327680000 totalling 3.36GiB\n",
      "2023-09-22 01:58:01.582972: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 409019648 totalling 390.07MiB\n",
      "2023-09-22 01:58:01.582976: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 421200128 totalling 401.69MiB\n",
      "2023-09-22 01:58:01.582982: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 436527616 totalling 416.30MiB\n",
      "2023-09-22 01:58:01.582986: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 485895936 totalling 463.39MiB\n",
      "2023-09-22 01:58:01.582990: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1263840000 totalling 1.18GiB\n",
      "2023-09-22 01:58:01.582994: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1272900352 totalling 1.18GiB\n",
      "2023-09-22 01:58:01.582998: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 3200000000 totalling 8.94GiB\n",
      "2023-09-22 01:58:01.583001: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 18.81GiB\n",
      "2023-09-22 01:58:01.583005: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 23023321088 memory_limit_: 23023321088 available bytes: 0 curr_region_allocation_bytes_: 46046642176\n",
      "2023-09-22 01:58:01.583013: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     23023321088\n",
      "InUse:                     20199950080\n",
      "MaxInUse:                  22300408832\n",
      "NumAllocs:                    34106442\n",
      "MaxAllocSize:               6400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-22 01:58:01.583046: W tensorflow/tsl/framework/bfc_allocator.cc:492] *******************************************_________***********************************************_\n",
      "2023-09-22 01:58:01.583075: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at einsum_op_impl.h:598 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,4,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'model/multi_head_attention_2/einsum/Einsum' defined at (most recent call last):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_3386617/1959657965.py\", line 121, in <module>\n",
      "      hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3},\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 524, in _compute_attention\n",
      "      attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
      "Node: 'model/multi_head_attention_2/einsum/Einsum'\n",
      "OOM when allocating tensor with shape[128,4,1250,1250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/multi_head_attention_2/einsum/Einsum}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_1861591]\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size11_pool4_do0.5_tra3_head2_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1169 - mean_squared_error: 0.0309\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size11_pool4_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 15s 146ms/step - loss: 0.1171 - mean_squared_error: 0.0309 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "42/42 [==============================] - 6s 132ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size11_pool4_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 5s 127ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size11_pool4_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 5s 127ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss did not improve from 0.11004\n",
      "42/42 [==============================] - 6s 138ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 6: val_loss did not improve from 0.11004\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 7: val_loss did not improve from 0.11004\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 1s 15ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1188 - mean_squared_error: 0.0319\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size11_pool4_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 19s 161ms/step - loss: 0.1189 - mean_squared_error: 0.0319 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10696\n",
      "42/42 [==============================] - 5s 131ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1186 - mean_squared_error: 0.0312\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size11_pool4_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 16s 154ms/step - loss: 0.1185 - mean_squared_error: 0.0312 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 1s 15ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1184 - mean_squared_error: 0.0311\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size11_pool4_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 15s 147ms/step - loss: 0.1184 - mean_squared_error: 0.0311 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 5s 130ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 14ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0872 - mean_squared_error: 0.0161\n",
      "Epoch 1: val_loss improved from inf to 0.06439, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 14s 49ms/step - loss: 0.0871 - mean_squared_error: 0.0161 - val_loss: 0.0644 - val_mean_squared_error: 0.0090\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0559 - mean_squared_error: 0.0067\n",
      "Epoch 2: val_loss did not improve from 0.06439\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0559 - mean_squared_error: 0.0067 - val_loss: 0.0670 - val_mean_squared_error: 0.0087\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0451 - mean_squared_error: 0.0046\n",
      "Epoch 3: val_loss improved from 0.06439 to 0.05273, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.0451 - mean_squared_error: 0.0046 - val_loss: 0.0527 - val_mean_squared_error: 0.0058\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0040\n",
      "Epoch 4: val_loss improved from 0.05273 to 0.04883, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0416 - mean_squared_error: 0.0040 - val_loss: 0.0488 - val_mean_squared_error: 0.0053\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0037\n",
      "Epoch 5: val_loss did not improve from 0.04883\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0398 - mean_squared_error: 0.0037 - val_loss: 0.0632 - val_mean_squared_error: 0.0080\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0033\n",
      "Epoch 6: val_loss did not improve from 0.04883\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0371 - mean_squared_error: 0.0033 - val_loss: 0.0557 - val_mean_squared_error: 0.0061\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0033\n",
      "Epoch 7: val_loss improved from 0.04883 to 0.03518, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.0369 - mean_squared_error: 0.0033 - val_loss: 0.0352 - val_mean_squared_error: 0.0033\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0350 - mean_squared_error: 0.0031\n",
      "Epoch 8: val_loss did not improve from 0.03518\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0350 - mean_squared_error: 0.0031 - val_loss: 0.0519 - val_mean_squared_error: 0.0060\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0032\n",
      "Epoch 9: val_loss improved from 0.03518 to 0.03259, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.0360 - mean_squared_error: 0.0032 - val_loss: 0.0326 - val_mean_squared_error: 0.0029\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0343 - mean_squared_error: 0.0030\n",
      "Epoch 10: val_loss did not improve from 0.03259\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0343 - mean_squared_error: 0.0030 - val_loss: 0.0355 - val_mean_squared_error: 0.0034\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0327 - mean_squared_error: 0.0027\n",
      "Epoch 11: val_loss did not improve from 0.03259\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0327 - mean_squared_error: 0.0027 - val_loss: 0.0379 - val_mean_squared_error: 0.0037\n",
      "Epoch 12/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0322 - mean_squared_error: 0.0026\n",
      "Epoch 12: val_loss did not improve from 0.03259\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0322 - mean_squared_error: 0.0026 - val_loss: 0.0341 - val_mean_squared_error: 0.0032\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###0 fold : val mae 0.03###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0868 - mean_squared_error: 0.0158\n",
      "Epoch 1: val_loss improved from inf to 0.07317, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 12s 42ms/step - loss: 0.0864 - mean_squared_error: 0.0157 - val_loss: 0.0732 - val_mean_squared_error: 0.0115\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.0070\n",
      "Epoch 2: val_loss improved from 0.07317 to 0.04139, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 0.0573 - mean_squared_error: 0.0070 - val_loss: 0.0414 - val_mean_squared_error: 0.0039\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0452 - mean_squared_error: 0.0046\n",
      "Epoch 3: val_loss did not improve from 0.04139\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.0452 - mean_squared_error: 0.0046 - val_loss: 0.0446 - val_mean_squared_error: 0.0047\n",
      "Epoch 4/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0408 - mean_squared_error: 0.0039\n",
      "Epoch 4: val_loss improved from 0.04139 to 0.03815, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.0409 - mean_squared_error: 0.0039 - val_loss: 0.0382 - val_mean_squared_error: 0.0036\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0037\n",
      "Epoch 5: val_loss improved from 0.03815 to 0.03325, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0395 - mean_squared_error: 0.0037 - val_loss: 0.0332 - val_mean_squared_error: 0.0030\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0033\n",
      "Epoch 6: val_loss did not improve from 0.03325\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0376 - mean_squared_error: 0.0033 - val_loss: 0.0501 - val_mean_squared_error: 0.0060\n",
      "Epoch 7/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0034\n",
      "Epoch 7: val_loss did not improve from 0.03325\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0376 - mean_squared_error: 0.0034 - val_loss: 0.0421 - val_mean_squared_error: 0.0042\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0353 - mean_squared_error: 0.0031\n",
      "Epoch 8: val_loss did not improve from 0.03325\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0353 - mean_squared_error: 0.0031 - val_loss: 0.0342 - val_mean_squared_error: 0.0030\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###1 fold : val mae 0.03###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0889 - mean_squared_error: 0.0165\n",
      "Epoch 1: val_loss improved from inf to 0.08042, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 12s 43ms/step - loss: 0.0889 - mean_squared_error: 0.0165 - val_loss: 0.0804 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0602 - mean_squared_error: 0.0075\n",
      "Epoch 2: val_loss improved from 0.08042 to 0.07965, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 34ms/step - loss: 0.0602 - mean_squared_error: 0.0075 - val_loss: 0.0796 - val_mean_squared_error: 0.0120\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0454 - mean_squared_error: 0.0046\n",
      "Epoch 3: val_loss improved from 0.07965 to 0.05295, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.0454 - mean_squared_error: 0.0046 - val_loss: 0.0529 - val_mean_squared_error: 0.0058\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0040\n",
      "Epoch 4: val_loss improved from 0.05295 to 0.03379, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0416 - mean_squared_error: 0.0040 - val_loss: 0.0338 - val_mean_squared_error: 0.0029\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0035\n",
      "Epoch 5: val_loss did not improve from 0.03379\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0386 - mean_squared_error: 0.0035 - val_loss: 0.0393 - val_mean_squared_error: 0.0036\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0033\n",
      "Epoch 6: val_loss did not improve from 0.03379\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0361 - mean_squared_error: 0.0032 - val_loss: 0.0346 - val_mean_squared_error: 0.0029\n",
      "Epoch 7/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0031\n",
      "Epoch 7: val_loss improved from 0.03379 to 0.03178, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 32ms/step - loss: 0.0357 - mean_squared_error: 0.0031 - val_loss: 0.0318 - val_mean_squared_error: 0.0028\n",
      "Epoch 8/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0352 - mean_squared_error: 0.0030\n",
      "Epoch 8: val_loss did not improve from 0.03178\n",
      "83/83 [==============================] - 3s 33ms/step - loss: 0.0351 - mean_squared_error: 0.0030 - val_loss: 0.0543 - val_mean_squared_error: 0.0070\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0029\n",
      "Epoch 9: val_loss did not improve from 0.03178\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0340 - mean_squared_error: 0.0029 - val_loss: 0.0331 - val_mean_squared_error: 0.0028\n",
      "Epoch 10/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0031\n",
      "Epoch 10: val_loss did not improve from 0.03178\n",
      "83/83 [==============================] - 3s 31ms/step - loss: 0.0360 - mean_squared_error: 0.0031 - val_loss: 0.0320 - val_mean_squared_error: 0.0027\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###2 fold : val mae 0.03###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0879 - mean_squared_error: 0.0163\n",
      "Epoch 1: val_loss improved from inf to 0.09701, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 16s 45ms/step - loss: 0.0878 - mean_squared_error: 0.0163 - val_loss: 0.0970 - val_mean_squared_error: 0.0179\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0595 - mean_squared_error: 0.0075\n",
      "Epoch 2: val_loss improved from 0.09701 to 0.05673, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0595 - mean_squared_error: 0.0075 - val_loss: 0.0567 - val_mean_squared_error: 0.0071\n",
      "Epoch 3/100\n",
      "81/83 [============================>.] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.0046\n",
      "Epoch 3: val_loss improved from 0.05673 to 0.04397, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0449 - mean_squared_error: 0.0045 - val_loss: 0.0440 - val_mean_squared_error: 0.0044\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0037\n",
      "Epoch 4: val_loss did not improve from 0.04397\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0400 - mean_squared_error: 0.0037 - val_loss: 0.0640 - val_mean_squared_error: 0.0083\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0035\n",
      "Epoch 5: val_loss did not improve from 0.04397\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0386 - mean_squared_error: 0.0035 - val_loss: 0.0615 - val_mean_squared_error: 0.0074\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0035\n",
      "Epoch 6: val_loss improved from 0.04397 to 0.04106, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn3_filt16_size9_pool4_do0.1_tra3_head8_kdim64_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0390 - mean_squared_error: 0.0035 - val_loss: 0.0411 - val_mean_squared_error: 0.0037\n",
      "Epoch 7/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0364 - mean_squared_error: 0.0032\n",
      "Epoch 7: val_loss did not improve from 0.04106\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0364 - mean_squared_error: 0.0032 - val_loss: 0.0466 - val_mean_squared_error: 0.0050\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0029\n",
      "Epoch 8: val_loss did not improve from 0.04106\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0344 - mean_squared_error: 0.0029 - val_loss: 0.0511 - val_mean_squared_error: 0.0059\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0029\n",
      "Epoch 9: val_loss did not improve from 0.04106\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0339 - mean_squared_error: 0.0029 - val_loss: 0.0519 - val_mean_squared_error: 0.0061\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###3 fold : val mae 0.04###\n",
      "mae0.71+-0.08\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1080 - mean_squared_error: 0.0216\n",
      "Epoch 1: val_loss improved from inf to 0.11003, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_0.hdf5\n",
      "21/21 [==============================] - 14s 191ms/step - loss: 0.1080 - mean_squared_error: 0.0216 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11003\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11003\n",
      "21/21 [==============================] - 3s 153ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss did not improve from 0.11003\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0215\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_1.hdf5\n",
      "21/21 [==============================] - 17s 181ms/step - loss: 0.1082 - mean_squared_error: 0.0215 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 3s 134ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 3s 140ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0217\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_2.hdf5\n",
      "21/21 [==============================] - 14s 176ms/step - loss: 0.1090 - mean_squared_error: 0.0217 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 3s 146ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0218\n",
      "Epoch 1: val_loss improved from inf to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "21/21 [==============================] - 13s 181ms/step - loss: 0.1090 - mean_squared_error: 0.0218 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10638\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10638\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 162ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10638 to 0.10638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.10638 to 0.10635, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10635 to 0.09275, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt32_size7_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.0927 - val_mean_squared_error: 0.0177\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0864 - mean_squared_error: 0.0145\n",
      "Epoch 8: val_loss did not improve from 0.09275\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.0864 - mean_squared_error: 0.0145 - val_loss: 0.1445 - val_mean_squared_error: 0.0263\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0782 - mean_squared_error: 0.0117\n",
      "Epoch 9: val_loss did not improve from 0.09275\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.0782 - mean_squared_error: 0.0117 - val_loss: 0.1325 - val_mean_squared_error: 0.0222\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0559 - mean_squared_error: 0.0066\n",
      "Epoch 10: val_loss did not improve from 0.09275\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.0559 - mean_squared_error: 0.0066 - val_loss: 0.2086 - val_mean_squared_error: 0.0520\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae2.19+-0.12\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size11_pool5_do0.2_tra3_head2_kdim256_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1132 - mean_squared_error: 0.0268\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size11_pool5_do0.2_tra3_head2_kdim256_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 14s 58ms/step - loss: 0.1132 - mean_squared_error: 0.0268 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 4s 47ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss did not improve from 0.11004\n",
      "83/83 [==============================] - 4s 51ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 1s 12ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1142 - mean_squared_error: 0.0268\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size11_pool5_do0.2_tra3_head2_kdim256_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 14s 61ms/step - loss: 0.1142 - mean_squared_error: 0.0268 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 4s 49ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10696\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1144 - mean_squared_error: 0.0268\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size11_pool5_do0.2_tra3_head2_kdim256_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 18s 65ms/step - loss: 0.1144 - mean_squared_error: 0.0268 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 5s 55ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 4s 46ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "83/83 [==============================] - 4s 52ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 2s 11ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1155 - mean_squared_error: 0.0280\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn2_filt32_size11_pool5_do0.2_tra3_head2_kdim256_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 15s 62ms/step - loss: 0.1155 - mean_squared_error: 0.0280 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 4s 53ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "83/83 [==============================] - 4s 50ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 12ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0244\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 19s 149ms/step - loss: 0.1113 - mean_squared_error: 0.0243 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 2: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 4s 106ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 4s 106ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss improved from 0.11004 to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 5s 113ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 5: val_loss improved from 0.11004 to 0.11000, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 5s 118ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.11000 to 0.10971, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 5s 118ms/step - loss: 0.1067 - mean_squared_error: 0.0210 - val_loss: 0.1097 - val_mean_squared_error: 0.0216\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 7: val_loss improved from 0.10971 to 0.10928, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 5s 119ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1093 - val_mean_squared_error: 0.0215\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0204\n",
      "Epoch 8: val_loss did not improve from 0.10928\n",
      "42/42 [==============================] - 5s 113ms/step - loss: 0.1047 - mean_squared_error: 0.0204 - val_loss: 0.1244 - val_mean_squared_error: 0.0190\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.0155\n",
      "Epoch 9: val_loss did not improve from 0.10928\n",
      "42/42 [==============================] - 5s 117ms/step - loss: 0.0892 - mean_squared_error: 0.0155 - val_loss: 0.4061 - val_mean_squared_error: 0.1744\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.0132\n",
      "Epoch 10: val_loss did not improve from 0.10928\n",
      "42/42 [==============================] - 4s 103ms/step - loss: 0.0824 - mean_squared_error: 0.0133 - val_loss: 0.3108 - val_mean_squared_error: 0.1062\n",
      "55/55 [==============================] - 1s 15ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0243\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 18s 123ms/step - loss: 0.1116 - mean_squared_error: 0.0242 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10696 to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 4s 105ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10696 to 0.10685, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 4s 105ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.0175\n",
      "Epoch 4: val_loss did not improve from 0.10685\n",
      "42/42 [==============================] - 5s 112ms/step - loss: 0.0947 - mean_squared_error: 0.0175 - val_loss: 0.3247 - val_mean_squared_error: 0.1147\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0864 - mean_squared_error: 0.0144\n",
      "Epoch 5: val_loss did not improve from 0.10685\n",
      "42/42 [==============================] - 4s 101ms/step - loss: 0.0864 - mean_squared_error: 0.0144 - val_loss: 0.1634 - val_mean_squared_error: 0.0340\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0827 - mean_squared_error: 0.0131\n",
      "Epoch 6: val_loss did not improve from 0.10685\n",
      "42/42 [==============================] - 4s 101ms/step - loss: 0.0827 - mean_squared_error: 0.0131 - val_loss: 0.1769 - val_mean_squared_error: 0.0394\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1127 - mean_squared_error: 0.0248\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 22s 137ms/step - loss: 0.1127 - mean_squared_error: 0.0248 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 4s 105ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 5s 112ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.10585 to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 5s 115ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10585 to 0.10583, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 5s 118ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0188\n",
      "Epoch 6: val_loss did not improve from 0.10583\n",
      "42/42 [==============================] - 5s 113ms/step - loss: 0.0995 - mean_squared_error: 0.0188 - val_loss: 0.4448 - val_mean_squared_error: 0.2071\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0857 - mean_squared_error: 0.0142\n",
      "Epoch 7: val_loss did not improve from 0.10583\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 0.0856 - mean_squared_error: 0.0142 - val_loss: 0.3354 - val_mean_squared_error: 0.1217\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.0129\n",
      "Epoch 8: val_loss did not improve from 0.10583\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 0.0823 - mean_squared_error: 0.0129 - val_loss: 0.2824 - val_mean_squared_error: 0.0890\n",
      "55/55 [==============================] - 2s 15ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1126 - mean_squared_error: 0.0250\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 19s 132ms/step - loss: 0.1124 - mean_squared_error: 0.0249 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10639 to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 5s 112ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.10639 to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 5s 118ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.10639 to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 5s 117ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10639 to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt16_size11_pool5_do0.2_tra5_head4_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 5s 117ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 5s 114ms/step - loss: 0.1067 - mean_squared_error: 0.0208 - val_loss: 0.1955 - val_mean_squared_error: 0.0469\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0892 - mean_squared_error: 0.0153\n",
      "Epoch 7: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 0.0892 - mean_squared_error: 0.0153 - val_loss: 0.4062 - val_mean_squared_error: 0.1744\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0834 - mean_squared_error: 0.0133\n",
      "Epoch 8: val_loss did not improve from 0.10639\n",
      "42/42 [==============================] - 4s 101ms/step - loss: 0.0834 - mean_squared_error: 0.0133 - val_loss: 0.3840 - val_mean_squared_error: 0.1569\n",
      "55/55 [==============================] - 2s 14ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.25+-0.01\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1172 - mean_squared_error: 0.0305\n",
      "Epoch 1: val_loss improved from inf to 0.10822, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 21s 189ms/step - loss: 0.1172 - mean_squared_error: 0.0305 - val_loss: 0.1082 - val_mean_squared_error: 0.0213\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss improved from 0.10822 to 0.10734, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 7s 160ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1073 - val_mean_squared_error: 0.0211\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss improved from 0.10734 to 0.10499, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1050 - val_mean_squared_error: 0.0206\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss improved from 0.10499 to 0.08394, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 7s 173ms/step - loss: 0.1061 - mean_squared_error: 0.0206 - val_loss: 0.0839 - val_mean_squared_error: 0.0151\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0204\n",
      "Epoch 5: val_loss improved from 0.08394 to 0.07763, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1055 - mean_squared_error: 0.0204 - val_loss: 0.0776 - val_mean_squared_error: 0.0113\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0200\n",
      "Epoch 6: val_loss did not improve from 0.07763\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.1035 - mean_squared_error: 0.0200 - val_loss: 0.1561 - val_mean_squared_error: 0.0315\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.0178\n",
      "Epoch 7: val_loss did not improve from 0.07763\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.0948 - mean_squared_error: 0.0178 - val_loss: 0.2800 - val_mean_squared_error: 0.0880\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0878 - mean_squared_error: 0.0149\n",
      "Epoch 8: val_loss did not improve from 0.07763\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.0877 - mean_squared_error: 0.0149 - val_loss: 0.4366 - val_mean_squared_error: 0.2002\n",
      "55/55 [==============================] - 2s 20ms/step\n",
      " ###0 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1197 - mean_squared_error: 0.0315\n",
      "Epoch 1: val_loss improved from inf to 0.10578, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 20s 184ms/step - loss: 0.1197 - mean_squared_error: 0.0315 - val_loss: 0.1058 - val_mean_squared_error: 0.0205\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10578 to 0.10559, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 7s 168ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1056 - val_mean_squared_error: 0.0205\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10559 to 0.10523, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1052 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10523 to 0.10465, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1047 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10465 to 0.10326, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1033 - val_mean_squared_error: 0.0200\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.10326 to 0.10181, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.1074 - mean_squared_error: 0.0210 - val_loss: 0.1018 - val_mean_squared_error: 0.0197\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10181 to 0.07811, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 7s 173ms/step - loss: 0.1070 - mean_squared_error: 0.0209 - val_loss: 0.0781 - val_mean_squared_error: 0.0131\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1048 - mean_squared_error: 0.0205\n",
      "Epoch 8: val_loss did not improve from 0.07811\n",
      "42/42 [==============================] - 7s 158ms/step - loss: 0.1048 - mean_squared_error: 0.0205 - val_loss: 0.2090 - val_mean_squared_error: 0.0527\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0979 - mean_squared_error: 0.0184\n",
      "Epoch 9: val_loss did not improve from 0.07811\n",
      "42/42 [==============================] - 7s 158ms/step - loss: 0.0979 - mean_squared_error: 0.0184 - val_loss: 0.3720 - val_mean_squared_error: 0.1478\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.0147\n",
      "Epoch 10: val_loss did not improve from 0.07811\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.0876 - mean_squared_error: 0.0147 - val_loss: 0.4508 - val_mean_squared_error: 0.2126\n",
      "55/55 [==============================] - 1s 18ms/step\n",
      " ###1 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1183 - mean_squared_error: 0.0308\n",
      "Epoch 1: val_loss improved from inf to 0.10279, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 19s 192ms/step - loss: 0.1182 - mean_squared_error: 0.0308 - val_loss: 0.1028 - val_mean_squared_error: 0.0198\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10279 to 0.09952, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.0995 - val_mean_squared_error: 0.0191\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.09952 to 0.08819, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.1074 - mean_squared_error: 0.0210 - val_loss: 0.0882 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.08819 to 0.07478, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1072 - mean_squared_error: 0.0211 - val_loss: 0.0748 - val_mean_squared_error: 0.0112\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0207\n",
      "Epoch 5: val_loss did not improve from 0.07478\n",
      "42/42 [==============================] - 7s 171ms/step - loss: 0.1060 - mean_squared_error: 0.0207 - val_loss: 0.1594 - val_mean_squared_error: 0.0325\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0192\n",
      "Epoch 6: val_loss did not improve from 0.07478\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.1005 - mean_squared_error: 0.0192 - val_loss: 0.2980 - val_mean_squared_error: 0.0980\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0901 - mean_squared_error: 0.0156\n",
      "Epoch 7: val_loss did not improve from 0.07478\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.0901 - mean_squared_error: 0.0157 - val_loss: 0.3086 - val_mean_squared_error: 0.1044\n",
      "55/55 [==============================] - 2s 19ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1177 - mean_squared_error: 0.0303\n",
      "Epoch 1: val_loss improved from inf to 0.10558, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 23s 184ms/step - loss: 0.1177 - mean_squared_error: 0.0303 - val_loss: 0.1056 - val_mean_squared_error: 0.0206\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10558 to 0.10536, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 7s 165ms/step - loss: 0.1076 - mean_squared_error: 0.0209 - val_loss: 0.1054 - val_mean_squared_error: 0.0205\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10536 to 0.10461, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 7s 162ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1046 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10461 to 0.10050, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1005 - val_mean_squared_error: 0.0195\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0208\n",
      "Epoch 5: val_loss improved from 0.10050 to 0.08507, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.1069 - mean_squared_error: 0.0208 - val_loss: 0.0851 - val_mean_squared_error: 0.0158\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.08507 to 0.07534, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt16_size7_pool2_do0.5_tra4_head8_kdim64_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 7s 163ms/step - loss: 0.1066 - mean_squared_error: 0.0210 - val_loss: 0.0753 - val_mean_squared_error: 0.0115\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0198\n",
      "Epoch 7: val_loss did not improve from 0.07534\n",
      "42/42 [==============================] - 7s 168ms/step - loss: 0.1029 - mean_squared_error: 0.0198 - val_loss: 0.1356 - val_mean_squared_error: 0.0227\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0938 - mean_squared_error: 0.0167\n",
      "Epoch 8: val_loss did not improve from 0.07534\n",
      "42/42 [==============================] - 7s 157ms/step - loss: 0.0938 - mean_squared_error: 0.0167 - val_loss: 0.3722 - val_mean_squared_error: 0.1480\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.0141\n",
      "Epoch 9: val_loss did not improve from 0.07534\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.0859 - mean_squared_error: 0.0141 - val_loss: 0.3232 - val_mean_squared_error: 0.1139\n",
      "55/55 [==============================] - 2s 19ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae1.60+-0.03\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size11_pool2_do0.5_tra3_head4_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1495 - mean_squared_error: 0.0626\n",
      "Epoch 1: val_loss improved from inf to 0.11004, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size11_pool2_do0.5_tra3_head4_kdim128_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 18s 367ms/step - loss: 0.1495 - mean_squared_error: 0.0626 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 6s 279ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 6s 275ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 4: val_loss did not improve from 0.11004\n",
      "21/21 [==============================] - 6s 277ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 1s 16ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1509 - mean_squared_error: 0.0624\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size11_pool2_do0.5_tra3_head4_kdim128_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 17s 342ms/step - loss: 0.1509 - mean_squared_error: 0.0624 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 6s 278ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 6s 282ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10696\n",
      "21/21 [==============================] - 6s 278ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 3s 17ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1514 - mean_squared_error: 0.0627\n",
      "Epoch 1: val_loss improved from inf to 0.10585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size11_pool2_do0.5_tra3_head4_kdim128_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 19s 347ms/step - loss: 0.1514 - mean_squared_error: 0.0627 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 6s 283ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 6s 277ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10585\n",
      "21/21 [==============================] - 6s 279ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1059 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 2s 17ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1506 - mean_squared_error: 0.0622\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt64_size11_pool2_do0.5_tra3_head4_kdim128_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 16s 325ms/step - loss: 0.1506 - mean_squared_error: 0.0622 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 6s 281ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 6s 277ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.10639\n",
      "21/21 [==============================] - 6s 279ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 1s 17ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.26+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn3_filt16_size5_pool2_do0.2_tra5_head4_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 02:19:34.888928: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.49GiB (rounded to 1600000000)requested by op model/multi_head_attention_4/softmax/Softmax\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-22 02:19:34.889146: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-22 02:19:34.889175: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 441, Chunks in use: 440. 110.2KiB allocated for chunks. 110.0KiB in use in bin. 49.0KiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889187: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 264, Chunks in use: 264. 135.8KiB allocated for chunks. 135.8KiB in use in bin. 132.0KiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889199: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889210: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 128, Chunks in use: 128. 283.2KiB allocated for chunks. 283.2KiB in use in bin. 259.5KiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889221: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 8, Chunks in use: 7. 40.2KiB allocated for chunks. 36.0KiB in use in bin. 33.8KiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889232: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 3, Chunks in use: 3. 37.0KiB allocated for chunks. 37.0KiB in use in bin. 24.0KiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889243: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 2, Chunks in use: 0. 58.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889254: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 115, Chunks in use: 115. 3.84MiB allocated for chunks. 3.84MiB in use in bin. 3.59MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889263: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889274: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 21, Chunks in use: 21. 4.01MiB allocated for chunks. 4.01MiB in use in bin. 3.61MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889285: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 174, Chunks in use: 174. 48.92MiB allocated for chunks. 48.92MiB in use in bin. 43.03MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889296: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 16, Chunks in use: 16. 9.81MiB allocated for chunks. 9.81MiB in use in bin. 9.77MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889305: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889314: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889323: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889334: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 3, Chunks in use: 2. 33.67MiB allocated for chunks. 20.24MiB in use in bin. 19.53MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889346: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 13, Chunks in use: 12. 256.74MiB allocated for chunks. 237.21MiB in use in bin. 234.38MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889359: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 10, Chunks in use: 10. 461.91MiB allocated for chunks. 461.91MiB in use in bin. 390.62MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889369: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 27, Chunks in use: 26. 2.21GiB allocated for chunks. 2.09GiB in use in bin. 1.95GiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889383: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 3. 669.38MiB allocated for chunks. 435.00MiB in use in bin. 234.38MiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889395: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 29, Chunks in use: 26. 17.78GiB allocated for chunks. 16.06GiB in use in bin. 15.92GiB client-requested in use in bin.\n",
      "2023-09-22 02:19:34.889405: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 1.49GiB was 256.00MiB, Chunk State: \n",
      "2023-09-22 02:19:34.889425: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 312.50MiB | Requested Size: 128.0KiB | in_use: 0 | bin_num: 20, prev:   Size: 1.49GiB | Requested Size: 1.49GiB | in_use: 1 | bin_num: -1, next:   Size: 1.49GiB | Requested Size: 1.49GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 02:19:34.889441: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 588.38MiB | Requested Size: 312.50MiB | in_use: 0 | bin_num: 20, prev:   Size: 312.50MiB | Requested Size: 312.50MiB | in_use: 1 | bin_num: -1, next:   Size: 1.49GiB | Requested Size: 1.49GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 02:19:34.889452: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 859.64MiB | Requested Size: 256B | in_use: 0 | bin_num: 20, prev:   Size: 1.49GiB | Requested Size: 1.49GiB | in_use: 1 | bin_num: -1\n",
      "2023-09-22 02:19:34.889460: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 23023321088\n",
      "2023-09-22 02:19:34.889471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000000 of size 1280 next 1\n",
      "2023-09-22 02:19:34.889480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000500 of size 256 next 2\n",
      "2023-09-22 02:19:34.889487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000600 of size 256 next 3\n",
      "2023-09-22 02:19:34.889495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000700 of size 256 next 5\n",
      "2023-09-22 02:19:34.889502: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000800 of size 256 next 6\n",
      "2023-09-22 02:19:34.889509: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000900 of size 256 next 4\n",
      "2023-09-22 02:19:34.889517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000a00 of size 256 next 1112\n",
      "2023-09-22 02:19:34.889524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000b00 of size 256 next 950\n",
      "2023-09-22 02:19:34.889532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000c00 of size 256 next 328\n",
      "2023-09-22 02:19:34.889539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000d00 of size 256 next 12\n",
      "2023-09-22 02:19:34.889546: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000e00 of size 256 next 13\n",
      "2023-09-22 02:19:34.889554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de000f00 of size 256 next 14\n",
      "2023-09-22 02:19:34.889562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001000 of size 2048 next 1716\n",
      "2023-09-22 02:19:34.889574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de001800 of size 2048 next 952\n",
      "2023-09-22 02:19:34.889582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002000 of size 2048 next 976\n",
      "2023-09-22 02:19:34.889590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de002800 of size 2048 next 171\n",
      "2023-09-22 02:19:34.889603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003000 of size 2048 next 636\n",
      "2023-09-22 02:19:34.889611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de003800 of size 2304 next 28\n",
      "2023-09-22 02:19:34.889621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004100 of size 256 next 29\n",
      "2023-09-22 02:19:34.889629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004200 of size 256 next 30\n",
      "2023-09-22 02:19:34.889638: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004300 of size 256 next 61\n",
      "2023-09-22 02:19:34.889645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004400 of size 256 next 309\n",
      "2023-09-22 02:19:34.889653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004500 of size 256 next 563\n",
      "2023-09-22 02:19:34.889660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004600 of size 256 next 42\n",
      "2023-09-22 02:19:34.889670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004700 of size 256 next 37\n",
      "2023-09-22 02:19:34.889678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004800 of size 256 next 36\n",
      "2023-09-22 02:19:34.889687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004900 of size 512 next 855\n",
      "2023-09-22 02:19:34.889697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004b00 of size 512 next 213\n",
      "2023-09-22 02:19:34.889707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004d00 of size 512 next 310\n",
      "2023-09-22 02:19:34.889715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de004f00 of size 512 next 1236\n",
      "2023-09-22 02:19:34.889724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005100 of size 2048 next 1564\n",
      "2023-09-22 02:19:34.889732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005900 of size 512 next 15\n",
      "2023-09-22 02:19:34.889739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005b00 of size 512 next 958\n",
      "2023-09-22 02:19:34.889748: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005d00 of size 512 next 366\n",
      "2023-09-22 02:19:34.889756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de005f00 of size 512 next 32\n",
      "2023-09-22 02:19:34.889767: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006100 of size 256 next 31\n",
      "2023-09-22 02:19:34.889777: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006200 of size 256 next 33\n",
      "2023-09-22 02:19:34.889787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006300 of size 256 next 1131\n",
      "2023-09-22 02:19:34.889797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006400 of size 256 next 1257\n",
      "2023-09-22 02:19:34.889807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006500 of size 256 next 813\n",
      "2023-09-22 02:19:34.889815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006600 of size 256 next 1689\n",
      "2023-09-22 02:19:34.889824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006700 of size 256 next 911\n",
      "2023-09-22 02:19:34.889831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006800 of size 256 next 35\n",
      "2023-09-22 02:19:34.889841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006900 of size 256 next 45\n",
      "2023-09-22 02:19:34.889851: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006a00 of size 256 next 48\n",
      "2023-09-22 02:19:34.889861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006b00 of size 256 next 49\n",
      "2023-09-22 02:19:34.889872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de006c00 of size 32768 next 54\n",
      "2023-09-22 02:19:34.889881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de00ec00 of size 32768 next 394\n",
      "2023-09-22 02:19:34.889891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de016c00 of size 32768 next 1285\n",
      "2023-09-22 02:19:34.889900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de01ec00 of size 32768 next 865\n",
      "2023-09-22 02:19:34.889910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de026c00 of size 36608 next 105\n",
      "2023-09-22 02:19:34.889918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fb00 of size 256 next 103\n",
      "2023-09-22 02:19:34.889927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fc00 of size 256 next 104\n",
      "2023-09-22 02:19:34.889935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fd00 of size 256 next 107\n",
      "2023-09-22 02:19:34.889942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02fe00 of size 256 next 110\n",
      "2023-09-22 02:19:34.889952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de02ff00 of size 256 next 115\n",
      "2023-09-22 02:19:34.889959: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030000 of size 256 next 116\n",
      "2023-09-22 02:19:34.889968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030100 of size 256 next 117\n",
      "2023-09-22 02:19:34.889976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030200 of size 256 next 1229\n",
      "2023-09-22 02:19:34.889983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030300 of size 256 next 176\n",
      "2023-09-22 02:19:34.889992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030400 of size 256 next 501\n",
      "2023-09-22 02:19:34.890002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030500 of size 256 next 646\n",
      "2023-09-22 02:19:34.890012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030600 of size 256 next 108\n",
      "2023-09-22 02:19:34.890021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030700 of size 256 next 109\n",
      "2023-09-22 02:19:34.890031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11de030800 of size 327680000 next 1629\n",
      "2023-09-22 02:19:34.890040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11f18b0800 of size 327680000 next 1251\n",
      "2023-09-22 02:19:34.890049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1205130800 of size 327680000 next 1524\n",
      "2023-09-22 02:19:34.890059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12189b0800 of size 327680000 next 899\n",
      "2023-09-22 02:19:34.890068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f122c230800 of size 81920000 next 1468\n",
      "2023-09-22 02:19:34.890080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1231050800 of size 81920000 next 691\n",
      "2023-09-22 02:19:34.890089: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1235e70800 of size 81920000 next 151\n",
      "2023-09-22 02:19:34.890098: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f123ac90800 of size 125521920 next 953\n",
      "2023-09-22 02:19:34.890107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445800 of size 256 next 925\n",
      "2023-09-22 02:19:34.890117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1242445900 of size 65561344 next 894\n",
      "2023-09-22 02:19:34.890126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbc00 of size 256 next 695\n",
      "2023-09-22 02:19:34.890135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbd00 of size 256 next 1266\n",
      "2023-09-22 02:19:34.890144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12462cbe00 of size 320768 next 1347\n",
      "2023-09-22 02:19:34.890153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124631a300 of size 262144 next 1375\n",
      "2023-09-22 02:19:34.890163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124635a300 of size 378880 next 587\n",
      "2023-09-22 02:19:34.890172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463b6b00 of size 256 next 415\n",
      "2023-09-22 02:19:34.890181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463b6c00 of size 256 next 159\n",
      "2023-09-22 02:19:34.890190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463b6d00 of size 262144 next 19\n",
      "2023-09-22 02:19:34.890200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12463f6d00 of size 379136 next 774\n",
      "2023-09-22 02:19:34.890209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246453600 of size 32768 next 371\n",
      "2023-09-22 02:19:34.890218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124645b600 of size 32768 next 621\n",
      "2023-09-22 02:19:34.890227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246463600 of size 32768 next 786\n",
      "2023-09-22 02:19:34.890236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124646b600 of size 32768 next 397\n",
      "2023-09-22 02:19:34.890244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246473600 of size 320512 next 8\n",
      "2023-09-22 02:19:34.890253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464c1a00 of size 32768 next 212\n",
      "2023-09-22 02:19:34.890262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12464c9a00 of size 262144 next 1458\n",
      "2023-09-22 02:19:34.890271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246509a00 of size 477184 next 1238\n",
      "2023-09-22 02:19:34.890280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124657e200 of size 32768 next 1501\n",
      "2023-09-22 02:19:34.890290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246586200 of size 32768 next 985\n",
      "2023-09-22 02:19:34.890297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124658e200 of size 32768 next 1419\n",
      "2023-09-22 02:19:34.890306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246596200 of size 262144 next 1756\n",
      "2023-09-22 02:19:34.890315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12465d6200 of size 262144 next 433\n",
      "2023-09-22 02:19:34.890325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246616200 of size 262144 next 590\n",
      "2023-09-22 02:19:34.890334: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246656200 of size 262144 next 289\n",
      "2023-09-22 02:19:34.890343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1246696200 of size 311808 next 959\n",
      "2023-09-22 02:19:34.890355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2400 of size 256 next 1426\n",
      "2023-09-22 02:19:34.890365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466e2500 of size 64256 next 291\n",
      "2023-09-22 02:19:34.890374: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2000 of size 256 next 880\n",
      "2023-09-22 02:19:34.890384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2100 of size 512 next 63\n",
      "2023-09-22 02:19:34.890393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2300 of size 512 next 965\n",
      "2023-09-22 02:19:34.890402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2500 of size 512 next 640\n",
      "2023-09-22 02:19:34.890411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2700 of size 256 next 568\n",
      "2023-09-22 02:19:34.890421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2800 of size 256 next 1018\n",
      "2023-09-22 02:19:34.890431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f2900 of size 2048 next 1728\n",
      "2023-09-22 02:19:34.890441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3100 of size 512 next 873\n",
      "2023-09-22 02:19:34.890450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3300 of size 512 next 1017\n",
      "2023-09-22 02:19:34.890459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3500 of size 512 next 147\n",
      "2023-09-22 02:19:34.890470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3700 of size 512 next 227\n",
      "2023-09-22 02:19:34.890479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f3900 of size 2048 next 127\n",
      "2023-09-22 02:19:34.890488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4100 of size 3072 next 1325\n",
      "2023-09-22 02:19:34.890497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4d00 of size 512 next 1252\n",
      "2023-09-22 02:19:34.890506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f4f00 of size 512 next 1781\n",
      "2023-09-22 02:19:34.890516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5100 of size 512 next 1143\n",
      "2023-09-22 02:19:34.890526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5300 of size 512 next 849\n",
      "2023-09-22 02:19:34.890535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5500 of size 768 next 98\n",
      "2023-09-22 02:19:34.890545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5800 of size 256 next 385\n",
      "2023-09-22 02:19:34.890555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5900 of size 256 next 705\n",
      "2023-09-22 02:19:34.890565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5a00 of size 256 next 225\n",
      "2023-09-22 02:19:34.890575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12466f5b00 of size 10556928 next 1155\n",
      "2023-09-22 02:19:34.890584: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107100 of size 256 next 995\n",
      "2023-09-22 02:19:34.890595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247107200 of size 32768 next 893\n",
      "2023-09-22 02:19:34.890603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124710f200 of size 32768 next 332\n",
      "2023-09-22 02:19:34.890612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247117200 of size 62720 next 1140\n",
      "2023-09-22 02:19:34.890621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126700 of size 256 next 47\n",
      "2023-09-22 02:19:34.890630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126800 of size 256 next 1130\n",
      "2023-09-22 02:19:34.890640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126900 of size 256 next 1708\n",
      "2023-09-22 02:19:34.890650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126a00 of size 256 next 312\n",
      "2023-09-22 02:19:34.890660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126b00 of size 256 next 1329\n",
      "2023-09-22 02:19:34.890670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126c00 of size 256 next 730\n",
      "2023-09-22 02:19:34.890679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126d00 of size 256 next 1291\n",
      "2023-09-22 02:19:34.890688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126e00 of size 256 next 1114\n",
      "2023-09-22 02:19:34.890698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247126f00 of size 256 next 268\n",
      "2023-09-22 02:19:34.890707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127000 of size 256 next 399\n",
      "2023-09-22 02:19:34.890716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127100 of size 256 next 1399\n",
      "2023-09-22 02:19:34.890726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127200 of size 256 next 34\n",
      "2023-09-22 02:19:34.890735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127300 of size 256 next 1334\n",
      "2023-09-22 02:19:34.890744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127400 of size 1024 next 1045\n",
      "2023-09-22 02:19:34.890754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127800 of size 256 next 201\n",
      "2023-09-22 02:19:34.890763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127900 of size 256 next 1219\n",
      "2023-09-22 02:19:34.890772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127a00 of size 256 next 1228\n",
      "2023-09-22 02:19:34.890781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127b00 of size 256 next 1032\n",
      "2023-09-22 02:19:34.890790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127c00 of size 256 next 1402\n",
      "2023-09-22 02:19:34.890798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127d00 of size 256 next 185\n",
      "2023-09-22 02:19:34.890808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127e00 of size 256 next 137\n",
      "2023-09-22 02:19:34.890817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247127f00 of size 256 next 812\n",
      "2023-09-22 02:19:34.890826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128000 of size 256 next 729\n",
      "2023-09-22 02:19:34.890835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128100 of size 256 next 742\n",
      "2023-09-22 02:19:34.890844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128200 of size 256 next 470\n",
      "2023-09-22 02:19:34.890853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128300 of size 256 next 374\n",
      "2023-09-22 02:19:34.890862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128400 of size 2048 next 1415\n",
      "2023-09-22 02:19:34.890871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247128c00 of size 2048 next 1460\n",
      "2023-09-22 02:19:34.890881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129400 of size 2048 next 719\n",
      "2023-09-22 02:19:34.890890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129c00 of size 512 next 1822\n",
      "2023-09-22 02:19:34.890899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129e00 of size 256 next 96\n",
      "2023-09-22 02:19:34.890907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247129f00 of size 512 next 1821\n",
      "2023-09-22 02:19:34.890915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a100 of size 512 next 589\n",
      "2023-09-22 02:19:34.890925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a300 of size 512 next 468\n",
      "2023-09-22 02:19:34.890935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712a500 of size 2816 next 823\n",
      "2023-09-22 02:19:34.890944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b000 of size 256 next 832\n",
      "2023-09-22 02:19:34.890953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124712b100 of size 246528 next 858\n",
      "2023-09-22 02:19:34.890964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247167400 of size 256 next 653\n",
      "2023-09-22 02:19:34.890973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247167500 of size 33792 next 545\n",
      "2023-09-22 02:19:34.890982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124716f900 of size 32768 next 405\n",
      "2023-09-22 02:19:34.890991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247177900 of size 32768 next 889\n",
      "2023-09-22 02:19:34.891000: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f124717f900 of size 32768 next 183\n",
      "2023-09-22 02:19:34.891009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247187900 of size 50432 next 163\n",
      "2023-09-22 02:19:34.891019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193e00 of size 256 next 123\n",
      "2023-09-22 02:19:34.891027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247193f00 of size 256 next 1630\n",
      "2023-09-22 02:19:34.891036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194000 of size 256 next 776\n",
      "2023-09-22 02:19:34.891045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194100 of size 256 next 1311\n",
      "2023-09-22 02:19:34.891054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194200 of size 256 next 658\n",
      "2023-09-22 02:19:34.891063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194300 of size 256 next 453\n",
      "2023-09-22 02:19:34.891072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194400 of size 256 next 989\n",
      "2023-09-22 02:19:34.891082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247194500 of size 262144 next 948\n",
      "2023-09-22 02:19:34.891092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12471d4500 of size 475648 next 1262\n",
      "2023-09-22 02:19:34.891101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247248700 of size 256 next 1385\n",
      "2023-09-22 02:19:34.891111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247248800 of size 512 next 1633\n",
      "2023-09-22 02:19:34.891120: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247248a00 of size 512 next 1739\n",
      "2023-09-22 02:19:34.891129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247248c00 of size 256 next 1479\n",
      "2023-09-22 02:19:34.891150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247248d00 of size 256 next 694\n",
      "2023-09-22 02:19:34.891160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247248e00 of size 2560 next 1051\n",
      "2023-09-22 02:19:34.891170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247249800 of size 262144 next 1684\n",
      "2023-09-22 02:19:34.891180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247289800 of size 378880 next 571\n",
      "2023-09-22 02:19:34.891190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12472e6000 of size 262144 next 293\n",
      "2023-09-22 02:19:34.891200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247326000 of size 262144 next 592\n",
      "2023-09-22 02:19:34.891209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247366000 of size 262144 next 535\n",
      "2023-09-22 02:19:34.891220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473a6000 of size 262144 next 1527\n",
      "2023-09-22 02:19:34.891229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12473e6000 of size 262144 next 1159\n",
      "2023-09-22 02:19:34.891238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247426000 of size 262144 next 71\n",
      "2023-09-22 02:19:34.891248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247466000 of size 350208 next 373\n",
      "2023-09-22 02:19:34.891257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474bb800 of size 32768 next 1698\n",
      "2023-09-22 02:19:34.891266: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12474c3800 of size 262144 next 1351\n",
      "2023-09-22 02:19:34.891275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247503800 of size 477184 next 449\n",
      "2023-09-22 02:19:34.891284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247578000 of size 32768 next 585\n",
      "2023-09-22 02:19:34.891294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247580000 of size 32768 next 348\n",
      "2023-09-22 02:19:34.891303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247588000 of size 32768 next 1064\n",
      "2023-09-22 02:19:34.891312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247590000 of size 262144 next 1273\n",
      "2023-09-22 02:19:34.891321: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12475d0000 of size 262144 next 1137\n",
      "2023-09-22 02:19:34.891330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247610000 of size 262144 next 629\n",
      "2023-09-22 02:19:34.891339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247650000 of size 262144 next 382\n",
      "2023-09-22 02:19:34.891348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247690000 of size 262144 next 173\n",
      "2023-09-22 02:19:34.891358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12476d0000 of size 262144 next 500\n",
      "2023-09-22 02:19:34.891367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247710000 of size 262144 next 914\n",
      "2023-09-22 02:19:34.891376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247750000 of size 262144 next 1494\n",
      "2023-09-22 02:19:34.891386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247790000 of size 366336 next 918\n",
      "2023-09-22 02:19:34.891395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9700 of size 256 next 440\n",
      "2023-09-22 02:19:34.891404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9800 of size 256 next 999\n",
      "2023-09-22 02:19:34.891413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12477e9900 of size 263424 next 1115\n",
      "2023-09-22 02:19:34.891421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247829e00 of size 262144 next 1676\n",
      "2023-09-22 02:19:34.891430: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247869e00 of size 262144 next 1113\n",
      "2023-09-22 02:19:34.891439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12478a9e00 of size 262144 next 192\n",
      "2023-09-22 02:19:34.891448: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12478e9e00 of size 262144 next 987\n",
      "2023-09-22 02:19:34.891457: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247929e00 of size 262144 next 1457\n",
      "2023-09-22 02:19:34.891467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247969e00 of size 262144 next 1407\n",
      "2023-09-22 02:19:34.891476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479a9e00 of size 32768 next 620\n",
      "2023-09-22 02:19:34.891485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479b1e00 of size 33280 next 1517\n",
      "2023-09-22 02:19:34.891496: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479ba000 of size 32768 next 992\n",
      "2023-09-22 02:19:34.891506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479c2000 of size 51200 next 265\n",
      "2023-09-22 02:19:34.891515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479ce800 of size 32768 next 664\n",
      "2023-09-22 02:19:34.891524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479d6800 of size 33280 next 245\n",
      "2023-09-22 02:19:34.891533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479dea00 of size 32768 next 1668\n",
      "2023-09-22 02:19:34.891543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479e6a00 of size 46336 next 1581\n",
      "2023-09-22 02:19:34.891552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f1f00 of size 256 next 1464\n",
      "2023-09-22 02:19:34.891561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2000 of size 256 next 1589\n",
      "2023-09-22 02:19:34.891570: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12479f2100 of size 180224 next 1706\n",
      "2023-09-22 02:19:34.891580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a1e100 of size 299776 next 1020\n",
      "2023-09-22 02:19:34.891589: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67400 of size 256 next 1361\n",
      "2023-09-22 02:19:34.891599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a67500 of size 3584 next 1784\n",
      "2023-09-22 02:19:34.891608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68300 of size 512 next 766\n",
      "2023-09-22 02:19:34.891617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68500 of size 512 next 1549\n",
      "2023-09-22 02:19:34.891626: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68700 of size 512 next 65\n",
      "2023-09-22 02:19:34.891635: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68900 of size 512 next 1274\n",
      "2023-09-22 02:19:34.891644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68b00 of size 512 next 1700\n",
      "2023-09-22 02:19:34.891653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68d00 of size 512 next 323\n",
      "2023-09-22 02:19:34.891662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a68f00 of size 512 next 1048\n",
      "2023-09-22 02:19:34.891672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69100 of size 256 next 1393\n",
      "2023-09-22 02:19:34.891681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69200 of size 256 next 184\n",
      "2023-09-22 02:19:34.891690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247a69300 of size 262144 next 737\n",
      "2023-09-22 02:19:34.891699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247aa9300 of size 262144 next 1522\n",
      "2023-09-22 02:19:34.891708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ae9300 of size 262144 next 230\n",
      "2023-09-22 02:19:34.891717: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b29300 of size 262144 next 957\n",
      "2023-09-22 02:19:34.891725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247b69300 of size 262144 next 734\n",
      "2023-09-22 02:19:34.891734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ba9300 of size 276736 next 725\n",
      "2023-09-22 02:19:34.891743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247becc00 of size 262144 next 525\n",
      "2023-09-22 02:19:34.891752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247c2cc00 of size 262144 next 370\n",
      "2023-09-22 02:19:34.891762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247c6cc00 of size 437248 next 1695\n",
      "2023-09-22 02:19:34.891771: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247cd7800 of size 414720 next 1103\n",
      "2023-09-22 02:19:34.891782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247d3cc00 of size 262144 next 656\n",
      "2023-09-22 02:19:34.891791: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247d7cc00 of size 393216 next 1604\n",
      "2023-09-22 02:19:34.891800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247ddcc00 of size 32768 next 1004\n",
      "2023-09-22 02:19:34.891809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247de4c00 of size 32768 next 612\n",
      "2023-09-22 02:19:34.891818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247decc00 of size 32768 next 933\n",
      "2023-09-22 02:19:34.891827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247df4c00 of size 32768 next 924\n",
      "2023-09-22 02:19:34.891836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247dfcc00 of size 32768 next 651\n",
      "2023-09-22 02:19:34.891845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e04c00 of size 32768 next 1505\n",
      "2023-09-22 02:19:34.891854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e0cc00 of size 32768 next 1442\n",
      "2023-09-22 02:19:34.891863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e14c00 of size 32768 next 800\n",
      "2023-09-22 02:19:34.891872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e1cc00 of size 32768 next 197\n",
      "2023-09-22 02:19:34.891881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e24c00 of size 32768 next 852\n",
      "2023-09-22 02:19:34.891891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e2cc00 of size 32768 next 700\n",
      "2023-09-22 02:19:34.891900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e34c00 of size 32768 next 384\n",
      "2023-09-22 02:19:34.891909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e3cc00 of size 32768 next 134\n",
      "2023-09-22 02:19:34.891919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e44c00 of size 32768 next 805\n",
      "2023-09-22 02:19:34.891929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e4cc00 of size 32768 next 1144\n",
      "2023-09-22 02:19:34.891938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e54c00 of size 2048 next 1080\n",
      "2023-09-22 02:19:34.891947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e55400 of size 512 next 488\n",
      "2023-09-22 02:19:34.891957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e55600 of size 512 next 713\n",
      "2023-09-22 02:19:34.891967: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e55800 of size 512 next 1184\n",
      "2023-09-22 02:19:34.891976: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e55a00 of size 256 next 1146\n",
      "2023-09-22 02:19:34.891986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e55b00 of size 256 next 1283\n",
      "2023-09-22 02:19:34.891996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e55c00 of size 2048 next 1568\n",
      "2023-09-22 02:19:34.892007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e56400 of size 2048 next 923\n",
      "2023-09-22 02:19:34.892016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e56c00 of size 2048 next 1631\n",
      "2023-09-22 02:19:34.892025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e57400 of size 512 next 1309\n",
      "2023-09-22 02:19:34.892033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e57600 of size 512 next 1090\n",
      "2023-09-22 02:19:34.892042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e57800 of size 512 next 1530\n",
      "2023-09-22 02:19:34.892051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e57a00 of size 2048 next 679\n",
      "2023-09-22 02:19:34.892060: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e58200 of size 2048 next 22\n",
      "2023-09-22 02:19:34.892070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e58a00 of size 2048 next 1717\n",
      "2023-09-22 02:19:34.892078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e59200 of size 2048 next 1160\n",
      "2023-09-22 02:19:34.892085: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e59a00 of size 2048 next 1188\n",
      "2023-09-22 02:19:34.892095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5a200 of size 2048 next 667\n",
      "2023-09-22 02:19:34.892105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5aa00 of size 512 next 119\n",
      "2023-09-22 02:19:34.892114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5ac00 of size 512 next 1264\n",
      "2023-09-22 02:19:34.892123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5ae00 of size 256 next 1814\n",
      "2023-09-22 02:19:34.892133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5af00 of size 768 next 234\n",
      "2023-09-22 02:19:34.892142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5b200 of size 2048 next 237\n",
      "2023-09-22 02:19:34.892151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5ba00 of size 2048 next 1675\n",
      "2023-09-22 02:19:34.892161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5c200 of size 2560 next 1176\n",
      "2023-09-22 02:19:34.892170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e5cc00 of size 262144 next 1200\n",
      "2023-09-22 02:19:34.892179: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247e9cc00 of size 273408 next 609\n",
      "2023-09-22 02:19:34.892188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247edf800 of size 262144 next 708\n",
      "2023-09-22 02:19:34.892197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247f1f800 of size 262144 next 1661\n",
      "2023-09-22 02:19:34.892207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247f5f800 of size 336384 next 1542\n",
      "2023-09-22 02:19:34.892216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247fb1a00 of size 32768 next 55\n",
      "2023-09-22 02:19:34.892225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1247fb9a00 of size 491520 next 749\n",
      "2023-09-22 02:19:34.892235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1248031a00 of size 262144 next 388\n",
      "2023-09-22 02:19:34.892245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1248071a00 of size 363264 next 1295\n",
      "2023-09-22 02:19:34.892254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca500 of size 256 next 671\n",
      "2023-09-22 02:19:34.892263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca600 of size 256 next 1061\n",
      "2023-09-22 02:19:34.892273: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca700 of size 256 next 1514\n",
      "2023-09-22 02:19:34.892282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12480ca800 of size 154428416 next 827\n",
      "2023-09-22 02:19:34.892292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251410c00 of size 32768 next 1009\n",
      "2023-09-22 02:19:34.892301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251418c00 of size 32768 next 552\n",
      "2023-09-22 02:19:34.892311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251420c00 of size 32768 next 1439\n",
      "2023-09-22 02:19:34.892320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251428c00 of size 32768 next 1509\n",
      "2023-09-22 02:19:34.892330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251430c00 of size 262144 next 1293\n",
      "2023-09-22 02:19:34.892339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251470c00 of size 262144 next 1332\n",
      "2023-09-22 02:19:34.892348: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12514b0c00 of size 262144 next 1110\n",
      "2023-09-22 02:19:34.892357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12514f0c00 of size 262144 next 1745\n",
      "2023-09-22 02:19:34.892367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251530c00 of size 262144 next 272\n",
      "2023-09-22 02:19:34.892376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1251570c00 of size 262144 next 919\n",
      "2023-09-22 02:19:34.892383: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12515b0c00 of size 262144 next 111\n",
      "2023-09-22 02:19:34.892392: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12515f0c00 of size 437248 next 434\n",
      "2023-09-22 02:19:34.892403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125165b800 of size 349184 next 1164\n",
      "2023-09-22 02:19:34.892412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12516b0c00 of size 452608 next 1386\n",
      "2023-09-22 02:19:34.892424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125171f400 of size 73954048 next 514\n",
      "2023-09-22 02:19:34.892433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6700 of size 256 next 284\n",
      "2023-09-22 02:19:34.892442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6800 of size 256 next 796\n",
      "2023-09-22 02:19:34.892451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255da6900 of size 262144 next 1721\n",
      "2023-09-22 02:19:34.892460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255de6900 of size 262144 next 1622\n",
      "2023-09-22 02:19:34.892469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e26900 of size 262144 next 1815\n",
      "2023-09-22 02:19:34.892478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255e66900 of size 506880 next 1066\n",
      "2023-09-22 02:19:34.892487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee2500 of size 512 next 1598\n",
      "2023-09-22 02:19:34.892497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee2700 of size 512 next 1463\n",
      "2023-09-22 02:19:34.892506: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee2900 of size 512 next 963\n",
      "2023-09-22 02:19:34.892515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee2b00 of size 512 next 1525\n",
      "2023-09-22 02:19:34.892524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee2d00 of size 512 next 448\n",
      "2023-09-22 02:19:34.892533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee2f00 of size 512 next 884\n",
      "2023-09-22 02:19:34.892542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3100 of size 256 next 16\n",
      "2023-09-22 02:19:34.892551: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3200 of size 256 next 1592\n",
      "2023-09-22 02:19:34.892561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3300 of size 512 next 46\n",
      "2023-09-22 02:19:34.892570: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3500 of size 512 next 905\n",
      "2023-09-22 02:19:34.892579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3700 of size 512 next 1733\n",
      "2023-09-22 02:19:34.892588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3900 of size 512 next 1382\n",
      "2023-09-22 02:19:34.892598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3b00 of size 512 next 1359\n",
      "2023-09-22 02:19:34.892607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3d00 of size 512 next 315\n",
      "2023-09-22 02:19:34.892616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee3f00 of size 2048 next 44\n",
      "2023-09-22 02:19:34.892625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee4700 of size 2048 next 1043\n",
      "2023-09-22 02:19:34.892634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee4f00 of size 2048 next 1657\n",
      "2023-09-22 02:19:34.892643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee5700 of size 2048 next 1735\n",
      "2023-09-22 02:19:34.892652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee5f00 of size 2048 next 1284\n",
      "2023-09-22 02:19:34.892661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee6700 of size 2048 next 177\n",
      "2023-09-22 02:19:34.892671: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee6f00 of size 2048 next 983\n",
      "2023-09-22 02:19:34.892680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee7700 of size 2048 next 326\n",
      "2023-09-22 02:19:34.892687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee7f00 of size 512 next 207\n",
      "2023-09-22 02:19:34.892696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee8100 of size 512 next 1226\n",
      "2023-09-22 02:19:34.892705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee8300 of size 512 next 333\n",
      "2023-09-22 02:19:34.892714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee8500 of size 2048 next 1613\n",
      "2023-09-22 02:19:34.892723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee8d00 of size 2048 next 1340\n",
      "2023-09-22 02:19:34.892733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee9500 of size 2560 next 1192\n",
      "2023-09-22 02:19:34.892742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ee9f00 of size 46848 next 673\n",
      "2023-09-22 02:19:34.892752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5600 of size 256 next 1259\n",
      "2023-09-22 02:19:34.892761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5700 of size 2048 next 888\n",
      "2023-09-22 02:19:34.892770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef5f00 of size 2048 next 170\n",
      "2023-09-22 02:19:34.892779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef6700 of size 3840 next 520\n",
      "2023-09-22 02:19:34.892788: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7600 of size 256 next 214\n",
      "2023-09-22 02:19:34.892798: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7700 of size 512 next 623\n",
      "2023-09-22 02:19:34.892807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7900 of size 512 next 1021\n",
      "2023-09-22 02:19:34.892816: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7b00 of size 512 next 81\n",
      "2023-09-22 02:19:34.892825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7d00 of size 256 next 1250\n",
      "2023-09-22 02:19:34.892834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7e00 of size 256 next 172\n",
      "2023-09-22 02:19:34.892844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef7f00 of size 256 next 1843\n",
      "2023-09-22 02:19:34.892853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8000 of size 256 next 542\n",
      "2023-09-22 02:19:34.892862: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8100 of size 512 next 600\n",
      "2023-09-22 02:19:34.892871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8300 of size 768 next 202\n",
      "2023-09-22 02:19:34.892880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8600 of size 256 next 1324\n",
      "2023-09-22 02:19:34.892889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef8700 of size 5888 next 256\n",
      "2023-09-22 02:19:34.892898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9e00 of size 256 next 152\n",
      "2023-09-22 02:19:34.892907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255ef9f00 of size 256 next 562\n",
      "2023-09-22 02:19:34.892916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa000 of size 256 next 1052\n",
      "2023-09-22 02:19:34.892925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa100 of size 512 next 1459\n",
      "2023-09-22 02:19:34.892934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa300 of size 256 next 878\n",
      "2023-09-22 02:19:34.892943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa400 of size 256 next 676\n",
      "2023-09-22 02:19:34.892952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa500 of size 256 next 220\n",
      "2023-09-22 02:19:34.892961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa600 of size 256 next 1799\n",
      "2023-09-22 02:19:34.892970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa700 of size 256 next 462\n",
      "2023-09-22 02:19:34.892979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa800 of size 256 next 1015\n",
      "2023-09-22 02:19:34.892987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efa900 of size 256 next 1646\n",
      "2023-09-22 02:19:34.892996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efaa00 of size 256 next 1414\n",
      "2023-09-22 02:19:34.893005: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efab00 of size 256 next 1019\n",
      "2023-09-22 02:19:34.893014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efac00 of size 256 next 430\n",
      "2023-09-22 02:19:34.893023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efad00 of size 256 next 1644\n",
      "2023-09-22 02:19:34.893032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efae00 of size 256 next 1662\n",
      "2023-09-22 02:19:34.893041: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efaf00 of size 256 next 762\n",
      "2023-09-22 02:19:34.893050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb000 of size 256 next 1380\n",
      "2023-09-22 02:19:34.893059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb100 of size 256 next 1579\n",
      "2023-09-22 02:19:34.893068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb200 of size 256 next 1748\n",
      "2023-09-22 02:19:34.893077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb300 of size 256 next 1313\n",
      "2023-09-22 02:19:34.893086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb400 of size 256 next 1342\n",
      "2023-09-22 02:19:34.893095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb500 of size 256 next 1718\n",
      "2023-09-22 02:19:34.893104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb600 of size 256 next 1215\n",
      "2023-09-22 02:19:34.893113: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb700 of size 256 next 1368\n",
      "2023-09-22 02:19:34.893122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb800 of size 256 next 1027\n",
      "2023-09-22 02:19:34.893131: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efb900 of size 256 next 624\n",
      "2023-09-22 02:19:34.893141: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efba00 of size 2560 next 120\n",
      "2023-09-22 02:19:34.893150: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efc400 of size 3584 next 683\n",
      "2023-09-22 02:19:34.893159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd200 of size 256 next 1296\n",
      "2023-09-22 02:19:34.893168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1255efd300 of size 23455488 next 1409\n",
      "2023-09-22 02:19:34.893177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ba00 of size 256 next 630\n",
      "2023-09-22 02:19:34.893186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755bb00 of size 5120 next 1168\n",
      "2023-09-22 02:19:34.893195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755cf00 of size 256 next 789\n",
      "2023-09-22 02:19:34.893204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755d000 of size 256 next 203\n",
      "2023-09-22 02:19:34.893214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755d100 of size 256 next 709\n",
      "2023-09-22 02:19:34.893223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755d200 of size 256 next 1041\n",
      "2023-09-22 02:19:34.893233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755d300 of size 256 next 808\n",
      "2023-09-22 02:19:34.893243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755d400 of size 256 next 1028\n",
      "2023-09-22 02:19:34.893253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755d500 of size 5120 next 1395\n",
      "2023-09-22 02:19:34.893263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755e900 of size 5120 next 1072\n",
      "2023-09-22 02:19:34.893272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755fd00 of size 256 next 1819\n",
      "2023-09-22 02:19:34.893282: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755fe00 of size 256 next 631\n",
      "2023-09-22 02:19:34.893292: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125755ff00 of size 256 next 196\n",
      "2023-09-22 02:19:34.893301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257560000 of size 256 next 1771\n",
      "2023-09-22 02:19:34.893310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257560100 of size 256 next 1057\n",
      "2023-09-22 02:19:34.893319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257560200 of size 256 next 95\n",
      "2023-09-22 02:19:34.893329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257560300 of size 15360 next 554\n",
      "2023-09-22 02:19:34.893341: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257563f00 of size 33792 next 1330\n",
      "2023-09-22 02:19:34.893350: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125756c300 of size 33792 next 1302\n",
      "2023-09-22 02:19:34.893359: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257574700 of size 33792 next 26\n",
      "2023-09-22 02:19:34.893369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125757cb00 of size 45056 next 971\n",
      "2023-09-22 02:19:34.893378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257587b00 of size 180224 next 860\n",
      "2023-09-22 02:19:34.893387: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12575b3b00 of size 33792 next 794\n",
      "2023-09-22 02:19:34.893396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12575bbf00 of size 33792 next 1149\n",
      "2023-09-22 02:19:34.893405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12575c4300 of size 33792 next 280\n",
      "2023-09-22 02:19:34.893415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12575cc700 of size 33792 next 1816\n",
      "2023-09-22 02:19:34.893424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12575d4b00 of size 45056 next 368\n",
      "2023-09-22 02:19:34.893433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12575dfb00 of size 180224 next 1626\n",
      "2023-09-22 02:19:34.893442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125760bb00 of size 344064 next 367\n",
      "2023-09-22 02:19:34.893452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125765fb00 of size 464896 next 1634\n",
      "2023-09-22 02:19:34.893462: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1300 of size 256 next 780\n",
      "2023-09-22 02:19:34.893471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12576d1400 of size 262144 next 253\n",
      "2023-09-22 02:19:34.893480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257711400 of size 262144 next 1239\n",
      "2023-09-22 02:19:34.893489: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257751400 of size 262144 next 1736\n",
      "2023-09-22 02:19:34.893498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257791400 of size 262144 next 1425\n",
      "2023-09-22 02:19:34.893508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12577d1400 of size 294912 next 1381\n",
      "2023-09-22 02:19:34.893517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257819400 of size 32768 next 1258\n",
      "2023-09-22 02:19:34.893526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257821400 of size 32768 next 1710\n",
      "2023-09-22 02:19:34.893535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257829400 of size 33280 next 711\n",
      "2023-09-22 02:19:34.893545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257831600 of size 36864 next 191\n",
      "2023-09-22 02:19:34.893554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783a600 of size 256 next 1353\n",
      "2023-09-22 02:19:34.893561: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783a700 of size 256 next 475\n",
      "2023-09-22 02:19:34.893570: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783a800 of size 256 next 576\n",
      "2023-09-22 02:19:34.893580: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783a900 of size 512 next 1377\n",
      "2023-09-22 02:19:34.893589: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783ab00 of size 512 next 1498\n",
      "2023-09-22 02:19:34.893598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783ad00 of size 512 next 772\n",
      "2023-09-22 02:19:34.893607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783af00 of size 512 next 390\n",
      "2023-09-22 02:19:34.893616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783b100 of size 512 next 1469\n",
      "2023-09-22 02:19:34.893625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783b300 of size 512 next 921\n",
      "2023-09-22 02:19:34.893634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783b500 of size 512 next 1267\n",
      "2023-09-22 02:19:34.893643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783b700 of size 512 next 879\n",
      "2023-09-22 02:19:34.893652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783b900 of size 512 next 364\n",
      "2023-09-22 02:19:34.893661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783bb00 of size 768 next 200\n",
      "2023-09-22 02:19:34.893671: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783be00 of size 256 next 419\n",
      "2023-09-22 02:19:34.893680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783bf00 of size 256 next 1119\n",
      "2023-09-22 02:19:34.893689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c000 of size 256 next 1433\n",
      "2023-09-22 02:19:34.893698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c100 of size 256 next 565\n",
      "2023-09-22 02:19:34.893707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c200 of size 256 next 1256\n",
      "2023-09-22 02:19:34.893716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c300 of size 256 next 1129\n",
      "2023-09-22 02:19:34.893725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c400 of size 256 next 716\n",
      "2023-09-22 02:19:34.893735: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c500 of size 256 next 1610\n",
      "2023-09-22 02:19:34.893744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c600 of size 256 next 869\n",
      "2023-09-22 02:19:34.893753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c700 of size 256 next 1390\n",
      "2023-09-22 02:19:34.893762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c800 of size 256 next 1587\n",
      "2023-09-22 02:19:34.893772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783c900 of size 256 next 1528\n",
      "2023-09-22 02:19:34.893781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783ca00 of size 256 next 844\n",
      "2023-09-22 02:19:34.893790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783cb00 of size 256 next 241\n",
      "2023-09-22 02:19:34.893799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783cc00 of size 256 next 298\n",
      "2023-09-22 02:19:34.893808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783cd00 of size 256 next 1235\n",
      "2023-09-22 02:19:34.893817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783ce00 of size 256 next 302\n",
      "2023-09-22 02:19:34.893826: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783cf00 of size 512 next 1243\n",
      "2023-09-22 02:19:34.893835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d100 of size 256 next 752\n",
      "2023-09-22 02:19:34.893845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d200 of size 256 next 728\n",
      "2023-09-22 02:19:34.893854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d300 of size 256 next 1591\n",
      "2023-09-22 02:19:34.893861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d400 of size 256 next 450\n",
      "2023-09-22 02:19:34.893870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d500 of size 256 next 1099\n",
      "2023-09-22 02:19:34.893880: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d600 of size 256 next 1576\n",
      "2023-09-22 02:19:34.893889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d700 of size 256 next 495\n",
      "2023-09-22 02:19:34.893898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d800 of size 256 next 1254\n",
      "2023-09-22 02:19:34.893907: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783d900 of size 256 next 1540\n",
      "2023-09-22 02:19:34.893916: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783da00 of size 256 next 300\n",
      "2023-09-22 02:19:34.893926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783db00 of size 256 next 325\n",
      "2023-09-22 02:19:34.893935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783dc00 of size 256 next 113\n",
      "2023-09-22 02:19:34.893944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783dd00 of size 256 next 51\n",
      "2023-09-22 02:19:34.893953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125783de00 of size 262144 next 23\n",
      "2023-09-22 02:19:34.893962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f125787de00 of size 262144 next 1567\n",
      "2023-09-22 02:19:34.893972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12578bde00 of size 262144 next 704\n",
      "2023-09-22 02:19:34.893982: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12578fde00 of size 496128 next 429\n",
      "2023-09-22 02:19:34.893991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257977000 of size 262144 next 79\n",
      "2023-09-22 02:19:34.894001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12579b7000 of size 378880 next 508\n",
      "2023-09-22 02:19:34.894011: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257a13800 of size 256 next 1429\n",
      "2023-09-22 02:19:34.894021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257a13900 of size 256 next 513\n",
      "2023-09-22 02:19:34.894031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257a13a00 of size 256 next 1493\n",
      "2023-09-22 02:19:34.894040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257a13b00 of size 262144 next 1615\n",
      "2023-09-22 02:19:34.894049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257a53b00 of size 292096 next 1456\n",
      "2023-09-22 02:19:34.894058: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1257a9b000 of size 29696 next 456\n",
      "2023-09-22 02:19:34.894068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aa2400 of size 512 next 1152\n",
      "2023-09-22 02:19:34.894077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aa2600 of size 512 next 846\n",
      "2023-09-22 02:19:34.894086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aa2800 of size 512 next 951\n",
      "2023-09-22 02:19:34.894095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aa2a00 of size 512 next 1122\n",
      "2023-09-22 02:19:34.894104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aa2c00 of size 2048 next 1690\n",
      "2023-09-22 02:19:34.894113: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aa3400 of size 296960 next 150\n",
      "2023-09-22 02:19:34.894125: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aebc00 of size 256 next 1369\n",
      "2023-09-22 02:19:34.894134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aebd00 of size 768 next 1300\n",
      "2023-09-22 02:19:34.894143: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aec000 of size 768 next 954\n",
      "2023-09-22 02:19:34.894153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aec300 of size 256 next 205\n",
      "2023-09-22 02:19:34.894162: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aec400 of size 256 next 1649\n",
      "2023-09-22 02:19:34.894169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aec500 of size 512 next 644\n",
      "2023-09-22 02:19:34.894178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aec700 of size 512 next 131\n",
      "2023-09-22 02:19:34.894187: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aec900 of size 768 next 1204\n",
      "2023-09-22 02:19:34.894196: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257aecc00 of size 262144 next 1792\n",
      "2023-09-22 02:19:34.894206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b2cc00 of size 330240 next 1543\n",
      "2023-09-22 02:19:34.894215: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b7d600 of size 256 next 938\n",
      "2023-09-22 02:19:34.894224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b7d700 of size 2048 next 778\n",
      "2023-09-22 02:19:34.894233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b7df00 of size 2048 next 1723\n",
      "2023-09-22 02:19:34.894242: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b7e700 of size 2048 next 1659\n",
      "2023-09-22 02:19:34.894252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b7ef00 of size 3584 next 922\n",
      "2023-09-22 02:19:34.894261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b7fd00 of size 768 next 577\n",
      "2023-09-22 02:19:34.894271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80000 of size 256 next 1703\n",
      "2023-09-22 02:19:34.894281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80100 of size 512 next 1100\n",
      "2023-09-22 02:19:34.894290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80300 of size 512 next 1719\n",
      "2023-09-22 02:19:34.894301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80500 of size 256 next 1743\n",
      "2023-09-22 02:19:34.894310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80600 of size 768 next 1535\n",
      "2023-09-22 02:19:34.894319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80900 of size 512 next 1658\n",
      "2023-09-22 02:19:34.894329: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80b00 of size 512 next 1672\n",
      "2023-09-22 02:19:34.894338: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80d00 of size 512 next 418\n",
      "2023-09-22 02:19:34.894347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b80f00 of size 256 next 1423\n",
      "2023-09-22 02:19:34.894357: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b81000 of size 256 next 423\n",
      "2023-09-22 02:19:34.894367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b81100 of size 512 next 363\n",
      "2023-09-22 02:19:34.894376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b81300 of size 512 next 797\n",
      "2023-09-22 02:19:34.894385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b81500 of size 256 next 1693\n",
      "2023-09-22 02:19:34.894394: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b81600 of size 256 next 756\n",
      "2023-09-22 02:19:34.894404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b81700 of size 256 next 1683\n",
      "2023-09-22 02:19:34.894413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b81800 of size 3840 next 287\n",
      "2023-09-22 02:19:34.894423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b82700 of size 512 next 1392\n",
      "2023-09-22 02:19:34.894433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b82900 of size 512 next 927\n",
      "2023-09-22 02:19:34.894442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b82b00 of size 512 next 1151\n",
      "2023-09-22 02:19:34.894451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b82d00 of size 256 next 389\n",
      "2023-09-22 02:19:34.894460: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b82e00 of size 256 next 516\n",
      "2023-09-22 02:19:34.894469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b82f00 of size 256 next 482\n",
      "2023-09-22 02:19:34.894477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83000 of size 256 next 250\n",
      "2023-09-22 02:19:34.894486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83100 of size 256 next 944\n",
      "2023-09-22 02:19:34.894495: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83200 of size 256 next 1585\n",
      "2023-09-22 02:19:34.894505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83300 of size 256 next 275\n",
      "2023-09-22 02:19:34.894514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83400 of size 256 next 839\n",
      "2023-09-22 02:19:34.894523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83500 of size 256 next 1175\n",
      "2023-09-22 02:19:34.894532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83600 of size 256 next 375\n",
      "2023-09-22 02:19:34.894541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83700 of size 256 next 1360\n",
      "2023-09-22 02:19:34.894550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83800 of size 256 next 1124\n",
      "2023-09-22 02:19:34.894559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83900 of size 256 next 718\n",
      "2023-09-22 02:19:34.894569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83a00 of size 256 next 231\n",
      "2023-09-22 02:19:34.894578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83b00 of size 256 next 1023\n",
      "2023-09-22 02:19:34.894587: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83c00 of size 256 next 510\n",
      "2023-09-22 02:19:34.894596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83d00 of size 256 next 208\n",
      "2023-09-22 02:19:34.894605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83e00 of size 256 next 355\n",
      "2023-09-22 02:19:34.894614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b83f00 of size 2048 next 1421\n",
      "2023-09-22 02:19:34.894623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84700 of size 256 next 156\n",
      "2023-09-22 02:19:34.894632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84800 of size 256 next 1504\n",
      "2023-09-22 02:19:34.894642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84900 of size 256 next 304\n",
      "2023-09-22 02:19:34.894651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84a00 of size 256 next 404\n",
      "2023-09-22 02:19:34.894659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84b00 of size 256 next 840\n",
      "2023-09-22 02:19:34.894669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84c00 of size 256 next 396\n",
      "2023-09-22 02:19:34.894678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84d00 of size 256 next 599\n",
      "2023-09-22 02:19:34.894688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84e00 of size 256 next 1312\n",
      "2023-09-22 02:19:34.894697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b84f00 of size 256 next 428\n",
      "2023-09-22 02:19:34.894707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85000 of size 256 next 1725\n",
      "2023-09-22 02:19:34.894716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85100 of size 256 next 816\n",
      "2023-09-22 02:19:34.894725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85200 of size 256 next 7\n",
      "2023-09-22 02:19:34.894734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85300 of size 256 next 979\n",
      "2023-09-22 02:19:34.894743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85400 of size 256 next 934\n",
      "2023-09-22 02:19:34.894753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85500 of size 256 next 1123\n",
      "2023-09-22 02:19:34.894762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85600 of size 256 next 393\n",
      "2023-09-22 02:19:34.894771: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85700 of size 256 next 746\n",
      "2023-09-22 02:19:34.894781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85800 of size 256 next 969\n",
      "2023-09-22 02:19:34.894790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85900 of size 256 next 1000\n",
      "2023-09-22 02:19:34.894799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85a00 of size 256 next 1358\n",
      "2023-09-22 02:19:34.894809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85b00 of size 256 next 765\n",
      "2023-09-22 02:19:34.894818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85c00 of size 256 next 710\n",
      "2023-09-22 02:19:34.894827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85d00 of size 256 next 441\n",
      "2023-09-22 02:19:34.894836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85e00 of size 256 next 155\n",
      "2023-09-22 02:19:34.894846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b85f00 of size 256 next 126\n",
      "2023-09-22 02:19:34.894855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b86000 of size 256 next 736\n",
      "2023-09-22 02:19:34.894864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b86100 of size 256 next 875\n",
      "2023-09-22 02:19:34.894873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b86200 of size 256 next 335\n",
      "2023-09-22 02:19:34.894883: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b86300 of size 256 next 838\n",
      "2023-09-22 02:19:34.894892: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b86400 of size 256 next 1687\n",
      "2023-09-22 02:19:34.894901: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1257b86500 of size 256 next 1546\n",
      "2023-09-22 02:19:34.894910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b86600 of size 256 next 1452\n",
      "2023-09-22 02:19:34.894919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b86700 of size 256 next 1454\n",
      "2023-09-22 02:19:34.894928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1257b86800 of size 4352 next 926\n",
      "2023-09-22 02:19:34.894937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b87900 of size 512 next 770\n",
      "2023-09-22 02:19:34.894946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b87b00 of size 512 next 504\n",
      "2023-09-22 02:19:34.894955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b87d00 of size 512 next 391\n",
      "2023-09-22 02:19:34.894963: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b87f00 of size 512 next 1370\n",
      "2023-09-22 02:19:34.894972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88100 of size 512 next 527\n",
      "2023-09-22 02:19:34.894981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88300 of size 512 next 830\n",
      "2023-09-22 02:19:34.894990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88500 of size 512 next 362\n",
      "2023-09-22 02:19:34.894999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88700 of size 768 next 18\n",
      "2023-09-22 02:19:34.895008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88a00 of size 256 next 477\n",
      "2023-09-22 02:19:34.895017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88b00 of size 256 next 1547\n",
      "2023-09-22 02:19:34.895026: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88c00 of size 256 next 233\n",
      "2023-09-22 02:19:34.895035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88d00 of size 256 next 936\n",
      "2023-09-22 02:19:34.895045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1257b88e00 of size 10667520 next 1408\n",
      "2023-09-22 02:19:34.895054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5400 of size 256 next 1605\n",
      "2023-09-22 02:19:34.895064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12585b5500 of size 327680000 next 350\n",
      "2023-09-22 02:19:34.895073: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f126be35500 of size 158345728 next 972\n",
      "2023-09-22 02:19:34.895083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275537f00 of size 256 next 929\n",
      "2023-09-22 02:19:34.895092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538000 of size 256 next 940\n",
      "2023-09-22 02:19:34.895101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538100 of size 2048 next 1472\n",
      "2023-09-22 02:19:34.895110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538900 of size 512 next 458\n",
      "2023-09-22 02:19:34.895119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538b00 of size 512 next 1269\n",
      "2023-09-22 02:19:34.895129: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538d00 of size 256 next 1225\n",
      "2023-09-22 02:19:34.895138: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538e00 of size 256 next 733\n",
      "2023-09-22 02:19:34.895154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275538f00 of size 256 next 675\n",
      "2023-09-22 02:19:34.895163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539000 of size 256 next 295\n",
      "2023-09-22 02:19:34.895173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539100 of size 2048 next 179\n",
      "2023-09-22 02:19:34.895183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539900 of size 512 next 518\n",
      "2023-09-22 02:19:34.895192: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539b00 of size 512 next 306\n",
      "2023-09-22 02:19:34.895202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539d00 of size 512 next 1056\n",
      "2023-09-22 02:19:34.895211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275539f00 of size 512 next 313\n",
      "2023-09-22 02:19:34.895220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a100 of size 768 next 1677\n",
      "2023-09-22 02:19:34.895230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a400 of size 256 next 1432\n",
      "2023-09-22 02:19:34.895239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a500 of size 256 next 1586\n",
      "2023-09-22 02:19:34.895248: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a600 of size 256 next 1755\n",
      "2023-09-22 02:19:34.895258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a700 of size 256 next 1179\n",
      "2023-09-22 02:19:34.895267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a800 of size 256 next 771\n",
      "2023-09-22 02:19:34.895275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127553a900 of size 249344 next 1093\n",
      "2023-09-22 02:19:34.895284: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577700 of size 256 next 1255\n",
      "2023-09-22 02:19:34.895294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275577800 of size 180224 next 1652\n",
      "2023-09-22 02:19:34.895303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755a3800 of size 32768 next 798\n",
      "2023-09-22 02:19:34.895312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755ab800 of size 32768 next 258\n",
      "2023-09-22 02:19:34.895322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755b3800 of size 32768 next 523\n",
      "2023-09-22 02:19:34.895331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755bb800 of size 32768 next 1563\n",
      "2023-09-22 02:19:34.895340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c3800 of size 8192 next 740\n",
      "2023-09-22 02:19:34.895349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c5800 of size 512 next 845\n",
      "2023-09-22 02:19:34.895358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c5a00 of size 512 next 1516\n",
      "2023-09-22 02:19:34.895367: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c5c00 of size 2048 next 452\n",
      "2023-09-22 02:19:34.895376: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c6400 of size 2048 next 1656\n",
      "2023-09-22 02:19:34.895386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c6c00 of size 2048 next 56\n",
      "2023-09-22 02:19:34.895396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c7400 of size 2048 next 221\n",
      "2023-09-22 02:19:34.895404: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c7c00 of size 2048 next 66\n",
      "2023-09-22 02:19:34.895414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c8400 of size 2048 next 1145\n",
      "2023-09-22 02:19:34.895423: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c8c00 of size 512 next 1488\n",
      "2023-09-22 02:19:34.895432: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c8e00 of size 512 next 469\n",
      "2023-09-22 02:19:34.895441: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c9000 of size 512 next 169\n",
      "2023-09-22 02:19:34.895449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c9200 of size 512 next 311\n",
      "2023-09-22 02:19:34.895459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c9400 of size 512 next 1087\n",
      "2023-09-22 02:19:34.895467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c9600 of size 512 next 17\n",
      "2023-09-22 02:19:34.895477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755c9800 of size 57344 next 87\n",
      "2023-09-22 02:19:34.895486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755d7800 of size 32768 next 584\n",
      "2023-09-22 02:19:34.895496: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755df800 of size 32768 next 1031\n",
      "2023-09-22 02:19:34.895505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755e7800 of size 32768 next 97\n",
      "2023-09-22 02:19:34.895514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755ef800 of size 50176 next 499\n",
      "2023-09-22 02:19:34.895523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12755fbc00 of size 32768 next 1602\n",
      "2023-09-22 02:19:34.895533: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275603c00 of size 48128 next 851\n",
      "2023-09-22 02:19:34.895544: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127560f800 of size 180224 next 1446\n",
      "2023-09-22 02:19:34.895553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f127563b800 of size 223232 next 472\n",
      "2023-09-22 02:19:34.895563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1275672000 of size 223232 next 474\n",
      "2023-09-22 02:19:34.895572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8800 of size 256 next 859\n",
      "2023-09-22 02:19:34.895579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8900 of size 256 next 24\n",
      "2023-09-22 02:19:34.895588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8a00 of size 512 next 1724\n",
      "2023-09-22 02:19:34.895597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8c00 of size 256 next 483\n",
      "2023-09-22 02:19:34.895606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8d00 of size 256 next 1499\n",
      "2023-09-22 02:19:34.895615: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8e00 of size 256 next 1076\n",
      "2023-09-22 02:19:34.895625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a8f00 of size 256 next 1214\n",
      "2023-09-22 02:19:34.895634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9000 of size 256 next 763\n",
      "2023-09-22 02:19:34.895643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9100 of size 512 next 359\n",
      "2023-09-22 02:19:34.895652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9300 of size 256 next 351\n",
      "2023-09-22 02:19:34.895661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9400 of size 256 next 125\n",
      "2023-09-22 02:19:34.895670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9500 of size 256 next 1005\n",
      "2023-09-22 02:19:34.895679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9600 of size 256 next 1350\n",
      "2023-09-22 02:19:34.895688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9700 of size 256 next 841\n",
      "2023-09-22 02:19:34.895697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9800 of size 512 next 626\n",
      "2023-09-22 02:19:34.895706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9a00 of size 256 next 810\n",
      "2023-09-22 02:19:34.895716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9b00 of size 256 next 492\n",
      "2023-09-22 02:19:34.895725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9c00 of size 256 next 1521\n",
      "2023-09-22 02:19:34.895734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9d00 of size 512 next 1669\n",
      "2023-09-22 02:19:34.895742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756a9f00 of size 512 next 1286\n",
      "2023-09-22 02:19:34.895751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aa100 of size 2048 next 1642\n",
      "2023-09-22 02:19:34.895760: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756aa900 of size 2048 next 1063\n",
      "2023-09-22 02:19:34.895769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ab100 of size 2048 next 649\n",
      "2023-09-22 02:19:34.895779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ab900 of size 2048 next 1141\n",
      "2023-09-22 02:19:34.895787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ac100 of size 3840 next 682\n",
      "2023-09-22 02:19:34.895797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad000 of size 256 next 836\n",
      "2023-09-22 02:19:34.895806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad100 of size 256 next 659\n",
      "2023-09-22 02:19:34.895815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad200 of size 256 next 276\n",
      "2023-09-22 02:19:34.895824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad300 of size 256 next 531\n",
      "2023-09-22 02:19:34.895833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad400 of size 256 next 897\n",
      "2023-09-22 02:19:34.895842: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad500 of size 256 next 93\n",
      "2023-09-22 02:19:34.895852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad600 of size 256 next 928\n",
      "2023-09-22 02:19:34.895861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12756ad700 of size 327680000 next 1627\n",
      "2023-09-22 02:19:34.895870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1288f2d700 of size 327680000 next 386\n",
      "2023-09-22 02:19:34.895878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f129c7ad700 of size 81920000 next 358\n",
      "2023-09-22 02:19:34.895887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a15cd700 of size 640000 next 1139\n",
      "2023-09-22 02:19:34.895896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a1669b00 of size 40960000 next 1323\n",
      "2023-09-22 02:19:34.895906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a3d79b00 of size 20480000 next 1580\n",
      "2023-09-22 02:19:34.895915: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a5101b00 of size 640000 next 1038\n",
      "2023-09-22 02:19:34.895924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a519df00 of size 640000 next 451\n",
      "2023-09-22 02:19:34.895934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a523a300 of size 640000 next 939\n",
      "2023-09-22 02:19:34.895943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a52d6700 of size 640000 next 75\n",
      "2023-09-22 02:19:34.895952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a5372b00 of size 640000 next 1290\n",
      "2023-09-22 02:19:34.895961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a540ef00 of size 640000 next 365\n",
      "2023-09-22 02:19:34.895970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a54ab300 of size 640000 next 376\n",
      "2023-09-22 02:19:34.895979: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a5547700 of size 640000 next 1510\n",
      "2023-09-22 02:19:34.895988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a55e3b00 of size 640000 next 194\n",
      "2023-09-22 02:19:34.895997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a567ff00 of size 640000 next 345\n",
      "2023-09-22 02:19:34.896006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12a571c300 of size 14080000 next 902\n",
      "2023-09-22 02:19:34.896015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12a6489b00 of size 81920000 next 553\n",
      "2023-09-22 02:19:34.896024: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ab2a9b00 of size 81920000 next 1316\n",
      "2023-09-22 02:19:34.896033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12b00c9b00 of size 81920000 next 608\n",
      "2023-09-22 02:19:34.896042: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12b4ee9b00 of size 81920000 next 299\n",
      "2023-09-22 02:19:34.896051: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12b9d09b00 of size 81920000 next 773\n",
      "2023-09-22 02:19:34.896060: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12beb29b00 of size 81920000 next 835\n",
      "2023-09-22 02:19:34.896069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c3949b00 of size 20480000 next 1240\n",
      "2023-09-22 02:19:34.896078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c4cd1b00 of size 40960000 next 544\n",
      "2023-09-22 02:19:34.896088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12c73e1b00 of size 86695936 next 1447\n",
      "2023-09-22 02:19:34.896097: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc68fb00 of size 256 next 558\n",
      "2023-09-22 02:19:34.896106: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc68fc00 of size 256 next 1248\n",
      "2023-09-22 02:19:34.896115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc68fd00 of size 256 next 1147\n",
      "2023-09-22 02:19:34.896124: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc68fe00 of size 512 next 1075\n",
      "2023-09-22 02:19:34.896133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc690000 of size 768 next 1831\n",
      "2023-09-22 02:19:34.896142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc690300 of size 256 next 82\n",
      "2023-09-22 02:19:34.896151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc690400 of size 256 next 261\n",
      "2023-09-22 02:19:34.896160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc690500 of size 256 next 392\n",
      "2023-09-22 02:19:34.896168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc690600 of size 256 next 1548\n",
      "2023-09-22 02:19:34.896176: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc690700 of size 256 next 638\n",
      "2023-09-22 02:19:34.896186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f12cc690800 of size 30208 next 662\n",
      "2023-09-22 02:19:34.896195: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc697e00 of size 256 next 750\n",
      "2023-09-22 02:19:34.896204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc697f00 of size 3840 next 1117\n",
      "2023-09-22 02:19:34.896213: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc698e00 of size 256 next 1539\n",
      "2023-09-22 02:19:34.896222: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc698f00 of size 256 next 1617\n",
      "2023-09-22 02:19:34.896231: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc699000 of size 256 next 217\n",
      "2023-09-22 02:19:34.896240: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc699100 of size 256 next 681\n",
      "2023-09-22 02:19:34.896249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc699200 of size 256 next 186\n",
      "2023-09-22 02:19:34.896258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc699300 of size 256 next 1348\n",
      "2023-09-22 02:19:34.896267: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc699400 of size 256 next 1085\n",
      "2023-09-22 02:19:34.896276: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cc699500 of size 20480000 next 1034\n",
      "2023-09-22 02:19:34.896285: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12cda21500 of size 20480000 next 341\n",
      "2023-09-22 02:19:34.896294: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ceda9500 of size 20480000 next 1492\n",
      "2023-09-22 02:19:34.896303: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12d0131500 of size 81920000 next 1443\n",
      "2023-09-22 02:19:34.896312: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12d4f51500 of size 133975552 next 863\n",
      "2023-09-22 02:19:34.896322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16300 of size 256 next 867\n",
      "2023-09-22 02:19:34.896331: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16400 of size 512 next 1058\n",
      "2023-09-22 02:19:34.896340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16600 of size 512 next 806\n",
      "2023-09-22 02:19:34.896347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16800 of size 512 next 538\n",
      "2023-09-22 02:19:34.896354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16a00 of size 512 next 459\n",
      "2023-09-22 02:19:34.896362: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16c00 of size 512 next 1789\n",
      "2023-09-22 02:19:34.896371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf16e00 of size 512 next 85\n",
      "2023-09-22 02:19:34.896380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17000 of size 512 next 77\n",
      "2023-09-22 02:19:34.896389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17200 of size 512 next 1297\n",
      "2023-09-22 02:19:34.896399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17400 of size 512 next 264\n",
      "2023-09-22 02:19:34.896408: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17600 of size 512 next 850\n",
      "2023-09-22 02:19:34.896417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17800 of size 512 next 377\n",
      "2023-09-22 02:19:34.896427: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17a00 of size 512 next 344\n",
      "2023-09-22 02:19:34.896436: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17c00 of size 256 next 165\n",
      "2023-09-22 02:19:34.896445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17d00 of size 256 next 645\n",
      "2023-09-22 02:19:34.896454: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf17e00 of size 512 next 570\n",
      "2023-09-22 02:19:34.896463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18000 of size 512 next 1714\n",
      "2023-09-22 02:19:34.896472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18200 of size 512 next 824\n",
      "2023-09-22 02:19:34.896482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18400 of size 256 next 1490\n",
      "2023-09-22 02:19:34.896491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18500 of size 256 next 1111\n",
      "2023-09-22 02:19:34.896500: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18600 of size 2048 next 413\n",
      "2023-09-22 02:19:34.896509: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf18e00 of size 2048 next 1014\n",
      "2023-09-22 02:19:34.896518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19600 of size 2048 next 868\n",
      "2023-09-22 02:19:34.896528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf19e00 of size 3584 next 1346\n",
      "2023-09-22 02:19:34.896538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1ac00 of size 2560 next 1167\n",
      "2023-09-22 02:19:34.896547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1b600 of size 3072 next 342\n",
      "2023-09-22 02:19:34.896556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf1c200 of size 180224 next 1318\n",
      "2023-09-22 02:19:34.896566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf48200 of size 239616 next 669\n",
      "2023-09-22 02:19:34.896575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82a00 of size 256 next 785\n",
      "2023-09-22 02:19:34.896586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82b00 of size 256 next 672\n",
      "2023-09-22 02:19:34.896596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82c00 of size 256 next 296\n",
      "2023-09-22 02:19:34.896607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82d00 of size 256 next 674\n",
      "2023-09-22 02:19:34.896616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf82e00 of size 512 next 1565\n",
      "2023-09-22 02:19:34.896625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83000 of size 512 next 1678\n",
      "2023-09-22 02:19:34.896634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83200 of size 256 next 467\n",
      "2023-09-22 02:19:34.896643: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83300 of size 256 next 792\n",
      "2023-09-22 02:19:34.896651: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83400 of size 512 next 257\n",
      "2023-09-22 02:19:34.896660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83600 of size 512 next 802\n",
      "2023-09-22 02:19:34.896669: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83800 of size 768 next 551\n",
      "2023-09-22 02:19:34.896678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83b00 of size 256 next 910\n",
      "2023-09-22 02:19:34.896688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12dcf83c00 of size 20480000 next 1444\n",
      "2023-09-22 02:19:34.896697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12de30bc00 of size 40960000 next 955\n",
      "2023-09-22 02:19:34.896706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e0a1bc00 of size 20480000 next 1734\n",
      "2023-09-22 02:19:34.896715: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e1da3c00 of size 20480000 next 1253\n",
      "2023-09-22 02:19:34.896724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e312bc00 of size 81920000 next 67\n",
      "2023-09-22 02:19:34.896733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12e7f4bc00 of size 102449664 next 1082\n",
      "2023-09-22 02:19:34.896745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0ffe00 of size 256 next 407\n",
      "2023-09-22 02:19:34.896754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee0fff00 of size 256 next 826\n",
      "2023-09-22 02:19:34.896763: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100000 of size 2048 next 353\n",
      "2023-09-22 02:19:34.896772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee100800 of size 2048 next 611\n",
      "2023-09-22 02:19:34.896781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101000 of size 256 next 1279\n",
      "2023-09-22 02:19:34.896790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101100 of size 256 next 892\n",
      "2023-09-22 02:19:34.896800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee101200 of size 262144 next 1193\n",
      "2023-09-22 02:19:34.896809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee141200 of size 262144 next 1485\n",
      "2023-09-22 02:19:34.896818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee181200 of size 262144 next 1688\n",
      "2023-09-22 02:19:34.896827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee1c1200 of size 327680 next 1651\n",
      "2023-09-22 02:19:34.896836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee211200 of size 32768 next 254\n",
      "2023-09-22 02:19:34.896845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee219200 of size 32768 next 1001\n",
      "2023-09-22 02:19:34.896854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee221200 of size 32768 next 560\n",
      "2023-09-22 02:19:34.896864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee229200 of size 32768 next 99\n",
      "2023-09-22 02:19:34.896873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee231200 of size 180224 next 1088\n",
      "2023-09-22 02:19:34.896882: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee25d200 of size 180224 next 267\n",
      "2023-09-22 02:19:34.896891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee289200 of size 180224 next 465\n",
      "2023-09-22 02:19:34.896900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee2b5200 of size 180224 next 1331\n",
      "2023-09-22 02:19:34.896909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee2e1200 of size 262144 next 1523\n",
      "2023-09-22 02:19:34.896918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee321200 of size 262144 next 1026\n",
      "2023-09-22 02:19:34.896927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee361200 of size 262144 next 872\n",
      "2023-09-22 02:19:34.896936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee3a1200 of size 262144 next 1671\n",
      "2023-09-22 02:19:34.896946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee3e1200 of size 458752 next 507\n",
      "2023-09-22 02:19:34.896953: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee451200 of size 33792 next 1653\n",
      "2023-09-22 02:19:34.896962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee459600 of size 33792 next 548\n",
      "2023-09-22 02:19:34.896972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee461a00 of size 211456 next 74\n",
      "2023-09-22 02:19:34.896981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee495400 of size 512 next 139\n",
      "2023-09-22 02:19:34.896990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee495600 of size 512 next 57\n",
      "2023-09-22 02:19:34.896999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee495800 of size 512 next 427\n",
      "2023-09-22 02:19:34.897008: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee495a00 of size 512 next 435\n",
      "2023-09-22 02:19:34.897018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee495c00 of size 512 next 1246\n",
      "2023-09-22 02:19:34.897027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee495e00 of size 512 next 1109\n",
      "2023-09-22 02:19:34.897036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496000 of size 256 next 1404\n",
      "2023-09-22 02:19:34.897045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496100 of size 512 next 540\n",
      "2023-09-22 02:19:34.897054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496300 of size 256 next 1127\n",
      "2023-09-22 02:19:34.897063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496400 of size 256 next 11\n",
      "2023-09-22 02:19:34.897072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496500 of size 256 next 321\n",
      "2023-09-22 02:19:34.897081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496600 of size 256 next 898\n",
      "2023-09-22 02:19:34.897090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496700 of size 256 next 1532\n",
      "2023-09-22 02:19:34.897099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee496800 of size 2048 next 166\n",
      "2023-09-22 02:19:34.897108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee497000 of size 2048 next 1487\n",
      "2023-09-22 02:19:34.897118: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee497800 of size 2048 next 1060\n",
      "2023-09-22 02:19:34.897127: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee498000 of size 373760 next 266\n",
      "2023-09-22 02:19:34.897136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3400 of size 256 next 755\n",
      "2023-09-22 02:19:34.897145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3500 of size 256 next 885\n",
      "2023-09-22 02:19:34.897154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f3600 of size 5120 next 317\n",
      "2023-09-22 02:19:34.897163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f4a00 of size 5120 next 118\n",
      "2023-09-22 02:19:34.897172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f5e00 of size 2048 next 1322\n",
      "2023-09-22 02:19:34.897181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f6600 of size 2048 next 1455\n",
      "2023-09-22 02:19:34.897191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f6e00 of size 512 next 1006\n",
      "2023-09-22 02:19:34.897200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7000 of size 512 next 1635\n",
      "2023-09-22 02:19:34.897209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7200 of size 256 next 1685\n",
      "2023-09-22 02:19:34.897218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7300 of size 512 next 1624\n",
      "2023-09-22 02:19:34.897227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7500 of size 512 next 1271\n",
      "2023-09-22 02:19:34.897236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7700 of size 512 next 1213\n",
      "2023-09-22 02:19:34.897246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7900 of size 512 next 218\n",
      "2023-09-22 02:19:34.897253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7b00 of size 768 next 1116\n",
      "2023-09-22 02:19:34.897263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4f7e00 of size 14336 next 246\n",
      "2023-09-22 02:19:34.897272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee4fb600 of size 38656 next 1059\n",
      "2023-09-22 02:19:34.897281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee504d00 of size 256 next 1265\n",
      "2023-09-22 02:19:34.897290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee504e00 of size 512 next 239\n",
      "2023-09-22 02:19:34.897300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505000 of size 256 next 1150\n",
      "2023-09-22 02:19:34.897309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee505100 of size 262144 next 1431\n",
      "2023-09-22 02:19:34.897318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee545100 of size 262144 next 1247\n",
      "2023-09-22 02:19:34.897327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee585100 of size 262144 next 690\n",
      "2023-09-22 02:19:34.897336: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee5c5100 of size 393216 next 1596\n",
      "2023-09-22 02:19:34.897345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee625100 of size 262144 next 135\n",
      "2023-09-22 02:19:34.897354: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee665100 of size 262144 next 232\n",
      "2023-09-22 02:19:34.897363: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee6a5100 of size 262144 next 1373\n",
      "2023-09-22 02:19:34.897372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee6e5100 of size 262144 next 647\n",
      "2023-09-22 02:19:34.897381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee725100 of size 262144 next 498\n",
      "2023-09-22 02:19:34.897390: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee765100 of size 327680 next 52\n",
      "2023-09-22 02:19:34.897400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7b5100 of size 32768 next 1767\n",
      "2023-09-22 02:19:34.897410: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7bd100 of size 32768 next 224\n",
      "2023-09-22 02:19:34.897419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c5100 of size 2048 next 633\n",
      "2023-09-22 02:19:34.897428: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c5900 of size 2048 next 38\n",
      "2023-09-22 02:19:34.897437: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6100 of size 512 next 1594\n",
      "2023-09-22 02:19:34.897446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6300 of size 512 next 993\n",
      "2023-09-22 02:19:34.897455: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6500 of size 512 next 297\n",
      "2023-09-22 02:19:34.897464: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6700 of size 256 next 697\n",
      "2023-09-22 02:19:34.897473: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6800 of size 512 next 1566\n",
      "2023-09-22 02:19:34.897482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6a00 of size 512 next 223\n",
      "2023-09-22 02:19:34.897491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6c00 of size 512 next 1699\n",
      "2023-09-22 02:19:34.897501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c6e00 of size 2048 next 829\n",
      "2023-09-22 02:19:34.897510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c7600 of size 2048 next 906\n",
      "2023-09-22 02:19:34.897519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c7e00 of size 2048 next 1511\n",
      "2023-09-22 02:19:34.897528: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c8600 of size 512 next 330\n",
      "2023-09-22 02:19:34.897537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c8800 of size 512 next 1012\n",
      "2023-09-22 02:19:34.897546: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c8a00 of size 512 next 677\n",
      "2023-09-22 02:19:34.897553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c8c00 of size 256 next 270\n",
      "2023-09-22 02:19:34.897562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c8d00 of size 512 next 1008\n",
      "2023-09-22 02:19:34.897572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c8f00 of size 512 next 1621\n",
      "2023-09-22 02:19:34.897581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c9100 of size 512 next 222\n",
      "2023-09-22 02:19:34.897590: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c9300 of size 256 next 1379\n",
      "2023-09-22 02:19:34.897599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c9400 of size 256 next 519\n",
      "2023-09-22 02:19:34.897609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c9500 of size 256 next 642\n",
      "2023-09-22 02:19:34.897618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c9600 of size 256 next 1263\n",
      "2023-09-22 02:19:34.897627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c9700 of size 256 next 1232\n",
      "2023-09-22 02:19:34.897636: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7c9800 of size 3840 next 153\n",
      "2023-09-22 02:19:34.897649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7ca700 of size 3840 next 320\n",
      "2023-09-22 02:19:34.897657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cb600 of size 256 next 1808\n",
      "2023-09-22 02:19:34.897668: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cb700 of size 256 next 1134\n",
      "2023-09-22 02:19:34.897677: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cb800 of size 256 next 757\n",
      "2023-09-22 02:19:34.897687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cb900 of size 256 next 102\n",
      "2023-09-22 02:19:34.897696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cba00 of size 256 next 1157\n",
      "2023-09-22 02:19:34.897705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cbb00 of size 256 next 536\n",
      "2023-09-22 02:19:34.897714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cbc00 of size 5376 next 1544\n",
      "2023-09-22 02:19:34.897723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7cd100 of size 32768 next 596\n",
      "2023-09-22 02:19:34.897732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee7d5100 of size 262144 next 597\n",
      "2023-09-22 02:19:34.897741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee815100 of size 180224 next 854\n",
      "2023-09-22 02:19:34.897751: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee841100 of size 261376 next 1601\n",
      "2023-09-22 02:19:34.897762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880e00 of size 256 next 1389\n",
      "2023-09-22 02:19:34.897772: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12ee880f00 of size 104168448 next 593\n",
      "2023-09-22 02:19:34.897781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8b00 of size 256 next 843\n",
      "2023-09-22 02:19:34.897790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8c00 of size 256 next 947\n",
      "2023-09-22 02:19:34.897799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f4bd8d00 of size 53242112 next 932\n",
      "2023-09-22 02:19:34.897808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f600 of size 256 next 101\n",
      "2023-09-22 02:19:34.897817: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f700 of size 256 next 761\n",
      "2023-09-22 02:19:34.897827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12f7e9f800 of size 39062528 next 657\n",
      "2023-09-22 02:19:34.897836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0400 of size 256 next 1326\n",
      "2023-09-22 02:19:34.897846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa3e0500 of size 476160 next 1747\n",
      "2023-09-22 02:19:34.897855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454900 of size 256 next 244\n",
      "2023-09-22 02:19:34.897863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454a00 of size 256 next 1345\n",
      "2023-09-22 02:19:34.897872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa454b00 of size 180224 next 1077\n",
      "2023-09-22 02:19:34.897881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa480b00 of size 183808 next 1590\n",
      "2023-09-22 02:19:34.897890: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ad900 of size 256 next 319\n",
      "2023-09-22 02:19:34.897899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4ada00 of size 256 next 783\n",
      "2023-09-22 02:19:34.897909: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4adb00 of size 262144 next 168\n",
      "2023-09-22 02:19:34.897918: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa4edb00 of size 354816 next 1218\n",
      "2023-09-22 02:19:34.897927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa544500 of size 512 next 1306\n",
      "2023-09-22 02:19:34.897936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa544700 of size 512 next 1101\n",
      "2023-09-22 02:19:34.897946: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa544900 of size 512 next 1720\n",
      "2023-09-22 02:19:34.897955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa544b00 of size 512 next 1500\n",
      "2023-09-22 02:19:34.897964: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa544d00 of size 2048 next 1611\n",
      "2023-09-22 02:19:34.897973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa545500 of size 2048 next 547\n",
      "2023-09-22 02:19:34.897983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa545d00 of size 2048 next 1713\n",
      "2023-09-22 02:19:34.897992: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa546500 of size 2048 next 1242\n",
      "2023-09-22 02:19:34.898001: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa546d00 of size 2048 next 247\n",
      "2023-09-22 02:19:34.898010: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa547500 of size 512 next 1029\n",
      "2023-09-22 02:19:34.898019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa547700 of size 512 next 395\n",
      "2023-09-22 02:19:34.898028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa547900 of size 512 next 88\n",
      "2023-09-22 02:19:34.898037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa547b00 of size 512 next 857\n",
      "2023-09-22 02:19:34.898046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa547d00 of size 512 next 1237\n",
      "2023-09-22 02:19:34.898056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa547f00 of size 2048 next 1609\n",
      "2023-09-22 02:19:34.898065: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa548700 of size 512 next 506\n",
      "2023-09-22 02:19:34.898074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa548900 of size 512 next 643\n",
      "2023-09-22 02:19:34.898083: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa548b00 of size 512 next 937\n",
      "2023-09-22 02:19:34.898092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa548d00 of size 512 next 1569\n",
      "2023-09-22 02:19:34.898101: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa548f00 of size 512 next 1665\n",
      "2023-09-22 02:19:34.898110: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549100 of size 512 next 76\n",
      "2023-09-22 02:19:34.898119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549300 of size 512 next 668\n",
      "2023-09-22 02:19:34.898128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549500 of size 256 next 457\n",
      "2023-09-22 02:19:34.898137: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549600 of size 256 next 721\n",
      "2023-09-22 02:19:34.898146: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549700 of size 256 next 1366\n",
      "2023-09-22 02:19:34.898155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549800 of size 256 next 998\n",
      "2023-09-22 02:19:34.898163: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549900 of size 256 next 27\n",
      "2023-09-22 02:19:34.898172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa549a00 of size 59904 next 411\n",
      "2023-09-22 02:19:34.898181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558400 of size 256 next 271\n",
      "2023-09-22 02:19:34.898190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558500 of size 2048 next 1195\n",
      "2023-09-22 02:19:34.898199: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa558d00 of size 2048 next 398\n",
      "2023-09-22 02:19:34.898209: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa559500 of size 3584 next 1475\n",
      "2023-09-22 02:19:34.898218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a300 of size 256 next 327\n",
      "2023-09-22 02:19:34.898226: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a400 of size 256 next 1520\n",
      "2023-09-22 02:19:34.898236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55a500 of size 3840 next 1481\n",
      "2023-09-22 02:19:34.898245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55b400 of size 512 next 1396\n",
      "2023-09-22 02:19:34.898254: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55b600 of size 256 next 142\n",
      "2023-09-22 02:19:34.898263: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55b700 of size 256 next 984\n",
      "2023-09-22 02:19:34.898272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55b800 of size 256 next 1189\n",
      "2023-09-22 02:19:34.898281: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55b900 of size 256 next 900\n",
      "2023-09-22 02:19:34.898290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55ba00 of size 256 next 661\n",
      "2023-09-22 02:19:34.898300: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55bb00 of size 256 next 292\n",
      "2023-09-22 02:19:34.898309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55bc00 of size 256 next 1573\n",
      "2023-09-22 02:19:34.898319: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55bd00 of size 256 next 1308\n",
      "2023-09-22 02:19:34.898328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55be00 of size 256 next 1466\n",
      "2023-09-22 02:19:34.898337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55bf00 of size 256 next 1011\n",
      "2023-09-22 02:19:34.898346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c000 of size 512 next 1818\n",
      "2023-09-22 02:19:34.898355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c200 of size 768 next 146\n",
      "2023-09-22 02:19:34.898364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c500 of size 512 next 288\n",
      "2023-09-22 02:19:34.898373: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c700 of size 512 next 1403\n",
      "2023-09-22 02:19:34.898382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55c900 of size 512 next 1282\n",
      "2023-09-22 02:19:34.898391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55cb00 of size 512 next 1185\n",
      "2023-09-22 02:19:34.898400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55cd00 of size 512 next 1559\n",
      "2023-09-22 02:19:34.898409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55cf00 of size 512 next 354\n",
      "2023-09-22 02:19:34.898418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55d100 of size 256 next 529\n",
      "2023-09-22 02:19:34.898426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa55d200 of size 201216 next 1686\n",
      "2023-09-22 02:19:34.898438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e400 of size 256 next 1096\n",
      "2023-09-22 02:19:34.898447: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e500 of size 256 next 252\n",
      "2023-09-22 02:19:34.898456: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e600 of size 256 next 1674\n",
      "2023-09-22 02:19:34.898465: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e700 of size 256 next 825\n",
      "2023-09-22 02:19:34.898476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa58e800 of size 262144 next 1205\n",
      "2023-09-22 02:19:34.898485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa5ce800 of size 32768 next 240\n",
      "2023-09-22 02:19:34.898494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa5d6800 of size 32768 next 1128\n",
      "2023-09-22 02:19:34.898503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa5de800 of size 32768 next 331\n",
      "2023-09-22 02:19:34.898513: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa5e6800 of size 32768 next 490\n",
      "2023-09-22 02:19:34.898522: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa5ee800 of size 393216 next 1074\n",
      "2023-09-22 02:19:34.898531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa64e800 of size 262144 next 352\n",
      "2023-09-22 02:19:34.898541: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa68e800 of size 370944 next 1507\n",
      "2023-09-22 02:19:34.898550: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9100 of size 256 next 1364\n",
      "2023-09-22 02:19:34.898559: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9200 of size 256 next 699\n",
      "2023-09-22 02:19:34.898568: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9300 of size 256 next 1471\n",
      "2023-09-22 02:19:34.898577: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9400 of size 256 next 1078\n",
      "2023-09-22 02:19:34.898586: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9500 of size 512 next 726\n",
      "2023-09-22 02:19:34.898595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9700 of size 256 next 206\n",
      "2023-09-22 02:19:34.898605: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa6e9800 of size 341504 next 1696\n",
      "2023-09-22 02:19:34.898614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73ce00 of size 256 next 106\n",
      "2023-09-22 02:19:34.898623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa73cf00 of size 320512 next 1007\n",
      "2023-09-22 02:19:34.898631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa78b300 of size 262144 next 1701\n",
      "2023-09-22 02:19:34.898639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa7cb300 of size 378880 next 764\n",
      "2023-09-22 02:19:34.898648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa827b00 of size 512 next 822\n",
      "2023-09-22 02:19:34.898657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa827d00 of size 256 next 1401\n",
      "2023-09-22 02:19:34.898670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa827e00 of size 262144 next 1178\n",
      "2023-09-22 02:19:34.898680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa867e00 of size 378880 next 807\n",
      "2023-09-22 02:19:34.898689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa8c4600 of size 262144 next 255\n",
      "2023-09-22 02:19:34.898698: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa904600 of size 379136 next 1441\n",
      "2023-09-22 02:19:34.898707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa960f00 of size 256 next 1394\n",
      "2023-09-22 02:19:34.898716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa961000 of size 512 next 149\n",
      "2023-09-22 02:19:34.898724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa961200 of size 262144 next 1070\n",
      "2023-09-22 02:19:34.898733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9a1200 of size 262144 next 706\n",
      "2023-09-22 02:19:34.898742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12fa9e1200 of size 372736 next 689\n",
      "2023-09-22 02:19:34.898752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c200 of size 256 next 383\n",
      "2023-09-22 02:19:34.898761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3c300 of size 2048 next 1437\n",
      "2023-09-22 02:19:34.898770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3cb00 of size 2048 next 768\n",
      "2023-09-22 02:19:34.898779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3d300 of size 2048 next 1836\n",
      "2023-09-22 02:19:34.898787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3db00 of size 2048 next 20\n",
      "2023-09-22 02:19:34.898796: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3e300 of size 2048 next 1079\n",
      "2023-09-22 02:19:34.898805: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3eb00 of size 2560 next 1727\n",
      "2023-09-22 02:19:34.898814: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3f500 of size 2048 next 967\n",
      "2023-09-22 02:19:34.898823: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa3fd00 of size 3584 next 956\n",
      "2023-09-22 02:19:34.898832: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40b00 of size 256 next 443\n",
      "2023-09-22 02:19:34.898841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40c00 of size 256 next 339\n",
      "2023-09-22 02:19:34.898850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40d00 of size 256 next 401\n",
      "2023-09-22 02:19:34.898859: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40e00 of size 256 next 625\n",
      "2023-09-22 02:19:34.898868: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa40f00 of size 256 next 1383\n",
      "2023-09-22 02:19:34.898876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41000 of size 256 next 820\n",
      "2023-09-22 02:19:34.898885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41100 of size 256 next 1612\n",
      "2023-09-22 02:19:34.898894: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41200 of size 256 next 622\n",
      "2023-09-22 02:19:34.898903: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41300 of size 256 next 1343\n",
      "2023-09-22 02:19:34.898912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41400 of size 256 next 781\n",
      "2023-09-22 02:19:34.898921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41500 of size 256 next 988\n",
      "2023-09-22 02:19:34.898929: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41600 of size 512 next 182\n",
      "2023-09-22 02:19:34.898938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41800 of size 256 next 1187\n",
      "2023-09-22 02:19:34.898947: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41900 of size 256 next 439\n",
      "2023-09-22 02:19:34.898956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41a00 of size 256 next 1793\n",
      "2023-09-22 02:19:34.898965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41b00 of size 256 next 1197\n",
      "2023-09-22 02:19:34.898974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41c00 of size 256 next 795\n",
      "2023-09-22 02:19:34.898983: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41d00 of size 512 next 1278\n",
      "2023-09-22 02:19:34.898991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa41f00 of size 256 next 603\n",
      "2023-09-22 02:19:34.899000: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42000 of size 256 next 1016\n",
      "2023-09-22 02:19:34.899009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42100 of size 256 next 856\n",
      "2023-09-22 02:19:34.899018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42200 of size 512 next 1180\n",
      "2023-09-22 02:19:34.899027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42400 of size 256 next 684\n",
      "2023-09-22 02:19:34.899036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42500 of size 512 next 78\n",
      "2023-09-22 02:19:34.899045: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42700 of size 512 next 916\n",
      "2023-09-22 02:19:34.899054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42900 of size 512 next 1336\n",
      "2023-09-22 02:19:34.899063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42b00 of size 512 next 511\n",
      "2023-09-22 02:19:34.899072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42d00 of size 512 next 1277\n",
      "2023-09-22 02:19:34.899081: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa42f00 of size 512 next 1550\n",
      "2023-09-22 02:19:34.899090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43100 of size 256 next 1551\n",
      "2023-09-22 02:19:34.899099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f12faa43200 of size 449005824 next 1593\n",
      "2023-09-22 02:19:34.899108: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677b00 of size 256 next 628\n",
      "2023-09-22 02:19:34.899117: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677c00 of size 256 next 92\n",
      "2023-09-22 02:19:34.899126: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677d00 of size 512 next 1597\n",
      "2023-09-22 02:19:34.899135: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315677f00 of size 512 next 1126\n",
      "2023-09-22 02:19:34.899161: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315678100 of size 512 next 1758\n",
      "2023-09-22 02:19:34.899171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315678300 of size 512 next 1702\n",
      "2023-09-22 02:19:34.899180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315678500 of size 512 next 1039\n",
      "2023-09-22 02:19:34.899189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315678700 of size 512 next 1757\n",
      "2023-09-22 02:19:34.899198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315678900 of size 32768 next 1766\n",
      "2023-09-22 02:19:34.899207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315680900 of size 32768 next 1679\n",
      "2023-09-22 02:19:34.899216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315688900 of size 256 next 438\n",
      "2023-09-22 02:19:34.899225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315688a00 of size 256 next 594\n",
      "2023-09-22 02:19:34.899234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315688b00 of size 32768 next 1763\n",
      "2023-09-22 02:19:34.899244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315690b00 of size 32768 next 1764\n",
      "2023-09-22 02:19:34.899252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315698b00 of size 512 next 980\n",
      "2023-09-22 02:19:34.899261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315698d00 of size 512 next 1737\n",
      "2023-09-22 02:19:34.899270: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315698f00 of size 512 next 1761\n",
      "2023-09-22 02:19:34.899279: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315699100 of size 512 next 641\n",
      "2023-09-22 02:19:34.899288: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315699300 of size 512 next 1762\n",
      "2023-09-22 02:19:34.899297: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315699500 of size 512 next 1765\n",
      "2023-09-22 02:19:34.899306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315699700 of size 262144 next 269\n",
      "2023-09-22 02:19:34.899315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13156d9700 of size 262144 next 41\n",
      "2023-09-22 02:19:34.899324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315719700 of size 2048 next 1778\n",
      "2023-09-22 02:19:34.899333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315719f00 of size 2048 next 1769\n",
      "2023-09-22 02:19:34.899342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131571a700 of size 262144 next 517\n",
      "2023-09-22 02:19:34.899351: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131575a700 of size 262144 next 1786\n",
      "2023-09-22 02:19:34.899360: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131579a700 of size 2048 next 1562\n",
      "2023-09-22 02:19:34.899369: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131579af00 of size 2048 next 743\n",
      "2023-09-22 02:19:34.899378: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131579b700 of size 262144 next 1355\n",
      "2023-09-22 02:19:34.899387: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13157db700 of size 262144 next 1199\n",
      "2023-09-22 02:19:34.899396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131581b700 of size 2048 next 896\n",
      "2023-09-22 02:19:34.899405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131581bf00 of size 2048 next 1607\n",
      "2023-09-22 02:19:34.899413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131581c700 of size 262144 next 1299\n",
      "2023-09-22 02:19:34.899422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131585c700 of size 262144 next 1161\n",
      "2023-09-22 02:19:34.899431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131589c700 of size 512 next 1047\n",
      "2023-09-22 02:19:34.899440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131589c900 of size 512 next 1774\n",
      "2023-09-22 02:19:34.899449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131589cb00 of size 512 next 130\n",
      "2023-09-22 02:19:34.899458: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131589cd00 of size 512 next 1711\n",
      "2023-09-22 02:19:34.899467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131589cf00 of size 512 next 1773\n",
      "2023-09-22 02:19:34.899476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131589d100 of size 512 next 1640\n",
      "2023-09-22 02:19:34.899484: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131589d300 of size 32768 next 1541\n",
      "2023-09-22 02:19:34.899493: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158a5300 of size 32768 next 1770\n",
      "2023-09-22 02:19:34.899502: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158ad300 of size 256 next 907\n",
      "2023-09-22 02:19:34.899511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158ad400 of size 256 next 1768\n",
      "2023-09-22 02:19:34.899520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158ad500 of size 32768 next 1785\n",
      "2023-09-22 02:19:34.899529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158b5500 of size 32768 next 1787\n",
      "2023-09-22 02:19:34.899538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158bd500 of size 512 next 1202\n",
      "2023-09-22 02:19:34.899547: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158bd700 of size 512 next 1249\n",
      "2023-09-22 02:19:34.899556: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158bd900 of size 512 next 1062\n",
      "2023-09-22 02:19:34.899565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158bdb00 of size 512 next 1783\n",
      "2023-09-22 02:19:34.899574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158bdd00 of size 512 next 1741\n",
      "2023-09-22 02:19:34.899583: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158bdf00 of size 512 next 1810\n",
      "2023-09-22 02:19:34.899587: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158be100 of size 262144 next 1108\n",
      "2023-09-22 02:19:34.899592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13158fe100 of size 262144 next 1384\n",
      "2023-09-22 02:19:34.899596: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131593e100 of size 2048 next 1801\n",
      "2023-09-22 02:19:34.899600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131593e900 of size 2048 next 1803\n",
      "2023-09-22 02:19:34.899604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131593f100 of size 262144 next 1791\n",
      "2023-09-22 02:19:34.899608: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131597f100 of size 262144 next 782\n",
      "2023-09-22 02:19:34.899612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13159bf100 of size 2048 next 1424\n",
      "2023-09-22 02:19:34.899616: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13159bf900 of size 2048 next 1790\n",
      "2023-09-22 02:19:34.899621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13159c0100 of size 262144 next 1663\n",
      "2023-09-22 02:19:34.899625: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315a00100 of size 262144 next 717\n",
      "2023-09-22 02:19:34.899629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315a40100 of size 2048 next 660\n",
      "2023-09-22 02:19:34.899633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315a40900 of size 2048 next 303\n",
      "2023-09-22 02:19:34.899637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315a41100 of size 262144 next 606\n",
      "2023-09-22 02:19:34.899641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315a81100 of size 262144 next 1486\n",
      "2023-09-22 02:19:34.899645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac1100 of size 512 next 1705\n",
      "2023-09-22 02:19:34.899649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac1300 of size 512 next 1795\n",
      "2023-09-22 02:19:34.899653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac1500 of size 512 next 1796\n",
      "2023-09-22 02:19:34.899657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac1700 of size 512 next 1503\n",
      "2023-09-22 02:19:34.899662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac1900 of size 512 next 1817\n",
      "2023-09-22 02:19:34.899666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac1b00 of size 512 next 1798\n",
      "2023-09-22 02:19:34.899670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac1d00 of size 32768 next 1794\n",
      "2023-09-22 02:19:34.899674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ac9d00 of size 32768 next 1797\n",
      "2023-09-22 02:19:34.899678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ad1d00 of size 256 next 1362\n",
      "2023-09-22 02:19:34.899682: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ad1e00 of size 256 next 1806\n",
      "2023-09-22 02:19:34.899687: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ad1f00 of size 32768 next 1807\n",
      "2023-09-22 02:19:34.899691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ad9f00 of size 32768 next 723\n",
      "2023-09-22 02:19:34.899695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ae1f00 of size 512 next 981\n",
      "2023-09-22 02:19:34.899699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ae2100 of size 512 next 1804\n",
      "2023-09-22 02:19:34.899703: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ae2300 of size 512 next 886\n",
      "2023-09-22 02:19:34.899707: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ae2500 of size 512 next 1376\n",
      "2023-09-22 02:19:34.899712: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ae2700 of size 512 next 904\n",
      "2023-09-22 02:19:34.899716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ae2900 of size 512 next 1809\n",
      "2023-09-22 02:19:34.899720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315ae2b00 of size 32768 next 610\n",
      "2023-09-22 02:19:34.899724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315aeab00 of size 32768 next 1172\n",
      "2023-09-22 02:19:34.899728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315af2b00 of size 256 next 1451\n",
      "2023-09-22 02:19:34.899732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315af2c00 of size 256 next 478\n",
      "2023-09-22 02:19:34.899737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315af2d00 of size 256 next 1132\n",
      "2023-09-22 02:19:34.899741: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315af2e00 of size 256 next 741\n",
      "2023-09-22 02:19:34.899744: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315af2f00 of size 256 next 1210\n",
      "2023-09-22 02:19:34.899749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315af3000 of size 256 next 634\n",
      "2023-09-22 02:19:34.899753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315af3100 of size 640000 next 817\n",
      "2023-09-22 02:19:34.899757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315b8f500 of size 640000 next 229\n",
      "2023-09-22 02:19:34.899761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315c2b900 of size 640000 next 60\n",
      "2023-09-22 02:19:34.899765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315cc7d00 of size 640000 next 1089\n",
      "2023-09-22 02:19:34.899770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315d64100 of size 689664 next 754\n",
      "2023-09-22 02:19:34.899774: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c700 of size 256 next 848\n",
      "2023-09-22 02:19:34.899778: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c800 of size 256 next 136\n",
      "2023-09-22 02:19:34.899782: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1315e0c900 of size 81920000 next 1344\n",
      "2023-09-22 02:19:34.899786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131ac2c900 of size 40960000 next 775\n",
      "2023-09-22 02:19:34.899790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f131d33c900 of size 56506112 next 190\n",
      "2023-09-22 02:19:34.899794: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920000 of size 256 next 1574\n",
      "2023-09-22 02:19:34.899799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320920100 of size 262144 next 935\n",
      "2023-09-22 02:19:34.899803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320960100 of size 262144 next 616\n",
      "2023-09-22 02:19:34.899807: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13209a0100 of size 262144 next 1772\n",
      "2023-09-22 02:19:34.899811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13209e0100 of size 262144 next 1294\n",
      "2023-09-22 02:19:34.899815: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320a20100 of size 262144 next 340\n",
      "2023-09-22 02:19:34.899819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320a60100 of size 262144 next 997\n",
      "2023-09-22 02:19:34.899823: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320aa0100 of size 262144 next 1398\n",
      "2023-09-22 02:19:34.899827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320ae0100 of size 262144 next 970\n",
      "2023-09-22 02:19:34.899831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b20100 of size 32768 next 619\n",
      "2023-09-22 02:19:34.899835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b28100 of size 256 next 422\n",
      "2023-09-22 02:19:34.899839: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b28200 of size 256 next 834\n",
      "2023-09-22 02:19:34.899844: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b28300 of size 32768 next 1445\n",
      "2023-09-22 02:19:34.899848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b30300 of size 32768 next 1092\n",
      "2023-09-22 02:19:34.899852: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b38300 of size 512 next 59\n",
      "2023-09-22 02:19:34.899857: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b38500 of size 512 next 1430\n",
      "2023-09-22 02:19:34.899861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b38700 of size 512 next 1694\n",
      "2023-09-22 02:19:34.899865: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b38900 of size 512 next 487\n",
      "2023-09-22 02:19:34.899869: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b38b00 of size 512 next 1704\n",
      "2023-09-22 02:19:34.899873: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b38d00 of size 512 next 424\n",
      "2023-09-22 02:19:34.899878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b38f00 of size 262144 next 1206\n",
      "2023-09-22 02:19:34.899881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320b78f00 of size 262144 next 338\n",
      "2023-09-22 02:19:34.899885: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320bb8f00 of size 2048 next 1289\n",
      "2023-09-22 02:19:34.899889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320bb9700 of size 2048 next 502\n",
      "2023-09-22 02:19:34.899893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320bb9f00 of size 262144 next 650\n",
      "2023-09-22 02:19:34.899898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320bf9f00 of size 262144 next 278\n",
      "2023-09-22 02:19:34.899902: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320c39f00 of size 2048 next 1276\n",
      "2023-09-22 02:19:34.899906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320c3a700 of size 2048 next 1691\n",
      "2023-09-22 02:19:34.899910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320c3af00 of size 262144 next 580\n",
      "2023-09-22 02:19:34.899914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320c7af00 of size 262144 next 1749\n",
      "2023-09-22 02:19:34.899919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320cbaf00 of size 2048 next 403\n",
      "2023-09-22 02:19:34.899923: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320cbb700 of size 2048 next 494\n",
      "2023-09-22 02:19:34.899927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320cbbf00 of size 262144 next 1292\n",
      "2023-09-22 02:19:34.899932: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320cfbf00 of size 262144 next 1230\n",
      "2023-09-22 02:19:34.899936: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d3bf00 of size 512 next 821\n",
      "2023-09-22 02:19:34.899940: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d3c100 of size 512 next 442\n",
      "2023-09-22 02:19:34.899944: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d3c300 of size 512 next 489\n",
      "2023-09-22 02:19:34.899948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d3c500 of size 512 next 188\n",
      "2023-09-22 02:19:34.899952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d3c700 of size 512 next 1033\n",
      "2023-09-22 02:19:34.899956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d3c900 of size 512 next 1474\n",
      "2023-09-22 02:19:34.899961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d3cb00 of size 32768 next 1231\n",
      "2023-09-22 02:19:34.899965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d44b00 of size 32768 next 555\n",
      "2023-09-22 02:19:34.899969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d4cb00 of size 256 next 1071\n",
      "2023-09-22 02:19:34.899973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d4cc00 of size 256 next 1148\n",
      "2023-09-22 02:19:34.899977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d4cd00 of size 32768 next 578\n",
      "2023-09-22 02:19:34.899981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d54d00 of size 32768 next 1750\n",
      "2023-09-22 02:19:34.899986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d5cd00 of size 512 next 281\n",
      "2023-09-22 02:19:34.899990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d5cf00 of size 512 next 1473\n",
      "2023-09-22 02:19:34.899994: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d5d100 of size 512 next 1731\n",
      "2023-09-22 02:19:34.899998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d5d300 of size 512 next 874\n",
      "2023-09-22 02:19:34.900002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d5d500 of size 512 next 1571\n",
      "2023-09-22 02:19:34.900007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d5d700 of size 512 next 181\n",
      "2023-09-22 02:19:34.900011: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d5d900 of size 262144 next 1495\n",
      "2023-09-22 02:19:34.900015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320d9d900 of size 262144 next 994\n",
      "2023-09-22 02:19:34.900018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320ddd900 of size 2048 next 803\n",
      "2023-09-22 02:19:34.900023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320dde100 of size 2048 next 1588\n",
      "2023-09-22 02:19:34.900027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320dde900 of size 262144 next 1751\n",
      "2023-09-22 02:19:34.900031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320e1e900 of size 262144 next 1753\n",
      "2023-09-22 02:19:34.900035: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320e5e900 of size 2048 next 144\n",
      "2023-09-22 02:19:34.900039: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320e5f100 of size 2048 next 1513\n",
      "2023-09-22 02:19:34.900043: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320e5f900 of size 262144 next 575\n",
      "2023-09-22 02:19:34.900046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320e9f900 of size 262144 next 1754\n",
      "2023-09-22 02:19:34.900050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320edf900 of size 2048 next 260\n",
      "2023-09-22 02:19:34.900054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320ee0100 of size 2048 next 1732\n",
      "2023-09-22 02:19:34.900059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320ee0900 of size 262144 next 425\n",
      "2023-09-22 02:19:34.900063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320f20900 of size 453888 next 1625\n",
      "2023-09-22 02:19:34.900067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320f8f600 of size 256 next 290\n",
      "2023-09-22 02:19:34.900072: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1320f8f700 of size 65180416 next 112\n",
      "2023-09-22 02:19:34.900078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8a00 of size 256 next 687\n",
      "2023-09-22 02:19:34.900082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8b00 of size 256 next 301\n",
      "2023-09-22 02:19:34.900086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8c00 of size 256 next 143\n",
      "2023-09-22 02:19:34.900090: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8d00 of size 512 next 86\n",
      "2023-09-22 02:19:34.900094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db8f00 of size 256 next 493\n",
      "2023-09-22 02:19:34.900099: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1324db9000 of size 327680000 next 1742\n",
      "2023-09-22 02:19:34.900103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1338639000 of size 81920000 next 515\n",
      "2023-09-22 02:19:34.900107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f133d459000 of size 81920000 next 637\n",
      "2023-09-22 02:19:34.900111: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1342279000 of size 81920000 next 432\n",
      "2023-09-22 02:19:34.900115: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1347099000 of size 327680000 next 1639\n",
      "2023-09-22 02:19:34.900119: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f135a919000 of size 362720000 next 666\n",
      "2023-09-22 02:19:34.900123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1370303b00 of size 1263600128 next 1203\n",
      "2023-09-22 02:19:34.900128: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f13bb813d00 of size 1600000000 next 930\n",
      "2023-09-22 02:19:34.900132: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f141adf4d00 of size 1600000000 next 1620\n",
      "2023-09-22 02:19:34.900136: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f147a3d5d00 of size 81920000 next 1036\n",
      "2023-09-22 02:19:34.900140: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f147f1f5d00 of size 81920000 next 1478\n",
      "2023-09-22 02:19:34.900144: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1484015d00 of size 20480000 next 678\n",
      "2023-09-22 02:19:34.900148: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f148539dd00 of size 143360000 next 1470\n",
      "2023-09-22 02:19:34.900152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f148dc55d00 of size 327680000 next 978\n",
      "2023-09-22 02:19:34.900156: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14a14d5d00 of size 327680000 next 1712\n",
      "2023-09-22 02:19:34.900160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14b4d55d00 of size 327680000 next 604\n",
      "2023-09-22 02:19:34.900164: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14c85d5d00 of size 327680000 next 1413\n",
      "2023-09-22 02:19:34.900169: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14dbe55d00 of size 81920000 next 864\n",
      "2023-09-22 02:19:34.900173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14e0c75d00 of size 20480000 next 760\n",
      "2023-09-22 02:19:34.900177: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14e1ffdd00 of size 40960000 next 1233\n",
      "2023-09-22 02:19:34.900181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14e470dd00 of size 20480000 next 573\n",
      "2023-09-22 02:19:34.900186: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f14e5a95d00 of size 20480000 next 1534\n",
      "2023-09-22 02:19:34.900190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14e6e1dd00 of size 104960000 next 409\n",
      "2023-09-22 02:19:34.900194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f14ed236d00 of size 1600000000 next 966\n",
      "2023-09-22 02:19:34.900198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f154c817d00 of size 81920000 next 883\n",
      "2023-09-22 02:19:34.900202: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1551637d00 of size 327680000 next 758\n",
      "2023-09-22 02:19:34.900206: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1564eb7d00 of size 245760000 next 961\n",
      "2023-09-22 02:19:34.900210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1573917d00 of size 327680000 next 1337\n",
      "2023-09-22 02:19:34.900214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1587197d00 of size 327680000 next 1476\n",
      "2023-09-22 02:19:34.900217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f159aa17d00 of size 327680000 next 566\n",
      "2023-09-22 02:19:34.900220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f15ae297d00 of size 616960000 next 316\n",
      "2023-09-22 02:19:34.900224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f15d2ef8d00 of size 1600000000 next 503\n",
      "2023-09-22 02:19:34.900227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16324d9d00 of size 1600000000 next 811\n",
      "2023-09-22 02:19:34.900230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f1691abad00 of size 327680000 next 1482\n",
      "2023-09-22 02:19:34.900234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f16a533ad00 of size 1600000000 next 148\n",
      "2023-09-22 02:19:34.900238: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f170491bd00 of size 901399296 next 18446744073709551615\n",
      "2023-09-22 02:19:34.900243: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-09-22 02:19:34.900248: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 440 Chunks of size 256 totalling 110.0KiB\n",
      "2023-09-22 02:19:34.900253: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 249 Chunks of size 512 totalling 124.5KiB\n",
      "2023-09-22 02:19:34.900258: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 15 Chunks of size 768 totalling 11.2KiB\n",
      "2023-09-22 02:19:34.900263: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2023-09-22 02:19:34.900267: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-09-22 02:19:34.900272: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 105 Chunks of size 2048 totalling 210.0KiB\n",
      "2023-09-22 02:19:34.900276: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2304 totalling 2.2KiB\n",
      "2023-09-22 02:19:34.900281: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 2560 totalling 15.0KiB\n",
      "2023-09-22 02:19:34.900285: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2816 totalling 2.8KiB\n",
      "2023-09-22 02:19:34.900290: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 3072 totalling 6.0KiB\n",
      "2023-09-22 02:19:34.900295: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 3584 totalling 21.0KiB\n",
      "2023-09-22 02:19:34.900299: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 7 Chunks of size 3840 totalling 26.2KiB\n",
      "2023-09-22 02:19:34.900304: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 5120 totalling 25.0KiB\n",
      "2023-09-22 02:19:34.900308: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 5376 totalling 5.2KiB\n",
      "2023-09-22 02:19:34.900313: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 5888 totalling 5.8KiB\n",
      "2023-09-22 02:19:34.900317: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 8192 totalling 8.0KiB\n",
      "2023-09-22 02:19:34.900322: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14336 totalling 14.0KiB\n",
      "2023-09-22 02:19:34.900326: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15360 totalling 15.0KiB\n",
      "2023-09-22 02:19:34.900331: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 87 Chunks of size 32768 totalling 2.72MiB\n",
      "2023-09-22 02:19:34.900336: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 33280 totalling 97.5KiB\n",
      "2023-09-22 02:19:34.900340: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 10 Chunks of size 33792 totalling 330.0KiB\n",
      "2023-09-22 02:19:34.900345: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 36608 totalling 35.8KiB\n",
      "2023-09-22 02:19:34.900349: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 36864 totalling 36.0KiB\n",
      "2023-09-22 02:19:34.900354: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 38656 totalling 37.8KiB\n",
      "2023-09-22 02:19:34.900358: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 45056 totalling 88.0KiB\n",
      "2023-09-22 02:19:34.900362: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 46336 totalling 45.2KiB\n",
      "2023-09-22 02:19:34.900367: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 46848 totalling 45.8KiB\n",
      "2023-09-22 02:19:34.900371: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 48128 totalling 47.0KiB\n",
      "2023-09-22 02:19:34.900376: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 50176 totalling 49.0KiB\n",
      "2023-09-22 02:19:34.900381: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 50432 totalling 49.2KiB\n",
      "2023-09-22 02:19:34.900385: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 51200 totalling 50.0KiB\n",
      "2023-09-22 02:19:34.900390: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 57344 totalling 56.0KiB\n",
      "2023-09-22 02:19:34.900394: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 59904 totalling 58.5KiB\n",
      "2023-09-22 02:19:34.900399: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 62720 totalling 61.2KiB\n",
      "2023-09-22 02:19:34.900403: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 64256 totalling 62.8KiB\n",
      "2023-09-22 02:19:34.900408: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 12 Chunks of size 180224 totalling 2.06MiB\n",
      "2023-09-22 02:19:34.900412: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 183808 totalling 179.5KiB\n",
      "2023-09-22 02:19:34.900417: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 201216 totalling 196.5KiB\n",
      "2023-09-22 02:19:34.900422: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 211456 totalling 206.5KiB\n",
      "2023-09-22 02:19:34.900426: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 223232 totalling 436.0KiB\n",
      "2023-09-22 02:19:34.900431: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 239616 totalling 234.0KiB\n",
      "2023-09-22 02:19:34.900436: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 246528 totalling 240.8KiB\n",
      "2023-09-22 02:19:34.900440: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 249344 totalling 243.5KiB\n",
      "2023-09-22 02:19:34.900445: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 261376 totalling 255.2KiB\n",
      "2023-09-22 02:19:34.900449: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 125 Chunks of size 262144 totalling 31.25MiB\n",
      "2023-09-22 02:19:34.900454: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 263424 totalling 257.2KiB\n",
      "2023-09-22 02:19:34.900458: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 273408 totalling 267.0KiB\n",
      "2023-09-22 02:19:34.900463: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 276736 totalling 270.2KiB\n",
      "2023-09-22 02:19:34.900468: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 292096 totalling 285.2KiB\n",
      "2023-09-22 02:19:34.900472: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2023-09-22 02:19:34.900477: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 296960 totalling 290.0KiB\n",
      "2023-09-22 02:19:34.900481: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 299776 totalling 292.8KiB\n",
      "2023-09-22 02:19:34.900486: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 311808 totalling 304.5KiB\n",
      "2023-09-22 02:19:34.900490: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 320512 totalling 626.0KiB\n",
      "2023-09-22 02:19:34.900495: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 320768 totalling 313.2KiB\n",
      "2023-09-22 02:19:34.900500: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 327680 totalling 640.0KiB\n",
      "2023-09-22 02:19:34.900504: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 330240 totalling 322.5KiB\n",
      "2023-09-22 02:19:34.900509: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 336384 totalling 328.5KiB\n",
      "2023-09-22 02:19:34.900513: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 341504 totalling 333.5KiB\n",
      "2023-09-22 02:19:34.900517: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 344064 totalling 336.0KiB\n",
      "2023-09-22 02:19:34.900522: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 349184 totalling 341.0KiB\n",
      "2023-09-22 02:19:34.900527: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 350208 totalling 342.0KiB\n",
      "2023-09-22 02:19:34.900531: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 354816 totalling 346.5KiB\n",
      "2023-09-22 02:19:34.900536: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 363264 totalling 354.8KiB\n",
      "2023-09-22 02:19:34.900540: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 366336 totalling 357.8KiB\n",
      "2023-09-22 02:19:34.900545: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 370944 totalling 362.2KiB\n",
      "2023-09-22 02:19:34.900549: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 372736 totalling 364.0KiB\n",
      "2023-09-22 02:19:34.900554: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 373760 totalling 365.0KiB\n",
      "2023-09-22 02:19:34.900558: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 378880 totalling 1.81MiB\n",
      "2023-09-22 02:19:34.900563: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 379136 totalling 740.5KiB\n",
      "2023-09-22 02:19:34.900567: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 393216 totalling 1.12MiB\n",
      "2023-09-22 02:19:34.900572: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 414720 totalling 405.0KiB\n",
      "2023-09-22 02:19:34.900577: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 437248 totalling 854.0KiB\n",
      "2023-09-22 02:19:34.900581: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 452608 totalling 442.0KiB\n",
      "2023-09-22 02:19:34.900586: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 453888 totalling 443.2KiB\n",
      "2023-09-22 02:19:34.900590: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 458752 totalling 448.0KiB\n",
      "2023-09-22 02:19:34.900595: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 464896 totalling 454.0KiB\n",
      "2023-09-22 02:19:34.900600: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 475648 totalling 464.5KiB\n",
      "2023-09-22 02:19:34.900604: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 476160 totalling 465.0KiB\n",
      "2023-09-22 02:19:34.900609: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 477184 totalling 932.0KiB\n",
      "2023-09-22 02:19:34.900613: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 491520 totalling 480.0KiB\n",
      "2023-09-22 02:19:34.900618: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 496128 totalling 484.5KiB\n",
      "2023-09-22 02:19:34.900622: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 506880 totalling 495.0KiB\n",
      "2023-09-22 02:19:34.900627: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 15 Chunks of size 640000 totalling 9.16MiB\n",
      "2023-09-22 02:19:34.900632: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 689664 totalling 673.5KiB\n",
      "2023-09-22 02:19:34.900637: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10556928 totalling 10.07MiB\n",
      "2023-09-22 02:19:34.900641: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10667520 totalling 10.17MiB\n",
      "2023-09-22 02:19:34.900646: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 11 Chunks of size 20480000 totalling 214.84MiB\n",
      "2023-09-22 02:19:34.900651: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 23455488 totalling 22.37MiB\n",
      "2023-09-22 02:19:34.900655: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 39062528 totalling 37.25MiB\n",
      "2023-09-22 02:19:34.900660: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 40960000 totalling 195.31MiB\n",
      "2023-09-22 02:19:34.900664: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 53242112 totalling 50.78MiB\n",
      "2023-09-22 02:19:34.900668: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 56506112 totalling 53.89MiB\n",
      "2023-09-22 02:19:34.900673: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 65180416 totalling 62.16MiB\n",
      "2023-09-22 02:19:34.900678: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 65561344 totalling 62.52MiB\n",
      "2023-09-22 02:19:34.900682: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 73954048 totalling 70.53MiB\n",
      "2023-09-22 02:19:34.900687: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 20 Chunks of size 81920000 totalling 1.53GiB\n",
      "2023-09-22 02:19:34.900691: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 86695936 totalling 82.68MiB\n",
      "2023-09-22 02:19:34.900696: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 102449664 totalling 97.70MiB\n",
      "2023-09-22 02:19:34.900701: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 104168448 totalling 99.34MiB\n",
      "2023-09-22 02:19:34.900705: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 104960000 totalling 100.10MiB\n",
      "2023-09-22 02:19:34.900710: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 133975552 totalling 127.77MiB\n",
      "2023-09-22 02:19:34.900715: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 143360000 totalling 136.72MiB\n",
      "2023-09-22 02:19:34.900719: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 154428416 totalling 147.27MiB\n",
      "2023-09-22 02:19:34.900724: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 158345728 totalling 151.01MiB\n",
      "2023-09-22 02:19:34.900728: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 17 Chunks of size 327680000 totalling 5.19GiB\n",
      "2023-09-22 02:19:34.900733: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 362720000 totalling 345.92MiB\n",
      "2023-09-22 02:19:34.900738: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 449005824 totalling 428.21MiB\n",
      "2023-09-22 02:19:34.900742: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1263600128 totalling 1.18GiB\n",
      "2023-09-22 02:19:34.900747: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 1600000000 totalling 8.94GiB\n",
      "2023-09-22 02:19:34.900751: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 19.34GiB\n",
      "2023-09-22 02:19:34.900755: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 23023321088 memory_limit_: 23023321088 available bytes: 0 curr_region_allocation_bytes_: 46046642176\n",
      "2023-09-22 02:19:34.900764: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                     23023321088\n",
      "InUse:                     20771375360\n",
      "MaxInUse:                  22300408832\n",
      "NumAllocs:                    40440371\n",
      "MaxAllocSize:               6400000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-22 02:19:34.900795: W tensorflow/tsl/framework/bfc_allocator.cc:492] ************************************************************************_***************_********___\n",
      "2023-09-22 02:19:34.900820: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at softmax_op_gpu.cu.cc:222 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[256,4,625,625] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'model/multi_head_attention_4/softmax/Softmax' defined at (most recent call last):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_3386617/1959657965.py\", line 121, in <module>\n",
      "      hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3},\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 595, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 526, in _compute_attention\n",
      "      attention_scores = self._masked_softmax(\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/attention/multi_head_attention.py\", line 492, in _masked_softmax\n",
      "      return self._softmax(attention_scores, attention_mask)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/layers/activation/softmax.py\", line 103, in call\n",
      "      return backend.softmax(inputs, axis=self.axis[0])\n",
      "    File \"/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/keras/backend.py\", line 5416, in softmax\n",
      "      return tf.nn.softmax(x, axis=axis)\n",
      "Node: 'model/multi_head_attention_4/softmax/Softmax'\n",
      "OOM when allocating tensor with shape[256,4,625,625] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/multi_head_attention_4/softmax/Softmax}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_2300871]\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool4_do0.5_tra5_head8_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1328 - mean_squared_error: 0.0432\n",
      "Epoch 1: val_loss improved from inf to 0.07885, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool4_do0.5_tra5_head8_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 17s 87ms/step - loss: 0.1327 - mean_squared_error: 0.0431 - val_loss: 0.0789 - val_mean_squared_error: 0.0127\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0974 - mean_squared_error: 0.0179\n",
      "Epoch 2: val_loss did not improve from 0.07885\n",
      "42/42 [==============================] - 2s 60ms/step - loss: 0.0975 - mean_squared_error: 0.0180 - val_loss: 0.0811 - val_mean_squared_error: 0.0098\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0947 - mean_squared_error: 0.0171\n",
      "Epoch 3: val_loss did not improve from 0.07885\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.0948 - mean_squared_error: 0.0171 - val_loss: 0.0853 - val_mean_squared_error: 0.0095\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0918 - mean_squared_error: 0.0160\n",
      "Epoch 4: val_loss did not improve from 0.07885\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.0917 - mean_squared_error: 0.0159 - val_loss: 0.0914 - val_mean_squared_error: 0.0100\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###0 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1333 - mean_squared_error: 0.0430\n",
      "Epoch 1: val_loss improved from inf to 0.07572, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool4_do0.5_tra5_head8_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 20s 89ms/step - loss: 0.1334 - mean_squared_error: 0.0430 - val_loss: 0.0757 - val_mean_squared_error: 0.0115\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0192\n",
      "Epoch 2: val_loss did not improve from 0.07572\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.1014 - mean_squared_error: 0.0192 - val_loss: 0.0790 - val_mean_squared_error: 0.0097\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0970 - mean_squared_error: 0.0177\n",
      "Epoch 3: val_loss did not improve from 0.07572\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.0970 - mean_squared_error: 0.0177 - val_loss: 0.0864 - val_mean_squared_error: 0.0095\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.0162\n",
      "Epoch 4: val_loss did not improve from 0.07572\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0926 - mean_squared_error: 0.0161 - val_loss: 0.1018 - val_mean_squared_error: 0.0121\n",
      "55/55 [==============================] - 2s 11ms/step\n",
      " ###1 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1338 - mean_squared_error: 0.0437\n",
      "Epoch 1: val_loss improved from inf to 0.07514, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool4_do0.5_tra5_head8_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 17s 78ms/step - loss: 0.1336 - mean_squared_error: 0.0436 - val_loss: 0.0751 - val_mean_squared_error: 0.0115\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0191\n",
      "Epoch 2: val_loss did not improve from 0.07514\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.1006 - mean_squared_error: 0.0191 - val_loss: 0.0777 - val_mean_squared_error: 0.0096\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0972 - mean_squared_error: 0.0176\n",
      "Epoch 3: val_loss did not improve from 0.07514\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.0972 - mean_squared_error: 0.0176 - val_loss: 0.0850 - val_mean_squared_error: 0.0093\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.0161\n",
      "Epoch 4: val_loss did not improve from 0.07514\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.0927 - mean_squared_error: 0.0161 - val_loss: 0.0829 - val_mean_squared_error: 0.0091\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1322 - mean_squared_error: 0.0421\n",
      "Epoch 1: val_loss improved from inf to 0.08105, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool4_do0.5_tra5_head8_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 18s 76ms/step - loss: 0.1322 - mean_squared_error: 0.0420 - val_loss: 0.0811 - val_mean_squared_error: 0.0145\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0190\n",
      "Epoch 2: val_loss improved from 0.08105 to 0.07694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size5_pool4_do0.5_tra5_head8_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.1007 - mean_squared_error: 0.0190 - val_loss: 0.0769 - val_mean_squared_error: 0.0102\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0963 - mean_squared_error: 0.0175\n",
      "Epoch 3: val_loss did not improve from 0.07694\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.0962 - mean_squared_error: 0.0174 - val_loss: 0.0853 - val_mean_squared_error: 0.0095\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.0163\n",
      "Epoch 4: val_loss did not improve from 0.07694\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0928 - mean_squared_error: 0.0163 - val_loss: 0.0858 - val_mean_squared_error: 0.0095\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.0149\n",
      "Epoch 5: val_loss did not improve from 0.07694\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.0899 - mean_squared_error: 0.0150 - val_loss: 0.0870 - val_mean_squared_error: 0.0095\n",
      "55/55 [==============================] - 2s 11ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae1.59+-0.01\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1108 - mean_squared_error: 0.0248\n",
      "Epoch 1: val_loss improved from inf to 0.10527, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_0.hdf5\n",
      "83/83 [==============================] - 23s 166ms/step - loss: 0.1108 - mean_squared_error: 0.0248 - val_loss: 0.1053 - val_mean_squared_error: 0.0206\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.10527\n",
      "83/83 [==============================] - 13s 151ms/step - loss: 0.1065 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 3: val_loss did not improve from 0.10527\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss did not improve from 0.10527\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "55/55 [==============================] - 2s 30ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1108 - mean_squared_error: 0.0241\n",
      "Epoch 1: val_loss improved from inf to 0.10692, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 27s 168ms/step - loss: 0.1108 - mean_squared_error: 0.0241 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10692 to 0.10669, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10669 to 0.10654, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1065 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10654 to 0.10592, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_1.hdf5\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1059 - val_mean_squared_error: 0.0206\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss did not improve from 0.10592\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss did not improve from 0.10592\n",
      "83/83 [==============================] - 13s 151ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.10592\n",
      "83/83 [==============================] - 13s 151ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "55/55 [==============================] - 2s 29ms/step\n",
      " ###1 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0244\n",
      "Epoch 1: val_loss improved from inf to 0.10536, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_2.hdf5\n",
      "83/83 [==============================] - 24s 165ms/step - loss: 0.1114 - mean_squared_error: 0.0244 - val_loss: 0.1054 - val_mean_squared_error: 0.0203\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss did not improve from 0.10536\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10536\n",
      "83/83 [==============================] - 13s 151ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss did not improve from 0.10536\n",
      "83/83 [==============================] - 13s 151ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "55/55 [==============================] - 2s 29ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0241\n",
      "Epoch 1: val_loss improved from inf to 0.10636, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt16_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_3.hdf5\n",
      "83/83 [==============================] - 23s 166ms/step - loss: 0.1112 - mean_squared_error: 0.0241 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.10636\n",
      "83/83 [==============================] - 12s 150ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10636\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss did not improve from 0.10636\n",
      "83/83 [==============================] - 12s 150ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "55/55 [==============================] - 2s 29ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae2.23+-0.04\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1450 - mean_squared_error: 0.0560\n",
      "Epoch 1: val_loss improved from inf to 0.10995, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_0.hdf5\n",
      "21/21 [==============================] - 13s 201ms/step - loss: 0.1450 - mean_squared_error: 0.0560 - val_loss: 0.1099 - val_mean_squared_error: 0.0216\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.10995\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0207\n",
      "Epoch 3: val_loss did not improve from 0.10995\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.1064 - mean_squared_error: 0.0207 - val_loss: 0.1100 - val_mean_squared_error: 0.0216\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0206\n",
      "Epoch 4: val_loss did not improve from 0.10995\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 0.1063 - mean_squared_error: 0.0206 - val_loss: 0.1099 - val_mean_squared_error: 0.0216\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###0 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1430 - mean_squared_error: 0.0534\n",
      "Epoch 1: val_loss improved from inf to 0.10689, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 13s 208ms/step - loss: 0.1430 - mean_squared_error: 0.0534 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10689 to 0.10688, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10688 to 0.10686, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10686 to 0.10685, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1074 - mean_squared_error: 0.0209 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10685 to 0.10683, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss improved from 0.10683 to 0.10679, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1068 - val_mean_squared_error: 0.0208\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss improved from 0.10679 to 0.10670, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1067 - val_mean_squared_error: 0.0207\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 8: val_loss improved from 0.10670 to 0.10648, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1065 - val_mean_squared_error: 0.0207\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 9: val_loss improved from 0.10648 to 0.10619, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1062 - val_mean_squared_error: 0.0206\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0210\n",
      "Epoch 10: val_loss did not improve from 0.10619\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 0.1072 - mean_squared_error: 0.0210 - val_loss: 0.1064 - val_mean_squared_error: 0.0207\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0208\n",
      "Epoch 11: val_loss improved from 0.10619 to 0.10604, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1070 - mean_squared_error: 0.0208 - val_loss: 0.1060 - val_mean_squared_error: 0.0206\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0208\n",
      "Epoch 12: val_loss improved from 0.10604 to 0.10563, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1070 - mean_squared_error: 0.0208 - val_loss: 0.1056 - val_mean_squared_error: 0.0205\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 13: val_loss improved from 0.10563 to 0.10460, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1046 - val_mean_squared_error: 0.0203\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0209\n",
      "Epoch 14: val_loss improved from 0.10460 to 0.09952, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1066 - mean_squared_error: 0.0209 - val_loss: 0.0995 - val_mean_squared_error: 0.0192\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0211\n",
      "Epoch 15: val_loss improved from 0.09952 to 0.09423, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1062 - mean_squared_error: 0.0211 - val_loss: 0.0942 - val_mean_squared_error: 0.0180\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0208\n",
      "Epoch 16: val_loss did not improve from 0.09423\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.1063 - mean_squared_error: 0.0208 - val_loss: 0.0974 - val_mean_squared_error: 0.0187\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0205\n",
      "Epoch 17: val_loss improved from 0.09423 to 0.08332, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 163ms/step - loss: 0.1041 - mean_squared_error: 0.0205 - val_loss: 0.0833 - val_mean_squared_error: 0.0150\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0194\n",
      "Epoch 18: val_loss improved from 0.08332 to 0.07758, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.1013 - mean_squared_error: 0.0194 - val_loss: 0.0776 - val_mean_squared_error: 0.0129\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0963 - mean_squared_error: 0.0181\n",
      "Epoch 19: val_loss improved from 0.07758 to 0.07625, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_1.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.0963 - mean_squared_error: 0.0181 - val_loss: 0.0762 - val_mean_squared_error: 0.0102\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0923 - mean_squared_error: 0.0166\n",
      "Epoch 20: val_loss did not improve from 0.07625\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.0923 - mean_squared_error: 0.0166 - val_loss: 0.0815 - val_mean_squared_error: 0.0093\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0891 - mean_squared_error: 0.0151\n",
      "Epoch 21: val_loss did not improve from 0.07625\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.0891 - mean_squared_error: 0.0151 - val_loss: 0.1045 - val_mean_squared_error: 0.0127\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0865 - mean_squared_error: 0.0144\n",
      "Epoch 22: val_loss did not improve from 0.07625\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0865 - mean_squared_error: 0.0144 - val_loss: 0.1437 - val_mean_squared_error: 0.0262\n",
      "55/55 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1443 - mean_squared_error: 0.0544\n",
      "Epoch 1: val_loss improved from inf to 0.10576, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 17s 222ms/step - loss: 0.1443 - mean_squared_error: 0.0544 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss did not improve from 0.10576\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.10576 to 0.10576, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.10576 to 0.10576, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1058 - val_mean_squared_error: 0.0204\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.10576 to 0.10575, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.10575 to 0.10574, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 7: val_loss improved from 0.10574 to 0.10572, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 8: val_loss improved from 0.10572 to 0.10567, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1057 - val_mean_squared_error: 0.0204\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0210\n",
      "Epoch 9: val_loss improved from 0.10567 to 0.10560, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1077 - mean_squared_error: 0.0210 - val_loss: 0.1056 - val_mean_squared_error: 0.0204\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0211\n",
      "Epoch 10: val_loss improved from 0.10560 to 0.10549, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1078 - mean_squared_error: 0.0211 - val_loss: 0.1055 - val_mean_squared_error: 0.0203\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0211\n",
      "Epoch 11: val_loss improved from 0.10549 to 0.10530, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 155ms/step - loss: 0.1077 - mean_squared_error: 0.0211 - val_loss: 0.1053 - val_mean_squared_error: 0.0203\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 12: val_loss improved from 0.10530 to 0.10494, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1049 - val_mean_squared_error: 0.0202\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0210\n",
      "Epoch 13: val_loss improved from 0.10494 to 0.10356, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.1073 - mean_squared_error: 0.0210 - val_loss: 0.1036 - val_mean_squared_error: 0.0199\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0212\n",
      "Epoch 14: val_loss improved from 0.10356 to 0.10258, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1076 - mean_squared_error: 0.0212 - val_loss: 0.1026 - val_mean_squared_error: 0.0197\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0210\n",
      "Epoch 15: val_loss improved from 0.10258 to 0.10107, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1074 - mean_squared_error: 0.0210 - val_loss: 0.1011 - val_mean_squared_error: 0.0194\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0208\n",
      "Epoch 16: val_loss improved from 0.10107 to 0.08529, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1067 - mean_squared_error: 0.0208 - val_loss: 0.0853 - val_mean_squared_error: 0.0158\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0208\n",
      "Epoch 17: val_loss improved from 0.08529 to 0.07933, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1055 - mean_squared_error: 0.0208 - val_loss: 0.0793 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0207\n",
      "Epoch 18: val_loss improved from 0.07933 to 0.07505, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_2.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.1050 - mean_squared_error: 0.0207 - val_loss: 0.0750 - val_mean_squared_error: 0.0115\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0201\n",
      "Epoch 19: val_loss did not improve from 0.07505\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.1029 - mean_squared_error: 0.0201 - val_loss: 0.0772 - val_mean_squared_error: 0.0097\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.0185\n",
      "Epoch 20: val_loss did not improve from 0.07505\n",
      "21/21 [==============================] - 3s 153ms/step - loss: 0.0982 - mean_squared_error: 0.0185 - val_loss: 0.0917 - val_mean_squared_error: 0.0100\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0946 - mean_squared_error: 0.0170\n",
      "Epoch 21: val_loss did not improve from 0.07505\n",
      "21/21 [==============================] - 3s 153ms/step - loss: 0.0946 - mean_squared_error: 0.0170 - val_loss: 0.1362 - val_mean_squared_error: 0.0233\n",
      "55/55 [==============================] - 2s 12ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1487 - mean_squared_error: 0.0588\n",
      "Epoch 1: val_loss improved from inf to 0.10632, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 15s 215ms/step - loss: 0.1487 - mean_squared_error: 0.0588 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10632 to 0.10631, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10631 to 0.10630, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 4: val_loss improved from 0.10630 to 0.10630, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss improved from 0.10630 to 0.10629, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss improved from 0.10629 to 0.10626, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 7: val_loss improved from 0.10626 to 0.10620, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1062 - val_mean_squared_error: 0.0207\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 8: val_loss improved from 0.10620 to 0.10609, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1061 - val_mean_squared_error: 0.0207\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 9: val_loss improved from 0.10609 to 0.10566, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1075 - mean_squared_error: 0.0210 - val_loss: 0.1057 - val_mean_squared_error: 0.0206\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 10: val_loss improved from 0.10566 to 0.10452, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1045 - val_mean_squared_error: 0.0204\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 11: val_loss improved from 0.10452 to 0.10348, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1035 - val_mean_squared_error: 0.0201\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0209\n",
      "Epoch 12: val_loss did not improve from 0.10348\n",
      "21/21 [==============================] - 3s 153ms/step - loss: 0.1073 - mean_squared_error: 0.0209 - val_loss: 0.1037 - val_mean_squared_error: 0.0202\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 13: val_loss improved from 0.10348 to 0.10229, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 158ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1023 - val_mean_squared_error: 0.0199\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0207\n",
      "Epoch 14: val_loss improved from 0.10229 to 0.09146, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 157ms/step - loss: 0.1063 - mean_squared_error: 0.0207 - val_loss: 0.0915 - val_mean_squared_error: 0.0174\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0209\n",
      "Epoch 15: val_loss improved from 0.09146 to 0.08332, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 164ms/step - loss: 0.1061 - mean_squared_error: 0.0209 - val_loss: 0.0833 - val_mean_squared_error: 0.0153\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0207\n",
      "Epoch 16: val_loss improved from 0.08332 to 0.07778, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size15_pool2_do0.5_tra3_head4_kdim64_fnn64/weights_3.hdf5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.1055 - mean_squared_error: 0.0207 - val_loss: 0.0778 - val_mean_squared_error: 0.0132\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0200\n",
      "Epoch 17: val_loss did not improve from 0.07778\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.1030 - mean_squared_error: 0.0200 - val_loss: 0.0814 - val_mean_squared_error: 0.0094\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.0188\n",
      "Epoch 18: val_loss did not improve from 0.07778\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.0991 - mean_squared_error: 0.0188 - val_loss: 0.0920 - val_mean_squared_error: 0.0102\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0949 - mean_squared_error: 0.0175\n",
      "Epoch 19: val_loss did not improve from 0.07778\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.0949 - mean_squared_error: 0.0175 - val_loss: 0.1521 - val_mean_squared_error: 0.0293\n",
      "55/55 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae1.77+-0.28\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1525 - mean_squared_error: 0.0561\n",
      "Epoch 1: val_loss improved from inf to 0.10009, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 18s 93ms/step - loss: 0.1525 - mean_squared_error: 0.0561 - val_loss: 0.1001 - val_mean_squared_error: 0.0195\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0222\n",
      "Epoch 2: val_loss did not improve from 0.10009\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.1076 - mean_squared_error: 0.0222 - val_loss: 0.1013 - val_mean_squared_error: 0.0197\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss did not improve from 0.10009\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.1055 - mean_squared_error: 0.0210 - val_loss: 0.1012 - val_mean_squared_error: 0.0197\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0217\n",
      "Epoch 4: val_loss improved from 0.10009 to 0.09985, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.1067 - mean_squared_error: 0.0216 - val_loss: 0.0999 - val_mean_squared_error: 0.0194\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0203\n",
      "Epoch 5: val_loss improved from 0.09985 to 0.09600, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.1042 - mean_squared_error: 0.0203 - val_loss: 0.0960 - val_mean_squared_error: 0.0184\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0200\n",
      "Epoch 6: val_loss improved from 0.09600 to 0.09171, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.1032 - mean_squared_error: 0.0200 - val_loss: 0.0917 - val_mean_squared_error: 0.0173\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0200\n",
      "Epoch 7: val_loss did not improve from 0.09171\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.1029 - mean_squared_error: 0.0200 - val_loss: 0.0988 - val_mean_squared_error: 0.0184\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0193\n",
      "Epoch 8: val_loss improved from 0.09171 to 0.09147, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 67ms/step - loss: 0.1008 - mean_squared_error: 0.0193 - val_loss: 0.0915 - val_mean_squared_error: 0.0160\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0972 - mean_squared_error: 0.0182\n",
      "Epoch 9: val_loss improved from 0.09147 to 0.06657, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 0.0971 - mean_squared_error: 0.0182 - val_loss: 0.0666 - val_mean_squared_error: 0.0088\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0943 - mean_squared_error: 0.0172\n",
      "Epoch 10: val_loss did not improve from 0.06657\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0943 - mean_squared_error: 0.0172 - val_loss: 0.0696 - val_mean_squared_error: 0.0094\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0875 - mean_squared_error: 0.0153\n",
      "Epoch 11: val_loss did not improve from 0.06657\n",
      "42/42 [==============================] - 3s 73ms/step - loss: 0.0875 - mean_squared_error: 0.0153 - val_loss: 0.1517 - val_mean_squared_error: 0.0453\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0798 - mean_squared_error: 0.0130\n",
      "Epoch 12: val_loss did not improve from 0.06657\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0797 - mean_squared_error: 0.0130 - val_loss: 0.1543 - val_mean_squared_error: 0.0447\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###0 fold : val mae 0.07###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1552 - mean_squared_error: 0.0582\n",
      "Epoch 1: val_loss improved from inf to 0.09846, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 17s 95ms/step - loss: 0.1552 - mean_squared_error: 0.0582 - val_loss: 0.0985 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1096 - mean_squared_error: 0.0227\n",
      "Epoch 2: val_loss did not improve from 0.09846\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.1097 - mean_squared_error: 0.0228 - val_loss: 0.1019 - val_mean_squared_error: 0.0197\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0220\n",
      "Epoch 3: val_loss did not improve from 0.09846\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 0.1078 - mean_squared_error: 0.0220 - val_loss: 0.1012 - val_mean_squared_error: 0.0195\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0217\n",
      "Epoch 4: val_loss did not improve from 0.09846\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.1074 - mean_squared_error: 0.0217 - val_loss: 0.1007 - val_mean_squared_error: 0.0194\n",
      "55/55 [==============================] - 1s 12ms/step\n",
      " ###1 fold : val mae 0.10###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1591 - mean_squared_error: 0.0617\n",
      "Epoch 1: val_loss improved from inf to 0.09564, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 21s 95ms/step - loss: 0.1589 - mean_squared_error: 0.0616 - val_loss: 0.0956 - val_mean_squared_error: 0.0183\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0228\n",
      "Epoch 2: val_loss did not improve from 0.09564\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.1098 - mean_squared_error: 0.0228 - val_loss: 0.0962 - val_mean_squared_error: 0.0184\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0219\n",
      "Epoch 3: val_loss improved from 0.09564 to 0.09519, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 0.1081 - mean_squared_error: 0.0219 - val_loss: 0.0952 - val_mean_squared_error: 0.0181\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0211\n",
      "Epoch 4: val_loss improved from 0.09519 to 0.09301, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.1062 - mean_squared_error: 0.0211 - val_loss: 0.0930 - val_mean_squared_error: 0.0175\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1053 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss improved from 0.09301 to 0.08657, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.1053 - mean_squared_error: 0.0206 - val_loss: 0.0866 - val_mean_squared_error: 0.0160\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0203\n",
      "Epoch 6: val_loss improved from 0.08657 to 0.07767, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.1044 - mean_squared_error: 0.0204 - val_loss: 0.0777 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0194\n",
      "Epoch 7: val_loss improved from 0.07767 to 0.06988, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.1008 - mean_squared_error: 0.0193 - val_loss: 0.0699 - val_mean_squared_error: 0.0094\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0177\n",
      "Epoch 8: val_loss did not improve from 0.06988\n",
      "42/42 [==============================] - 3s 73ms/step - loss: 0.0953 - mean_squared_error: 0.0177 - val_loss: 0.0731 - val_mean_squared_error: 0.0105\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0902 - mean_squared_error: 0.0164\n",
      "Epoch 9: val_loss did not improve from 0.06988\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.0901 - mean_squared_error: 0.0163 - val_loss: 0.1507 - val_mean_squared_error: 0.0372\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.0132\n",
      "Epoch 10: val_loss did not improve from 0.06988\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.0810 - mean_squared_error: 0.0132 - val_loss: 0.2377 - val_mean_squared_error: 0.0899\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1520 - mean_squared_error: 0.0559\n",
      "Epoch 1: val_loss improved from inf to 0.09799, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn4_filt64_size11_pool4_do0.5_tra5_head2_kdim16_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 18s 103ms/step - loss: 0.1519 - mean_squared_error: 0.0558 - val_loss: 0.0980 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1087 - mean_squared_error: 0.0225\n",
      "Epoch 2: val_loss did not improve from 0.09799\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.1088 - mean_squared_error: 0.0225 - val_loss: 0.1024 - val_mean_squared_error: 0.0199\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0215\n",
      "Epoch 3: val_loss did not improve from 0.09799\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.1070 - mean_squared_error: 0.0215 - val_loss: 0.1006 - val_mean_squared_error: 0.0195\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0215\n",
      "Epoch 4: val_loss did not improve from 0.09799\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.1071 - mean_squared_error: 0.0215 - val_loss: 0.0987 - val_mean_squared_error: 0.0191\n",
      "55/55 [==============================] - 2s 11ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae1.77+-0.32\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0840 - mean_squared_error: 0.0180\n",
      "Epoch 1: val_loss improved from inf to 0.05944, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 15s 49ms/step - loss: 0.0840 - mean_squared_error: 0.0180 - val_loss: 0.0594 - val_mean_squared_error: 0.0081\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0498 - mean_squared_error: 0.0055\n",
      "Epoch 2: val_loss did not improve from 0.05944\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 0.0498 - mean_squared_error: 0.0055 - val_loss: 0.0959 - val_mean_squared_error: 0.0183\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0435 - mean_squared_error: 0.0043\n",
      "Epoch 3: val_loss did not improve from 0.05944\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0435 - mean_squared_error: 0.0043 - val_loss: 0.0639 - val_mean_squared_error: 0.0082\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0039\n",
      "Epoch 4: val_loss improved from 0.05944 to 0.04633, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0416 - mean_squared_error: 0.0039 - val_loss: 0.0463 - val_mean_squared_error: 0.0051\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0036\n",
      "Epoch 5: val_loss did not improve from 0.04633\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0393 - mean_squared_error: 0.0036 - val_loss: 0.0481 - val_mean_squared_error: 0.0050\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0378 - mean_squared_error: 0.0033\n",
      "Epoch 6: val_loss did not improve from 0.04633\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0378 - mean_squared_error: 0.0033 - val_loss: 0.0602 - val_mean_squared_error: 0.0073\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0350 - mean_squared_error: 0.0030\n",
      "Epoch 7: val_loss improved from 0.04633 to 0.03862, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.0350 - mean_squared_error: 0.0030 - val_loss: 0.0386 - val_mean_squared_error: 0.0035\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0029\n",
      "Epoch 8: val_loss improved from 0.03862 to 0.03656, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0344 - mean_squared_error: 0.0029 - val_loss: 0.0366 - val_mean_squared_error: 0.0033\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0027\n",
      "Epoch 9: val_loss did not improve from 0.03656\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0335 - mean_squared_error: 0.0027 - val_loss: 0.0471 - val_mean_squared_error: 0.0052\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0026\n",
      "Epoch 10: val_loss improved from 0.03656 to 0.03105, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_0.hdf5\n",
      "83/83 [==============================] - 3s 42ms/step - loss: 0.0323 - mean_squared_error: 0.0026 - val_loss: 0.0310 - val_mean_squared_error: 0.0027\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0025\n",
      "Epoch 11: val_loss did not improve from 0.03105\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0319 - mean_squared_error: 0.0025 - val_loss: 0.0326 - val_mean_squared_error: 0.0028\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0023\n",
      "Epoch 12: val_loss did not improve from 0.03105\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0302 - mean_squared_error: 0.0023 - val_loss: 0.0315 - val_mean_squared_error: 0.0027\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0302 - mean_squared_error: 0.0023\n",
      "Epoch 13: val_loss did not improve from 0.03105\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0302 - mean_squared_error: 0.0023 - val_loss: 0.0335 - val_mean_squared_error: 0.0029\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###0 fold : val mae 0.03###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.0189\n",
      "Epoch 1: val_loss improved from inf to 0.10247, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 16s 50ms/step - loss: 0.0890 - mean_squared_error: 0.0189 - val_loss: 0.1025 - val_mean_squared_error: 0.0263\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0530 - mean_squared_error: 0.0061\n",
      "Epoch 2: val_loss improved from 0.10247 to 0.06049, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 4s 44ms/step - loss: 0.0529 - mean_squared_error: 0.0061 - val_loss: 0.0605 - val_mean_squared_error: 0.0078\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0434 - mean_squared_error: 0.0042\n",
      "Epoch 3: val_loss did not improve from 0.06049\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0434 - mean_squared_error: 0.0042 - val_loss: 0.0683 - val_mean_squared_error: 0.0096\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0411 - mean_squared_error: 0.0038\n",
      "Epoch 4: val_loss improved from 0.06049 to 0.03918, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_1.hdf5\n",
      "83/83 [==============================] - 3s 41ms/step - loss: 0.0411 - mean_squared_error: 0.0038 - val_loss: 0.0392 - val_mean_squared_error: 0.0037\n",
      "Epoch 5/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0035\n",
      "Epoch 5: val_loss did not improve from 0.03918\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0381 - mean_squared_error: 0.0035 - val_loss: 0.0475 - val_mean_squared_error: 0.0054\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0031\n",
      "Epoch 6: val_loss did not improve from 0.03918\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0363 - mean_squared_error: 0.0031 - val_loss: 0.0431 - val_mean_squared_error: 0.0044\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0030\n",
      "Epoch 7: val_loss did not improve from 0.03918\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0360 - mean_squared_error: 0.0030 - val_loss: 0.0603 - val_mean_squared_error: 0.0079\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      " ###1 fold : val mae 0.04###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0847 - mean_squared_error: 0.0178\n",
      "Epoch 1: val_loss improved from inf to 0.04873, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 19s 57ms/step - loss: 0.0847 - mean_squared_error: 0.0178 - val_loss: 0.0487 - val_mean_squared_error: 0.0056\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0542 - mean_squared_error: 0.0063\n",
      "Epoch 2: val_loss improved from 0.04873 to 0.04640, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0542 - mean_squared_error: 0.0063 - val_loss: 0.0464 - val_mean_squared_error: 0.0048\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0459 - mean_squared_error: 0.0047\n",
      "Epoch 3: val_loss did not improve from 0.04640\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0459 - mean_squared_error: 0.0047 - val_loss: 0.0889 - val_mean_squared_error: 0.0132\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0415 - mean_squared_error: 0.0040\n",
      "Epoch 4: val_loss improved from 0.04640 to 0.03474, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0415 - mean_squared_error: 0.0040 - val_loss: 0.0347 - val_mean_squared_error: 0.0030\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0035\n",
      "Epoch 5: val_loss did not improve from 0.03474\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0383 - mean_squared_error: 0.0035 - val_loss: 0.0381 - val_mean_squared_error: 0.0039\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0365 - mean_squared_error: 0.0032\n",
      "Epoch 6: val_loss did not improve from 0.03474\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0365 - mean_squared_error: 0.0032 - val_loss: 0.0417 - val_mean_squared_error: 0.0037\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0355 - mean_squared_error: 0.0030\n",
      "Epoch 7: val_loss improved from 0.03474 to 0.03002, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0355 - mean_squared_error: 0.0030 - val_loss: 0.0300 - val_mean_squared_error: 0.0025\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0349 - mean_squared_error: 0.0030\n",
      "Epoch 8: val_loss improved from 0.03002 to 0.02987, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_2.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0349 - mean_squared_error: 0.0030 - val_loss: 0.0299 - val_mean_squared_error: 0.0022\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0026\n",
      "Epoch 9: val_loss did not improve from 0.02987\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0330 - mean_squared_error: 0.0026 - val_loss: 0.0332 - val_mean_squared_error: 0.0027\n",
      "Epoch 10/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0025\n",
      "Epoch 10: val_loss did not improve from 0.02987\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0323 - mean_squared_error: 0.0025 - val_loss: 0.0388 - val_mean_squared_error: 0.0029\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0315 - mean_squared_error: 0.0024\n",
      "Epoch 11: val_loss did not improve from 0.02987\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0315 - mean_squared_error: 0.0024 - val_loss: 0.0356 - val_mean_squared_error: 0.0024\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###2 fold : val mae 0.03###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0781 - mean_squared_error: 0.0162\n",
      "Epoch 1: val_loss improved from inf to 0.07670, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 16s 57ms/step - loss: 0.0781 - mean_squared_error: 0.0162 - val_loss: 0.0767 - val_mean_squared_error: 0.0121\n",
      "Epoch 2/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0509 - mean_squared_error: 0.0056\n",
      "Epoch 2: val_loss improved from 0.07670 to 0.04050, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0508 - mean_squared_error: 0.0056 - val_loss: 0.0405 - val_mean_squared_error: 0.0038\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0432 - mean_squared_error: 0.0042\n",
      "Epoch 3: val_loss did not improve from 0.04050\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0432 - mean_squared_error: 0.0042 - val_loss: 0.0476 - val_mean_squared_error: 0.0053\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0037\n",
      "Epoch 4: val_loss improved from 0.04050 to 0.03319, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 40ms/step - loss: 0.0394 - mean_squared_error: 0.0037 - val_loss: 0.0332 - val_mean_squared_error: 0.0028\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0034\n",
      "Epoch 5: val_loss did not improve from 0.03319\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0380 - mean_squared_error: 0.0034 - val_loss: 0.0644 - val_mean_squared_error: 0.0081\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0032\n",
      "Epoch 6: val_loss improved from 0.03319 to 0.03316, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0369 - mean_squared_error: 0.0032 - val_loss: 0.0332 - val_mean_squared_error: 0.0029\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0351 - mean_squared_error: 0.0030\n",
      "Epoch 7: val_loss improved from 0.03316 to 0.03215, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch64_cnn4_filt32_size7_pool5_do0.2_tra4_head2_kdim64_fnn128/weights_3.hdf5\n",
      "83/83 [==============================] - 3s 39ms/step - loss: 0.0351 - mean_squared_error: 0.0030 - val_loss: 0.0321 - val_mean_squared_error: 0.0027\n",
      "Epoch 8/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0345 - mean_squared_error: 0.0029\n",
      "Epoch 8: val_loss did not improve from 0.03215\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0345 - mean_squared_error: 0.0029 - val_loss: 0.0424 - val_mean_squared_error: 0.0040\n",
      "Epoch 9/100\n",
      "82/83 [============================>.] - ETA: 0s - loss: 0.0325 - mean_squared_error: 0.0027\n",
      "Epoch 9: val_loss did not improve from 0.03215\n",
      "83/83 [==============================] - 3s 38ms/step - loss: 0.0325 - mean_squared_error: 0.0026 - val_loss: 0.0329 - val_mean_squared_error: 0.0029\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0025\n",
      "Epoch 10: val_loss did not improve from 0.03215\n",
      "83/83 [==============================] - 3s 37ms/step - loss: 0.0323 - mean_squared_error: 0.0025 - val_loss: 0.0335 - val_mean_squared_error: 0.0032\n",
      "55/55 [==============================] - 1s 10ms/step\n",
      " ###3 fold : val mae 0.03###\n",
      "mae0.68+-0.06\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size19_pool5_do0.5_tra5_head2_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0255\n",
      "Epoch 1: val_loss improved from inf to 0.08047, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size19_pool5_do0.5_tra5_head2_kdim16_fnn128/weights_0.hdf5\n",
      "42/42 [==============================] - 16s 79ms/step - loss: 0.1100 - mean_squared_error: 0.0256 - val_loss: 0.0805 - val_mean_squared_error: 0.0098\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0962 - mean_squared_error: 0.0177\n",
      "Epoch 2: val_loss did not improve from 0.08047\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.0962 - mean_squared_error: 0.0177 - val_loss: 0.0993 - val_mean_squared_error: 0.0115\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0911 - mean_squared_error: 0.0157\n",
      "Epoch 3: val_loss did not improve from 0.08047\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.0911 - mean_squared_error: 0.0157 - val_loss: 0.1303 - val_mean_squared_error: 0.0213\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.0147\n",
      "Epoch 4: val_loss did not improve from 0.08047\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 0.0882 - mean_squared_error: 0.0148 - val_loss: 0.1620 - val_mean_squared_error: 0.0337\n",
      "55/55 [==============================] - 2s 11ms/step\n",
      " ###0 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0251\n",
      "Epoch 1: val_loss improved from inf to 0.07555, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size19_pool5_do0.5_tra5_head2_kdim16_fnn128/weights_1.hdf5\n",
      "42/42 [==============================] - 15s 79ms/step - loss: 0.1110 - mean_squared_error: 0.0251 - val_loss: 0.0756 - val_mean_squared_error: 0.0115\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0974 - mean_squared_error: 0.0179\n",
      "Epoch 2: val_loss did not improve from 0.07555\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.0974 - mean_squared_error: 0.0179 - val_loss: 0.0909 - val_mean_squared_error: 0.0099\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0920 - mean_squared_error: 0.0161\n",
      "Epoch 3: val_loss did not improve from 0.07555\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.0920 - mean_squared_error: 0.0160 - val_loss: 0.1056 - val_mean_squared_error: 0.0130\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.0139\n",
      "Epoch 4: val_loss did not improve from 0.07555\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0853 - mean_squared_error: 0.0139 - val_loss: 0.1384 - val_mean_squared_error: 0.0255\n",
      "55/55 [==============================] - 2s 11ms/step\n",
      " ###1 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1118 - mean_squared_error: 0.0263\n",
      "Epoch 1: val_loss improved from inf to 0.07429, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size19_pool5_do0.5_tra5_head2_kdim16_fnn128/weights_2.hdf5\n",
      "42/42 [==============================] - 20s 90ms/step - loss: 0.1117 - mean_squared_error: 0.0263 - val_loss: 0.0743 - val_mean_squared_error: 0.0110\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0978 - mean_squared_error: 0.0180\n",
      "Epoch 2: val_loss did not improve from 0.07429\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.0978 - mean_squared_error: 0.0180 - val_loss: 0.0853 - val_mean_squared_error: 0.0091\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.0160\n",
      "Epoch 3: val_loss did not improve from 0.07429\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.0921 - mean_squared_error: 0.0160 - val_loss: 0.1137 - val_mean_squared_error: 0.0154\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.0140\n",
      "Epoch 4: val_loss did not improve from 0.07429\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0853 - mean_squared_error: 0.0140 - val_loss: 0.1856 - val_mean_squared_error: 0.0418\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      " ###2 fold : val mae 0.08###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1113 - mean_squared_error: 0.0252\n",
      "Epoch 1: val_loss improved from inf to 0.07835, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn2_filt32_size19_pool5_do0.5_tra5_head2_kdim16_fnn128/weights_3.hdf5\n",
      "42/42 [==============================] - 16s 81ms/step - loss: 0.1113 - mean_squared_error: 0.0252 - val_loss: 0.0784 - val_mean_squared_error: 0.0135\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0184\n",
      "Epoch 2: val_loss did not improve from 0.07835\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 0.0984 - mean_squared_error: 0.0184 - val_loss: 0.0924 - val_mean_squared_error: 0.0102\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0919 - mean_squared_error: 0.0159\n",
      "Epoch 3: val_loss did not improve from 0.07835\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.0919 - mean_squared_error: 0.0159 - val_loss: 0.0994 - val_mean_squared_error: 0.0114\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0849 - mean_squared_error: 0.0139\n",
      "Epoch 4: val_loss did not improve from 0.07835\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0849 - mean_squared_error: 0.0139 - val_loss: 0.1063 - val_mean_squared_error: 0.0182\n",
      "55/55 [==============================] - 2s 10ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae1.61+-0.04\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0208\n",
      "Epoch 1: val_loss improved from inf to 0.11002, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 12s 74ms/step - loss: 0.1069 - mean_squared_error: 0.0208 - val_loss: 0.1100 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0174\n",
      "Epoch 2: val_loss improved from 0.11002 to 0.08880, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0953 - mean_squared_error: 0.0174 - val_loss: 0.0888 - val_mean_squared_error: 0.0098\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0806 - mean_squared_error: 0.0125\n",
      "Epoch 3: val_loss did not improve from 0.08880\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0806 - mean_squared_error: 0.0126 - val_loss: 0.1769 - val_mean_squared_error: 0.0393\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0658 - mean_squared_error: 0.0089\n",
      "Epoch 4: val_loss did not improve from 0.08880\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0657 - mean_squared_error: 0.0089 - val_loss: 0.1901 - val_mean_squared_error: 0.0497\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0455 - mean_squared_error: 0.0046\n",
      "Epoch 5: val_loss improved from 0.08880 to 0.05383, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_0.hdf5\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.0456 - mean_squared_error: 0.0046 - val_loss: 0.0538 - val_mean_squared_error: 0.0056\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.0040\n",
      "Epoch 6: val_loss did not improve from 0.05383\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0418 - mean_squared_error: 0.0040 - val_loss: 0.1347 - val_mean_squared_error: 0.0237\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0037\n",
      "Epoch 7: val_loss did not improve from 0.05383\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0397 - mean_squared_error: 0.0037 - val_loss: 0.1115 - val_mean_squared_error: 0.0166\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0032\n",
      "Epoch 8: val_loss did not improve from 0.05383\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0363 - mean_squared_error: 0.0032 - val_loss: 0.1548 - val_mean_squared_error: 0.0305\n",
      "55/55 [==============================] - 3s 8ms/step\n",
      " ###0 fold : val mae 0.05###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0211\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 13s 65ms/step - loss: 0.1076 - mean_squared_error: 0.0211 - val_loss: 0.1070 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10696 to 0.10687, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.1076 - mean_squared_error: 0.0210 - val_loss: 0.1069 - val_mean_squared_error: 0.0208\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0209\n",
      "Epoch 3: val_loss improved from 0.10687 to 0.10504, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1050 - val_mean_squared_error: 0.0204\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0883 - mean_squared_error: 0.0150\n",
      "Epoch 4: val_loss did not improve from 0.10504\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0882 - mean_squared_error: 0.0150 - val_loss: 0.1683 - val_mean_squared_error: 0.0360\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.0121\n",
      "Epoch 5: val_loss did not improve from 0.10504\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0793 - mean_squared_error: 0.0121 - val_loss: 0.1451 - val_mean_squared_error: 0.0267\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0765 - mean_squared_error: 0.0110\n",
      "Epoch 6: val_loss improved from 0.10504 to 0.05991, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0764 - mean_squared_error: 0.0110 - val_loss: 0.0599 - val_mean_squared_error: 0.0068\n",
      "Epoch 7/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0588 - mean_squared_error: 0.0071\n",
      "Epoch 7: val_loss did not improve from 0.05991\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0587 - mean_squared_error: 0.0071 - val_loss: 0.1329 - val_mean_squared_error: 0.0256\n",
      "Epoch 8/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.0042\n",
      "Epoch 8: val_loss improved from 0.05991 to 0.05015, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0424 - mean_squared_error: 0.0042 - val_loss: 0.0502 - val_mean_squared_error: 0.0046\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0037\n",
      "Epoch 9: val_loss did not improve from 0.05015\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0398 - mean_squared_error: 0.0037 - val_loss: 0.0731 - val_mean_squared_error: 0.0077\n",
      "Epoch 10/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0374 - mean_squared_error: 0.0033\n",
      "Epoch 10: val_loss did not improve from 0.05015\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0374 - mean_squared_error: 0.0033 - val_loss: 0.0734 - val_mean_squared_error: 0.0086\n",
      "Epoch 11/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0360 - mean_squared_error: 0.0031\n",
      "Epoch 11: val_loss improved from 0.05015 to 0.04202, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.0360 - mean_squared_error: 0.0031 - val_loss: 0.0420 - val_mean_squared_error: 0.0039\n",
      "Epoch 12/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.0031\n",
      "Epoch 12: val_loss did not improve from 0.04202\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0354 - mean_squared_error: 0.0031 - val_loss: 0.0659 - val_mean_squared_error: 0.0071\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0362 - mean_squared_error: 0.0031\n",
      "Epoch 13: val_loss improved from 0.04202 to 0.03270, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_1.hdf5\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.0361 - mean_squared_error: 0.0031 - val_loss: 0.0327 - val_mean_squared_error: 0.0028\n",
      "Epoch 14/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.0027\n",
      "Epoch 14: val_loss did not improve from 0.03270\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0331 - mean_squared_error: 0.0027 - val_loss: 0.0480 - val_mean_squared_error: 0.0042\n",
      "Epoch 15/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0323 - mean_squared_error: 0.0027\n",
      "Epoch 15: val_loss did not improve from 0.03270\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.0323 - mean_squared_error: 0.0027 - val_loss: 0.0407 - val_mean_squared_error: 0.0032\n",
      "Epoch 16/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.0025\n",
      "Epoch 16: val_loss did not improve from 0.03270\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0312 - mean_squared_error: 0.0025 - val_loss: 0.0457 - val_mean_squared_error: 0.0042\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###1 fold : val mae 0.03###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1165 - mean_squared_error: 0.0277\n",
      "Epoch 1: val_loss improved from inf to 0.10450, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_2.hdf5\n",
      "42/42 [==============================] - 13s 74ms/step - loss: 0.1165 - mean_squared_error: 0.0277 - val_loss: 0.1045 - val_mean_squared_error: 0.0201\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0186\n",
      "Epoch 2: val_loss did not improve from 0.10450\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0990 - mean_squared_error: 0.0185 - val_loss: 0.5594 - val_mean_squared_error: 0.3222\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0830 - mean_squared_error: 0.0131\n",
      "Epoch 3: val_loss did not improve from 0.10450\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0831 - mean_squared_error: 0.0132 - val_loss: 0.2251 - val_mean_squared_error: 0.0597\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0793 - mean_squared_error: 0.0121\n",
      "Epoch 4: val_loss did not improve from 0.10450\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.0793 - mean_squared_error: 0.0121 - val_loss: 0.2598 - val_mean_squared_error: 0.0730\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      " ###2 fold : val mae 0.11###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0212\n",
      "Epoch 1: val_loss improved from inf to 0.10639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 13s 74ms/step - loss: 0.1082 - mean_squared_error: 0.0212 - val_loss: 0.1064 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10639 to 0.10628, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.1081 - mean_squared_error: 0.0211 - val_loss: 0.1063 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.10628 to 0.10550, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch128_cnn3_filt16_size15_pool5_do0.1_tra3_head8_kdim128_fnn32/weights_3.hdf5\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1055 - val_mean_squared_error: 0.0206\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.0170\n",
      "Epoch 4: val_loss did not improve from 0.10550\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0947 - mean_squared_error: 0.0170 - val_loss: 0.4386 - val_mean_squared_error: 0.2018\n",
      "Epoch 5/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0805 - mean_squared_error: 0.0122\n",
      "Epoch 5: val_loss did not improve from 0.10550\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.0805 - mean_squared_error: 0.0122 - val_loss: 0.3075 - val_mean_squared_error: 0.1038\n",
      "Epoch 6/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0782 - mean_squared_error: 0.0116\n",
      "Epoch 6: val_loss did not improve from 0.10550\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.0781 - mean_squared_error: 0.0116 - val_loss: 0.1169 - val_mean_squared_error: 0.0163\n",
      "55/55 [==============================] - 1s 8ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae1.54+-0.70\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size5_pool2_do0.1_tra5_head8_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.0161\n",
      "Epoch 1: val_loss improved from inf to 0.07768, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size5_pool2_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 19s 300ms/step - loss: 0.0890 - mean_squared_error: 0.0161 - val_loss: 0.0777 - val_mean_squared_error: 0.0105\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.0121\n",
      "Epoch 2: val_loss improved from 0.07768 to 0.07607, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size5_pool2_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 6s 266ms/step - loss: 0.0794 - mean_squared_error: 0.0121 - val_loss: 0.0761 - val_mean_squared_error: 0.0112\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0713 - mean_squared_error: 0.0102\n",
      "Epoch 3: val_loss improved from 0.07607 to 0.06095, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size5_pool2_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 246ms/step - loss: 0.0713 - mean_squared_error: 0.0102 - val_loss: 0.0610 - val_mean_squared_error: 0.0073\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0596 - mean_squared_error: 0.0072\n",
      "Epoch 4: val_loss did not improve from 0.06095\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 0.0596 - mean_squared_error: 0.0072 - val_loss: 0.0640 - val_mean_squared_error: 0.0068\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0511 - mean_squared_error: 0.0055\n",
      "Epoch 5: val_loss did not improve from 0.06095\n",
      "21/21 [==============================] - 5s 242ms/step - loss: 0.0511 - mean_squared_error: 0.0055 - val_loss: 0.0735 - val_mean_squared_error: 0.0084\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0491 - mean_squared_error: 0.0051\n",
      "Epoch 6: val_loss improved from 0.06095 to 0.05257, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_child_female_train/CNN+transformer_age%20(sigmoid)_loss(mae)-nodecay_4fold_500cases/batch256_cnn4_filt16_size5_pool2_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "21/21 [==============================] - 5s 248ms/step - loss: 0.0491 - mean_squared_error: 0.0051 - val_loss: 0.0526 - val_mean_squared_error: 0.0048\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.0044\n",
      "Epoch 7: val_loss did not improve from 0.05257\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 0.0448 - mean_squared_error: 0.0044 - val_loss: 0.0602 - val_mean_squared_error: 0.0060\n",
      "Epoch 8/100\n",
      " 4/21 [====>.........................] - ETA: 3s - loss: 0.0431 - mean_squared_error: 0.0041"
     ]
    }
   ],
   "source": [
    "random.seed(98)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, LayerNormalization, Dense, Dropout, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Input, concatenate, multiply, dot, MultiHeadAttention\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "\n",
    "SRATE = 500  # in hz\n",
    "SEGLEN = 10 * SRATE  # samples\n",
    "#BATCH_SIZE = 256\n",
    "MAX_CASES = 500\n",
    "nfold = 4\n",
    "\n",
    "hyperparameters = {\n",
    "    \"nfilt\" : [16, 32, 64],\n",
    "    'nhead' : [2, 4, 8],\n",
    "    'kdim': [16, 64, 128, 256],\n",
    "    \"fnode\" : [32, 64, 128],\n",
    "    \"clayer\" : [2, 3, 4],\n",
    "    \"tlayer\" : [3, 4, 5],\n",
    "    \"droprate\" : [0.1, 0.2, 0.5],\n",
    "    \"filtsize\" : [5, 7, 9, 11, 15, 19],\n",
    "    'poolsize' : [2, 4, 5],\n",
    "    'batch_size': [64, 128, 256]\n",
    "}\n",
    "keys, values = zip(*hyperparameters.items())\n",
    "permutations_dicts = it.product(*values)\n",
    "permutations_dicts = list(permutations_dicts)\n",
    "random.shuffle(permutations_dicts)\n",
    "for nfilt, nhead, kdim, fnode, clayer, tlayer, droprate, filtsize, poolsize, batch_size in permutations_dicts:\n",
    "    test_start = time.time()\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    rootdir = f'randomSearch/{hyper_path}/CNN+transformer_age%{SCALE_Y}(sigmoid)_loss(mae)-nodecay_{nfold}fold_{MAX_CASES}cases'\n",
    "    odir_f = 'batch{}_cnn{}_filt{}_size{}_pool{}_do{}'.format(batch_size, clayer, nfilt, filtsize, poolsize, droprate)\n",
    "    odir_f += '_tra{}_head{}_kdim{}_fnn{}'.format(tlayer, nhead, kdim, fnode)\n",
    "    \n",
    "    if not os.path.exists(rootdir):\n",
    "        os.mkdir(rootdir)\n",
    "    \n",
    "    odir = rootdir+'/'+odir_f\n",
    "    print(\"============================\")\n",
    "    print(odir)\n",
    "    print(\"============================\")\n",
    "\n",
    "    # cnn-transformer\n",
    "    # https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        out = inp = Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "\n",
    "        # out = Conv1D(filters=kdim, kernel_size=filtsize, padding='same')(out)\n",
    "\n",
    "        # conv 여러층    \n",
    "        for i in range(clayer):\n",
    "            out = Conv1D(filters=nfilt, kernel_size=filtsize, padding='same', activation=None)(out)\n",
    "            out = BatchNormalization()(out)\n",
    "            out = Activation('relu')(out)\n",
    "            out = MaxPooling1D(poolsize, padding='same')(out)\n",
    "        out = Dense(kdim)(out)  # 마지막 차원이 nfilt 인데 kdim 으로 바꿔야 transformer block을 쌓을 수 있다.\n",
    "        for i in range(tlayer):  # transformer\n",
    "            attn_output = MultiHeadAttention(num_heads=nhead, key_dim=kdim, attention_axes=[1,])(out, out)\n",
    "            attn_output = Dropout(droprate)(attn_output)\n",
    "            out1 = LayerNormalization(epsilon=1e-6)(out + attn_output)  # sum and norm\n",
    "            ffn_output = tf.keras.Sequential([Dense(fnode, activation=\"relu\"), Dense(kdim)])(out1)\n",
    "            out2 = Dropout(droprate)(ffn_output)\n",
    "            out = LayerNormalization(epsilon=1e-6)(out1 + out2)  # sum and norm\n",
    "        out = GlobalMaxPooling1D()(out)\n",
    "\n",
    "        if droprate:\n",
    "            out = Dropout(droprate)(out)\n",
    "        out = Dense(fnode)(out)\n",
    "        if droprate:\n",
    "            out = Dropout(droprate)(out)\n",
    "        out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "        if not os.path.exists(odir):\n",
    "            os.mkdir(odir)\n",
    "\n",
    "\n",
    "        model = Model(inputs=[inp], outputs=[out])\n",
    "        model.save_weights(f'{odir}/initial_weights.hdf5')\n",
    "    \n",
    "    \n",
    "    # 4-fold cv\n",
    "    kfold = KFold(nfold)\n",
    "    tprs, aucs, prs = [], [], []\n",
    "    test_rmse, test_mae = [], []\n",
    "    f1_scores, thvals = [], []\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    mean_recall = np.linspace(0,1,100)\n",
    "\n",
    "    switch = 0\n",
    "    caseids_train = np.unique(c_train)\n",
    "    for fold, (c_cv_trains_mask, c_cv_test_mask) in enumerate(kfold.split(caseids_train)):\n",
    "        c_cv_trains = caseids_train[c_cv_trains_mask]\n",
    "\n",
    "        cv_train_mask = np.isin(c_train, c_cv_trains)\n",
    "        cv_val_mask = ~cv_train_mask\n",
    "\n",
    "        X_train = x_train[cv_train_mask]\n",
    "        X_val = x_train[cv_val_mask]\n",
    "\n",
    "        Y_train = y_train[cv_train_mask]\n",
    "        Y_val = y_train[cv_val_mask]\n",
    "\n",
    "\n",
    "        # model 학습\n",
    "        try:\n",
    "            # learning scheduler\n",
    "            def step_decay(epoch):\n",
    "                start = 1e-3\n",
    "                drop = 0.1\n",
    "                epochs_drop = 10\n",
    "                lr = start * (drop ** np.floor((epoch)/epochs_drop))\n",
    "                return lr\n",
    "            lr_scheduler = LearningRateScheduler(step_decay, verbose=1)\n",
    "\n",
    "            weightcache = f\"{odir}/weights_{fold}.hdf5\"\n",
    "            #model = multi_gpu_model(model, gpus=4)\n",
    "            model.compile(loss='mae', optimizer=Adam(lr=lr_scheduler, weight_decay=None), metrics=['mean_squared_error'])\n",
    "            hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3}, \n",
    "                                    callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weightcache, verbose=1, save_best_only=True),\n",
    "                                                EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')])\n",
    "\n",
    "            model.load_weights(weightcache)\n",
    "            y_pred = model.predict(x_test).flatten()\n",
    "\n",
    "            # MAE 계산\n",
    "            model_err = metrics.MeanAbsoluteError()\n",
    "            model_err.update_state(y_test, y_pred)\n",
    "            mae_val = model_err.result().numpy()\n",
    "            test_mae.append(mae_val)\n",
    "\n",
    "\n",
    "            print(f' ###{fold} fold : val mae {mae_val:.2f}###')\n",
    "            tf.keras.backend.clear_session()\n",
    "            model.load_weights(f'{odir}/initial_weights.hdf5')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            switch = 1\n",
    "            shutil.rmtree(odir)\n",
    "            break\n",
    "    ###\n",
    "    if switch:\n",
    "        switch = 0\n",
    "        tf.keras.backend.clear_session()\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    mean_mae = np.mean(test_mae)\n",
    "    std_mae = np.std(test_mae)\n",
    "\n",
    "    max_idx = test_mae.index(min(test_mae))\n",
    "\n",
    "\n",
    "    print(f'mae{mean_mae*SCALE_Y:.2f}+-{std_mae*SCALE_Y:.2f}')\n",
    "    open(odir+\"/model.json\", \"wt\").write(model.to_json())\n",
    "\n",
    "    os.rename(odir, rootdir+f'/mae{mean_mae*SCALE_Y:.2f}+-{std_mae*SCALE_Y:.2f}_max{max_idx}__{odir_f}')\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02060fc9-65f9-472c-8300-bc198bc835be",
   "metadata": {},
   "source": [
    "## cnn-transformer + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970ceed-bc81-4c87-8534-fccb9f6b157f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool5_do0.2_tra5_head2_kdim256_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 17:39:23.683901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 17:39:24.703052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22324 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 17:39:37.511919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8904\n",
      "2023-09-22 17:39:37.988165: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-22 17:39:38.059190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-22 17:39:38.073051: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f698ff045e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-22 17:39:38.073091: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-09-22 17:39:38.081588: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-22 17:39:38.158901: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-22 17:39:38.210908: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3784 - mean_squared_error: 0.1691\n",
      "Epoch 1: val_loss improved from inf to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool5_do0.2_tra5_head2_kdim256_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 21s 87ms/step - loss: 0.3784 - mean_squared_error: 0.1691 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3800 - mean_squared_error: 0.1698\n",
      "Epoch 2: val_loss did not improve from 0.38420\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 3: val_loss did not improve from 0.38420\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 4: val_loss did not improve from 0.38420\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###0 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3801 - mean_squared_error: 0.1707\n",
      "Epoch 1: val_loss improved from inf to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool5_do0.2_tra5_head2_kdim256_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 5s 84ms/step - loss: 0.3800 - mean_squared_error: 0.1707 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 2: val_loss did not improve from 0.38084\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1709\n",
      "Epoch 3: val_loss did not improve from 0.38084\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 4: val_loss did not improve from 0.38084\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###1 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3788 - mean_squared_error: 0.1693\n",
      "Epoch 1: val_loss improved from inf to 0.38054, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool5_do0.2_tra5_head2_kdim256_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 5s 79ms/step - loss: 0.3788 - mean_squared_error: 0.1693 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 2: val_loss did not improve from 0.38054\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss did not improve from 0.38054\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1705\n",
      "Epoch 4: val_loss did not improve from 0.38054\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "14/14 [==============================] - 1s 24ms/step\n",
      " ###2 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3807 - mean_squared_error: 0.1705\n",
      "Epoch 1: val_loss improved from inf to 0.37833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool5_do0.2_tra5_head2_kdim256_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 5s 81ms/step - loss: 0.3809 - mean_squared_error: 0.1707 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss did not improve from 0.37833\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss did not improve from 0.37833\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 4: val_loss did not improve from 0.37833\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "14/14 [==============================] - 2s 26ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae38.15+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3319 - mean_squared_error: 0.1455\n",
      "Epoch 1: val_loss improved from inf to 0.16183, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 16s 180ms/step - loss: 0.3319 - mean_squared_error: 0.1455 - val_loss: 0.1618 - val_mean_squared_error: 0.0402\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2577 - mean_squared_error: 0.0947\n",
      "Epoch 2: val_loss improved from 0.16183 to 0.11889, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 6s 158ms/step - loss: 0.2574 - mean_squared_error: 0.0946 - val_loss: 0.1189 - val_mean_squared_error: 0.0231\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2122 - mean_squared_error: 0.0678\n",
      "Epoch 3: val_loss did not improve from 0.11889\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.2123 - mean_squared_error: 0.0678 - val_loss: 0.1221 - val_mean_squared_error: 0.0231\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1767 - mean_squared_error: 0.0492\n",
      "Epoch 4: val_loss improved from 0.11889 to 0.11374, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 6s 158ms/step - loss: 0.1766 - mean_squared_error: 0.0491 - val_loss: 0.1137 - val_mean_squared_error: 0.0194\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1547 - mean_squared_error: 0.0385\n",
      "Epoch 5: val_loss did not improve from 0.11374\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.1546 - mean_squared_error: 0.0385 - val_loss: 0.1198 - val_mean_squared_error: 0.0209\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1386 - mean_squared_error: 0.0310\n",
      "Epoch 6: val_loss did not improve from 0.11374\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.1384 - mean_squared_error: 0.0310 - val_loss: 0.1446 - val_mean_squared_error: 0.0292\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1302 - mean_squared_error: 0.0275\n",
      "Epoch 7: val_loss did not improve from 0.11374\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.1302 - mean_squared_error: 0.0275 - val_loss: 0.1776 - val_mean_squared_error: 0.0421\n",
      "14/14 [==============================] - 2s 57ms/step\n",
      " ###0 fold : val mae 0.12###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3255 - mean_squared_error: 0.1416\n",
      "Epoch 1: val_loss improved from inf to 0.14845, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 8s 176ms/step - loss: 0.3254 - mean_squared_error: 0.1416 - val_loss: 0.1484 - val_mean_squared_error: 0.0347\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2323 - mean_squared_error: 0.0805\n",
      "Epoch 2: val_loss improved from 0.14845 to 0.11868, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 6s 159ms/step - loss: 0.2323 - mean_squared_error: 0.0805 - val_loss: 0.1187 - val_mean_squared_error: 0.0229\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1861 - mean_squared_error: 0.0536\n",
      "Epoch 3: val_loss did not improve from 0.11868\n",
      "40/40 [==============================] - 6s 156ms/step - loss: 0.1860 - mean_squared_error: 0.0535 - val_loss: 0.1647 - val_mean_squared_error: 0.0377\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1609 - mean_squared_error: 0.0416\n",
      "Epoch 4: val_loss did not improve from 0.11868\n",
      "40/40 [==============================] - 6s 157ms/step - loss: 0.1608 - mean_squared_error: 0.0415 - val_loss: 0.1396 - val_mean_squared_error: 0.0280\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1439 - mean_squared_error: 0.0338\n",
      "Epoch 5: val_loss did not improve from 0.11868\n",
      "40/40 [==============================] - 6s 157ms/step - loss: 0.1438 - mean_squared_error: 0.0337 - val_loss: 0.1445 - val_mean_squared_error: 0.0291\n",
      "14/14 [==============================] - 1s 59ms/step\n",
      " ###1 fold : val mae 0.12###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3331 - mean_squared_error: 0.1459\n",
      "Epoch 1: val_loss improved from inf to 0.15590, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 8s 180ms/step - loss: 0.3330 - mean_squared_error: 0.1458 - val_loss: 0.1559 - val_mean_squared_error: 0.0368\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2490 - mean_squared_error: 0.0902\n",
      "Epoch 2: val_loss did not improve from 0.15590\n",
      "40/40 [==============================] - 6s 157ms/step - loss: 0.2491 - mean_squared_error: 0.0903 - val_loss: 0.1805 - val_mean_squared_error: 0.0460\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1910 - mean_squared_error: 0.0566\n",
      "Epoch 3: val_loss did not improve from 0.15590\n",
      "40/40 [==============================] - 6s 157ms/step - loss: 0.1910 - mean_squared_error: 0.0566 - val_loss: 0.2140 - val_mean_squared_error: 0.0589\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1627 - mean_squared_error: 0.0417\n",
      "Epoch 4: val_loss did not improve from 0.15590\n",
      "40/40 [==============================] - 6s 158ms/step - loss: 0.1627 - mean_squared_error: 0.0417 - val_loss: 0.2485 - val_mean_squared_error: 0.0757\n",
      "14/14 [==============================] - 1s 59ms/step\n",
      " ###2 fold : val mae 0.16###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3308 - mean_squared_error: 0.1452\n",
      "Epoch 1: val_loss improved from inf to 0.25263, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 9s 194ms/step - loss: 0.3306 - mean_squared_error: 0.1451 - val_loss: 0.2526 - val_mean_squared_error: 0.0864\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2444 - mean_squared_error: 0.0875\n",
      "Epoch 2: val_loss improved from 0.25263 to 0.23180, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 161ms/step - loss: 0.2443 - mean_squared_error: 0.0875 - val_loss: 0.2318 - val_mean_squared_error: 0.0696\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1943 - mean_squared_error: 0.0583\n",
      "Epoch 3: val_loss improved from 0.23180 to 0.16368, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 161ms/step - loss: 0.1943 - mean_squared_error: 0.0583 - val_loss: 0.1637 - val_mean_squared_error: 0.0398\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1611 - mean_squared_error: 0.0418\n",
      "Epoch 4: val_loss improved from 0.16368 to 0.13240, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 162ms/step - loss: 0.1611 - mean_squared_error: 0.0418 - val_loss: 0.1324 - val_mean_squared_error: 0.0289\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1433 - mean_squared_error: 0.0333\n",
      "Epoch 5: val_loss improved from 0.13240 to 0.10961, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 162ms/step - loss: 0.1433 - mean_squared_error: 0.0333 - val_loss: 0.1096 - val_mean_squared_error: 0.0207\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1312 - mean_squared_error: 0.0281\n",
      "Epoch 6: val_loss improved from 0.10961 to 0.10025, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt128_stride4_size9_pool2_do0.5_tra3_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 160ms/step - loss: 0.1312 - mean_squared_error: 0.0281 - val_loss: 0.1003 - val_mean_squared_error: 0.0165\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1260 - mean_squared_error: 0.0259\n",
      "Epoch 7: val_loss did not improve from 0.10025\n",
      "40/40 [==============================] - 6s 157ms/step - loss: 0.1259 - mean_squared_error: 0.0259 - val_loss: 0.1030 - val_mean_squared_error: 0.0166\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1198 - mean_squared_error: 0.0233\n",
      "Epoch 8: val_loss did not improve from 0.10025\n",
      "40/40 [==============================] - 6s 157ms/step - loss: 0.1197 - mean_squared_error: 0.0233 - val_loss: 0.1043 - val_mean_squared_error: 0.0168\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1173 - mean_squared_error: 0.0221\n",
      "Epoch 9: val_loss did not improve from 0.10025\n",
      "40/40 [==============================] - 6s 158ms/step - loss: 0.1173 - mean_squared_error: 0.0221 - val_loss: 0.1093 - val_mean_squared_error: 0.0179\n",
      "14/14 [==============================] - 2s 58ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae12.46+-2.19\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3233 - mean_squared_error: 0.1390\n",
      "Epoch 1: val_loss improved from inf to 0.16455, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 16s 96ms/step - loss: 0.3233 - mean_squared_error: 0.1390 - val_loss: 0.1646 - val_mean_squared_error: 0.0425\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2646 - mean_squared_error: 0.0979\n",
      "Epoch 2: val_loss improved from 0.16455 to 0.13061, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.2645 - mean_squared_error: 0.0978 - val_loss: 0.1306 - val_mean_squared_error: 0.0276\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2220 - mean_squared_error: 0.0729\n",
      "Epoch 3: val_loss did not improve from 0.13061\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.2222 - mean_squared_error: 0.0730 - val_loss: 0.1353 - val_mean_squared_error: 0.0277\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1879 - mean_squared_error: 0.0553\n",
      "Epoch 4: val_loss did not improve from 0.13061\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1879 - mean_squared_error: 0.0553 - val_loss: 0.1593 - val_mean_squared_error: 0.0358\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1614 - mean_squared_error: 0.0426\n",
      "Epoch 5: val_loss did not improve from 0.13061\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1614 - mean_squared_error: 0.0426 - val_loss: 0.1401 - val_mean_squared_error: 0.0279\n",
      "14/14 [==============================] - 1s 31ms/step\n",
      " ###0 fold : val mae 0.13###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3332 - mean_squared_error: 0.1466\n",
      "Epoch 1: val_loss improved from inf to 0.21344, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 6s 95ms/step - loss: 0.3332 - mean_squared_error: 0.1466 - val_loss: 0.2134 - val_mean_squared_error: 0.0626\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2611 - mean_squared_error: 0.0971\n",
      "Epoch 2: val_loss improved from 0.21344 to 0.15998, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.2611 - mean_squared_error: 0.0972 - val_loss: 0.1600 - val_mean_squared_error: 0.0379\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2169 - mean_squared_error: 0.0707\n",
      "Epoch 3: val_loss improved from 0.15998 to 0.11632, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.2168 - mean_squared_error: 0.0706 - val_loss: 0.1163 - val_mean_squared_error: 0.0220\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1906 - mean_squared_error: 0.0563\n",
      "Epoch 4: val_loss improved from 0.11632 to 0.10007, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.1906 - mean_squared_error: 0.0563 - val_loss: 0.1001 - val_mean_squared_error: 0.0166\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1632 - mean_squared_error: 0.0425\n",
      "Epoch 5: val_loss improved from 0.10007 to 0.09930, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.1631 - mean_squared_error: 0.0425 - val_loss: 0.0993 - val_mean_squared_error: 0.0158\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1455 - mean_squared_error: 0.0344\n",
      "Epoch 6: val_loss did not improve from 0.09930\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1455 - mean_squared_error: 0.0344 - val_loss: 0.1076 - val_mean_squared_error: 0.0177\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1348 - mean_squared_error: 0.0296\n",
      "Epoch 7: val_loss did not improve from 0.09930\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1348 - mean_squared_error: 0.0296 - val_loss: 0.1162 - val_mean_squared_error: 0.0200\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1271 - mean_squared_error: 0.0264\n",
      "Epoch 8: val_loss did not improve from 0.09930\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1271 - mean_squared_error: 0.0264 - val_loss: 0.1381 - val_mean_squared_error: 0.0269\n",
      "14/14 [==============================] - 1s 29ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3248 - mean_squared_error: 0.1408\n",
      "Epoch 1: val_loss improved from inf to 0.16405, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 5s 92ms/step - loss: 0.3247 - mean_squared_error: 0.1407 - val_loss: 0.1641 - val_mean_squared_error: 0.0413\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2644 - mean_squared_error: 0.0990\n",
      "Epoch 2: val_loss improved from 0.16405 to 0.12505, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.2642 - mean_squared_error: 0.0989 - val_loss: 0.1251 - val_mean_squared_error: 0.0265\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2194 - mean_squared_error: 0.0723\n",
      "Epoch 3: val_loss did not improve from 0.12505\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.2193 - mean_squared_error: 0.0722 - val_loss: 0.1380 - val_mean_squared_error: 0.0286\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1841 - mean_squared_error: 0.0532\n",
      "Epoch 4: val_loss did not improve from 0.12505\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1839 - mean_squared_error: 0.0531 - val_loss: 0.1388 - val_mean_squared_error: 0.0280\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1594 - mean_squared_error: 0.0409\n",
      "Epoch 5: val_loss did not improve from 0.12505\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1594 - mean_squared_error: 0.0409 - val_loss: 0.1768 - val_mean_squared_error: 0.0419\n",
      "14/14 [==============================] - 2s 31ms/step\n",
      " ###2 fold : val mae 0.13###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3281 - mean_squared_error: 0.1431\n",
      "Epoch 1: val_loss improved from inf to 0.16212, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride4_size11_pool4_do0.5_tra5_head4_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 5s 87ms/step - loss: 0.3281 - mean_squared_error: 0.1431 - val_loss: 0.1621 - val_mean_squared_error: 0.0413\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2516 - mean_squared_error: 0.0914\n",
      "Epoch 2: val_loss did not improve from 0.16212\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.2516 - mean_squared_error: 0.0914 - val_loss: 0.1884 - val_mean_squared_error: 0.0510\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2060 - mean_squared_error: 0.0651\n",
      "Epoch 3: val_loss did not improve from 0.16212\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.2060 - mean_squared_error: 0.0651 - val_loss: 0.1635 - val_mean_squared_error: 0.0379\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1752 - mean_squared_error: 0.0486\n",
      "Epoch 4: val_loss did not improve from 0.16212\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1752 - mean_squared_error: 0.0486 - val_loss: 0.1778 - val_mean_squared_error: 0.0430\n",
      "14/14 [==============================] - 1s 29ms/step\n",
      " ###3 fold : val mae 0.16###\n",
      "mae13.07+-2.13\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1423 - mean_squared_error: 0.0340\n",
      "Epoch 1: val_loss improved from inf to 0.13230, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 17s 66ms/step - loss: 0.1423 - mean_squared_error: 0.0340 - val_loss: 0.1323 - val_mean_squared_error: 0.0263\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0206\n",
      "Epoch 2: val_loss improved from 0.13230 to 0.09275, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1109 - mean_squared_error: 0.0206 - val_loss: 0.0927 - val_mean_squared_error: 0.0137\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0174\n",
      "Epoch 3: val_loss improved from 0.09275 to 0.08928, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1012 - mean_squared_error: 0.0174 - val_loss: 0.0893 - val_mean_squared_error: 0.0133\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.0161\n",
      "Epoch 4: val_loss improved from 0.08928 to 0.08631, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.0982 - mean_squared_error: 0.0161 - val_loss: 0.0863 - val_mean_squared_error: 0.0124\n",
      "Epoch 5/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0922 - mean_squared_error: 0.0143\n",
      "Epoch 5: val_loss improved from 0.08631 to 0.08253, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.0923 - mean_squared_error: 0.0144 - val_loss: 0.0825 - val_mean_squared_error: 0.0115\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0905 - mean_squared_error: 0.0137\n",
      "Epoch 6: val_loss did not improve from 0.08253\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0905 - mean_squared_error: 0.0137 - val_loss: 0.0932 - val_mean_squared_error: 0.0142\n",
      "Epoch 7/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.0128\n",
      "Epoch 7: val_loss did not improve from 0.08253\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.0871 - mean_squared_error: 0.0128 - val_loss: 0.0833 - val_mean_squared_error: 0.0118\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.0125\n",
      "Epoch 8: val_loss did not improve from 0.08253\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.0861 - mean_squared_error: 0.0125 - val_loss: 0.1001 - val_mean_squared_error: 0.0169\n",
      "27/27 [==============================] - 2s 20ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1431 - mean_squared_error: 0.0347\n",
      "Epoch 1: val_loss improved from inf to 0.11362, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 6s 60ms/step - loss: 0.1431 - mean_squared_error: 0.0347 - val_loss: 0.1136 - val_mean_squared_error: 0.0202\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0206\n",
      "Epoch 2: val_loss did not improve from 0.11362\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1109 - mean_squared_error: 0.0206 - val_loss: 0.1521 - val_mean_squared_error: 0.0343\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0171\n",
      "Epoch 3: val_loss improved from 0.11362 to 0.08819, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1005 - mean_squared_error: 0.0171 - val_loss: 0.0882 - val_mean_squared_error: 0.0131\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0972 - mean_squared_error: 0.0161\n",
      "Epoch 4: val_loss did not improve from 0.08819\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0972 - mean_squared_error: 0.0161 - val_loss: 0.0883 - val_mean_squared_error: 0.0127\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0932 - mean_squared_error: 0.0148\n",
      "Epoch 5: val_loss did not improve from 0.08819\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.0932 - mean_squared_error: 0.0148 - val_loss: 0.0905 - val_mean_squared_error: 0.0131\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0891 - mean_squared_error: 0.0135\n",
      "Epoch 6: val_loss did not improve from 0.08819\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0891 - mean_squared_error: 0.0135 - val_loss: 0.0989 - val_mean_squared_error: 0.0157\n",
      "27/27 [==============================] - 1s 19ms/step\n",
      " ###1 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1433 - mean_squared_error: 0.0345\n",
      "Epoch 1: val_loss improved from inf to 0.10987, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 12s 129ms/step - loss: 0.1433 - mean_squared_error: 0.0345 - val_loss: 0.1099 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0205\n",
      "Epoch 2: val_loss improved from 0.10987 to 0.09487, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1109 - mean_squared_error: 0.0205 - val_loss: 0.0949 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0177\n",
      "Epoch 3: val_loss did not improve from 0.09487\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1028 - mean_squared_error: 0.0177 - val_loss: 0.1009 - val_mean_squared_error: 0.0163\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0970 - mean_squared_error: 0.0157\n",
      "Epoch 4: val_loss improved from 0.09487 to 0.08910, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.0970 - mean_squared_error: 0.0157 - val_loss: 0.0891 - val_mean_squared_error: 0.0136\n",
      "Epoch 5/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0931 - mean_squared_error: 0.0144\n",
      "Epoch 5: val_loss did not improve from 0.08910\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.0931 - mean_squared_error: 0.0144 - val_loss: 0.0901 - val_mean_squared_error: 0.0139\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0907 - mean_squared_error: 0.0138\n",
      "Epoch 6: val_loss improved from 0.08910 to 0.08463, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.0907 - mean_squared_error: 0.0138 - val_loss: 0.0846 - val_mean_squared_error: 0.0121\n",
      "Epoch 7/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.0127\n",
      "Epoch 7: val_loss did not improve from 0.08463\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.0872 - mean_squared_error: 0.0127 - val_loss: 0.0981 - val_mean_squared_error: 0.0167\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0862 - mean_squared_error: 0.0124\n",
      "Epoch 8: val_loss improved from 0.08463 to 0.08276, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.0862 - mean_squared_error: 0.0124 - val_loss: 0.0828 - val_mean_squared_error: 0.0119\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0834 - mean_squared_error: 0.0117\n",
      "Epoch 9: val_loss improved from 0.08276 to 0.08246, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.0834 - mean_squared_error: 0.0117 - val_loss: 0.0825 - val_mean_squared_error: 0.0118\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.0116\n",
      "Epoch 10: val_loss did not improve from 0.08246\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.0832 - mean_squared_error: 0.0116 - val_loss: 0.0844 - val_mean_squared_error: 0.0123\n",
      "Epoch 11/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0799 - mean_squared_error: 0.0108\n",
      "Epoch 11: val_loss did not improve from 0.08246\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.0799 - mean_squared_error: 0.0108 - val_loss: 0.0843 - val_mean_squared_error: 0.0118\n",
      "Epoch 12/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0780 - mean_squared_error: 0.0104\n",
      "Epoch 12: val_loss did not improve from 0.08246\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.0780 - mean_squared_error: 0.0104 - val_loss: 0.0848 - val_mean_squared_error: 0.0125\n",
      "27/27 [==============================] - 2s 20ms/step\n",
      " ###2 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1382 - mean_squared_error: 0.0323\n",
      "Epoch 1: val_loss improved from inf to 0.14362, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 6s 59ms/step - loss: 0.1381 - mean_squared_error: 0.0323 - val_loss: 0.1436 - val_mean_squared_error: 0.0303\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0201\n",
      "Epoch 2: val_loss improved from 0.14362 to 0.09480, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1086 - mean_squared_error: 0.0201 - val_loss: 0.0948 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0989 - mean_squared_error: 0.0165\n",
      "Epoch 3: val_loss improved from 0.09480 to 0.08668, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.0989 - mean_squared_error: 0.0165 - val_loss: 0.0867 - val_mean_squared_error: 0.0123\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0944 - mean_squared_error: 0.0150\n",
      "Epoch 4: val_loss improved from 0.08668 to 0.08517, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.0944 - mean_squared_error: 0.0150 - val_loss: 0.0852 - val_mean_squared_error: 0.0118\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0906 - mean_squared_error: 0.0137\n",
      "Epoch 5: val_loss improved from 0.08517 to 0.08319, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size19_pool5_do0.1_tra4_head2_kdim16_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.0906 - mean_squared_error: 0.0137 - val_loss: 0.0832 - val_mean_squared_error: 0.0115\n",
      "Epoch 6/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0891 - mean_squared_error: 0.0134\n",
      "Epoch 6: val_loss did not improve from 0.08319\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.0891 - mean_squared_error: 0.0134 - val_loss: 0.0859 - val_mean_squared_error: 0.0119\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0869 - mean_squared_error: 0.0126\n",
      "Epoch 7: val_loss did not improve from 0.08319\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0869 - mean_squared_error: 0.0126 - val_loss: 0.0889 - val_mean_squared_error: 0.0135\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.0119\n",
      "Epoch 8: val_loss did not improve from 0.08319\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0839 - mean_squared_error: 0.0119 - val_loss: 0.0889 - val_mean_squared_error: 0.0134\n",
      "27/27 [==============================] - 1s 18ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae8.38+-0.24\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride2_size19_pool5_do0.1_tra5_head2_kdim256_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3769 - mean_squared_error: 0.1679\n",
      "Epoch 1: val_loss improved from inf to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride2_size19_pool5_do0.1_tra5_head2_kdim256_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 131ms/step - loss: 0.3769 - mean_squared_error: 0.1679 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3798 - mean_squared_error: 0.1697\n",
      "Epoch 2: val_loss did not improve from 0.38420\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3798 - mean_squared_error: 0.1697\n",
      "Epoch 3: val_loss did not improve from 0.38420\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 4: val_loss did not improve from 0.38420\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "14/14 [==============================] - 2s 41ms/step\n",
      " ###0 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3777 - mean_squared_error: 0.1691\n",
      "Epoch 1: val_loss improved from inf to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride2_size19_pool5_do0.1_tra5_head2_kdim256_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 7s 133ms/step - loss: 0.3778 - mean_squared_error: 0.1691 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 2: val_loss did not improve from 0.38084\n",
      "40/40 [==============================] - 4s 98ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3809 - mean_squared_error: 0.1707\n",
      "Epoch 3: val_loss did not improve from 0.38084\n",
      "40/40 [==============================] - 4s 98ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1709\n",
      "Epoch 4: val_loss did not improve from 0.38084\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "14/14 [==============================] - 1s 38ms/step\n",
      " ###1 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3778 - mean_squared_error: 0.1686\n",
      "Epoch 1: val_loss improved from inf to 0.38054, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride2_size19_pool5_do0.1_tra5_head2_kdim256_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 7s 128ms/step - loss: 0.3778 - mean_squared_error: 0.1686 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1704\n",
      "Epoch 2: val_loss did not improve from 0.38054\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3812 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss did not improve from 0.38054\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 4: val_loss did not improve from 0.38054\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "14/14 [==============================] - 2s 41ms/step\n",
      " ###2 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3789 - mean_squared_error: 0.1694\n",
      "Epoch 1: val_loss improved from inf to 0.37833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt64_stride2_size19_pool5_do0.1_tra5_head2_kdim256_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 7s 125ms/step - loss: 0.3788 - mean_squared_error: 0.1693 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss did not improve from 0.37833\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss did not improve from 0.37833\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3821 - mean_squared_error: 0.1712\n",
      "Epoch 4: val_loss did not improve from 0.37833\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "14/14 [==============================] - 1s 39ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae38.15+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1613 - mean_squared_error: 0.0431\n",
      "Epoch 1: val_loss improved from inf to 0.10796, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 13s 50ms/step - loss: 0.1613 - mean_squared_error: 0.0431 - val_loss: 0.1080 - val_mean_squared_error: 0.0193\n",
      "Epoch 2/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1208 - mean_squared_error: 0.0244\n",
      "Epoch 2: val_loss improved from 0.10796 to 0.10305, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.1210 - mean_squared_error: 0.0244 - val_loss: 0.1031 - val_mean_squared_error: 0.0179\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0201\n",
      "Epoch 3: val_loss did not improve from 0.10305\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.1101 - mean_squared_error: 0.0201 - val_loss: 0.1214 - val_mean_squared_error: 0.0243\n",
      "Epoch 4/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0179\n",
      "Epoch 4: val_loss improved from 0.10305 to 0.09774, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1033 - mean_squared_error: 0.0179 - val_loss: 0.0977 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0993 - mean_squared_error: 0.0165\n",
      "Epoch 5: val_loss improved from 0.09774 to 0.09497, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0993 - mean_squared_error: 0.0165 - val_loss: 0.0950 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0951 - mean_squared_error: 0.0151\n",
      "Epoch 6: val_loss improved from 0.09497 to 0.09349, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0952 - mean_squared_error: 0.0151 - val_loss: 0.0935 - val_mean_squared_error: 0.0148\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.0145\n",
      "Epoch 7: val_loss improved from 0.09349 to 0.08879, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0928 - mean_squared_error: 0.0145 - val_loss: 0.0888 - val_mean_squared_error: 0.0128\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0887 - mean_squared_error: 0.0133\n",
      "Epoch 8: val_loss did not improve from 0.08879\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0887 - mean_squared_error: 0.0133 - val_loss: 0.0919 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.0129\n",
      "Epoch 9: val_loss improved from 0.08879 to 0.08768, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0876 - mean_squared_error: 0.0129 - val_loss: 0.0877 - val_mean_squared_error: 0.0126\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.0126\n",
      "Epoch 10: val_loss did not improve from 0.08768\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0861 - mean_squared_error: 0.0126 - val_loss: 0.0930 - val_mean_squared_error: 0.0147\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0845 - mean_squared_error: 0.0121\n",
      "Epoch 11: val_loss improved from 0.08768 to 0.08661, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0845 - mean_squared_error: 0.0121 - val_loss: 0.0866 - val_mean_squared_error: 0.0129\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0821 - mean_squared_error: 0.0114\n",
      "Epoch 12: val_loss improved from 0.08661 to 0.08520, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0821 - mean_squared_error: 0.0114 - val_loss: 0.0852 - val_mean_squared_error: 0.0123\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.0115\n",
      "Epoch 13: val_loss improved from 0.08520 to 0.08452, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0819 - mean_squared_error: 0.0115 - val_loss: 0.0845 - val_mean_squared_error: 0.0121\n",
      "Epoch 14/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0789 - mean_squared_error: 0.0107\n",
      "Epoch 14: val_loss did not improve from 0.08452\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0789 - mean_squared_error: 0.0106 - val_loss: 0.1240 - val_mean_squared_error: 0.0237\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0795 - mean_squared_error: 0.0108\n",
      "Epoch 15: val_loss did not improve from 0.08452\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0795 - mean_squared_error: 0.0108 - val_loss: 0.0899 - val_mean_squared_error: 0.0136\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0781 - mean_squared_error: 0.0105\n",
      "Epoch 16: val_loss did not improve from 0.08452\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0781 - mean_squared_error: 0.0105 - val_loss: 0.0863 - val_mean_squared_error: 0.0125\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1504 - mean_squared_error: 0.0385\n",
      "Epoch 1: val_loss improved from inf to 0.09937, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 5s 50ms/step - loss: 0.1504 - mean_squared_error: 0.0385 - val_loss: 0.0994 - val_mean_squared_error: 0.0160\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1154 - mean_squared_error: 0.0220\n",
      "Epoch 2: val_loss improved from 0.09937 to 0.09603, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1154 - mean_squared_error: 0.0220 - val_loss: 0.0960 - val_mean_squared_error: 0.0152\n",
      "Epoch 3/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0199\n",
      "Epoch 3: val_loss did not improve from 0.09603\n",
      "79/79 [==============================] - 3s 33ms/step - loss: 0.1101 - mean_squared_error: 0.0199 - val_loss: 0.0966 - val_mean_squared_error: 0.0151\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0190\n",
      "Epoch 4: val_loss improved from 0.09603 to 0.09479, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1066 - mean_squared_error: 0.0190 - val_loss: 0.0948 - val_mean_squared_error: 0.0151\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss did not improve from 0.09479\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1028 - mean_squared_error: 0.0176 - val_loss: 0.1143 - val_mean_squared_error: 0.0215\n",
      "Epoch 6/100\n",
      "77/79 [============================>.] - ETA: 0s - loss: 0.0980 - mean_squared_error: 0.0160\n",
      "Epoch 6: val_loss did not improve from 0.09479\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0979 - mean_squared_error: 0.0160 - val_loss: 0.1170 - val_mean_squared_error: 0.0231\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0938 - mean_squared_error: 0.0147\n",
      "Epoch 7: val_loss did not improve from 0.09479\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0938 - mean_squared_error: 0.0147 - val_loss: 0.1156 - val_mean_squared_error: 0.0222\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###1 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1540 - mean_squared_error: 0.0398\n",
      "Epoch 1: val_loss improved from inf to 0.09843, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 5s 47ms/step - loss: 0.1540 - mean_squared_error: 0.0398 - val_loss: 0.0984 - val_mean_squared_error: 0.0161\n",
      "Epoch 2/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1164 - mean_squared_error: 0.0223\n",
      "Epoch 2: val_loss improved from 0.09843 to 0.09655, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1163 - mean_squared_error: 0.0223 - val_loss: 0.0966 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0205\n",
      "Epoch 3: val_loss did not improve from 0.09655\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1116 - mean_squared_error: 0.0205 - val_loss: 0.0977 - val_mean_squared_error: 0.0155\n",
      "Epoch 4/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0193\n",
      "Epoch 4: val_loss did not improve from 0.09655\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.1082 - mean_squared_error: 0.0193 - val_loss: 0.0966 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "77/79 [============================>.] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0186\n",
      "Epoch 5: val_loss improved from 0.09655 to 0.09514, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1063 - mean_squared_error: 0.0186 - val_loss: 0.0951 - val_mean_squared_error: 0.0152\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1048 - mean_squared_error: 0.0180\n",
      "Epoch 6: val_loss improved from 0.09514 to 0.09487, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1048 - mean_squared_error: 0.0180 - val_loss: 0.0949 - val_mean_squared_error: 0.0151\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0179\n",
      "Epoch 7: val_loss did not improve from 0.09487\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1045 - mean_squared_error: 0.0179 - val_loss: 0.0956 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0172\n",
      "Epoch 8: val_loss did not improve from 0.09487\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1028 - mean_squared_error: 0.0172 - val_loss: 0.0958 - val_mean_squared_error: 0.0157\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.0170\n",
      "Epoch 9: val_loss improved from 0.09487 to 0.09475, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1016 - mean_squared_error: 0.0170 - val_loss: 0.0947 - val_mean_squared_error: 0.0150\n",
      "Epoch 10/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1024 - mean_squared_error: 0.0172\n",
      "Epoch 10: val_loss did not improve from 0.09475\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.1023 - mean_squared_error: 0.0172 - val_loss: 0.0951 - val_mean_squared_error: 0.0150\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0166\n",
      "Epoch 11: val_loss did not improve from 0.09475\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.1012 - mean_squared_error: 0.0166 - val_loss: 0.0951 - val_mean_squared_error: 0.0149\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0166\n",
      "Epoch 12: val_loss did not improve from 0.09475\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1011 - mean_squared_error: 0.0166 - val_loss: 0.0948 - val_mean_squared_error: 0.0151\n",
      "27/27 [==============================] - 2s 14ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "77/79 [============================>.] - ETA: 0s - loss: 0.1567 - mean_squared_error: 0.0409\n",
      "Epoch 1: val_loss improved from inf to 0.10389, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 5s 47ms/step - loss: 0.1559 - mean_squared_error: 0.0406 - val_loss: 0.1039 - val_mean_squared_error: 0.0171\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1162 - mean_squared_error: 0.0223\n",
      "Epoch 2: val_loss improved from 0.10389 to 0.09947, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1162 - mean_squared_error: 0.0223 - val_loss: 0.0995 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0201\n",
      "Epoch 3: val_loss improved from 0.09947 to 0.09796, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1103 - mean_squared_error: 0.0201 - val_loss: 0.0980 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0191\n",
      "Epoch 4: val_loss did not improve from 0.09796\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1074 - mean_squared_error: 0.0191 - val_loss: 0.0990 - val_mean_squared_error: 0.0163\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1057 - mean_squared_error: 0.0184\n",
      "Epoch 5: val_loss did not improve from 0.09796\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1057 - mean_squared_error: 0.0184 - val_loss: 0.0991 - val_mean_squared_error: 0.0157\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0177\n",
      "Epoch 6: val_loss improved from 0.09796 to 0.09767, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1035 - mean_squared_error: 0.0177 - val_loss: 0.0977 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0174\n",
      "Epoch 7: val_loss did not improve from 0.09767\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1030 - mean_squared_error: 0.0174 - val_loss: 0.0977 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0171\n",
      "Epoch 8: val_loss improved from 0.09767 to 0.09717, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride4_size15_pool5_do0.1_tra3_head4_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1015 - mean_squared_error: 0.0171 - val_loss: 0.0972 - val_mean_squared_error: 0.0155\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0168\n",
      "Epoch 9: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1007 - mean_squared_error: 0.0168 - val_loss: 0.0976 - val_mean_squared_error: 0.0158\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0167\n",
      "Epoch 10: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1006 - mean_squared_error: 0.0167 - val_loss: 0.0974 - val_mean_squared_error: 0.0156\n",
      "Epoch 11/100\n",
      "77/79 [============================>.] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0166\n",
      "Epoch 11: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1002 - mean_squared_error: 0.0166 - val_loss: 0.0979 - val_mean_squared_error: 0.0155\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.30+-0.58\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2255 - mean_squared_error: 0.0769\n",
      "Epoch 1: val_loss improved from inf to 0.12201, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 16s 38ms/step - loss: 0.2255 - mean_squared_error: 0.0769 - val_loss: 0.1220 - val_mean_squared_error: 0.0245\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1714 - mean_squared_error: 0.0469\n",
      "Epoch 2: val_loss improved from 0.12201 to 0.10251, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1713 - mean_squared_error: 0.0469 - val_loss: 0.1025 - val_mean_squared_error: 0.0172\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1318 - mean_squared_error: 0.0283\n",
      "Epoch 3: val_loss did not improve from 0.10251\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1318 - mean_squared_error: 0.0283 - val_loss: 0.1032 - val_mean_squared_error: 0.0177\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1161 - mean_squared_error: 0.0223\n",
      "Epoch 4: val_loss improved from 0.10251 to 0.10245, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1161 - mean_squared_error: 0.0223 - val_loss: 0.1024 - val_mean_squared_error: 0.0168\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1111 - mean_squared_error: 0.0202\n",
      "Epoch 5: val_loss improved from 0.10245 to 0.10128, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1111 - mean_squared_error: 0.0202 - val_loss: 0.1013 - val_mean_squared_error: 0.0165\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0187\n",
      "Epoch 6: val_loss improved from 0.10128 to 0.09902, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1072 - mean_squared_error: 0.0188 - val_loss: 0.0990 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0175\n",
      "Epoch 7: val_loss did not improve from 0.09902\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1039 - mean_squared_error: 0.0176 - val_loss: 0.1159 - val_mean_squared_error: 0.0196\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0169\n",
      "Epoch 8: val_loss improved from 0.09902 to 0.09249, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1015 - mean_squared_error: 0.0169 - val_loss: 0.0925 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0985 - mean_squared_error: 0.0160\n",
      "Epoch 9: val_loss did not improve from 0.09249\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0985 - mean_squared_error: 0.0160 - val_loss: 0.0928 - val_mean_squared_error: 0.0143\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0966 - mean_squared_error: 0.0155\n",
      "Epoch 10: val_loss did not improve from 0.09249\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0966 - mean_squared_error: 0.0154 - val_loss: 0.0958 - val_mean_squared_error: 0.0153\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0961 - mean_squared_error: 0.0152\n",
      "Epoch 11: val_loss improved from 0.09249 to 0.09239, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0961 - mean_squared_error: 0.0152 - val_loss: 0.0924 - val_mean_squared_error: 0.0135\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0150\n",
      "Epoch 12: val_loss improved from 0.09239 to 0.09203, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0953 - mean_squared_error: 0.0150 - val_loss: 0.0920 - val_mean_squared_error: 0.0143\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0938 - mean_squared_error: 0.0145\n",
      "Epoch 13: val_loss did not improve from 0.09203\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0938 - mean_squared_error: 0.0145 - val_loss: 0.1125 - val_mean_squared_error: 0.0193\n",
      "Epoch 14/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0924 - mean_squared_error: 0.0142\n",
      "Epoch 14: val_loss improved from 0.09203 to 0.08885, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0925 - mean_squared_error: 0.0142 - val_loss: 0.0888 - val_mean_squared_error: 0.0131\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0141\n",
      "Epoch 15: val_loss did not improve from 0.08885\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0917 - mean_squared_error: 0.0141 - val_loss: 0.0904 - val_mean_squared_error: 0.0138\n",
      "Epoch 16/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0140\n",
      "Epoch 16: val_loss did not improve from 0.08885\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0916 - mean_squared_error: 0.0141 - val_loss: 0.0910 - val_mean_squared_error: 0.0135\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0907 - mean_squared_error: 0.0138\n",
      "Epoch 17: val_loss did not improve from 0.08885\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0907 - mean_squared_error: 0.0138 - val_loss: 0.1029 - val_mean_squared_error: 0.0172\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2295 - mean_squared_error: 0.0794\n",
      "Epoch 1: val_loss improved from inf to 0.11647, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 38ms/step - loss: 0.2295 - mean_squared_error: 0.0794 - val_loss: 0.1165 - val_mean_squared_error: 0.0224\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1687 - mean_squared_error: 0.0462\n",
      "Epoch 2: val_loss improved from 0.11647 to 0.10318, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1688 - mean_squared_error: 0.0462 - val_loss: 0.1032 - val_mean_squared_error: 0.0176\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1360 - mean_squared_error: 0.0304\n",
      "Epoch 3: val_loss improved from 0.10318 to 0.09913, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1360 - mean_squared_error: 0.0304 - val_loss: 0.0991 - val_mean_squared_error: 0.0163\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1184 - mean_squared_error: 0.0231\n",
      "Epoch 4: val_loss improved from 0.09913 to 0.09879, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1184 - mean_squared_error: 0.0231 - val_loss: 0.0988 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss did not improve from 0.09879\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1125 - mean_squared_error: 0.0206 - val_loss: 0.0993 - val_mean_squared_error: 0.0163\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1108 - mean_squared_error: 0.0201\n",
      "Epoch 6: val_loss did not improve from 0.09879\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1108 - mean_squared_error: 0.0201 - val_loss: 0.0990 - val_mean_squared_error: 0.0162\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1088 - mean_squared_error: 0.0194\n",
      "Epoch 7: val_loss did not improve from 0.09879\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1089 - mean_squared_error: 0.0194 - val_loss: 0.1000 - val_mean_squared_error: 0.0165\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2262 - mean_squared_error: 0.0778\n",
      "Epoch 1: val_loss improved from inf to 0.12728, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.2262 - mean_squared_error: 0.0778 - val_loss: 0.1273 - val_mean_squared_error: 0.0268\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1654 - mean_squared_error: 0.0444\n",
      "Epoch 2: val_loss improved from 0.12728 to 0.10051, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1654 - mean_squared_error: 0.0444 - val_loss: 0.1005 - val_mean_squared_error: 0.0171\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1281 - mean_squared_error: 0.0270\n",
      "Epoch 3: val_loss improved from 0.10051 to 0.09887, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1281 - mean_squared_error: 0.0270 - val_loss: 0.0989 - val_mean_squared_error: 0.0162\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1160 - mean_squared_error: 0.0217\n",
      "Epoch 4: val_loss did not improve from 0.09887\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1160 - mean_squared_error: 0.0217 - val_loss: 0.1002 - val_mean_squared_error: 0.0166\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1112 - mean_squared_error: 0.0202\n",
      "Epoch 5: val_loss did not improve from 0.09887\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1111 - mean_squared_error: 0.0201 - val_loss: 0.1010 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0197\n",
      "Epoch 6: val_loss did not improve from 0.09887\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1098 - mean_squared_error: 0.0197 - val_loss: 0.1007 - val_mean_squared_error: 0.0167\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2253 - mean_squared_error: 0.0766\n",
      "Epoch 1: val_loss improved from inf to 0.11148, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 9s 45ms/step - loss: 0.2253 - mean_squared_error: 0.0766 - val_loss: 0.1115 - val_mean_squared_error: 0.0212\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1652 - mean_squared_error: 0.0445\n",
      "Epoch 2: val_loss improved from 0.11148 to 0.10392, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1652 - mean_squared_error: 0.0445 - val_loss: 0.1039 - val_mean_squared_error: 0.0171\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1285 - mean_squared_error: 0.0274\n",
      "Epoch 3: val_loss improved from 0.10392 to 0.10262, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1285 - mean_squared_error: 0.0274 - val_loss: 0.1026 - val_mean_squared_error: 0.0173\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1157 - mean_squared_error: 0.0217\n",
      "Epoch 4: val_loss improved from 0.10262 to 0.10233, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1157 - mean_squared_error: 0.0217 - val_loss: 0.1023 - val_mean_squared_error: 0.0168\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0201\n",
      "Epoch 5: val_loss improved from 0.10233 to 0.10219, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1110 - mean_squared_error: 0.0201 - val_loss: 0.1022 - val_mean_squared_error: 0.0171\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.0195\n",
      "Epoch 6: val_loss improved from 0.10219 to 0.10164, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1093 - mean_squared_error: 0.0195 - val_loss: 0.1016 - val_mean_squared_error: 0.0169\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0191\n",
      "Epoch 7: val_loss improved from 0.10164 to 0.10157, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1077 - mean_squared_error: 0.0191 - val_loss: 0.1016 - val_mean_squared_error: 0.0168\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0192\n",
      "Epoch 8: val_loss did not improve from 0.10157\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1084 - mean_squared_error: 0.0192 - val_loss: 0.1016 - val_mean_squared_error: 0.0168\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0190\n",
      "Epoch 9: val_loss improved from 0.10157 to 0.10140, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1077 - mean_squared_error: 0.0190 - val_loss: 0.1014 - val_mean_squared_error: 0.0167\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0191\n",
      "Epoch 10: val_loss did not improve from 0.10140\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1081 - mean_squared_error: 0.0191 - val_loss: 0.1015 - val_mean_squared_error: 0.0167\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0192\n",
      "Epoch 11: val_loss improved from 0.10140 to 0.10133, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1078 - mean_squared_error: 0.0192 - val_loss: 0.1013 - val_mean_squared_error: 0.0167\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0189\n",
      "Epoch 12: val_loss improved from 0.10133 to 0.10098, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1075 - mean_squared_error: 0.0189 - val_loss: 0.1010 - val_mean_squared_error: 0.0168\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 13: val_loss improved from 0.10098 to 0.10049, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt64_stride5_size11_pool4_do0.5_tra3_head4_kdim16_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1073 - mean_squared_error: 0.0190 - val_loss: 0.1005 - val_mean_squared_error: 0.0165\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0188\n",
      "Epoch 14: val_loss did not improve from 0.10049\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1071 - mean_squared_error: 0.0188 - val_loss: 0.1015 - val_mean_squared_error: 0.0167\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0189\n",
      "Epoch 15: val_loss did not improve from 0.10049\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1071 - mean_squared_error: 0.0189 - val_loss: 0.1020 - val_mean_squared_error: 0.0168\n",
      "Epoch 16/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0189\n",
      "Epoch 16: val_loss did not improve from 0.10049\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1075 - mean_squared_error: 0.0189 - val_loss: 0.1016 - val_mean_squared_error: 0.0168\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.72+-0.55\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3808 - mean_squared_error: 0.1707\n",
      "Epoch 1: val_loss improved from inf to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 34s 137ms/step - loss: 0.3808 - mean_squared_error: 0.1707 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 2: val_loss improved from 0.38420 to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 3: val_loss did not improve from 0.38420\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 4: val_loss improved from 0.38420 to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 5: val_loss did not improve from 0.38420\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 6: val_loss improved from 0.38420 to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 7: val_loss improved from 0.38420 to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 132ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 8: val_loss improved from 0.38420 to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 9: val_loss improved from 0.38420 to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 134ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 10: val_loss improved from 0.38420 to 0.38414, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3841 - val_mean_squared_error: 0.1728\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3799 - mean_squared_error: 0.1698\n",
      "Epoch 11: val_loss improved from 0.38414 to 0.38411, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3841 - val_mean_squared_error: 0.1728\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.5131 - mean_squared_error: 0.3033\n",
      "Epoch 12: val_loss did not improve from 0.38411\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.5131 - mean_squared_error: 0.3033 - val_loss: 0.6161 - val_mean_squared_error: 0.4050\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6201 - mean_squared_error: 0.4101\n",
      "Epoch 13: val_loss did not improve from 0.38411\n",
      "157/157 [==============================] - 21s 134ms/step - loss: 0.6201 - mean_squared_error: 0.4101 - val_loss: 0.6161 - val_mean_squared_error: 0.4050\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.6201 - mean_squared_error: 0.4101\n",
      "Epoch 14: val_loss did not improve from 0.38411\n",
      "157/157 [==============================] - 21s 135ms/step - loss: 0.6201 - mean_squared_error: 0.4101 - val_loss: 0.6161 - val_mean_squared_error: 0.4050\n",
      "53/53 [==============================] - 4s 49ms/step\n",
      " ###0 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3814 - mean_squared_error: 0.1713\n",
      "Epoch 1: val_loss improved from inf to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 24s 137ms/step - loss: 0.3814 - mean_squared_error: 0.1713 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 2: val_loss did not improve from 0.38084\n",
      "157/157 [==============================] - 21s 132ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 3: val_loss did not improve from 0.38084\n",
      "157/157 [==============================] - 21s 132ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 4: val_loss did not improve from 0.38084\n",
      "157/157 [==============================] - 21s 132ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "53/53 [==============================] - 3s 47ms/step\n",
      " ###1 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3821 - mean_squared_error: 0.1715\n",
      "Epoch 1: val_loss improved from inf to 0.38053, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 23s 138ms/step - loss: 0.3821 - mean_squared_error: 0.1715 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 2: val_loss improved from 0.38053 to 0.38053, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 21s 132ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss improved from 0.38053 to 0.38053, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 4: val_loss improved from 0.38053 to 0.38053, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 5: val_loss did not improve from 0.38053\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 6: val_loss did not improve from 0.38053\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 7: val_loss did not improve from 0.38053\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "53/53 [==============================] - 3s 48ms/step\n",
      " ###2 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3826 - mean_squared_error: 0.1718\n",
      "Epoch 1: val_loss improved from inf to 0.37833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride2_size19_pool2_do0.1_tra4_head4_kdim256_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 23s 137ms/step - loss: 0.3826 - mean_squared_error: 0.1718 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss did not improve from 0.37833\n",
      "157/157 [==============================] - 20s 130ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss did not improve from 0.37833\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 4: val_loss did not improve from 0.37833\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "53/53 [==============================] - 3s 48ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae38.15+-0.00\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2223 - mean_squared_error: 0.0768\n",
      "Epoch 1: val_loss improved from inf to 0.13673, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 16s 102ms/step - loss: 0.2223 - mean_squared_error: 0.0768 - val_loss: 0.1367 - val_mean_squared_error: 0.0295\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1580 - mean_squared_error: 0.0401\n",
      "Epoch 2: val_loss improved from 0.13673 to 0.11032, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1579 - mean_squared_error: 0.0400 - val_loss: 0.1103 - val_mean_squared_error: 0.0190\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1380 - mean_squared_error: 0.0312\n",
      "Epoch 3: val_loss improved from 0.11032 to 0.10444, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.1380 - mean_squared_error: 0.0312 - val_loss: 0.1044 - val_mean_squared_error: 0.0170\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1230 - mean_squared_error: 0.0252\n",
      "Epoch 4: val_loss improved from 0.10444 to 0.08884, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.1231 - mean_squared_error: 0.0252 - val_loss: 0.0888 - val_mean_squared_error: 0.0131\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0219\n",
      "Epoch 5: val_loss did not improve from 0.08884\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1145 - mean_squared_error: 0.0219 - val_loss: 0.0979 - val_mean_squared_error: 0.0157\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0195\n",
      "Epoch 6: val_loss did not improve from 0.08884\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1083 - mean_squared_error: 0.0195 - val_loss: 0.1147 - val_mean_squared_error: 0.0215\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0182\n",
      "Epoch 7: val_loss did not improve from 0.08884\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1041 - mean_squared_error: 0.0182 - val_loss: 0.0980 - val_mean_squared_error: 0.0158\n",
      "14/14 [==============================] - 2s 31ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2212 - mean_squared_error: 0.0761\n",
      "Epoch 1: val_loss improved from inf to 0.11149, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 5s 80ms/step - loss: 0.2212 - mean_squared_error: 0.0761 - val_loss: 0.1115 - val_mean_squared_error: 0.0205\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1522 - mean_squared_error: 0.0372\n",
      "Epoch 2: val_loss improved from 0.11149 to 0.09670, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1522 - mean_squared_error: 0.0372 - val_loss: 0.0967 - val_mean_squared_error: 0.0153\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1333 - mean_squared_error: 0.0292\n",
      "Epoch 3: val_loss did not improve from 0.09670\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1333 - mean_squared_error: 0.0292 - val_loss: 0.1219 - val_mean_squared_error: 0.0225\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1220 - mean_squared_error: 0.0246\n",
      "Epoch 4: val_loss did not improve from 0.09670\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1219 - mean_squared_error: 0.0246 - val_loss: 0.1932 - val_mean_squared_error: 0.0496\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1147 - mean_squared_error: 0.0218\n",
      "Epoch 5: val_loss did not improve from 0.09670\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1145 - mean_squared_error: 0.0217 - val_loss: 0.1596 - val_mean_squared_error: 0.0358\n",
      "14/14 [==============================] - 1s 31ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2320 - mean_squared_error: 0.0827\n",
      "Epoch 1: val_loss improved from inf to 0.13112, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 6s 93ms/step - loss: 0.2320 - mean_squared_error: 0.0827 - val_loss: 0.1311 - val_mean_squared_error: 0.0276\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1532 - mean_squared_error: 0.0379\n",
      "Epoch 2: val_loss improved from 0.13112 to 0.10075, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.1532 - mean_squared_error: 0.0379 - val_loss: 0.1007 - val_mean_squared_error: 0.0165\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1345 - mean_squared_error: 0.0295\n",
      "Epoch 3: val_loss did not improve from 0.10075\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1345 - mean_squared_error: 0.0295 - val_loss: 0.1154 - val_mean_squared_error: 0.0200\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1230 - mean_squared_error: 0.0250\n",
      "Epoch 4: val_loss improved from 0.10075 to 0.09521, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1229 - mean_squared_error: 0.0249 - val_loss: 0.0952 - val_mean_squared_error: 0.0146\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1150 - mean_squared_error: 0.0217\n",
      "Epoch 5: val_loss did not improve from 0.09521\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1150 - mean_squared_error: 0.0217 - val_loss: 0.1153 - val_mean_squared_error: 0.0205\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0189\n",
      "Epoch 6: val_loss did not improve from 0.09521\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1066 - mean_squared_error: 0.0188 - val_loss: 0.1026 - val_mean_squared_error: 0.0174\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0177\n",
      "Epoch 7: val_loss improved from 0.09521 to 0.09212, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.1034 - mean_squared_error: 0.0177 - val_loss: 0.0921 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0997 - mean_squared_error: 0.0164\n",
      "Epoch 8: val_loss improved from 0.09212 to 0.08874, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.0997 - mean_squared_error: 0.0164 - val_loss: 0.0887 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0151\n",
      "Epoch 9: val_loss improved from 0.08874 to 0.08626, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.0952 - mean_squared_error: 0.0150 - val_loss: 0.0863 - val_mean_squared_error: 0.0129\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.0140\n",
      "Epoch 10: val_loss improved from 0.08626 to 0.08514, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0921 - mean_squared_error: 0.0141 - val_loss: 0.0851 - val_mean_squared_error: 0.0121\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.0139\n",
      "Epoch 11: val_loss did not improve from 0.08514\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0914 - mean_squared_error: 0.0139 - val_loss: 0.0907 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.0128\n",
      "Epoch 12: val_loss did not improve from 0.08514\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0877 - mean_squared_error: 0.0128 - val_loss: 0.0866 - val_mean_squared_error: 0.0126\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0837 - mean_squared_error: 0.0119\n",
      "Epoch 13: val_loss did not improve from 0.08514\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0837 - mean_squared_error: 0.0119 - val_loss: 0.0935 - val_mean_squared_error: 0.0151\n",
      "14/14 [==============================] - 1s 29ms/step\n",
      " ###2 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2276 - mean_squared_error: 0.0805\n",
      "Epoch 1: val_loss improved from inf to 0.11395, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 99ms/step - loss: 0.2276 - mean_squared_error: 0.0805 - val_loss: 0.1140 - val_mean_squared_error: 0.0210\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1493 - mean_squared_error: 0.0363\n",
      "Epoch 2: val_loss improved from 0.11395 to 0.09985, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1493 - mean_squared_error: 0.0363 - val_loss: 0.0999 - val_mean_squared_error: 0.0164\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1324 - mean_squared_error: 0.0287\n",
      "Epoch 3: val_loss did not improve from 0.09985\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1324 - mean_squared_error: 0.0287 - val_loss: 0.1002 - val_mean_squared_error: 0.0160\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1238 - mean_squared_error: 0.0251\n",
      "Epoch 4: val_loss did not improve from 0.09985\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1238 - mean_squared_error: 0.0251 - val_loss: 0.1000 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1218 - mean_squared_error: 0.0243\n",
      "Epoch 5: val_loss improved from 0.09985 to 0.09931, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1218 - mean_squared_error: 0.0243 - val_loss: 0.0993 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1156 - mean_squared_error: 0.0220\n",
      "Epoch 6: val_loss improved from 0.09931 to 0.09828, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.1155 - mean_squared_error: 0.0219 - val_loss: 0.0983 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1136 - mean_squared_error: 0.0211\n",
      "Epoch 7: val_loss did not improve from 0.09828\n",
      "40/40 [==============================] - 3s 62ms/step - loss: 0.1136 - mean_squared_error: 0.0211 - val_loss: 0.0984 - val_mean_squared_error: 0.0158\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0204\n",
      "Epoch 8: val_loss improved from 0.09828 to 0.09815, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.1109 - mean_squared_error: 0.0204 - val_loss: 0.0982 - val_mean_squared_error: 0.0158\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1091 - mean_squared_error: 0.0196\n",
      "Epoch 9: val_loss did not improve from 0.09815\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1091 - mean_squared_error: 0.0196 - val_loss: 0.0984 - val_mean_squared_error: 0.0159\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0189\n",
      "Epoch 10: val_loss improved from 0.09815 to 0.09752, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride4_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1074 - mean_squared_error: 0.0189 - val_loss: 0.0975 - val_mean_squared_error: 0.0157\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0186\n",
      "Epoch 11: val_loss did not improve from 0.09752\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1066 - mean_squared_error: 0.0186 - val_loss: 0.0979 - val_mean_squared_error: 0.0155\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1057 - mean_squared_error: 0.0183\n",
      "Epoch 12: val_loss did not improve from 0.09752\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1057 - mean_squared_error: 0.0183 - val_loss: 0.0980 - val_mean_squared_error: 0.0154\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0181\n",
      "Epoch 13: val_loss did not improve from 0.09752\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1043 - mean_squared_error: 0.0181 - val_loss: 0.0977 - val_mean_squared_error: 0.0154\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.24+-0.55\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1354 - mean_squared_error: 0.0321\n",
      "Epoch 1: val_loss improved from inf to 0.10881, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 20s 47ms/step - loss: 0.1354 - mean_squared_error: 0.0321 - val_loss: 0.1088 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1126 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10881 to 0.10443, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1126 - mean_squared_error: 0.0210 - val_loss: 0.1044 - val_mean_squared_error: 0.0182\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1095 - mean_squared_error: 0.0197\n",
      "Epoch 3: val_loss did not improve from 0.10443\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1095 - mean_squared_error: 0.0197 - val_loss: 0.1061 - val_mean_squared_error: 0.0186\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0187\n",
      "Epoch 4: val_loss did not improve from 0.10443\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1060 - mean_squared_error: 0.0187 - val_loss: 0.1172 - val_mean_squared_error: 0.0227\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0179\n",
      "Epoch 5: val_loss improved from 0.10443 to 0.10397, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1039 - mean_squared_error: 0.0179 - val_loss: 0.1040 - val_mean_squared_error: 0.0183\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0177\n",
      "Epoch 6: val_loss improved from 0.10397 to 0.09983, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1032 - mean_squared_error: 0.0177 - val_loss: 0.0998 - val_mean_squared_error: 0.0163\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0170\n",
      "Epoch 7: val_loss improved from 0.09983 to 0.09886, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1013 - mean_squared_error: 0.0170 - val_loss: 0.0989 - val_mean_squared_error: 0.0159\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0167\n",
      "Epoch 8: val_loss improved from 0.09886 to 0.09822, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1008 - mean_squared_error: 0.0167 - val_loss: 0.0982 - val_mean_squared_error: 0.0155\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0168\n",
      "Epoch 9: val_loss did not improve from 0.09822\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1006 - mean_squared_error: 0.0168 - val_loss: 0.0990 - val_mean_squared_error: 0.0155\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1000 - mean_squared_error: 0.0164\n",
      "Epoch 10: val_loss did not improve from 0.09822\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1000 - mean_squared_error: 0.0164 - val_loss: 0.0995 - val_mean_squared_error: 0.0156\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0985 - mean_squared_error: 0.0160\n",
      "Epoch 11: val_loss improved from 0.09822 to 0.09734, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0985 - mean_squared_error: 0.0160 - val_loss: 0.0973 - val_mean_squared_error: 0.0155\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.0163\n",
      "Epoch 12: val_loss did not improve from 0.09734\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0990 - mean_squared_error: 0.0163 - val_loss: 0.0985 - val_mean_squared_error: 0.0154\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0989 - mean_squared_error: 0.0161\n",
      "Epoch 13: val_loss did not improve from 0.09734\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0989 - mean_squared_error: 0.0161 - val_loss: 0.0984 - val_mean_squared_error: 0.0153\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0161\n",
      "Epoch 14: val_loss did not improve from 0.09734\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.0987 - mean_squared_error: 0.0161 - val_loss: 0.0991 - val_mean_squared_error: 0.0156\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1353 - mean_squared_error: 0.0318\n",
      "Epoch 1: val_loss improved from inf to 0.10380, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 9s 46ms/step - loss: 0.1353 - mean_squared_error: 0.0318 - val_loss: 0.1038 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1106 - mean_squared_error: 0.0202\n",
      "Epoch 2: val_loss did not improve from 0.10380\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1106 - mean_squared_error: 0.0202 - val_loss: 0.1476 - val_mean_squared_error: 0.0332\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0188\n",
      "Epoch 3: val_loss did not improve from 0.10380\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1064 - mean_squared_error: 0.0188 - val_loss: 0.1512 - val_mean_squared_error: 0.0347\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0178\n",
      "Epoch 4: val_loss did not improve from 0.10380\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1037 - mean_squared_error: 0.0178 - val_loss: 0.1198 - val_mean_squared_error: 0.0233\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1351 - mean_squared_error: 0.0313\n",
      "Epoch 1: val_loss improved from inf to 0.12144, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 9s 48ms/step - loss: 0.1351 - mean_squared_error: 0.0313 - val_loss: 0.1214 - val_mean_squared_error: 0.0224\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1130 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.12144 to 0.09696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1130 - mean_squared_error: 0.0211 - val_loss: 0.0970 - val_mean_squared_error: 0.0162\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0191\n",
      "Epoch 3: val_loss did not improve from 0.09696\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1074 - mean_squared_error: 0.0191 - val_loss: 0.0987 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0179\n",
      "Epoch 4: val_loss did not improve from 0.09696\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1046 - mean_squared_error: 0.0179 - val_loss: 0.1085 - val_mean_squared_error: 0.0180\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0175\n",
      "Epoch 5: val_loss did not improve from 0.09696\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1035 - mean_squared_error: 0.0175 - val_loss: 0.0984 - val_mean_squared_error: 0.0156\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1359 - mean_squared_error: 0.0311\n",
      "Epoch 1: val_loss improved from inf to 0.14105, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 9s 47ms/step - loss: 0.1359 - mean_squared_error: 0.0311 - val_loss: 0.1411 - val_mean_squared_error: 0.0300\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1112 - mean_squared_error: 0.0205\n",
      "Epoch 2: val_loss improved from 0.14105 to 0.13310, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size19_pool2_do0.1_tra5_head4_kdim64_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1112 - mean_squared_error: 0.0205 - val_loss: 0.1331 - val_mean_squared_error: 0.0262\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0194\n",
      "Epoch 3: val_loss did not improve from 0.13310\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1079 - mean_squared_error: 0.0194 - val_loss: 0.1452 - val_mean_squared_error: 0.0305\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0178\n",
      "Epoch 4: val_loss did not improve from 0.13310\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1034 - mean_squared_error: 0.0178 - val_loss: 0.1538 - val_mean_squared_error: 0.0332\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss did not improve from 0.13310\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1031 - mean_squared_error: 0.0176 - val_loss: 0.1375 - val_mean_squared_error: 0.0272\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###3 fold : val mae 0.13###\n",
      "mae10.79+-1.39\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2050 - mean_squared_error: 0.0690\n",
      "Epoch 1: val_loss improved from inf to 0.22236, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 18s 44ms/step - loss: 0.2048 - mean_squared_error: 0.0689 - val_loss: 0.2224 - val_mean_squared_error: 0.0635\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1214 - mean_squared_error: 0.0245\n",
      "Epoch 2: val_loss improved from 0.22236 to 0.12477, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1214 - mean_squared_error: 0.0245 - val_loss: 0.1248 - val_mean_squared_error: 0.0232\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0204\n",
      "Epoch 3: val_loss improved from 0.12477 to 0.10232, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1110 - mean_squared_error: 0.0204 - val_loss: 0.1023 - val_mean_squared_error: 0.0163\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0194\n",
      "Epoch 4: val_loss did not improve from 0.10232\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1086 - mean_squared_error: 0.0194 - val_loss: 0.1024 - val_mean_squared_error: 0.0164\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0184\n",
      "Epoch 5: val_loss did not improve from 0.10232\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1056 - mean_squared_error: 0.0184 - val_loss: 0.1051 - val_mean_squared_error: 0.0168\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0175\n",
      "Epoch 6: val_loss did not improve from 0.10232\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1029 - mean_squared_error: 0.0175 - val_loss: 0.1038 - val_mean_squared_error: 0.0166\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3812 - mean_squared_error: 0.1711\n",
      "Epoch 1: val_loss improved from inf to 0.38081, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.3812 - mean_squared_error: 0.1711 - val_loss: 0.3808 - val_mean_squared_error: 0.1696\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1709\n",
      "Epoch 2: val_loss improved from 0.38081 to 0.38032, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3811 - mean_squared_error: 0.1709 - val_loss: 0.3803 - val_mean_squared_error: 0.1695\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3794 - mean_squared_error: 0.1699\n",
      "Epoch 3: val_loss improved from 0.38032 to 0.36532, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.3794 - mean_squared_error: 0.1699 - val_loss: 0.3653 - val_mean_squared_error: 0.1588\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1709\n",
      "Epoch 4: val_loss did not improve from 0.36532\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.3810 - mean_squared_error: 0.1709 - val_loss: 0.3788 - val_mean_squared_error: 0.1682\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 5: val_loss did not improve from 0.36532\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3704 - val_mean_squared_error: 0.1622\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1709\n",
      "Epoch 6: val_loss improved from 0.36532 to 0.35111, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.3811 - mean_squared_error: 0.1709 - val_loss: 0.3511 - val_mean_squared_error: 0.1496\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2909 - mean_squared_error: 0.1180\n",
      "Epoch 7: val_loss improved from 0.35111 to 0.33384, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.2909 - mean_squared_error: 0.1180 - val_loss: 0.3338 - val_mean_squared_error: 0.1289\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1185 - mean_squared_error: 0.0232\n",
      "Epoch 8: val_loss improved from 0.33384 to 0.18118, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1185 - mean_squared_error: 0.0232 - val_loss: 0.1812 - val_mean_squared_error: 0.0443\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0189\n",
      "Epoch 9: val_loss improved from 0.18118 to 0.12427, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1068 - mean_squared_error: 0.0189 - val_loss: 0.1243 - val_mean_squared_error: 0.0230\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.0178\n",
      "Epoch 10: val_loss did not improve from 0.12427\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1044 - mean_squared_error: 0.0178 - val_loss: 0.1465 - val_mean_squared_error: 0.0306\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0175\n",
      "Epoch 11: val_loss improved from 0.12427 to 0.11778, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1029 - mean_squared_error: 0.0175 - val_loss: 0.1178 - val_mean_squared_error: 0.0210\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0171\n",
      "Epoch 12: val_loss did not improve from 0.11778\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1023 - mean_squared_error: 0.0171 - val_loss: 0.1470 - val_mean_squared_error: 0.0306\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0171\n",
      "Epoch 13: val_loss did not improve from 0.11778\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1023 - mean_squared_error: 0.0171 - val_loss: 0.1380 - val_mean_squared_error: 0.0270\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0170\n",
      "Epoch 14: val_loss did not improve from 0.11778\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1014 - mean_squared_error: 0.0170 - val_loss: 0.1351 - val_mean_squared_error: 0.0265\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###1 fold : val mae 0.12###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3817 - mean_squared_error: 0.1713\n",
      "Epoch 1: val_loss improved from inf to 0.38053, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.3817 - mean_squared_error: 0.1713 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 2: val_loss did not improve from 0.38053\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss did not improve from 0.38053\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 4: val_loss did not improve from 0.38053\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###2 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3824 - mean_squared_error: 0.1716\n",
      "Epoch 1: val_loss improved from inf to 0.37839, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size7_pool5_do0.2_tra4_head4_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.3824 - mean_squared_error: 0.1716 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss did not improve from 0.37839\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss did not improve from 0.37839\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 4: val_loss did not improve from 0.37839\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae24.70+-13.47\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3798 - mean_squared_error: 0.1699\n",
      "Epoch 1: val_loss improved from inf to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 14s 49ms/step - loss: 0.3798 - mean_squared_error: 0.1699 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 2/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.3798 - mean_squared_error: 0.1697\n",
      "Epoch 2: val_loss did not improve from 0.38420\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.3799 - mean_squared_error: 0.1698 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.4598 - mean_squared_error: 0.2499\n",
      "Epoch 3: val_loss did not improve from 0.38420\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.4598 - mean_squared_error: 0.2499 - val_loss: 0.6160 - val_mean_squared_error: 0.4049\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2965 - mean_squared_error: 0.1335\n",
      "Epoch 4: val_loss improved from 0.38420 to 0.10348, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.2965 - mean_squared_error: 0.1335 - val_loss: 0.1035 - val_mean_squared_error: 0.0178\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1254 - mean_squared_error: 0.0257\n",
      "Epoch 5: val_loss improved from 0.10348 to 0.10201, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1254 - mean_squared_error: 0.0257 - val_loss: 0.1020 - val_mean_squared_error: 0.0175\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0205\n",
      "Epoch 6: val_loss did not improve from 0.10201\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1125 - mean_squared_error: 0.0205 - val_loss: 0.1033 - val_mean_squared_error: 0.0179\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0187\n",
      "Epoch 7: val_loss did not improve from 0.10201\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1067 - mean_squared_error: 0.0187 - val_loss: 0.1054 - val_mean_squared_error: 0.0187\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0180\n",
      "Epoch 8: val_loss improved from 0.10201 to 0.09811, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1050 - mean_squared_error: 0.0180 - val_loss: 0.0981 - val_mean_squared_error: 0.0156\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0175\n",
      "Epoch 9: val_loss did not improve from 0.09811\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1036 - mean_squared_error: 0.0175 - val_loss: 0.0989 - val_mean_squared_error: 0.0161\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0175\n",
      "Epoch 10: val_loss did not improve from 0.09811\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1037 - mean_squared_error: 0.0175 - val_loss: 0.0983 - val_mean_squared_error: 0.0156\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0171\n",
      "Epoch 11: val_loss did not improve from 0.09811\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1020 - mean_squared_error: 0.0171 - val_loss: 0.0988 - val_mean_squared_error: 0.0161\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1711\n",
      "Epoch 1: val_loss improved from inf to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 6s 55ms/step - loss: 0.3810 - mean_squared_error: 0.1711 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 2: val_loss improved from 0.38084 to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 3: val_loss improved from 0.38084 to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3151 - mean_squared_error: 0.1310\n",
      "Epoch 4: val_loss improved from 0.38084 to 0.11674, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.3151 - mean_squared_error: 0.1310 - val_loss: 0.1167 - val_mean_squared_error: 0.0223\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1394 - mean_squared_error: 0.0313\n",
      "Epoch 5: val_loss improved from 0.11674 to 0.11411, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1394 - mean_squared_error: 0.0313 - val_loss: 0.1141 - val_mean_squared_error: 0.0198\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1232 - mean_squared_error: 0.0248\n",
      "Epoch 6: val_loss improved from 0.11411 to 0.11019, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1232 - mean_squared_error: 0.0248 - val_loss: 0.1102 - val_mean_squared_error: 0.0203\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.0205\n",
      "Epoch 7: val_loss improved from 0.11019 to 0.09890, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1124 - mean_squared_error: 0.0205 - val_loss: 0.0989 - val_mean_squared_error: 0.0162\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0187\n",
      "Epoch 8: val_loss improved from 0.09890 to 0.09619, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1070 - mean_squared_error: 0.0187 - val_loss: 0.0962 - val_mean_squared_error: 0.0151\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0182\n",
      "Epoch 9: val_loss did not improve from 0.09619\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1056 - mean_squared_error: 0.0182 - val_loss: 0.0990 - val_mean_squared_error: 0.0163\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0175\n",
      "Epoch 10: val_loss did not improve from 0.09619\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1031 - mean_squared_error: 0.0175 - val_loss: 0.0963 - val_mean_squared_error: 0.0153\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0176\n",
      "Epoch 11: val_loss did not improve from 0.09619\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1038 - mean_squared_error: 0.0176 - val_loss: 0.0991 - val_mean_squared_error: 0.0164\n",
      "27/27 [==============================] - 2s 18ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3813 - mean_squared_error: 0.1711\n",
      "Epoch 1: val_loss improved from inf to 0.38054, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 6s 55ms/step - loss: 0.3813 - mean_squared_error: 0.1711 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 2: val_loss did not improve from 0.38054\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss did not improve from 0.38054\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 4: val_loss did not improve from 0.38054\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "27/27 [==============================] - 2s 17ms/step\n",
      " ###2 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3820 - mean_squared_error: 0.1714\n",
      "Epoch 1: val_loss improved from inf to 0.37833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 5s 48ms/step - loss: 0.3820 - mean_squared_error: 0.1714 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss improved from 0.37833 to 0.37833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss improved from 0.37833 to 0.37832, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride4_size7_pool4_do0.2_tra3_head4_kdim256_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3843 - mean_squared_error: 0.1734\n",
      "Epoch 4: val_loss did not improve from 0.37832\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.3843 - mean_squared_error: 0.1734 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 5: val_loss did not improve from 0.37832\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3818 - mean_squared_error: 0.1710\n",
      "Epoch 6: val_loss did not improve from 0.37832\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.3818 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae23.97+-14.18\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1446 - mean_squared_error: 0.0355\n",
      "Epoch 1: val_loss improved from inf to 0.09744, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 17s 120ms/step - loss: 0.1446 - mean_squared_error: 0.0355 - val_loss: 0.0974 - val_mean_squared_error: 0.0156\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0208\n",
      "Epoch 2: val_loss improved from 0.09744 to 0.09525, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1119 - mean_squared_error: 0.0207 - val_loss: 0.0952 - val_mean_squared_error: 0.0152\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0182\n",
      "Epoch 3: val_loss did not improve from 0.09525\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.1043 - mean_squared_error: 0.0182 - val_loss: 0.1004 - val_mean_squared_error: 0.0171\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0164\n",
      "Epoch 4: val_loss improved from 0.09525 to 0.09066, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.0987 - mean_squared_error: 0.0164 - val_loss: 0.0907 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.0155\n",
      "Epoch 5: val_loss improved from 0.09066 to 0.08640, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.0959 - mean_squared_error: 0.0155 - val_loss: 0.0864 - val_mean_squared_error: 0.0124\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.0148\n",
      "Epoch 6: val_loss did not improve from 0.08640\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0936 - mean_squared_error: 0.0148 - val_loss: 0.0870 - val_mean_squared_error: 0.0126\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0900 - mean_squared_error: 0.0138\n",
      "Epoch 7: val_loss improved from 0.08640 to 0.08561, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.0900 - mean_squared_error: 0.0138 - val_loss: 0.0856 - val_mean_squared_error: 0.0125\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.0129\n",
      "Epoch 8: val_loss improved from 0.08561 to 0.08401, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.0876 - mean_squared_error: 0.0129 - val_loss: 0.0840 - val_mean_squared_error: 0.0117\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0849 - mean_squared_error: 0.0123\n",
      "Epoch 9: val_loss did not improve from 0.08401\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.0848 - mean_squared_error: 0.0122 - val_loss: 0.0969 - val_mean_squared_error: 0.0158\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0815 - mean_squared_error: 0.0114\n",
      "Epoch 10: val_loss did not improve from 0.08401\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.0815 - mean_squared_error: 0.0114 - val_loss: 0.0914 - val_mean_squared_error: 0.0130\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0793 - mean_squared_error: 0.0108\n",
      "Epoch 11: val_loss did not improve from 0.08401\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0792 - mean_squared_error: 0.0108 - val_loss: 0.1138 - val_mean_squared_error: 0.0217\n",
      "14/14 [==============================] - 2s 31ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1461 - mean_squared_error: 0.0366\n",
      "Epoch 1: val_loss improved from inf to 0.10081, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 6s 100ms/step - loss: 0.1460 - mean_squared_error: 0.0365 - val_loss: 0.1008 - val_mean_squared_error: 0.0167\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1136 - mean_squared_error: 0.0214\n",
      "Epoch 2: val_loss improved from 0.10081 to 0.09385, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1136 - mean_squared_error: 0.0214 - val_loss: 0.0938 - val_mean_squared_error: 0.0145\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1052 - mean_squared_error: 0.0182\n",
      "Epoch 3: val_loss improved from 0.09385 to 0.09227, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.1051 - mean_squared_error: 0.0182 - val_loss: 0.0923 - val_mean_squared_error: 0.0140\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1019 - mean_squared_error: 0.0174\n",
      "Epoch 4: val_loss improved from 0.09227 to 0.09102, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1019 - mean_squared_error: 0.0174 - val_loss: 0.0910 - val_mean_squared_error: 0.0139\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0973 - mean_squared_error: 0.0159\n",
      "Epoch 5: val_loss improved from 0.09102 to 0.08645, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.0974 - mean_squared_error: 0.0159 - val_loss: 0.0865 - val_mean_squared_error: 0.0123\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0922 - mean_squared_error: 0.0143\n",
      "Epoch 6: val_loss did not improve from 0.08645\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0923 - mean_squared_error: 0.0144 - val_loss: 0.1108 - val_mean_squared_error: 0.0190\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0904 - mean_squared_error: 0.0139\n",
      "Epoch 7: val_loss did not improve from 0.08645\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.0904 - mean_squared_error: 0.0139 - val_loss: 0.0899 - val_mean_squared_error: 0.0134\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0894 - mean_squared_error: 0.0135\n",
      "Epoch 8: val_loss did not improve from 0.08645\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0895 - mean_squared_error: 0.0135 - val_loss: 0.0865 - val_mean_squared_error: 0.0121\n",
      "14/14 [==============================] - 1s 29ms/step\n",
      " ###1 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1491 - mean_squared_error: 0.0373\n",
      "Epoch 1: val_loss improved from inf to 0.10113, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 6s 98ms/step - loss: 0.1491 - mean_squared_error: 0.0373 - val_loss: 0.1011 - val_mean_squared_error: 0.0174\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1128 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10113 to 0.09067, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1128 - mean_squared_error: 0.0209 - val_loss: 0.0907 - val_mean_squared_error: 0.0141\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0183\n",
      "Epoch 3: val_loss did not improve from 0.09067\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1051 - mean_squared_error: 0.0183 - val_loss: 0.0963 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0999 - mean_squared_error: 0.0165\n",
      "Epoch 4: val_loss improved from 0.09067 to 0.08808, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.0998 - mean_squared_error: 0.0165 - val_loss: 0.0881 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0966 - mean_squared_error: 0.0156\n",
      "Epoch 5: val_loss did not improve from 0.08808\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0966 - mean_squared_error: 0.0156 - val_loss: 0.0945 - val_mean_squared_error: 0.0157\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0942 - mean_squared_error: 0.0148\n",
      "Epoch 6: val_loss did not improve from 0.08808\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0942 - mean_squared_error: 0.0148 - val_loss: 0.0939 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0908 - mean_squared_error: 0.0138\n",
      "Epoch 7: val_loss improved from 0.08808 to 0.08306, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0908 - mean_squared_error: 0.0138 - val_loss: 0.0831 - val_mean_squared_error: 0.0119\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0886 - mean_squared_error: 0.0133\n",
      "Epoch 8: val_loss did not improve from 0.08306\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.0886 - mean_squared_error: 0.0133 - val_loss: 0.0990 - val_mean_squared_error: 0.0156\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0856 - mean_squared_error: 0.0125\n",
      "Epoch 9: val_loss did not improve from 0.08306\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.0855 - mean_squared_error: 0.0125 - val_loss: 0.0841 - val_mean_squared_error: 0.0123\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.0115\n",
      "Epoch 10: val_loss did not improve from 0.08306\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0824 - mean_squared_error: 0.0115 - val_loss: 0.0832 - val_mean_squared_error: 0.0122\n",
      "14/14 [==============================] - 2s 32ms/step\n",
      " ###2 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1508 - mean_squared_error: 0.0387\n",
      "Epoch 1: val_loss improved from inf to 0.10384, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 103ms/step - loss: 0.1508 - mean_squared_error: 0.0387 - val_loss: 0.1038 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1131 - mean_squared_error: 0.0215\n",
      "Epoch 2: val_loss improved from 0.10384 to 0.09962, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1130 - mean_squared_error: 0.0215 - val_loss: 0.0996 - val_mean_squared_error: 0.0163\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0193\n",
      "Epoch 3: val_loss improved from 0.09962 to 0.09445, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1072 - mean_squared_error: 0.0193 - val_loss: 0.0945 - val_mean_squared_error: 0.0150\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0177\n",
      "Epoch 4: val_loss improved from 0.09445 to 0.09388, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1032 - mean_squared_error: 0.0177 - val_loss: 0.0939 - val_mean_squared_error: 0.0150\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0163\n",
      "Epoch 5: val_loss improved from 0.09388 to 0.08817, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0984 - mean_squared_error: 0.0163 - val_loss: 0.0882 - val_mean_squared_error: 0.0128\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.0155\n",
      "Epoch 6: val_loss did not improve from 0.08817\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0959 - mean_squared_error: 0.0155 - val_loss: 0.0884 - val_mean_squared_error: 0.0125\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0142\n",
      "Epoch 7: val_loss improved from 0.08817 to 0.08592, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.0917 - mean_squared_error: 0.0142 - val_loss: 0.0859 - val_mean_squared_error: 0.0126\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.0130\n",
      "Epoch 8: val_loss did not improve from 0.08592\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0877 - mean_squared_error: 0.0131 - val_loss: 0.0939 - val_mean_squared_error: 0.0144\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0878 - mean_squared_error: 0.0131\n",
      "Epoch 9: val_loss did not improve from 0.08592\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0878 - mean_squared_error: 0.0131 - val_loss: 0.0898 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0856 - mean_squared_error: 0.0124\n",
      "Epoch 10: val_loss improved from 0.08592 to 0.08563, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.0856 - mean_squared_error: 0.0124 - val_loss: 0.0856 - val_mean_squared_error: 0.0123\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.0115\n",
      "Epoch 11: val_loss improved from 0.08563 to 0.08429, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0819 - mean_squared_error: 0.0115 - val_loss: 0.0843 - val_mean_squared_error: 0.0117\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0785 - mean_squared_error: 0.0106\n",
      "Epoch 12: val_loss improved from 0.08429 to 0.08345, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size11_pool4_do0.1_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.0785 - mean_squared_error: 0.0106 - val_loss: 0.0835 - val_mean_squared_error: 0.0115\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0779 - mean_squared_error: 0.0103\n",
      "Epoch 13: val_loss did not improve from 0.08345\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0779 - mean_squared_error: 0.0102 - val_loss: 0.0879 - val_mean_squared_error: 0.0126\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0768 - mean_squared_error: 0.0101\n",
      "Epoch 14: val_loss did not improve from 0.08345\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.0768 - mean_squared_error: 0.0101 - val_loss: 0.0875 - val_mean_squared_error: 0.0126\n",
      "Epoch 15/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0737 - mean_squared_error: 0.0093\n",
      "Epoch 15: val_loss did not improve from 0.08345\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.0736 - mean_squared_error: 0.0093 - val_loss: 0.0844 - val_mean_squared_error: 0.0120\n",
      "14/14 [==============================] - 1s 28ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae8.34+-0.26\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1850 - mean_squared_error: 0.0558\n",
      "Epoch 1: val_loss improved from inf to 0.11348, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 88ms/step - loss: 0.1850 - mean_squared_error: 0.0558 - val_loss: 0.1135 - val_mean_squared_error: 0.0217\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1384 - mean_squared_error: 0.0312\n",
      "Epoch 2: val_loss improved from 0.11348 to 0.10086, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1384 - mean_squared_error: 0.0312 - val_loss: 0.1009 - val_mean_squared_error: 0.0170\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1301 - mean_squared_error: 0.0277\n",
      "Epoch 3: val_loss improved from 0.10086 to 0.09933, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1300 - mean_squared_error: 0.0277 - val_loss: 0.0993 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1225 - mean_squared_error: 0.0249\n",
      "Epoch 4: val_loss improved from 0.09933 to 0.09776, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1225 - mean_squared_error: 0.0249 - val_loss: 0.0978 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1187 - mean_squared_error: 0.0234\n",
      "Epoch 5: val_loss did not improve from 0.09776\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1187 - mean_squared_error: 0.0234 - val_loss: 0.0999 - val_mean_squared_error: 0.0163\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1144 - mean_squared_error: 0.0215\n",
      "Epoch 6: val_loss did not improve from 0.09776\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1144 - mean_squared_error: 0.0215 - val_loss: 0.0982 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0203\n",
      "Epoch 7: val_loss did not improve from 0.09776\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1114 - mean_squared_error: 0.0203 - val_loss: 0.0981 - val_mean_squared_error: 0.0158\n",
      "14/14 [==============================] - 1s 26ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1909 - mean_squared_error: 0.0586\n",
      "Epoch 1: val_loss improved from inf to 0.09987, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 5s 78ms/step - loss: 0.1909 - mean_squared_error: 0.0586 - val_loss: 0.0999 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1383 - mean_squared_error: 0.0312\n",
      "Epoch 2: val_loss did not improve from 0.09987\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1383 - mean_squared_error: 0.0312 - val_loss: 0.1000 - val_mean_squared_error: 0.0166\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1261 - mean_squared_error: 0.0261\n",
      "Epoch 3: val_loss improved from 0.09987 to 0.09936, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1261 - mean_squared_error: 0.0261 - val_loss: 0.0994 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1203 - mean_squared_error: 0.0239\n",
      "Epoch 4: val_loss improved from 0.09936 to 0.09895, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1203 - mean_squared_error: 0.0239 - val_loss: 0.0989 - val_mean_squared_error: 0.0162\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1161 - mean_squared_error: 0.0223\n",
      "Epoch 5: val_loss improved from 0.09895 to 0.09793, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1161 - mean_squared_error: 0.0223 - val_loss: 0.0979 - val_mean_squared_error: 0.0160\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1130 - mean_squared_error: 0.0209\n",
      "Epoch 6: val_loss improved from 0.09793 to 0.09635, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1130 - mean_squared_error: 0.0208 - val_loss: 0.0963 - val_mean_squared_error: 0.0151\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1118 - mean_squared_error: 0.0205\n",
      "Epoch 7: val_loss did not improve from 0.09635\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1117 - mean_squared_error: 0.0205 - val_loss: 0.0971 - val_mean_squared_error: 0.0156\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1104 - mean_squared_error: 0.0199\n",
      "Epoch 8: val_loss did not improve from 0.09635\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1104 - mean_squared_error: 0.0199 - val_loss: 0.0967 - val_mean_squared_error: 0.0154\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0189\n",
      "Epoch 9: val_loss improved from 0.09635 to 0.09594, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1073 - mean_squared_error: 0.0189 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0187\n",
      "Epoch 10: val_loss did not improve from 0.09594\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1069 - mean_squared_error: 0.0187 - val_loss: 0.0960 - val_mean_squared_error: 0.0149\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0186\n",
      "Epoch 11: val_loss improved from 0.09594 to 0.09574, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1058 - mean_squared_error: 0.0185 - val_loss: 0.0957 - val_mean_squared_error: 0.0151\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0178\n",
      "Epoch 12: val_loss did not improve from 0.09574\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1045 - mean_squared_error: 0.0178 - val_loss: 0.0963 - val_mean_squared_error: 0.0151\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0176\n",
      "Epoch 13: val_loss improved from 0.09574 to 0.09572, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1040 - mean_squared_error: 0.0177 - val_loss: 0.0957 - val_mean_squared_error: 0.0150\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0177\n",
      "Epoch 14: val_loss did not improve from 0.09572\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1038 - mean_squared_error: 0.0177 - val_loss: 0.0960 - val_mean_squared_error: 0.0152\n",
      "Epoch 15/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0174\n",
      "Epoch 15: val_loss did not improve from 0.09572\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1037 - mean_squared_error: 0.0174 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 16/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0173\n",
      "Epoch 16: val_loss did not improve from 0.09572\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1029 - mean_squared_error: 0.0173 - val_loss: 0.0958 - val_mean_squared_error: 0.0151\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1849 - mean_squared_error: 0.0555\n",
      "Epoch 1: val_loss improved from inf to 0.11122, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 5s 86ms/step - loss: 0.1849 - mean_squared_error: 0.0555 - val_loss: 0.1112 - val_mean_squared_error: 0.0210\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1327 - mean_squared_error: 0.0289\n",
      "Epoch 2: val_loss improved from 0.11122 to 0.10103, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1327 - mean_squared_error: 0.0289 - val_loss: 0.1010 - val_mean_squared_error: 0.0177\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1239 - mean_squared_error: 0.0251\n",
      "Epoch 3: val_loss improved from 0.10103 to 0.09629, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1239 - mean_squared_error: 0.0251 - val_loss: 0.0963 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1172 - mean_squared_error: 0.0226\n",
      "Epoch 4: val_loss did not improve from 0.09629\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1173 - mean_squared_error: 0.0226 - val_loss: 0.0993 - val_mean_squared_error: 0.0171\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1136 - mean_squared_error: 0.0212\n",
      "Epoch 5: val_loss did not improve from 0.09629\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1136 - mean_squared_error: 0.0212 - val_loss: 0.0963 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1121 - mean_squared_error: 0.0206\n",
      "Epoch 6: val_loss improved from 0.09629 to 0.09619, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1120 - mean_squared_error: 0.0206 - val_loss: 0.0962 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1085 - mean_squared_error: 0.0194\n",
      "Epoch 7: val_loss improved from 0.09619 to 0.09603, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1086 - mean_squared_error: 0.0194 - val_loss: 0.0960 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0188\n",
      "Epoch 8: val_loss improved from 0.09603 to 0.09556, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1075 - mean_squared_error: 0.0188 - val_loss: 0.0956 - val_mean_squared_error: 0.0151\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0185\n",
      "Epoch 9: val_loss improved from 0.09556 to 0.09556, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1061 - mean_squared_error: 0.0185 - val_loss: 0.0956 - val_mean_squared_error: 0.0151\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0183\n",
      "Epoch 10: val_loss did not improve from 0.09556\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1059 - mean_squared_error: 0.0183 - val_loss: 0.0956 - val_mean_squared_error: 0.0151\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1042 - mean_squared_error: 0.0177\n",
      "Epoch 11: val_loss did not improve from 0.09556\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1042 - mean_squared_error: 0.0177 - val_loss: 0.0961 - val_mean_squared_error: 0.0151\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0176\n",
      "Epoch 12: val_loss improved from 0.09556 to 0.09529, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1041 - mean_squared_error: 0.0176 - val_loss: 0.0953 - val_mean_squared_error: 0.0152\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0173\n",
      "Epoch 13: val_loss did not improve from 0.09529\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1031 - mean_squared_error: 0.0173 - val_loss: 0.0961 - val_mean_squared_error: 0.0151\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0173\n",
      "Epoch 14: val_loss did not improve from 0.09529\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1031 - mean_squared_error: 0.0173 - val_loss: 0.0958 - val_mean_squared_error: 0.0151\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0173\n",
      "Epoch 15: val_loss did not improve from 0.09529\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1033 - mean_squared_error: 0.0173 - val_loss: 0.0962 - val_mean_squared_error: 0.0151\n",
      "14/14 [==============================] - 1s 26ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1918 - mean_squared_error: 0.0596\n",
      "Epoch 1: val_loss improved from inf to 0.10279, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "40/40 [==============================] - 5s 84ms/step - loss: 0.1918 - mean_squared_error: 0.0596 - val_loss: 0.1028 - val_mean_squared_error: 0.0176\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1342 - mean_squared_error: 0.0293\n",
      "Epoch 2: val_loss improved from 0.10279 to 0.10045, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1342 - mean_squared_error: 0.0293 - val_loss: 0.1005 - val_mean_squared_error: 0.0168\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1227 - mean_squared_error: 0.0250\n",
      "Epoch 3: val_loss improved from 0.10045 to 0.09914, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1227 - mean_squared_error: 0.0250 - val_loss: 0.0991 - val_mean_squared_error: 0.0162\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1162 - mean_squared_error: 0.0222\n",
      "Epoch 4: val_loss improved from 0.09914 to 0.09821, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1162 - mean_squared_error: 0.0222 - val_loss: 0.0982 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.0212\n",
      "Epoch 5: val_loss improved from 0.09821 to 0.09809, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1137 - mean_squared_error: 0.0212 - val_loss: 0.0981 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0199\n",
      "Epoch 6: val_loss did not improve from 0.09809\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1101 - mean_squared_error: 0.0199 - val_loss: 0.0982 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0192\n",
      "Epoch 7: val_loss improved from 0.09809 to 0.09766, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1079 - mean_squared_error: 0.0192 - val_loss: 0.0977 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0188\n",
      "Epoch 8: val_loss did not improve from 0.09766\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1071 - mean_squared_error: 0.0188 - val_loss: 0.0994 - val_mean_squared_error: 0.0157\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1058 - mean_squared_error: 0.0183\n",
      "Epoch 9: val_loss improved from 0.09766 to 0.09761, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size19_pool4_do0.2_tra5_head8_kdim64_fnn64/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1058 - mean_squared_error: 0.0183 - val_loss: 0.0976 - val_mean_squared_error: 0.0157\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0179\n",
      "Epoch 10: val_loss did not improve from 0.09761\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1040 - mean_squared_error: 0.0178 - val_loss: 0.0980 - val_mean_squared_error: 0.0154\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0177\n",
      "Epoch 11: val_loss did not improve from 0.09761\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1037 - mean_squared_error: 0.0177 - val_loss: 0.0984 - val_mean_squared_error: 0.0156\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0175\n",
      "Epoch 12: val_loss did not improve from 0.09761\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1033 - mean_squared_error: 0.0175 - val_loss: 0.0979 - val_mean_squared_error: 0.0156\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.72+-0.01\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2593 - mean_squared_error: 0.1087\n",
      "Epoch 1: val_loss improved from inf to 0.12801, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 111ms/step - loss: 0.2593 - mean_squared_error: 0.1087 - val_loss: 0.1280 - val_mean_squared_error: 0.0267\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1338 - mean_squared_error: 0.0289\n",
      "Epoch 2: val_loss improved from 0.12801 to 0.10683, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.1336 - mean_squared_error: 0.0289 - val_loss: 0.1068 - val_mean_squared_error: 0.0189\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1196 - mean_squared_error: 0.0234\n",
      "Epoch 3: val_loss did not improve from 0.10683\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1196 - mean_squared_error: 0.0234 - val_loss: 0.1109 - val_mean_squared_error: 0.0203\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0213\n",
      "Epoch 4: val_loss improved from 0.10683 to 0.09738, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1134 - mean_squared_error: 0.0213 - val_loss: 0.0974 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss did not improve from 0.09738\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1124 - mean_squared_error: 0.0210 - val_loss: 0.0975 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0201\n",
      "Epoch 6: val_loss improved from 0.09738 to 0.09701, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.1100 - mean_squared_error: 0.0200 - val_loss: 0.0970 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0193\n",
      "Epoch 7: val_loss did not improve from 0.09701\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1078 - mean_squared_error: 0.0193 - val_loss: 0.0977 - val_mean_squared_error: 0.0153\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0186\n",
      "Epoch 8: val_loss did not improve from 0.09701\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1063 - mean_squared_error: 0.0186 - val_loss: 0.0978 - val_mean_squared_error: 0.0157\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1057 - mean_squared_error: 0.0184\n",
      "Epoch 9: val_loss did not improve from 0.09701\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1056 - mean_squared_error: 0.0184 - val_loss: 0.0984 - val_mean_squared_error: 0.0156\n",
      "14/14 [==============================] - 2s 35ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2097 - mean_squared_error: 0.0764\n",
      "Epoch 1: val_loss improved from inf to 0.11085, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 6s 102ms/step - loss: 0.2095 - mean_squared_error: 0.0762 - val_loss: 0.1109 - val_mean_squared_error: 0.0199\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1235 - mean_squared_error: 0.0249\n",
      "Epoch 2: val_loss improved from 0.11085 to 0.09716, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.1234 - mean_squared_error: 0.0249 - val_loss: 0.0972 - val_mean_squared_error: 0.0156\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0216\n",
      "Epoch 3: val_loss improved from 0.09716 to 0.09642, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.1145 - mean_squared_error: 0.0216 - val_loss: 0.0964 - val_mean_squared_error: 0.0151\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0200\n",
      "Epoch 4: val_loss did not improve from 0.09642\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1104 - mean_squared_error: 0.0200 - val_loss: 0.0973 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0195\n",
      "Epoch 5: val_loss improved from 0.09642 to 0.09609, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1084 - mean_squared_error: 0.0196 - val_loss: 0.0961 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0192\n",
      "Epoch 6: val_loss did not improve from 0.09609\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1082 - mean_squared_error: 0.0192 - val_loss: 0.1126 - val_mean_squared_error: 0.0196\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0187\n",
      "Epoch 7: val_loss did not improve from 0.09609\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1066 - mean_squared_error: 0.0187 - val_loss: 0.0964 - val_mean_squared_error: 0.0154\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0186\n",
      "Epoch 8: val_loss did not improve from 0.09609\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.1061 - mean_squared_error: 0.0186 - val_loss: 0.0999 - val_mean_squared_error: 0.0167\n",
      "14/14 [==============================] - 1s 34ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3042 - mean_squared_error: 0.1396\n",
      "Epoch 1: val_loss improved from inf to 0.14514, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 7s 109ms/step - loss: 0.3042 - mean_squared_error: 0.1396 - val_loss: 0.1451 - val_mean_squared_error: 0.0339\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1266 - mean_squared_error: 0.0263\n",
      "Epoch 2: val_loss improved from 0.14514 to 0.11575, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1265 - mean_squared_error: 0.0263 - val_loss: 0.1157 - val_mean_squared_error: 0.0201\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1149 - mean_squared_error: 0.0217\n",
      "Epoch 3: val_loss improved from 0.11575 to 0.09574, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 87ms/step - loss: 0.1148 - mean_squared_error: 0.0217 - val_loss: 0.0957 - val_mean_squared_error: 0.0152\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1094 - mean_squared_error: 0.0196\n",
      "Epoch 4: val_loss did not improve from 0.09574\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.1094 - mean_squared_error: 0.0197 - val_loss: 0.0994 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0191\n",
      "Epoch 5: val_loss improved from 0.09574 to 0.09531, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 4s 88ms/step - loss: 0.1082 - mean_squared_error: 0.0191 - val_loss: 0.0953 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0190\n",
      "Epoch 6: val_loss did not improve from 0.09531\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1077 - mean_squared_error: 0.0190 - val_loss: 0.0986 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0186\n",
      "Epoch 7: val_loss did not improve from 0.09531\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1065 - mean_squared_error: 0.0186 - val_loss: 0.0995 - val_mean_squared_error: 0.0159\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0182\n",
      "Epoch 8: val_loss did not improve from 0.09531\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1055 - mean_squared_error: 0.0183 - val_loss: 0.0960 - val_mean_squared_error: 0.0152\n",
      "14/14 [==============================] - 2s 37ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2063 - mean_squared_error: 0.0745\n",
      "Epoch 1: val_loss improved from inf to 0.10467, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 7s 113ms/step - loss: 0.2060 - mean_squared_error: 0.0743 - val_loss: 0.1047 - val_mean_squared_error: 0.0179\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1230 - mean_squared_error: 0.0247\n",
      "Epoch 2: val_loss did not improve from 0.10467\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1229 - mean_squared_error: 0.0247 - val_loss: 0.1091 - val_mean_squared_error: 0.0183\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0212\n",
      "Epoch 3: val_loss improved from 0.10467 to 0.09732, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 4s 89ms/step - loss: 0.1135 - mean_squared_error: 0.0212 - val_loss: 0.0973 - val_mean_squared_error: 0.0155\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0198\n",
      "Epoch 4: val_loss did not improve from 0.09732\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.1097 - mean_squared_error: 0.0198 - val_loss: 0.0979 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0192\n",
      "Epoch 5: val_loss did not improve from 0.09732\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.1082 - mean_squared_error: 0.0192 - val_loss: 0.1042 - val_mean_squared_error: 0.0169\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1058 - mean_squared_error: 0.0184\n",
      "Epoch 6: val_loss improved from 0.09732 to 0.09706, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride4_size11_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 86ms/step - loss: 0.1059 - mean_squared_error: 0.0184 - val_loss: 0.0971 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0184\n",
      "Epoch 7: val_loss did not improve from 0.09706\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.1055 - mean_squared_error: 0.0184 - val_loss: 0.0989 - val_mean_squared_error: 0.0156\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0178\n",
      "Epoch 8: val_loss did not improve from 0.09706\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1041 - mean_squared_error: 0.0178 - val_loss: 0.1010 - val_mean_squared_error: 0.0173\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0176\n",
      "Epoch 9: val_loss did not improve from 0.09706\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1039 - mean_squared_error: 0.0176 - val_loss: 0.1007 - val_mean_squared_error: 0.0160\n",
      "14/14 [==============================] - 1s 32ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.70+-0.06\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1451 - mean_squared_error: 0.0353\n",
      "Epoch 1: val_loss improved from inf to 0.09996, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 15s 63ms/step - loss: 0.1451 - mean_squared_error: 0.0353 - val_loss: 0.1000 - val_mean_squared_error: 0.0163\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1139 - mean_squared_error: 0.0214\n",
      "Epoch 2: val_loss did not improve from 0.09996\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1139 - mean_squared_error: 0.0214 - val_loss: 0.1006 - val_mean_squared_error: 0.0161\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0198\n",
      "Epoch 3: val_loss did not improve from 0.09996\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1092 - mean_squared_error: 0.0198 - val_loss: 0.1016 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0189\n",
      "Epoch 4: val_loss did not improve from 0.09996\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1069 - mean_squared_error: 0.0189 - val_loss: 0.1020 - val_mean_squared_error: 0.0166\n",
      "27/27 [==============================] - 2s 19ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1369 - mean_squared_error: 0.0312\n",
      "Epoch 1: val_loss improved from inf to 0.09914, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 7s 62ms/step - loss: 0.1369 - mean_squared_error: 0.0312 - val_loss: 0.0991 - val_mean_squared_error: 0.0163\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0206\n",
      "Epoch 2: val_loss did not improve from 0.09914\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1114 - mean_squared_error: 0.0206 - val_loss: 0.0996 - val_mean_squared_error: 0.0161\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1089 - mean_squared_error: 0.0198\n",
      "Epoch 3: val_loss did not improve from 0.09914\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1089 - mean_squared_error: 0.0198 - val_loss: 0.1001 - val_mean_squared_error: 0.0166\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0194\n",
      "Epoch 4: val_loss improved from 0.09914 to 0.09626, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.1084 - mean_squared_error: 0.0194 - val_loss: 0.0963 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0188\n",
      "Epoch 5: val_loss did not improve from 0.09626\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1061 - mean_squared_error: 0.0188 - val_loss: 0.0976 - val_mean_squared_error: 0.0157\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0181\n",
      "Epoch 6: val_loss did not improve from 0.09626\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1047 - mean_squared_error: 0.0181 - val_loss: 0.0973 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1042 - mean_squared_error: 0.0180\n",
      "Epoch 7: val_loss did not improve from 0.09626\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1042 - mean_squared_error: 0.0180 - val_loss: 0.0964 - val_mean_squared_error: 0.0152\n",
      "27/27 [==============================] - 2s 19ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1402 - mean_squared_error: 0.0338\n",
      "Epoch 1: val_loss improved from inf to 0.14400, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 6s 56ms/step - loss: 0.1402 - mean_squared_error: 0.0338 - val_loss: 0.1440 - val_mean_squared_error: 0.0300\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1135 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.14400 to 0.09613, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1135 - mean_squared_error: 0.0210 - val_loss: 0.0961 - val_mean_squared_error: 0.0159\n",
      "Epoch 3/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0194\n",
      "Epoch 3: val_loss did not improve from 0.09613\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1082 - mean_squared_error: 0.0194 - val_loss: 0.0981 - val_mean_squared_error: 0.0164\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0187\n",
      "Epoch 4: val_loss did not improve from 0.09613\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1066 - mean_squared_error: 0.0187 - val_loss: 0.0965 - val_mean_squared_error: 0.0154\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0183\n",
      "Epoch 5: val_loss improved from 0.09613 to 0.09497, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1054 - mean_squared_error: 0.0183 - val_loss: 0.0950 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0180\n",
      "Epoch 6: val_loss did not improve from 0.09497\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1049 - mean_squared_error: 0.0180 - val_loss: 0.0958 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0174\n",
      "Epoch 7: val_loss did not improve from 0.09497\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1027 - mean_squared_error: 0.0174 - val_loss: 0.0969 - val_mean_squared_error: 0.0159\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0173\n",
      "Epoch 8: val_loss did not improve from 0.09497\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1028 - mean_squared_error: 0.0173 - val_loss: 0.0981 - val_mean_squared_error: 0.0155\n",
      "27/27 [==============================] - 1s 19ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1400 - mean_squared_error: 0.0334\n",
      "Epoch 1: val_loss improved from inf to 0.12324, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 6s 60ms/step - loss: 0.1400 - mean_squared_error: 0.0334 - val_loss: 0.1232 - val_mean_squared_error: 0.0232\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0205\n",
      "Epoch 2: val_loss improved from 0.12324 to 0.10101, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1114 - mean_squared_error: 0.0205 - val_loss: 0.1010 - val_mean_squared_error: 0.0165\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0191\n",
      "Epoch 3: val_loss improved from 0.10101 to 0.09787, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size15_pool2_do0.1_tra3_head2_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1079 - mean_squared_error: 0.0191 - val_loss: 0.0979 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss did not improve from 0.09787\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1068 - mean_squared_error: 0.0188 - val_loss: 0.1025 - val_mean_squared_error: 0.0169\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0180\n",
      "Epoch 5: val_loss did not improve from 0.09787\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1045 - mean_squared_error: 0.0180 - val_loss: 0.1024 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0176\n",
      "Epoch 6: val_loss did not improve from 0.09787\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1033 - mean_squared_error: 0.0176 - val_loss: 0.1106 - val_mean_squared_error: 0.0186\n",
      "27/27 [==============================] - 1s 19ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.82+-0.12\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3216 - mean_squared_error: 0.1357\n",
      "Epoch 1: val_loss improved from inf to 0.20719, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 27s 387ms/step - loss: 0.3216 - mean_squared_error: 0.1357 - val_loss: 0.2072 - val_mean_squared_error: 0.0658\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2447 - mean_squared_error: 0.0862\n",
      "Epoch 2: val_loss improved from 0.20719 to 0.17574, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 14s 363ms/step - loss: 0.2447 - mean_squared_error: 0.0862 - val_loss: 0.1757 - val_mean_squared_error: 0.0446\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1983 - mean_squared_error: 0.0606\n",
      "Epoch 3: val_loss improved from 0.17574 to 0.17087, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 364ms/step - loss: 0.1983 - mean_squared_error: 0.0606 - val_loss: 0.1709 - val_mean_squared_error: 0.0406\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1714 - mean_squared_error: 0.0470\n",
      "Epoch 4: val_loss did not improve from 0.17087\n",
      "40/40 [==============================] - 14s 361ms/step - loss: 0.1714 - mean_squared_error: 0.0470 - val_loss: 0.1882 - val_mean_squared_error: 0.0474\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1514 - mean_squared_error: 0.0375\n",
      "Epoch 5: val_loss did not improve from 0.17087\n",
      "40/40 [==============================] - 14s 361ms/step - loss: 0.1514 - mean_squared_error: 0.0375 - val_loss: 0.1752 - val_mean_squared_error: 0.0415\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1357 - mean_squared_error: 0.0308\n",
      "Epoch 6: val_loss improved from 0.17087 to 0.17085, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 365ms/step - loss: 0.1357 - mean_squared_error: 0.0308 - val_loss: 0.1709 - val_mean_squared_error: 0.0392\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1257 - mean_squared_error: 0.0258\n",
      "Epoch 7: val_loss improved from 0.17085 to 0.15747, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 364ms/step - loss: 0.1257 - mean_squared_error: 0.0258 - val_loss: 0.1575 - val_mean_squared_error: 0.0342\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1170 - mean_squared_error: 0.0226\n",
      "Epoch 8: val_loss improved from 0.15747 to 0.15621, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 365ms/step - loss: 0.1170 - mean_squared_error: 0.0226 - val_loss: 0.1562 - val_mean_squared_error: 0.0334\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1141 - mean_squared_error: 0.0214\n",
      "Epoch 9: val_loss did not improve from 0.15621\n",
      "40/40 [==============================] - 14s 361ms/step - loss: 0.1141 - mean_squared_error: 0.0214 - val_loss: 0.1586 - val_mean_squared_error: 0.0342\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1121 - mean_squared_error: 0.0208\n",
      "Epoch 10: val_loss improved from 0.15621 to 0.15270, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1121 - mean_squared_error: 0.0208 - val_loss: 0.1527 - val_mean_squared_error: 0.0320\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1095 - mean_squared_error: 0.0195\n",
      "Epoch 11: val_loss did not improve from 0.15270\n",
      "40/40 [==============================] - 14s 361ms/step - loss: 0.1095 - mean_squared_error: 0.0195 - val_loss: 0.1540 - val_mean_squared_error: 0.0322\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0201\n",
      "Epoch 12: val_loss improved from 0.15270 to 0.14190, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 365ms/step - loss: 0.1099 - mean_squared_error: 0.0201 - val_loss: 0.1419 - val_mean_squared_error: 0.0277\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1089 - mean_squared_error: 0.0194\n",
      "Epoch 13: val_loss improved from 0.14190 to 0.14012, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1089 - mean_squared_error: 0.0194 - val_loss: 0.1401 - val_mean_squared_error: 0.0273\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1085 - mean_squared_error: 0.0194\n",
      "Epoch 14: val_loss improved from 0.14012 to 0.13926, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1085 - mean_squared_error: 0.0194 - val_loss: 0.1393 - val_mean_squared_error: 0.0268\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0193\n",
      "Epoch 15: val_loss improved from 0.13926 to 0.13643, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1084 - mean_squared_error: 0.0193 - val_loss: 0.1364 - val_mean_squared_error: 0.0259\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1080 - mean_squared_error: 0.0192\n",
      "Epoch 16: val_loss did not improve from 0.13643\n",
      "40/40 [==============================] - 14s 363ms/step - loss: 0.1080 - mean_squared_error: 0.0192 - val_loss: 0.1377 - val_mean_squared_error: 0.0262\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0189\n",
      "Epoch 17: val_loss improved from 0.13643 to 0.13137, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1073 - mean_squared_error: 0.0189 - val_loss: 0.1314 - val_mean_squared_error: 0.0243\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0190\n",
      "Epoch 18: val_loss improved from 0.13137 to 0.12881, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1072 - mean_squared_error: 0.0190 - val_loss: 0.1288 - val_mean_squared_error: 0.0234\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0191\n",
      "Epoch 19: val_loss did not improve from 0.12881\n",
      "40/40 [==============================] - 14s 362ms/step - loss: 0.1079 - mean_squared_error: 0.0191 - val_loss: 0.1322 - val_mean_squared_error: 0.0244\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0189\n",
      "Epoch 20: val_loss improved from 0.12881 to 0.12854, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.1075 - mean_squared_error: 0.0189 - val_loss: 0.1285 - val_mean_squared_error: 0.0234\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0187\n",
      "Epoch 21: val_loss improved from 0.12854 to 0.12693, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1068 - mean_squared_error: 0.0187 - val_loss: 0.1269 - val_mean_squared_error: 0.0228\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0189\n",
      "Epoch 22: val_loss improved from 0.12693 to 0.12530, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.1075 - mean_squared_error: 0.0189 - val_loss: 0.1253 - val_mean_squared_error: 0.0222\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0187\n",
      "Epoch 23: val_loss did not improve from 0.12530\n",
      "40/40 [==============================] - 14s 361ms/step - loss: 0.1071 - mean_squared_error: 0.0187 - val_loss: 0.1332 - val_mean_squared_error: 0.0247\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0189\n",
      "Epoch 24: val_loss did not improve from 0.12530\n",
      "40/40 [==============================] - 14s 362ms/step - loss: 0.1067 - mean_squared_error: 0.0189 - val_loss: 0.1273 - val_mean_squared_error: 0.0229\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0190\n",
      "Epoch 25: val_loss did not improve from 0.12530\n",
      "40/40 [==============================] - 15s 364ms/step - loss: 0.1076 - mean_squared_error: 0.0190 - val_loss: 0.1259 - val_mean_squared_error: 0.0223\n",
      "14/14 [==============================] - 3s 126ms/step\n",
      " ###0 fold : val mae 0.13###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2941 - mean_squared_error: 0.1194\n",
      "Epoch 1: val_loss improved from inf to 0.27208, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 18s 386ms/step - loss: 0.2941 - mean_squared_error: 0.1194 - val_loss: 0.2721 - val_mean_squared_error: 0.0934\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2092 - mean_squared_error: 0.0666\n",
      "Epoch 2: val_loss improved from 0.27208 to 0.25478, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.2092 - mean_squared_error: 0.0666 - val_loss: 0.2548 - val_mean_squared_error: 0.0823\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1751 - mean_squared_error: 0.0489\n",
      "Epoch 3: val_loss improved from 0.25478 to 0.24414, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.1751 - mean_squared_error: 0.0489 - val_loss: 0.2441 - val_mean_squared_error: 0.0743\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1538 - mean_squared_error: 0.0385\n",
      "Epoch 4: val_loss improved from 0.24414 to 0.20146, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.1538 - mean_squared_error: 0.0385 - val_loss: 0.2015 - val_mean_squared_error: 0.0534\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1409 - mean_squared_error: 0.0323\n",
      "Epoch 5: val_loss improved from 0.20146 to 0.14260, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.1409 - mean_squared_error: 0.0323 - val_loss: 0.1426 - val_mean_squared_error: 0.0286\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1274 - mean_squared_error: 0.0269\n",
      "Epoch 6: val_loss did not improve from 0.14260\n",
      "40/40 [==============================] - 15s 363ms/step - loss: 0.1274 - mean_squared_error: 0.0269 - val_loss: 0.1628 - val_mean_squared_error: 0.0365\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1205 - mean_squared_error: 0.0241\n",
      "Epoch 7: val_loss did not improve from 0.14260\n",
      "40/40 [==============================] - 15s 364ms/step - loss: 0.1205 - mean_squared_error: 0.0241 - val_loss: 0.1818 - val_mean_squared_error: 0.0437\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1159 - mean_squared_error: 0.0217\n",
      "Epoch 8: val_loss did not improve from 0.14260\n",
      "40/40 [==============================] - 14s 362ms/step - loss: 0.1159 - mean_squared_error: 0.0217 - val_loss: 0.1783 - val_mean_squared_error: 0.0419\n",
      "14/14 [==============================] - 3s 126ms/step\n",
      " ###1 fold : val mae 0.15###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2902 - mean_squared_error: 0.1165\n",
      "Epoch 1: val_loss improved from inf to 0.31943, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 18s 391ms/step - loss: 0.2902 - mean_squared_error: 0.1165 - val_loss: 0.3194 - val_mean_squared_error: 0.1244\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2038 - mean_squared_error: 0.0637\n",
      "Epoch 2: val_loss improved from 0.31943 to 0.29192, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 15s 366ms/step - loss: 0.2038 - mean_squared_error: 0.0637 - val_loss: 0.2919 - val_mean_squared_error: 0.1022\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1750 - mean_squared_error: 0.0485\n",
      "Epoch 3: val_loss improved from 0.29192 to 0.18317, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 15s 365ms/step - loss: 0.1750 - mean_squared_error: 0.0485 - val_loss: 0.1832 - val_mean_squared_error: 0.0449\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1551 - mean_squared_error: 0.0394\n",
      "Epoch 4: val_loss improved from 0.18317 to 0.15686, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.1551 - mean_squared_error: 0.0394 - val_loss: 0.1569 - val_mean_squared_error: 0.0344\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1403 - mean_squared_error: 0.0322\n",
      "Epoch 5: val_loss did not improve from 0.15686\n",
      "40/40 [==============================] - 15s 363ms/step - loss: 0.1403 - mean_squared_error: 0.0322 - val_loss: 0.1804 - val_mean_squared_error: 0.0437\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1278 - mean_squared_error: 0.0268\n",
      "Epoch 6: val_loss did not improve from 0.15686\n",
      "40/40 [==============================] - 15s 363ms/step - loss: 0.1278 - mean_squared_error: 0.0268 - val_loss: 0.1771 - val_mean_squared_error: 0.0414\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1193 - mean_squared_error: 0.0232\n",
      "Epoch 7: val_loss did not improve from 0.15686\n",
      "40/40 [==============================] - 14s 362ms/step - loss: 0.1193 - mean_squared_error: 0.0232 - val_loss: 0.1680 - val_mean_squared_error: 0.0377\n",
      "14/14 [==============================] - 3s 127ms/step\n",
      " ###2 fold : val mae 0.16###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3009 - mean_squared_error: 0.1226\n",
      "Epoch 1: val_loss improved from inf to 0.18470, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 17s 389ms/step - loss: 0.3009 - mean_squared_error: 0.1226 - val_loss: 0.1847 - val_mean_squared_error: 0.0511\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2147 - mean_squared_error: 0.0694\n",
      "Epoch 2: val_loss improved from 0.18470 to 0.10984, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride2_size19_pool2_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 15s 367ms/step - loss: 0.2147 - mean_squared_error: 0.0694 - val_loss: 0.1098 - val_mean_squared_error: 0.0192\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1777 - mean_squared_error: 0.0508\n",
      "Epoch 3: val_loss did not improve from 0.10984\n",
      "40/40 [==============================] - 15s 364ms/step - loss: 0.1777 - mean_squared_error: 0.0508 - val_loss: 0.1410 - val_mean_squared_error: 0.0288\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1553 - mean_squared_error: 0.0397\n",
      "Epoch 4: val_loss did not improve from 0.10984\n",
      "40/40 [==============================] - 14s 363ms/step - loss: 0.1553 - mean_squared_error: 0.0397 - val_loss: 0.1483 - val_mean_squared_error: 0.0309\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1385 - mean_squared_error: 0.0312\n",
      "Epoch 5: val_loss did not improve from 0.10984\n",
      "40/40 [==============================] - 15s 364ms/step - loss: 0.1385 - mean_squared_error: 0.0312 - val_loss: 0.2090 - val_mean_squared_error: 0.0565\n",
      "14/14 [==============================] - 3s 124ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae13.60+-1.86\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1792 - mean_squared_error: 0.0513\n",
      "Epoch 1: val_loss improved from inf to 0.13001, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 20s 72ms/step - loss: 0.1792 - mean_squared_error: 0.0513 - val_loss: 0.1300 - val_mean_squared_error: 0.0266\n",
      "Epoch 2/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1335 - mean_squared_error: 0.0295\n",
      "Epoch 2: val_loss improved from 0.13001 to 0.09912, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 55ms/step - loss: 0.1335 - mean_squared_error: 0.0295 - val_loss: 0.0991 - val_mean_squared_error: 0.0166\n",
      "Epoch 3/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1197 - mean_squared_error: 0.0239\n",
      "Epoch 3: val_loss improved from 0.09912 to 0.09869, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 56ms/step - loss: 0.1196 - mean_squared_error: 0.0239 - val_loss: 0.0987 - val_mean_squared_error: 0.0163\n",
      "Epoch 4/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1102 - mean_squared_error: 0.0202\n",
      "Epoch 4: val_loss improved from 0.09869 to 0.09406, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1101 - mean_squared_error: 0.0202 - val_loss: 0.0941 - val_mean_squared_error: 0.0148\n",
      "Epoch 5/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0181\n",
      "Epoch 5: val_loss did not improve from 0.09406\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1037 - mean_squared_error: 0.0180 - val_loss: 0.1036 - val_mean_squared_error: 0.0180\n",
      "Epoch 6/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0988 - mean_squared_error: 0.0163\n",
      "Epoch 6: val_loss did not improve from 0.09406\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.0988 - mean_squared_error: 0.0163 - val_loss: 0.1235 - val_mean_squared_error: 0.0245\n",
      "Epoch 7/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0941 - mean_squared_error: 0.0149\n",
      "Epoch 7: val_loss did not improve from 0.09406\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.0941 - mean_squared_error: 0.0149 - val_loss: 0.1004 - val_mean_squared_error: 0.0170\n",
      "27/27 [==============================] - 2s 22ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1799 - mean_squared_error: 0.0524\n",
      "Epoch 1: val_loss improved from inf to 0.11687, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 7s 65ms/step - loss: 0.1798 - mean_squared_error: 0.0524 - val_loss: 0.1169 - val_mean_squared_error: 0.0219\n",
      "Epoch 2/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1323 - mean_squared_error: 0.0288\n",
      "Epoch 2: val_loss improved from 0.11687 to 0.10555, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1323 - mean_squared_error: 0.0288 - val_loss: 0.1055 - val_mean_squared_error: 0.0185\n",
      "Epoch 3/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1228 - mean_squared_error: 0.0251\n",
      "Epoch 3: val_loss improved from 0.10555 to 0.10509, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 55ms/step - loss: 0.1227 - mean_squared_error: 0.0251 - val_loss: 0.1051 - val_mean_squared_error: 0.0185\n",
      "Epoch 4/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1152 - mean_squared_error: 0.0220\n",
      "Epoch 4: val_loss improved from 0.10509 to 0.09769, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 55ms/step - loss: 0.1153 - mean_squared_error: 0.0221 - val_loss: 0.0977 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1113 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss did not improve from 0.09769\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1113 - mean_squared_error: 0.0206 - val_loss: 0.0984 - val_mean_squared_error: 0.0163\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0196\n",
      "Epoch 6: val_loss did not improve from 0.09769\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1092 - mean_squared_error: 0.0196 - val_loss: 0.1007 - val_mean_squared_error: 0.0168\n",
      "Epoch 7/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0189\n",
      "Epoch 7: val_loss did not improve from 0.09769\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1070 - mean_squared_error: 0.0189 - val_loss: 0.0981 - val_mean_squared_error: 0.0160\n",
      "27/27 [==============================] - 1s 21ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1768 - mean_squared_error: 0.0508\n",
      "Epoch 1: val_loss improved from inf to 0.10067, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 8s 68ms/step - loss: 0.1768 - mean_squared_error: 0.0508 - val_loss: 0.1007 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1313 - mean_squared_error: 0.0285\n",
      "Epoch 2: val_loss did not improve from 0.10067\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1313 - mean_squared_error: 0.0284 - val_loss: 0.1230 - val_mean_squared_error: 0.0251\n",
      "Epoch 3/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1195 - mean_squared_error: 0.0235\n",
      "Epoch 3: val_loss did not improve from 0.10067\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1194 - mean_squared_error: 0.0235 - val_loss: 0.1052 - val_mean_squared_error: 0.0193\n",
      "Epoch 4/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1147 - mean_squared_error: 0.0218\n",
      "Epoch 4: val_loss did not improve from 0.10067\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1147 - mean_squared_error: 0.0218 - val_loss: 0.1026 - val_mean_squared_error: 0.0180\n",
      "27/27 [==============================] - 1s 21ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1766 - mean_squared_error: 0.0513\n",
      "Epoch 1: val_loss improved from inf to 0.13558, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 7s 62ms/step - loss: 0.1766 - mean_squared_error: 0.0513 - val_loss: 0.1356 - val_mean_squared_error: 0.0293\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1323 - mean_squared_error: 0.0288\n",
      "Epoch 2: val_loss improved from 0.13558 to 0.11373, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1323 - mean_squared_error: 0.0288 - val_loss: 0.1137 - val_mean_squared_error: 0.0217\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1205 - mean_squared_error: 0.0238\n",
      "Epoch 3: val_loss improved from 0.11373 to 0.10630, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1205 - mean_squared_error: 0.0238 - val_loss: 0.1063 - val_mean_squared_error: 0.0192\n",
      "Epoch 4/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1130 - mean_squared_error: 0.0212\n",
      "Epoch 4: val_loss improved from 0.10630 to 0.10513, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1130 - mean_squared_error: 0.0212 - val_loss: 0.1051 - val_mean_squared_error: 0.0186\n",
      "Epoch 5/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0198\n",
      "Epoch 5: val_loss did not improve from 0.10513\n",
      "79/79 [==============================] - 4s 55ms/step - loss: 0.1097 - mean_squared_error: 0.0198 - val_loss: 0.1109 - val_mean_squared_error: 0.0208\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0173\n",
      "Epoch 6: val_loss improved from 0.10513 to 0.09313, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1022 - mean_squared_error: 0.0173 - val_loss: 0.0931 - val_mean_squared_error: 0.0145\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0161\n",
      "Epoch 7: val_loss did not improve from 0.09313\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.0984 - mean_squared_error: 0.0161 - val_loss: 0.1163 - val_mean_squared_error: 0.0231\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0957 - mean_squared_error: 0.0153\n",
      "Epoch 8: val_loss did not improve from 0.09313\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.0957 - mean_squared_error: 0.0153 - val_loss: 0.1034 - val_mean_squared_error: 0.0184\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0919 - mean_squared_error: 0.0142\n",
      "Epoch 9: val_loss improved from 0.09313 to 0.09240, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.0919 - mean_squared_error: 0.0142 - val_loss: 0.0924 - val_mean_squared_error: 0.0146\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0895 - mean_squared_error: 0.0132\n",
      "Epoch 10: val_loss improved from 0.09240 to 0.09087, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.0895 - mean_squared_error: 0.0132 - val_loss: 0.0909 - val_mean_squared_error: 0.0141\n",
      "Epoch 11/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.0128\n",
      "Epoch 11: val_loss improved from 0.09087 to 0.08466, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.0876 - mean_squared_error: 0.0128 - val_loss: 0.0847 - val_mean_squared_error: 0.0122\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.0124\n",
      "Epoch 12: val_loss did not improve from 0.08466\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.0861 - mean_squared_error: 0.0124 - val_loss: 0.0870 - val_mean_squared_error: 0.0131\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0864 - mean_squared_error: 0.0125\n",
      "Epoch 13: val_loss improved from 0.08466 to 0.08298, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 56ms/step - loss: 0.0864 - mean_squared_error: 0.0125 - val_loss: 0.0830 - val_mean_squared_error: 0.0117\n",
      "Epoch 14/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0835 - mean_squared_error: 0.0118\n",
      "Epoch 14: val_loss did not improve from 0.08298\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.0835 - mean_squared_error: 0.0118 - val_loss: 0.0842 - val_mean_squared_error: 0.0122\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0836 - mean_squared_error: 0.0117\n",
      "Epoch 15: val_loss did not improve from 0.08298\n",
      "79/79 [==============================] - 4s 55ms/step - loss: 0.0836 - mean_squared_error: 0.0117 - val_loss: 0.0890 - val_mean_squared_error: 0.0134\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0827 - mean_squared_error: 0.0114\n",
      "Epoch 16: val_loss improved from 0.08298 to 0.08247, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 56ms/step - loss: 0.0827 - mean_squared_error: 0.0114 - val_loss: 0.0825 - val_mean_squared_error: 0.0116\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.0112\n",
      "Epoch 17: val_loss improved from 0.08247 to 0.08213, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride2_size7_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 56ms/step - loss: 0.0819 - mean_squared_error: 0.0112 - val_loss: 0.0821 - val_mean_squared_error: 0.0114\n",
      "Epoch 18/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.0110\n",
      "Epoch 18: val_loss did not improve from 0.08213\n",
      "79/79 [==============================] - 4s 55ms/step - loss: 0.0808 - mean_squared_error: 0.0110 - val_loss: 0.0830 - val_mean_squared_error: 0.0117\n",
      "Epoch 19/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0792 - mean_squared_error: 0.0106\n",
      "Epoch 19: val_loss did not improve from 0.08213\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.0792 - mean_squared_error: 0.0106 - val_loss: 0.0841 - val_mean_squared_error: 0.0121\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.0110\n",
      "Epoch 20: val_loss did not improve from 0.08213\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.0809 - mean_squared_error: 0.0110 - val_loss: 0.0843 - val_mean_squared_error: 0.0120\n",
      "27/27 [==============================] - 1s 20ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae9.31+-0.88\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1628 - mean_squared_error: 0.0442\n",
      "Epoch 1: val_loss improved from inf to 0.10155, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 14s 81ms/step - loss: 0.1628 - mean_squared_error: 0.0442 - val_loss: 0.1016 - val_mean_squared_error: 0.0170\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1280 - mean_squared_error: 0.0269\n",
      "Epoch 2: val_loss improved from 0.10155 to 0.09859, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1280 - mean_squared_error: 0.0270 - val_loss: 0.0986 - val_mean_squared_error: 0.0161\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1238 - mean_squared_error: 0.0254\n",
      "Epoch 3: val_loss did not improve from 0.09859\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1238 - mean_squared_error: 0.0254 - val_loss: 0.1004 - val_mean_squared_error: 0.0166\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1195 - mean_squared_error: 0.0237\n",
      "Epoch 4: val_loss improved from 0.09859 to 0.09673, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1195 - mean_squared_error: 0.0237 - val_loss: 0.0967 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1142 - mean_squared_error: 0.0216\n",
      "Epoch 5: val_loss improved from 0.09673 to 0.09612, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1142 - mean_squared_error: 0.0216 - val_loss: 0.0961 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1087 - mean_squared_error: 0.0197\n",
      "Epoch 6: val_loss did not improve from 0.09612\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1087 - mean_squared_error: 0.0197 - val_loss: 0.0974 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0181\n",
      "Epoch 7: val_loss improved from 0.09612 to 0.09337, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1046 - mean_squared_error: 0.0181 - val_loss: 0.0934 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.0165\n",
      "Epoch 8: val_loss improved from 0.09337 to 0.08977, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.0991 - mean_squared_error: 0.0165 - val_loss: 0.0898 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0961 - mean_squared_error: 0.0155\n",
      "Epoch 9: val_loss did not improve from 0.08977\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.0961 - mean_squared_error: 0.0155 - val_loss: 0.0921 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.0143\n",
      "Epoch 10: val_loss improved from 0.08977 to 0.08456, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0927 - mean_squared_error: 0.0143 - val_loss: 0.0846 - val_mean_squared_error: 0.0122\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0905 - mean_squared_error: 0.0137\n",
      "Epoch 11: val_loss did not improve from 0.08456\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.0905 - mean_squared_error: 0.0137 - val_loss: 0.0894 - val_mean_squared_error: 0.0136\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0883 - mean_squared_error: 0.0131\n",
      "Epoch 12: val_loss did not improve from 0.08456\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.0883 - mean_squared_error: 0.0131 - val_loss: 0.0856 - val_mean_squared_error: 0.0127\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0872 - mean_squared_error: 0.0129\n",
      "Epoch 13: val_loss improved from 0.08456 to 0.08442, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.0872 - mean_squared_error: 0.0129 - val_loss: 0.0844 - val_mean_squared_error: 0.0123\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0855 - mean_squared_error: 0.0124\n",
      "Epoch 14: val_loss did not improve from 0.08442\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.0855 - mean_squared_error: 0.0124 - val_loss: 0.0856 - val_mean_squared_error: 0.0125\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0843 - mean_squared_error: 0.0120\n",
      "Epoch 15: val_loss improved from 0.08442 to 0.08411, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0843 - mean_squared_error: 0.0120 - val_loss: 0.0841 - val_mean_squared_error: 0.0122\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0827 - mean_squared_error: 0.0117\n",
      "Epoch 16: val_loss did not improve from 0.08411\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0827 - mean_squared_error: 0.0117 - val_loss: 0.0939 - val_mean_squared_error: 0.0153\n",
      "Epoch 17/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0813 - mean_squared_error: 0.0113\n",
      "Epoch 17: val_loss improved from 0.08411 to 0.08399, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.0813 - mean_squared_error: 0.0113 - val_loss: 0.0840 - val_mean_squared_error: 0.0122\n",
      "Epoch 18/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.0112\n",
      "Epoch 18: val_loss did not improve from 0.08399\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.0810 - mean_squared_error: 0.0112 - val_loss: 0.0928 - val_mean_squared_error: 0.0146\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.0111\n",
      "Epoch 19: val_loss improved from 0.08399 to 0.08286, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0807 - mean_squared_error: 0.0111 - val_loss: 0.0829 - val_mean_squared_error: 0.0119\n",
      "Epoch 20/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0784 - mean_squared_error: 0.0105\n",
      "Epoch 20: val_loss did not improve from 0.08286\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.0784 - mean_squared_error: 0.0105 - val_loss: 0.0886 - val_mean_squared_error: 0.0138\n",
      "Epoch 21/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0788 - mean_squared_error: 0.0108\n",
      "Epoch 21: val_loss did not improve from 0.08286\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0788 - mean_squared_error: 0.0107 - val_loss: 0.0877 - val_mean_squared_error: 0.0133\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0786 - mean_squared_error: 0.0106\n",
      "Epoch 22: val_loss did not improve from 0.08286\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.0786 - mean_squared_error: 0.0106 - val_loss: 0.0839 - val_mean_squared_error: 0.0121\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1642 - mean_squared_error: 0.0450\n",
      "Epoch 1: val_loss improved from inf to 0.10774, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 5s 85ms/step - loss: 0.1642 - mean_squared_error: 0.0450 - val_loss: 0.1077 - val_mean_squared_error: 0.0195\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1297 - mean_squared_error: 0.0279\n",
      "Epoch 2: val_loss improved from 0.10774 to 0.10297, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1297 - mean_squared_error: 0.0278 - val_loss: 0.1030 - val_mean_squared_error: 0.0173\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1214 - mean_squared_error: 0.0245\n",
      "Epoch 3: val_loss improved from 0.10297 to 0.09686, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1213 - mean_squared_error: 0.0245 - val_loss: 0.0969 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1168 - mean_squared_error: 0.0224\n",
      "Epoch 4: val_loss did not improve from 0.09686\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1168 - mean_squared_error: 0.0224 - val_loss: 0.0999 - val_mean_squared_error: 0.0168\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1127 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss improved from 0.09686 to 0.09629, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1127 - mean_squared_error: 0.0210 - val_loss: 0.0963 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1106 - mean_squared_error: 0.0203\n",
      "Epoch 6: val_loss did not improve from 0.09629\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1106 - mean_squared_error: 0.0203 - val_loss: 0.0969 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0195\n",
      "Epoch 7: val_loss improved from 0.09629 to 0.09605, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1086 - mean_squared_error: 0.0195 - val_loss: 0.0961 - val_mean_squared_error: 0.0151\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0191\n",
      "Epoch 8: val_loss did not improve from 0.09605\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1075 - mean_squared_error: 0.0190 - val_loss: 0.0973 - val_mean_squared_error: 0.0157\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0185\n",
      "Epoch 9: val_loss did not improve from 0.09605\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1059 - mean_squared_error: 0.0185 - val_loss: 0.0966 - val_mean_squared_error: 0.0154\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0181\n",
      "Epoch 10: val_loss did not improve from 0.09605\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1050 - mean_squared_error: 0.0181 - val_loss: 0.0967 - val_mean_squared_error: 0.0154\n",
      "14/14 [==============================] - 1s 22ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1610 - mean_squared_error: 0.0434\n",
      "Epoch 1: val_loss improved from inf to 0.09960, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 5s 76ms/step - loss: 0.1610 - mean_squared_error: 0.0434 - val_loss: 0.0996 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1284 - mean_squared_error: 0.0269\n",
      "Epoch 2: val_loss improved from 0.09960 to 0.09716, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1285 - mean_squared_error: 0.0269 - val_loss: 0.0972 - val_mean_squared_error: 0.0161\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1204 - mean_squared_error: 0.0240\n",
      "Epoch 3: val_loss did not improve from 0.09716\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1204 - mean_squared_error: 0.0240 - val_loss: 0.0979 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1157 - mean_squared_error: 0.0220\n",
      "Epoch 4: val_loss improved from 0.09716 to 0.09702, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1157 - mean_squared_error: 0.0220 - val_loss: 0.0970 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1139 - mean_squared_error: 0.0214\n",
      "Epoch 5: val_loss improved from 0.09702 to 0.09684, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1139 - mean_squared_error: 0.0214 - val_loss: 0.0968 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1108 - mean_squared_error: 0.0201\n",
      "Epoch 6: val_loss improved from 0.09684 to 0.09646, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1108 - mean_squared_error: 0.0201 - val_loss: 0.0965 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1094 - mean_squared_error: 0.0197\n",
      "Epoch 7: val_loss improved from 0.09646 to 0.09538, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1094 - mean_squared_error: 0.0197 - val_loss: 0.0954 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0190\n",
      "Epoch 8: val_loss did not improve from 0.09538\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1076 - mean_squared_error: 0.0190 - val_loss: 0.0967 - val_mean_squared_error: 0.0156\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0188\n",
      "Epoch 9: val_loss did not improve from 0.09538\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1069 - mean_squared_error: 0.0188 - val_loss: 0.0963 - val_mean_squared_error: 0.0156\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1053 - mean_squared_error: 0.0182\n",
      "Epoch 10: val_loss did not improve from 0.09538\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1053 - mean_squared_error: 0.0182 - val_loss: 0.0955 - val_mean_squared_error: 0.0155\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1615 - mean_squared_error: 0.0437\n",
      "Epoch 1: val_loss improved from inf to 0.10475, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 4s 74ms/step - loss: 0.1615 - mean_squared_error: 0.0437 - val_loss: 0.1048 - val_mean_squared_error: 0.0181\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1279 - mean_squared_error: 0.0269\n",
      "Epoch 2: val_loss improved from 0.10475 to 0.09940, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1280 - mean_squared_error: 0.0270 - val_loss: 0.0994 - val_mean_squared_error: 0.0165\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1205 - mean_squared_error: 0.0241\n",
      "Epoch 3: val_loss improved from 0.09940 to 0.09805, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size9_pool5_do0.2_tra3_head8_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1206 - mean_squared_error: 0.0242 - val_loss: 0.0980 - val_mean_squared_error: 0.0160\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1149 - mean_squared_error: 0.0219\n",
      "Epoch 4: val_loss did not improve from 0.09805\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1149 - mean_squared_error: 0.0219 - val_loss: 0.0996 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1118 - mean_squared_error: 0.0205\n",
      "Epoch 5: val_loss did not improve from 0.09805\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1118 - mean_squared_error: 0.0206 - val_loss: 0.0985 - val_mean_squared_error: 0.0157\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0199\n",
      "Epoch 6: val_loss did not improve from 0.09805\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1099 - mean_squared_error: 0.0199 - val_loss: 0.0986 - val_mean_squared_error: 0.0159\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.39+-0.62\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2901 - mean_squared_error: 0.1161\n",
      "Epoch 1: val_loss improved from inf to 0.14258, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 18s 70ms/step - loss: 0.2901 - mean_squared_error: 0.1161 - val_loss: 0.1426 - val_mean_squared_error: 0.0321\n",
      "Epoch 2/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1974 - mean_squared_error: 0.0601\n",
      "Epoch 2: val_loss did not improve from 0.14258\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1974 - mean_squared_error: 0.0600 - val_loss: 0.2108 - val_mean_squared_error: 0.0585\n",
      "Epoch 3/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1580 - mean_squared_error: 0.0402\n",
      "Epoch 3: val_loss did not improve from 0.14258\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1580 - mean_squared_error: 0.0402 - val_loss: 0.1822 - val_mean_squared_error: 0.0447\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1316 - mean_squared_error: 0.0286\n",
      "Epoch 4: val_loss did not improve from 0.14258\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1316 - mean_squared_error: 0.0286 - val_loss: 0.1530 - val_mean_squared_error: 0.0325\n",
      "27/27 [==============================] - 2s 23ms/step\n",
      " ###0 fold : val mae 0.15###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2849 - mean_squared_error: 0.1129\n",
      "Epoch 1: val_loss improved from inf to 0.23979, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 7s 64ms/step - loss: 0.2849 - mean_squared_error: 0.1129 - val_loss: 0.2398 - val_mean_squared_error: 0.0746\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1836 - mean_squared_error: 0.0534\n",
      "Epoch 2: val_loss improved from 0.23979 to 0.13302, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1836 - mean_squared_error: 0.0534 - val_loss: 0.1330 - val_mean_squared_error: 0.0261\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1499 - mean_squared_error: 0.0369\n",
      "Epoch 3: val_loss did not improve from 0.13302\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1499 - mean_squared_error: 0.0369 - val_loss: 0.1934 - val_mean_squared_error: 0.0489\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1296 - mean_squared_error: 0.0278\n",
      "Epoch 4: val_loss did not improve from 0.13302\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1296 - mean_squared_error: 0.0278 - val_loss: 0.2072 - val_mean_squared_error: 0.0552\n",
      "Epoch 5/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1189 - mean_squared_error: 0.0234\n",
      "Epoch 5: val_loss did not improve from 0.13302\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1189 - mean_squared_error: 0.0234 - val_loss: 0.1853 - val_mean_squared_error: 0.0450\n",
      "27/27 [==============================] - 1s 22ms/step\n",
      " ###1 fold : val mae 0.14###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2822 - mean_squared_error: 0.1112\n",
      "Epoch 1: val_loss improved from inf to 0.43952, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 7s 65ms/step - loss: 0.2822 - mean_squared_error: 0.1112 - val_loss: 0.4395 - val_mean_squared_error: 0.2120\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1807 - mean_squared_error: 0.0516\n",
      "Epoch 2: val_loss improved from 0.43952 to 0.25730, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 5s 63ms/step - loss: 0.1807 - mean_squared_error: 0.0516 - val_loss: 0.2573 - val_mean_squared_error: 0.0813\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1476 - mean_squared_error: 0.0354\n",
      "Epoch 3: val_loss improved from 0.25730 to 0.24028, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1476 - mean_squared_error: 0.0354 - val_loss: 0.2403 - val_mean_squared_error: 0.0717\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1294 - mean_squared_error: 0.0275\n",
      "Epoch 4: val_loss improved from 0.24028 to 0.20516, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1294 - mean_squared_error: 0.0275 - val_loss: 0.2052 - val_mean_squared_error: 0.0541\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1189 - mean_squared_error: 0.0231\n",
      "Epoch 5: val_loss improved from 0.20516 to 0.16187, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1189 - mean_squared_error: 0.0231 - val_loss: 0.1619 - val_mean_squared_error: 0.0355\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1136 - mean_squared_error: 0.0213\n",
      "Epoch 6: val_loss improved from 0.16187 to 0.15583, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1136 - mean_squared_error: 0.0213 - val_loss: 0.1558 - val_mean_squared_error: 0.0327\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0201\n",
      "Epoch 7: val_loss improved from 0.15583 to 0.14886, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1109 - mean_squared_error: 0.0201 - val_loss: 0.1489 - val_mean_squared_error: 0.0299\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0197\n",
      "Epoch 8: val_loss did not improve from 0.14886\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1101 - mean_squared_error: 0.0197 - val_loss: 0.1524 - val_mean_squared_error: 0.0313\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0194\n",
      "Epoch 9: val_loss did not improve from 0.14886\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1092 - mean_squared_error: 0.0194 - val_loss: 0.1528 - val_mean_squared_error: 0.0313\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0194\n",
      "Epoch 10: val_loss did not improve from 0.14886\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1092 - mean_squared_error: 0.0194 - val_loss: 0.1493 - val_mean_squared_error: 0.0301\n",
      "27/27 [==============================] - 2s 22ms/step\n",
      " ###2 fold : val mae 0.15###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2882 - mean_squared_error: 0.1158\n",
      "Epoch 1: val_loss improved from inf to 0.37470, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 9s 66ms/step - loss: 0.2882 - mean_squared_error: 0.1158 - val_loss: 0.3747 - val_mean_squared_error: 0.1609\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1803 - mean_squared_error: 0.0511\n",
      "Epoch 2: val_loss improved from 0.37470 to 0.30600, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1803 - mean_squared_error: 0.0511 - val_loss: 0.3060 - val_mean_squared_error: 0.1106\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1466 - mean_squared_error: 0.0352\n",
      "Epoch 3: val_loss improved from 0.30600 to 0.23073, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1466 - mean_squared_error: 0.0352 - val_loss: 0.2307 - val_mean_squared_error: 0.0680\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1273 - mean_squared_error: 0.0265\n",
      "Epoch 4: val_loss improved from 0.23073 to 0.22442, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1273 - mean_squared_error: 0.0265 - val_loss: 0.2244 - val_mean_squared_error: 0.0641\n",
      "Epoch 5/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1163 - mean_squared_error: 0.0223\n",
      "Epoch 5: val_loss improved from 0.22442 to 0.21888, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1163 - mean_squared_error: 0.0223 - val_loss: 0.2189 - val_mean_squared_error: 0.0612\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0204\n",
      "Epoch 6: val_loss improved from 0.21888 to 0.19072, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1116 - mean_squared_error: 0.0204 - val_loss: 0.1907 - val_mean_squared_error: 0.0476\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0201\n",
      "Epoch 7: val_loss improved from 0.19072 to 0.18491, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.1109 - mean_squared_error: 0.0201 - val_loss: 0.1849 - val_mean_squared_error: 0.0449\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1088 - mean_squared_error: 0.0194\n",
      "Epoch 8: val_loss did not improve from 0.18491\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1088 - mean_squared_error: 0.0194 - val_loss: 0.1910 - val_mean_squared_error: 0.0477\n",
      "Epoch 9/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0190\n",
      "Epoch 9: val_loss did not improve from 0.18491\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1074 - mean_squared_error: 0.0190 - val_loss: 0.1878 - val_mean_squared_error: 0.0464\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0193\n",
      "Epoch 10: val_loss improved from 0.18491 to 0.16413, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1083 - mean_squared_error: 0.0193 - val_loss: 0.1641 - val_mean_squared_error: 0.0362\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1087 - mean_squared_error: 0.0193\n",
      "Epoch 11: val_loss did not improve from 0.16413\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1087 - mean_squared_error: 0.0193 - val_loss: 0.1651 - val_mean_squared_error: 0.0365\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0190\n",
      "Epoch 12: val_loss improved from 0.16413 to 0.15538, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1076 - mean_squared_error: 0.0190 - val_loss: 0.1554 - val_mean_squared_error: 0.0327\n",
      "Epoch 13/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0188\n",
      "Epoch 13: val_loss did not improve from 0.15538\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1066 - mean_squared_error: 0.0188 - val_loss: 0.1569 - val_mean_squared_error: 0.0333\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0188\n",
      "Epoch 14: val_loss improved from 0.15538 to 0.14484, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt128_stride5_size11_pool2_do0.5_tra5_head4_kdim128_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1071 - mean_squared_error: 0.0188 - val_loss: 0.1448 - val_mean_squared_error: 0.0290\n",
      "Epoch 15/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0189\n",
      "Epoch 15: val_loss did not improve from 0.14484\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1071 - mean_squared_error: 0.0189 - val_loss: 0.1554 - val_mean_squared_error: 0.0327\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0191\n",
      "Epoch 16: val_loss did not improve from 0.14484\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1075 - mean_squared_error: 0.0191 - val_loss: 0.1657 - val_mean_squared_error: 0.0367\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0188\n",
      "Epoch 17: val_loss did not improve from 0.14484\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1070 - mean_squared_error: 0.0188 - val_loss: 0.1514 - val_mean_squared_error: 0.0315\n",
      "27/27 [==============================] - 1s 22ms/step\n",
      " ###3 fold : val mae 0.14###\n",
      "mae14.40+-0.53\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3177 - mean_squared_error: 0.1350\n",
      "Epoch 1: val_loss improved from inf to 0.20261, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 16s 56ms/step - loss: 0.3177 - mean_squared_error: 0.1350 - val_loss: 0.2026 - val_mean_squared_error: 0.0571\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2635 - mean_squared_error: 0.0980\n",
      "Epoch 2: val_loss improved from 0.20261 to 0.15841, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.2635 - mean_squared_error: 0.0980 - val_loss: 0.1584 - val_mean_squared_error: 0.0374\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2219 - mean_squared_error: 0.0734\n",
      "Epoch 3: val_loss improved from 0.15841 to 0.13388, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.2219 - mean_squared_error: 0.0734 - val_loss: 0.1339 - val_mean_squared_error: 0.0282\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1760 - mean_squared_error: 0.0488\n",
      "Epoch 4: val_loss improved from 0.13388 to 0.10383, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1760 - mean_squared_error: 0.0488 - val_loss: 0.1038 - val_mean_squared_error: 0.0180\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1395 - mean_squared_error: 0.0316\n",
      "Epoch 5: val_loss improved from 0.10383 to 0.10324, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1395 - mean_squared_error: 0.0316 - val_loss: 0.1032 - val_mean_squared_error: 0.0176\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1219 - mean_squared_error: 0.0240\n",
      "Epoch 6: val_loss did not improve from 0.10324\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1219 - mean_squared_error: 0.0240 - val_loss: 0.1038 - val_mean_squared_error: 0.0176\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1152 - mean_squared_error: 0.0216\n",
      "Epoch 7: val_loss did not improve from 0.10324\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1152 - mean_squared_error: 0.0216 - val_loss: 0.1058 - val_mean_squared_error: 0.0189\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0207\n",
      "Epoch 8: val_loss did not improve from 0.10324\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1119 - mean_squared_error: 0.0207 - val_loss: 0.1045 - val_mean_squared_error: 0.0182\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3125 - mean_squared_error: 0.1312\n",
      "Epoch 1: val_loss improved from inf to 0.22521, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 6s 54ms/step - loss: 0.3125 - mean_squared_error: 0.1312 - val_loss: 0.2252 - val_mean_squared_error: 0.0662\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2672 - mean_squared_error: 0.0998\n",
      "Epoch 2: val_loss improved from 0.22521 to 0.20415, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.2672 - mean_squared_error: 0.0998 - val_loss: 0.2042 - val_mean_squared_error: 0.0549\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2200 - mean_squared_error: 0.0722\n",
      "Epoch 3: val_loss improved from 0.20415 to 0.14088, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.2200 - mean_squared_error: 0.0722 - val_loss: 0.1409 - val_mean_squared_error: 0.0308\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1754 - mean_squared_error: 0.0483\n",
      "Epoch 4: val_loss improved from 0.14088 to 0.11009, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1754 - mean_squared_error: 0.0483 - val_loss: 0.1101 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1412 - mean_squared_error: 0.0322\n",
      "Epoch 5: val_loss improved from 0.11009 to 0.10195, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1412 - mean_squared_error: 0.0322 - val_loss: 0.1020 - val_mean_squared_error: 0.0176\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1263 - mean_squared_error: 0.0257\n",
      "Epoch 6: val_loss improved from 0.10195 to 0.10063, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1263 - mean_squared_error: 0.0257 - val_loss: 0.1006 - val_mean_squared_error: 0.0170\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1180 - mean_squared_error: 0.0223\n",
      "Epoch 7: val_loss did not improve from 0.10063\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1180 - mean_squared_error: 0.0223 - val_loss: 0.1008 - val_mean_squared_error: 0.0171\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.0211\n",
      "Epoch 8: val_loss improved from 0.10063 to 0.10022, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1137 - mean_squared_error: 0.0211 - val_loss: 0.1002 - val_mean_squared_error: 0.0168\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0203\n",
      "Epoch 9: val_loss did not improve from 0.10022\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1116 - mean_squared_error: 0.0203 - val_loss: 0.1008 - val_mean_squared_error: 0.0172\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0199\n",
      "Epoch 10: val_loss did not improve from 0.10022\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1109 - mean_squared_error: 0.0199 - val_loss: 0.1011 - val_mean_squared_error: 0.0173\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0198\n",
      "Epoch 11: val_loss did not improve from 0.10022\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1099 - mean_squared_error: 0.0198 - val_loss: 0.1002 - val_mean_squared_error: 0.0168\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3181 - mean_squared_error: 0.1346\n",
      "Epoch 1: val_loss improved from inf to 0.31399, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 6s 54ms/step - loss: 0.3181 - mean_squared_error: 0.1346 - val_loss: 0.3140 - val_mean_squared_error: 0.1163\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2660 - mean_squared_error: 0.0990\n",
      "Epoch 2: val_loss improved from 0.31399 to 0.20454, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.2660 - mean_squared_error: 0.0990 - val_loss: 0.2045 - val_mean_squared_error: 0.0561\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2138 - mean_squared_error: 0.0688\n",
      "Epoch 3: val_loss improved from 0.20454 to 0.13054, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.2138 - mean_squared_error: 0.0688 - val_loss: 0.1305 - val_mean_squared_error: 0.0277\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1623 - mean_squared_error: 0.0421\n",
      "Epoch 4: val_loss improved from 0.13054 to 0.10207, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1623 - mean_squared_error: 0.0421 - val_loss: 0.1021 - val_mean_squared_error: 0.0181\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1350 - mean_squared_error: 0.0294\n",
      "Epoch 5: val_loss improved from 0.10207 to 0.10059, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1350 - mean_squared_error: 0.0294 - val_loss: 0.1006 - val_mean_squared_error: 0.0173\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1197 - mean_squared_error: 0.0233\n",
      "Epoch 6: val_loss did not improve from 0.10059\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1197 - mean_squared_error: 0.0233 - val_loss: 0.1022 - val_mean_squared_error: 0.0180\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0212\n",
      "Epoch 7: val_loss did not improve from 0.10059\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1145 - mean_squared_error: 0.0212 - val_loss: 0.1017 - val_mean_squared_error: 0.0175\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.0205\n",
      "Epoch 8: val_loss did not improve from 0.10059\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1124 - mean_squared_error: 0.0205 - val_loss: 0.1017 - val_mean_squared_error: 0.0177\n",
      "27/27 [==============================] - 1s 16ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3143 - mean_squared_error: 0.1319\n",
      "Epoch 1: val_loss improved from inf to 0.21630, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 6s 54ms/step - loss: 0.3143 - mean_squared_error: 0.1319 - val_loss: 0.2163 - val_mean_squared_error: 0.0633\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2592 - mean_squared_error: 0.0947\n",
      "Epoch 2: val_loss improved from 0.21630 to 0.17001, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.2592 - mean_squared_error: 0.0947 - val_loss: 0.1700 - val_mean_squared_error: 0.0416\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2083 - mean_squared_error: 0.0659\n",
      "Epoch 3: val_loss improved from 0.17001 to 0.12474, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.2083 - mean_squared_error: 0.0659 - val_loss: 0.1247 - val_mean_squared_error: 0.0252\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1627 - mean_squared_error: 0.0424\n",
      "Epoch 4: val_loss improved from 0.12474 to 0.10775, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1627 - mean_squared_error: 0.0424 - val_loss: 0.1077 - val_mean_squared_error: 0.0200\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1312 - mean_squared_error: 0.0279\n",
      "Epoch 5: val_loss improved from 0.10775 to 0.10379, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn4_filt32_stride5_size7_pool2_do0.5_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1312 - mean_squared_error: 0.0279 - val_loss: 0.1038 - val_mean_squared_error: 0.0185\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1191 - mean_squared_error: 0.0231\n",
      "Epoch 6: val_loss did not improve from 0.10379\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1191 - mean_squared_error: 0.0231 - val_loss: 0.1038 - val_mean_squared_error: 0.0184\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0211\n",
      "Epoch 7: val_loss did not improve from 0.10379\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1145 - mean_squared_error: 0.0211 - val_loss: 0.1042 - val_mean_squared_error: 0.0185\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0203\n",
      "Epoch 8: val_loss did not improve from 0.10379\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1116 - mean_squared_error: 0.0203 - val_loss: 0.1044 - val_mean_squared_error: 0.0185\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae10.27+-0.09\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1794 - mean_squared_error: 0.0517\n",
      "Epoch 1: val_loss improved from inf to 0.10424, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 12s 77ms/step - loss: 0.1793 - mean_squared_error: 0.0517 - val_loss: 0.1042 - val_mean_squared_error: 0.0179\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1344 - mean_squared_error: 0.0295\n",
      "Epoch 2: val_loss improved from 0.10424 to 0.10223, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1344 - mean_squared_error: 0.0295 - val_loss: 0.1022 - val_mean_squared_error: 0.0176\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1256 - mean_squared_error: 0.0262\n",
      "Epoch 3: val_loss improved from 0.10223 to 0.09864, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1257 - mean_squared_error: 0.0262 - val_loss: 0.0986 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1194 - mean_squared_error: 0.0237\n",
      "Epoch 4: val_loss did not improve from 0.09864\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1194 - mean_squared_error: 0.0237 - val_loss: 0.0991 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1176 - mean_squared_error: 0.0228\n",
      "Epoch 5: val_loss did not improve from 0.09864\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1177 - mean_squared_error: 0.0229 - val_loss: 0.0987 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1130 - mean_squared_error: 0.0213\n",
      "Epoch 6: val_loss did not improve from 0.09864\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1130 - mean_squared_error: 0.0213 - val_loss: 0.1044 - val_mean_squared_error: 0.0171\n",
      "14/14 [==============================] - 1s 22ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1761 - mean_squared_error: 0.0502\n",
      "Epoch 1: val_loss improved from inf to 0.10811, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 4s 65ms/step - loss: 0.1760 - mean_squared_error: 0.0501 - val_loss: 0.1081 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1310 - mean_squared_error: 0.0282\n",
      "Epoch 2: val_loss improved from 0.10811 to 0.10128, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1309 - mean_squared_error: 0.0281 - val_loss: 0.1013 - val_mean_squared_error: 0.0171\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1242 - mean_squared_error: 0.0257\n",
      "Epoch 3: val_loss improved from 0.10128 to 0.09973, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1243 - mean_squared_error: 0.0257 - val_loss: 0.0997 - val_mean_squared_error: 0.0166\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1192 - mean_squared_error: 0.0232\n",
      "Epoch 4: val_loss improved from 0.09973 to 0.09838, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1192 - mean_squared_error: 0.0232 - val_loss: 0.0984 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1163 - mean_squared_error: 0.0225\n",
      "Epoch 5: val_loss improved from 0.09838 to 0.09770, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1162 - mean_squared_error: 0.0224 - val_loss: 0.0977 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1135 - mean_squared_error: 0.0213\n",
      "Epoch 6: val_loss did not improve from 0.09770\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1135 - mean_squared_error: 0.0213 - val_loss: 0.0992 - val_mean_squared_error: 0.0164\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1117 - mean_squared_error: 0.0206\n",
      "Epoch 7: val_loss improved from 0.09770 to 0.09669, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1116 - mean_squared_error: 0.0206 - val_loss: 0.0967 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0195\n",
      "Epoch 8: val_loss improved from 0.09669 to 0.09607, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1091 - mean_squared_error: 0.0195 - val_loss: 0.0961 - val_mean_squared_error: 0.0151\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0192\n",
      "Epoch 9: val_loss did not improve from 0.09607\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1082 - mean_squared_error: 0.0192 - val_loss: 0.0976 - val_mean_squared_error: 0.0152\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0186\n",
      "Epoch 10: val_loss did not improve from 0.09607\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1066 - mean_squared_error: 0.0186 - val_loss: 0.0962 - val_mean_squared_error: 0.0150\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0188\n",
      "Epoch 11: val_loss did not improve from 0.09607\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1070 - mean_squared_error: 0.0188 - val_loss: 0.0972 - val_mean_squared_error: 0.0153\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1748 - mean_squared_error: 0.0494\n",
      "Epoch 1: val_loss improved from inf to 0.10000, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 4s 68ms/step - loss: 0.1746 - mean_squared_error: 0.0493 - val_loss: 0.1000 - val_mean_squared_error: 0.0170\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1307 - mean_squared_error: 0.0278\n",
      "Epoch 2: val_loss improved from 0.10000 to 0.09633, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1307 - mean_squared_error: 0.0278 - val_loss: 0.0963 - val_mean_squared_error: 0.0157\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1219 - mean_squared_error: 0.0246\n",
      "Epoch 3: val_loss did not improve from 0.09633\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1219 - mean_squared_error: 0.0246 - val_loss: 0.0967 - val_mean_squared_error: 0.0160\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1185 - mean_squared_error: 0.0231\n",
      "Epoch 4: val_loss did not improve from 0.09633\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1184 - mean_squared_error: 0.0231 - val_loss: 0.0973 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1141 - mean_squared_error: 0.0213\n",
      "Epoch 5: val_loss did not improve from 0.09633\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1142 - mean_squared_error: 0.0213 - val_loss: 0.0982 - val_mean_squared_error: 0.0157\n",
      "14/14 [==============================] - 1s 21ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1670 - mean_squared_error: 0.0460\n",
      "Epoch 1: val_loss improved from inf to 0.10152, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 4s 69ms/step - loss: 0.1670 - mean_squared_error: 0.0460 - val_loss: 0.1015 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1298 - mean_squared_error: 0.0276\n",
      "Epoch 2: val_loss improved from 0.10152 to 0.10146, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt32_stride5_size9_pool5_do0.2_tra3_head8_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1297 - mean_squared_error: 0.0276 - val_loss: 0.1015 - val_mean_squared_error: 0.0166\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1204 - mean_squared_error: 0.0237\n",
      "Epoch 3: val_loss did not improve from 0.10146\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1204 - mean_squared_error: 0.0237 - val_loss: 0.1015 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1177 - mean_squared_error: 0.0230\n",
      "Epoch 4: val_loss did not improve from 0.10146\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1178 - mean_squared_error: 0.0230 - val_loss: 0.1027 - val_mean_squared_error: 0.0165\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1140 - mean_squared_error: 0.0215\n",
      "Epoch 5: val_loss did not improve from 0.10146\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1139 - mean_squared_error: 0.0215 - val_loss: 0.1015 - val_mean_squared_error: 0.0162\n",
      "14/14 [==============================] - 1s 21ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.90+-0.17\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2485 - mean_squared_error: 0.0918\n",
      "Epoch 1: val_loss improved from inf to 0.12724, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 14s 35ms/step - loss: 0.2485 - mean_squared_error: 0.0918 - val_loss: 0.1272 - val_mean_squared_error: 0.0244\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1761 - mean_squared_error: 0.0500\n",
      "Epoch 2: val_loss improved from 0.12724 to 0.12615, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1761 - mean_squared_error: 0.0499 - val_loss: 0.1262 - val_mean_squared_error: 0.0232\n",
      "Epoch 3/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1335 - mean_squared_error: 0.0297\n",
      "Epoch 3: val_loss did not improve from 0.12615\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1335 - mean_squared_error: 0.0297 - val_loss: 0.1297 - val_mean_squared_error: 0.0239\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1175 - mean_squared_error: 0.0225\n",
      "Epoch 4: val_loss improved from 0.12615 to 0.11999, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1175 - mean_squared_error: 0.0225 - val_loss: 0.1200 - val_mean_squared_error: 0.0205\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss improved from 0.11999 to 0.11511, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1119 - mean_squared_error: 0.0206 - val_loss: 0.1151 - val_mean_squared_error: 0.0191\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0197\n",
      "Epoch 6: val_loss improved from 0.11511 to 0.11495, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1098 - mean_squared_error: 0.0197 - val_loss: 0.1150 - val_mean_squared_error: 0.0191\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1091 - mean_squared_error: 0.0195\n",
      "Epoch 7: val_loss improved from 0.11495 to 0.10790, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1092 - mean_squared_error: 0.0195 - val_loss: 0.1079 - val_mean_squared_error: 0.0173\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0190\n",
      "Epoch 8: val_loss improved from 0.10790 to 0.10429, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1076 - mean_squared_error: 0.0190 - val_loss: 0.1043 - val_mean_squared_error: 0.0166\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0190\n",
      "Epoch 9: val_loss improved from 0.10429 to 0.10209, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1073 - mean_squared_error: 0.0190 - val_loss: 0.1021 - val_mean_squared_error: 0.0159\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0183\n",
      "Epoch 10: val_loss did not improve from 0.10209\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1053 - mean_squared_error: 0.0183 - val_loss: 0.1031 - val_mean_squared_error: 0.0161\n",
      "Epoch 11/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0177\n",
      "Epoch 11: val_loss improved from 0.10209 to 0.09957, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1042 - mean_squared_error: 0.0178 - val_loss: 0.0996 - val_mean_squared_error: 0.0153\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0175\n",
      "Epoch 12: val_loss improved from 0.09957 to 0.09611, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1035 - mean_squared_error: 0.0175 - val_loss: 0.0961 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1019 - mean_squared_error: 0.0171\n",
      "Epoch 13: val_loss did not improve from 0.09611\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1019 - mean_squared_error: 0.0171 - val_loss: 0.0973 - val_mean_squared_error: 0.0149\n",
      "Epoch 14/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1000 - mean_squared_error: 0.0165\n",
      "Epoch 14: val_loss improved from 0.09611 to 0.09255, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0999 - mean_squared_error: 0.0164 - val_loss: 0.0926 - val_mean_squared_error: 0.0137\n",
      "Epoch 15/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.0161\n",
      "Epoch 15: val_loss did not improve from 0.09255\n",
      "157/157 [==============================] - 4s 27ms/step - loss: 0.0989 - mean_squared_error: 0.0161 - val_loss: 0.0957 - val_mean_squared_error: 0.0142\n",
      "Epoch 16/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0975 - mean_squared_error: 0.0157\n",
      "Epoch 16: val_loss improved from 0.09255 to 0.08996, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.0974 - mean_squared_error: 0.0157 - val_loss: 0.0900 - val_mean_squared_error: 0.0133\n",
      "Epoch 17/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0967 - mean_squared_error: 0.0154\n",
      "Epoch 17: val_loss did not improve from 0.08996\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0967 - mean_squared_error: 0.0154 - val_loss: 0.0921 - val_mean_squared_error: 0.0139\n",
      "Epoch 18/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0955 - mean_squared_error: 0.0151\n",
      "Epoch 18: val_loss did not improve from 0.08996\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0955 - mean_squared_error: 0.0151 - val_loss: 0.0938 - val_mean_squared_error: 0.0148\n",
      "Epoch 19/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0955 - mean_squared_error: 0.0150\n",
      "Epoch 19: val_loss did not improve from 0.08996\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0955 - mean_squared_error: 0.0150 - val_loss: 0.0934 - val_mean_squared_error: 0.0136\n",
      "53/53 [==============================] - 1s 10ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2342 - mean_squared_error: 0.0824\n",
      "Epoch 1: val_loss improved from inf to 0.14247, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 34ms/step - loss: 0.2342 - mean_squared_error: 0.0824 - val_loss: 0.1425 - val_mean_squared_error: 0.0317\n",
      "Epoch 2/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1701 - mean_squared_error: 0.0473\n",
      "Epoch 2: val_loss improved from 0.14247 to 0.13348, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1698 - mean_squared_error: 0.0472 - val_loss: 0.1335 - val_mean_squared_error: 0.0264\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1385 - mean_squared_error: 0.0316\n",
      "Epoch 3: val_loss improved from 0.13348 to 0.12518, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1385 - mean_squared_error: 0.0316 - val_loss: 0.1252 - val_mean_squared_error: 0.0227\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1223 - mean_squared_error: 0.0242\n",
      "Epoch 4: val_loss did not improve from 0.12518\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1222 - mean_squared_error: 0.0242 - val_loss: 0.1287 - val_mean_squared_error: 0.0236\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1151 - mean_squared_error: 0.0217\n",
      "Epoch 5: val_loss improved from 0.12518 to 0.12408, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1151 - mean_squared_error: 0.0217 - val_loss: 0.1241 - val_mean_squared_error: 0.0221\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1123 - mean_squared_error: 0.0207\n",
      "Epoch 6: val_loss improved from 0.12408 to 0.12167, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1123 - mean_squared_error: 0.0207 - val_loss: 0.1217 - val_mean_squared_error: 0.0214\n",
      "Epoch 7/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1104 - mean_squared_error: 0.0199\n",
      "Epoch 7: val_loss improved from 0.12167 to 0.11925, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1105 - mean_squared_error: 0.0199 - val_loss: 0.1192 - val_mean_squared_error: 0.0206\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1091 - mean_squared_error: 0.0193\n",
      "Epoch 8: val_loss improved from 0.11925 to 0.11027, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1091 - mean_squared_error: 0.0193 - val_loss: 0.1103 - val_mean_squared_error: 0.0182\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1088 - mean_squared_error: 0.0193\n",
      "Epoch 9: val_loss improved from 0.11027 to 0.10871, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1088 - mean_squared_error: 0.0193 - val_loss: 0.1087 - val_mean_squared_error: 0.0178\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1089 - mean_squared_error: 0.0195\n",
      "Epoch 10: val_loss improved from 0.10871 to 0.10384, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1089 - mean_squared_error: 0.0195 - val_loss: 0.1038 - val_mean_squared_error: 0.0167\n",
      "Epoch 11/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0192\n",
      "Epoch 11: val_loss did not improve from 0.10384\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1085 - mean_squared_error: 0.0193 - val_loss: 0.1080 - val_mean_squared_error: 0.0176\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0191\n",
      "Epoch 12: val_loss did not improve from 0.10384\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1082 - mean_squared_error: 0.0191 - val_loss: 0.1055 - val_mean_squared_error: 0.0171\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0193\n",
      "Epoch 13: val_loss did not improve from 0.10384\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1079 - mean_squared_error: 0.0193 - val_loss: 0.1057 - val_mean_squared_error: 0.0170\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.11###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2309 - mean_squared_error: 0.0811\n",
      "Epoch 1: val_loss improved from inf to 0.12545, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 35ms/step - loss: 0.2309 - mean_squared_error: 0.0811 - val_loss: 0.1255 - val_mean_squared_error: 0.0233\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1603 - mean_squared_error: 0.0416\n",
      "Epoch 2: val_loss improved from 0.12545 to 0.12257, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1601 - mean_squared_error: 0.0416 - val_loss: 0.1226 - val_mean_squared_error: 0.0220\n",
      "Epoch 3/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1238 - mean_squared_error: 0.0253\n",
      "Epoch 3: val_loss did not improve from 0.12257\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1237 - mean_squared_error: 0.0252 - val_loss: 0.1335 - val_mean_squared_error: 0.0246\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1139 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss did not improve from 0.12257\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1139 - mean_squared_error: 0.0210 - val_loss: 0.1280 - val_mean_squared_error: 0.0228\n",
      "Epoch 5/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0197\n",
      "Epoch 5: val_loss did not improve from 0.12257\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1098 - mean_squared_error: 0.0198 - val_loss: 0.1280 - val_mean_squared_error: 0.0229\n",
      "53/53 [==============================] - 1s 10ms/step\n",
      " ###2 fold : val mae 0.13###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2315 - mean_squared_error: 0.0816\n",
      "Epoch 1: val_loss improved from inf to 0.17776, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 7s 35ms/step - loss: 0.2313 - mean_squared_error: 0.0815 - val_loss: 0.1778 - val_mean_squared_error: 0.0440\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1618 - mean_squared_error: 0.0433\n",
      "Epoch 2: val_loss improved from 0.17776 to 0.13811, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1618 - mean_squared_error: 0.0433 - val_loss: 0.1381 - val_mean_squared_error: 0.0271\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1252 - mean_squared_error: 0.0259\n",
      "Epoch 3: val_loss improved from 0.13811 to 0.12862, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1252 - mean_squared_error: 0.0259 - val_loss: 0.1286 - val_mean_squared_error: 0.0235\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1142 - mean_squared_error: 0.0213\n",
      "Epoch 4: val_loss improved from 0.12862 to 0.12690, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1142 - mean_squared_error: 0.0213 - val_loss: 0.1269 - val_mean_squared_error: 0.0227\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0197\n",
      "Epoch 5: val_loss improved from 0.12690 to 0.12382, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1098 - mean_squared_error: 0.0197 - val_loss: 0.1238 - val_mean_squared_error: 0.0217\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1094 - mean_squared_error: 0.0196\n",
      "Epoch 6: val_loss improved from 0.12382 to 0.11843, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1094 - mean_squared_error: 0.0196 - val_loss: 0.1184 - val_mean_squared_error: 0.0202\n",
      "Epoch 7/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1085 - mean_squared_error: 0.0192\n",
      "Epoch 7: val_loss improved from 0.11843 to 0.11557, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1086 - mean_squared_error: 0.0192 - val_loss: 0.1156 - val_mean_squared_error: 0.0194\n",
      "Epoch 8/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0191\n",
      "Epoch 8: val_loss improved from 0.11557 to 0.11328, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1077 - mean_squared_error: 0.0191 - val_loss: 0.1133 - val_mean_squared_error: 0.0188\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0193\n",
      "Epoch 9: val_loss improved from 0.11328 to 0.11049, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1080 - mean_squared_error: 0.0193 - val_loss: 0.1105 - val_mean_squared_error: 0.0181\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0190\n",
      "Epoch 10: val_loss did not improve from 0.11049\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1077 - mean_squared_error: 0.0190 - val_loss: 0.1119 - val_mean_squared_error: 0.0185\n",
      "Epoch 11/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0189\n",
      "Epoch 11: val_loss improved from 0.11049 to 0.10928, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1073 - mean_squared_error: 0.0189 - val_loss: 0.1093 - val_mean_squared_error: 0.0178\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0190\n",
      "Epoch 12: val_loss did not improve from 0.10928\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1077 - mean_squared_error: 0.0190 - val_loss: 0.1100 - val_mean_squared_error: 0.0180\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0189\n",
      "Epoch 13: val_loss improved from 0.10928 to 0.10891, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1070 - mean_squared_error: 0.0188 - val_loss: 0.1089 - val_mean_squared_error: 0.0177\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0190\n",
      "Epoch 14: val_loss improved from 0.10891 to 0.10663, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1073 - mean_squared_error: 0.0190 - val_loss: 0.1066 - val_mean_squared_error: 0.0173\n",
      "Epoch 15/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0188\n",
      "Epoch 15: val_loss improved from 0.10663 to 0.10505, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1069 - mean_squared_error: 0.0188 - val_loss: 0.1051 - val_mean_squared_error: 0.0170\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 16: val_loss did not improve from 0.10505\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1072 - mean_squared_error: 0.0189 - val_loss: 0.1081 - val_mean_squared_error: 0.0176\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0188\n",
      "Epoch 17: val_loss improved from 0.10505 to 0.10345, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1064 - mean_squared_error: 0.0188 - val_loss: 0.1035 - val_mean_squared_error: 0.0167\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0185\n",
      "Epoch 18: val_loss did not improve from 0.10345\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1069 - mean_squared_error: 0.0185 - val_loss: 0.1048 - val_mean_squared_error: 0.0169\n",
      "Epoch 19/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0185\n",
      "Epoch 19: val_loss improved from 0.10345 to 0.10179, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size7_pool2_do0.5_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1067 - mean_squared_error: 0.0186 - val_loss: 0.1018 - val_mean_squared_error: 0.0164\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 20: val_loss did not improve from 0.10179\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.1072 - mean_squared_error: 0.0189 - val_loss: 0.1037 - val_mean_squared_error: 0.0167\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0189\n",
      "Epoch 21: val_loss did not improve from 0.10179\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1069 - mean_squared_error: 0.0189 - val_loss: 0.1035 - val_mean_squared_error: 0.0168\n",
      "Epoch 22/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0189\n",
      "Epoch 22: val_loss did not improve from 0.10179\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1070 - mean_squared_error: 0.0189 - val_loss: 0.1040 - val_mean_squared_error: 0.0169\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae10.56+-1.32\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3739 - mean_squared_error: 0.1900\n",
      "Epoch 1: val_loss improved from inf to 0.22446, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 17s 64ms/step - loss: 0.3739 - mean_squared_error: 0.1900 - val_loss: 0.2245 - val_mean_squared_error: 0.0668\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1296 - mean_squared_error: 0.0277\n",
      "Epoch 2: val_loss improved from 0.22446 to 0.11458, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1296 - mean_squared_error: 0.0277 - val_loss: 0.1146 - val_mean_squared_error: 0.0214\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1133 - mean_squared_error: 0.0212\n",
      "Epoch 3: val_loss improved from 0.11458 to 0.09843, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1133 - mean_squared_error: 0.0212 - val_loss: 0.0984 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.0198\n",
      "Epoch 4: val_loss did not improve from 0.09843\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1093 - mean_squared_error: 0.0198 - val_loss: 0.1007 - val_mean_squared_error: 0.0167\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0188\n",
      "Epoch 5: val_loss improved from 0.09843 to 0.09800, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1061 - mean_squared_error: 0.0188 - val_loss: 0.0980 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0183\n",
      "Epoch 6: val_loss improved from 0.09800 to 0.09781, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1054 - mean_squared_error: 0.0183 - val_loss: 0.0978 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0177\n",
      "Epoch 7: val_loss improved from 0.09781 to 0.09717, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1032 - mean_squared_error: 0.0177 - val_loss: 0.0972 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0173\n",
      "Epoch 8: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.1027 - mean_squared_error: 0.0173 - val_loss: 0.0972 - val_mean_squared_error: 0.0152\n",
      "Epoch 9/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0177\n",
      "Epoch 9: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.1034 - mean_squared_error: 0.0177 - val_loss: 0.0972 - val_mean_squared_error: 0.0154\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.0171\n",
      "Epoch 10: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1017 - mean_squared_error: 0.0171 - val_loss: 0.0979 - val_mean_squared_error: 0.0157\n",
      "27/27 [==============================] - 1s 20ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2029 - mean_squared_error: 0.0763\n",
      "Epoch 1: val_loss improved from inf to 0.10317, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 7s 61ms/step - loss: 0.2029 - mean_squared_error: 0.0763 - val_loss: 0.1032 - val_mean_squared_error: 0.0176\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1168 - mean_squared_error: 0.0225\n",
      "Epoch 2: val_loss did not improve from 0.10317\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.1168 - mean_squared_error: 0.0225 - val_loss: 0.1036 - val_mean_squared_error: 0.0177\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0198\n",
      "Epoch 3: val_loss improved from 0.10317 to 0.09717, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1098 - mean_squared_error: 0.0198 - val_loss: 0.0972 - val_mean_squared_error: 0.0155\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1095 - mean_squared_error: 0.0197\n",
      "Epoch 4: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1095 - mean_squared_error: 0.0197 - val_loss: 0.1003 - val_mean_squared_error: 0.0167\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0188\n",
      "Epoch 5: val_loss did not improve from 0.09717\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1061 - mean_squared_error: 0.0188 - val_loss: 0.1059 - val_mean_squared_error: 0.0187\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0179\n",
      "Epoch 6: val_loss improved from 0.09717 to 0.09658, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1034 - mean_squared_error: 0.0179 - val_loss: 0.0966 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0174\n",
      "Epoch 7: val_loss improved from 0.09658 to 0.09620, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1027 - mean_squared_error: 0.0174 - val_loss: 0.0962 - val_mean_squared_error: 0.0154\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0176\n",
      "Epoch 8: val_loss did not improve from 0.09620\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1031 - mean_squared_error: 0.0176 - val_loss: 0.0995 - val_mean_squared_error: 0.0165\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0172\n",
      "Epoch 9: val_loss improved from 0.09620 to 0.09593, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1022 - mean_squared_error: 0.0172 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1019 - mean_squared_error: 0.0171\n",
      "Epoch 10: val_loss did not improve from 0.09593\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1019 - mean_squared_error: 0.0171 - val_loss: 0.1002 - val_mean_squared_error: 0.0168\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0166\n",
      "Epoch 11: val_loss did not improve from 0.09593\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.1005 - mean_squared_error: 0.0166 - val_loss: 0.0988 - val_mean_squared_error: 0.0163\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0167\n",
      "Epoch 12: val_loss did not improve from 0.09593\n",
      "79/79 [==============================] - 4s 48ms/step - loss: 0.1007 - mean_squared_error: 0.0167 - val_loss: 0.0968 - val_mean_squared_error: 0.0156\n",
      "27/27 [==============================] - 1s 19ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2290 - mean_squared_error: 0.0850\n",
      "Epoch 1: val_loss improved from inf to 0.11637, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 7s 61ms/step - loss: 0.2290 - mean_squared_error: 0.0850 - val_loss: 0.1164 - val_mean_squared_error: 0.0213\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1178 - mean_squared_error: 0.0230\n",
      "Epoch 2: val_loss improved from 0.11637 to 0.09870, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1178 - mean_squared_error: 0.0230 - val_loss: 0.0987 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1111 - mean_squared_error: 0.0201\n",
      "Epoch 3: val_loss did not improve from 0.09870\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1111 - mean_squared_error: 0.0201 - val_loss: 0.0991 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0192\n",
      "Epoch 4: val_loss improved from 0.09870 to 0.09701, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1083 - mean_squared_error: 0.0192 - val_loss: 0.0970 - val_mean_squared_error: 0.0153\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0184\n",
      "Epoch 5: val_loss improved from 0.09701 to 0.09494, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.1065 - mean_squared_error: 0.0184 - val_loss: 0.0949 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0186\n",
      "Epoch 6: val_loss did not improve from 0.09494\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1063 - mean_squared_error: 0.0186 - val_loss: 0.0965 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0176\n",
      "Epoch 7: val_loss did not improve from 0.09494\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1039 - mean_squared_error: 0.0176 - val_loss: 0.0989 - val_mean_squared_error: 0.0156\n",
      "Epoch 8/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1024 - mean_squared_error: 0.0173\n",
      "Epoch 8: val_loss did not improve from 0.09494\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1025 - mean_squared_error: 0.0173 - val_loss: 0.0978 - val_mean_squared_error: 0.0154\n",
      "27/27 [==============================] - 1s 19ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.6015 - mean_squared_error: 0.3921\n",
      "Epoch 1: val_loss improved from inf to 0.62178, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 7s 65ms/step - loss: 0.6016 - mean_squared_error: 0.3922 - val_loss: 0.6218 - val_mean_squared_error: 0.4128\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.6181 - mean_squared_error: 0.4073\n",
      "Epoch 2: val_loss improved from 0.62178 to 0.62175, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.6181 - mean_squared_error: 0.4073 - val_loss: 0.6217 - val_mean_squared_error: 0.4128\n",
      "Epoch 3/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.4511 - mean_squared_error: 0.2652\n",
      "Epoch 3: val_loss improved from 0.62175 to 0.12137, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 53ms/step - loss: 0.4501 - mean_squared_error: 0.2644 - val_loss: 0.1214 - val_mean_squared_error: 0.0248\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1261 - mean_squared_error: 0.0264\n",
      "Epoch 4: val_loss improved from 0.12137 to 0.10276, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1261 - mean_squared_error: 0.0264 - val_loss: 0.1028 - val_mean_squared_error: 0.0178\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0203\n",
      "Epoch 5: val_loss improved from 0.10276 to 0.09767, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1109 - mean_squared_error: 0.0203 - val_loss: 0.0977 - val_mean_squared_error: 0.0158\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0191\n",
      "Epoch 6: val_loss did not improve from 0.09767\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1074 - mean_squared_error: 0.0191 - val_loss: 0.0979 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1061 - mean_squared_error: 0.0186\n",
      "Epoch 7: val_loss improved from 0.09767 to 0.09720, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 52ms/step - loss: 0.1061 - mean_squared_error: 0.0186 - val_loss: 0.0972 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0178\n",
      "Epoch 8: val_loss did not improve from 0.09720\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1038 - mean_squared_error: 0.0178 - val_loss: 0.1020 - val_mean_squared_error: 0.0176\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0175\n",
      "Epoch 9: val_loss did not improve from 0.09720\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1028 - mean_squared_error: 0.0175 - val_loss: 0.0975 - val_mean_squared_error: 0.0155\n",
      "Epoch 10/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0174\n",
      "Epoch 10: val_loss improved from 0.09720 to 0.09675, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt128_stride4_size7_pool2_do0.1_tra4_head8_kdim128_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 54ms/step - loss: 0.1025 - mean_squared_error: 0.0174 - val_loss: 0.0967 - val_mean_squared_error: 0.0154\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0169\n",
      "Epoch 11: val_loss did not improve from 0.09675\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1013 - mean_squared_error: 0.0169 - val_loss: 0.0976 - val_mean_squared_error: 0.0153\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0166\n",
      "Epoch 12: val_loss did not improve from 0.09675\n",
      "79/79 [==============================] - 4s 50ms/step - loss: 0.1006 - mean_squared_error: 0.0166 - val_loss: 0.0978 - val_mean_squared_error: 0.0155\n",
      "Epoch 13/100\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0167\n",
      "Epoch 13: val_loss did not improve from 0.09675\n",
      "79/79 [==============================] - 4s 51ms/step - loss: 0.1009 - mean_squared_error: 0.0167 - val_loss: 0.0977 - val_mean_squared_error: 0.0155\n",
      "27/27 [==============================] - 1s 21ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.68+-0.04\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1753 - mean_squared_error: 0.0499\n",
      "Epoch 1: val_loss improved from inf to 0.10209, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 16s 41ms/step - loss: 0.1753 - mean_squared_error: 0.0499 - val_loss: 0.1021 - val_mean_squared_error: 0.0174\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1290 - mean_squared_error: 0.0274\n",
      "Epoch 2: val_loss improved from 0.10209 to 0.10130, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1290 - mean_squared_error: 0.0274 - val_loss: 0.1013 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.0213\n",
      "Epoch 3: val_loss did not improve from 0.10130\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1137 - mean_squared_error: 0.0213 - val_loss: 0.1018 - val_mean_squared_error: 0.0173\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0174\n",
      "Epoch 4: val_loss did not improve from 0.10130\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1021 - mean_squared_error: 0.0174 - val_loss: 0.1060 - val_mean_squared_error: 0.0182\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0954 - mean_squared_error: 0.0153\n",
      "Epoch 5: val_loss improved from 0.10130 to 0.09818, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0954 - mean_squared_error: 0.0153 - val_loss: 0.0982 - val_mean_squared_error: 0.0162\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0908 - mean_squared_error: 0.0136\n",
      "Epoch 6: val_loss did not improve from 0.09818\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0908 - mean_squared_error: 0.0136 - val_loss: 0.1057 - val_mean_squared_error: 0.0185\n",
      "Epoch 7/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0873 - mean_squared_error: 0.0127\n",
      "Epoch 7: val_loss improved from 0.09818 to 0.08428, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0874 - mean_squared_error: 0.0128 - val_loss: 0.0843 - val_mean_squared_error: 0.0123\n",
      "Epoch 8/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.0122\n",
      "Epoch 8: val_loss did not improve from 0.08428\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0852 - mean_squared_error: 0.0122 - val_loss: 0.1023 - val_mean_squared_error: 0.0182\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0843 - mean_squared_error: 0.0119\n",
      "Epoch 9: val_loss improved from 0.08428 to 0.08339, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0843 - mean_squared_error: 0.0119 - val_loss: 0.0834 - val_mean_squared_error: 0.0120\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.0116\n",
      "Epoch 10: val_loss did not improve from 0.08339\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0831 - mean_squared_error: 0.0116 - val_loss: 0.0917 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0808 - mean_squared_error: 0.0111\n",
      "Epoch 11: val_loss improved from 0.08339 to 0.08303, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0808 - mean_squared_error: 0.0111 - val_loss: 0.0830 - val_mean_squared_error: 0.0118\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0806 - mean_squared_error: 0.0109\n",
      "Epoch 12: val_loss improved from 0.08303 to 0.08184, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0805 - mean_squared_error: 0.0109 - val_loss: 0.0818 - val_mean_squared_error: 0.0113\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0790 - mean_squared_error: 0.0106\n",
      "Epoch 13: val_loss did not improve from 0.08184\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0790 - mean_squared_error: 0.0106 - val_loss: 0.0843 - val_mean_squared_error: 0.0121\n",
      "Epoch 14/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0775 - mean_squared_error: 0.0103\n",
      "Epoch 14: val_loss did not improve from 0.08184\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0775 - mean_squared_error: 0.0103 - val_loss: 0.0970 - val_mean_squared_error: 0.0161\n",
      "Epoch 15/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0772 - mean_squared_error: 0.0101\n",
      "Epoch 15: val_loss did not improve from 0.08184\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0773 - mean_squared_error: 0.0101 - val_loss: 0.0863 - val_mean_squared_error: 0.0129\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1689 - mean_squared_error: 0.0467\n",
      "Epoch 1: val_loss improved from inf to 0.10008, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 38ms/step - loss: 0.1688 - mean_squared_error: 0.0467 - val_loss: 0.1001 - val_mean_squared_error: 0.0166\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1236 - mean_squared_error: 0.0253\n",
      "Epoch 2: val_loss improved from 0.10008 to 0.09847, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1236 - mean_squared_error: 0.0253 - val_loss: 0.0985 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1153 - mean_squared_error: 0.0217\n",
      "Epoch 3: val_loss did not improve from 0.09847\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1153 - mean_squared_error: 0.0217 - val_loss: 0.0997 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1094 - mean_squared_error: 0.0197\n",
      "Epoch 4: val_loss did not improve from 0.09847\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1094 - mean_squared_error: 0.0197 - val_loss: 0.1031 - val_mean_squared_error: 0.0168\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0190\n",
      "Epoch 5: val_loss improved from 0.09847 to 0.09843, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1071 - mean_squared_error: 0.0190 - val_loss: 0.0984 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0181\n",
      "Epoch 6: val_loss did not improve from 0.09843\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1048 - mean_squared_error: 0.0181 - val_loss: 0.0990 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0180\n",
      "Epoch 7: val_loss improved from 0.09843 to 0.09708, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1046 - mean_squared_error: 0.0180 - val_loss: 0.0971 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0174\n",
      "Epoch 8: val_loss improved from 0.09708 to 0.09650, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1028 - mean_squared_error: 0.0174 - val_loss: 0.0965 - val_mean_squared_error: 0.0150\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0172\n",
      "Epoch 9: val_loss improved from 0.09650 to 0.09598, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1024 - mean_squared_error: 0.0172 - val_loss: 0.0960 - val_mean_squared_error: 0.0151\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0173\n",
      "Epoch 10: val_loss did not improve from 0.09598\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1025 - mean_squared_error: 0.0173 - val_loss: 0.0971 - val_mean_squared_error: 0.0151\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0171\n",
      "Epoch 11: val_loss did not improve from 0.09598\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1019 - mean_squared_error: 0.0171 - val_loss: 0.0973 - val_mean_squared_error: 0.0152\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0168\n",
      "Epoch 12: val_loss did not improve from 0.09598\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1012 - mean_squared_error: 0.0168 - val_loss: 0.0962 - val_mean_squared_error: 0.0150\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1656 - mean_squared_error: 0.0454\n",
      "Epoch 1: val_loss improved from inf to 0.10640, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 37ms/step - loss: 0.1656 - mean_squared_error: 0.0454 - val_loss: 0.1064 - val_mean_squared_error: 0.0198\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1209 - mean_squared_error: 0.0238\n",
      "Epoch 2: val_loss improved from 0.10640 to 0.09709, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1208 - mean_squared_error: 0.0238 - val_loss: 0.0971 - val_mean_squared_error: 0.0157\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0203\n",
      "Epoch 3: val_loss improved from 0.09709 to 0.09648, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1110 - mean_squared_error: 0.0203 - val_loss: 0.0965 - val_mean_squared_error: 0.0152\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss did not improve from 0.09648\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1072 - mean_squared_error: 0.0188 - val_loss: 0.0989 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0179\n",
      "Epoch 5: val_loss improved from 0.09648 to 0.09540, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1049 - mean_squared_error: 0.0179 - val_loss: 0.0954 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0174\n",
      "Epoch 6: val_loss did not improve from 0.09540\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1032 - mean_squared_error: 0.0174 - val_loss: 0.0959 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0171\n",
      "Epoch 7: val_loss did not improve from 0.09540\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1026 - mean_squared_error: 0.0171 - val_loss: 0.0964 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0170\n",
      "Epoch 8: val_loss did not improve from 0.09540\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1021 - mean_squared_error: 0.0170 - val_loss: 0.0962 - val_mean_squared_error: 0.0152\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1628 - mean_squared_error: 0.0444\n",
      "Epoch 1: val_loss improved from inf to 0.09900, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 7s 36ms/step - loss: 0.1624 - mean_squared_error: 0.0442 - val_loss: 0.0990 - val_mean_squared_error: 0.0163\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1202 - mean_squared_error: 0.0238\n",
      "Epoch 2: val_loss did not improve from 0.09900\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1202 - mean_squared_error: 0.0238 - val_loss: 0.1079 - val_mean_squared_error: 0.0181\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1111 - mean_squared_error: 0.0204\n",
      "Epoch 3: val_loss improved from 0.09900 to 0.09819, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size15_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1111 - mean_squared_error: 0.0204 - val_loss: 0.0982 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss did not improve from 0.09819\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1065 - mean_squared_error: 0.0188 - val_loss: 0.0984 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss did not improve from 0.09819\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1034 - mean_squared_error: 0.0176 - val_loss: 0.0991 - val_mean_squared_error: 0.0157\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0173\n",
      "Epoch 6: val_loss did not improve from 0.09819\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1030 - mean_squared_error: 0.0173 - val_loss: 0.0984 - val_mean_squared_error: 0.0156\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.34+-0.74\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1445 - mean_squared_error: 0.0352\n",
      "Epoch 1: val_loss improved from inf to 0.10262, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 18s 43ms/step - loss: 0.1445 - mean_squared_error: 0.0352 - val_loss: 0.1026 - val_mean_squared_error: 0.0172\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1173 - mean_squared_error: 0.0227\n",
      "Epoch 2: val_loss improved from 0.10262 to 0.10177, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1173 - mean_squared_error: 0.0227 - val_loss: 0.1018 - val_mean_squared_error: 0.0174\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0199\n",
      "Epoch 3: val_loss improved from 0.10177 to 0.10122, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1100 - mean_squared_error: 0.0199 - val_loss: 0.1012 - val_mean_squared_error: 0.0171\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0189\n",
      "Epoch 4: val_loss did not improve from 0.10122\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1073 - mean_squared_error: 0.0189 - val_loss: 0.1031 - val_mean_squared_error: 0.0171\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0188\n",
      "Epoch 5: val_loss improved from 0.10122 to 0.10072, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1067 - mean_squared_error: 0.0188 - val_loss: 0.1007 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0176\n",
      "Epoch 6: val_loss did not improve from 0.10072\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1037 - mean_squared_error: 0.0176 - val_loss: 0.1010 - val_mean_squared_error: 0.0169\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0172\n",
      "Epoch 7: val_loss improved from 0.10072 to 0.09924, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1020 - mean_squared_error: 0.0172 - val_loss: 0.0992 - val_mean_squared_error: 0.0163\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.0169\n",
      "Epoch 8: val_loss improved from 0.09924 to 0.09871, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1016 - mean_squared_error: 0.0169 - val_loss: 0.0987 - val_mean_squared_error: 0.0158\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0166\n",
      "Epoch 9: val_loss improved from 0.09871 to 0.09686, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1004 - mean_squared_error: 0.0166 - val_loss: 0.0969 - val_mean_squared_error: 0.0152\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0998 - mean_squared_error: 0.0165\n",
      "Epoch 10: val_loss did not improve from 0.09686\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0998 - mean_squared_error: 0.0165 - val_loss: 0.0990 - val_mean_squared_error: 0.0154\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0163\n",
      "Epoch 11: val_loss did not improve from 0.09686\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0992 - mean_squared_error: 0.0163 - val_loss: 0.0976 - val_mean_squared_error: 0.0155\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.0162\n",
      "Epoch 12: val_loss did not improve from 0.09686\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0990 - mean_squared_error: 0.0162 - val_loss: 0.0982 - val_mean_squared_error: 0.0156\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3796 - mean_squared_error: 0.1702\n",
      "Epoch 1: val_loss improved from inf to 0.38083, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.3796 - mean_squared_error: 0.1702 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1709\n",
      "Epoch 2: val_loss did not improve from 0.38083\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.3809 - mean_squared_error: 0.1708 - val_loss: 0.3809 - val_mean_squared_error: 0.1698\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 3: val_loss did not improve from 0.38083\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3813 - val_mean_squared_error: 0.1701\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3793 - mean_squared_error: 0.1703\n",
      "Epoch 4: val_loss did not improve from 0.38083\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.3793 - mean_squared_error: 0.1703 - val_loss: 0.3812 - val_mean_squared_error: 0.1701\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###1 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1569 - mean_squared_error: 0.0427\n",
      "Epoch 1: val_loss improved from inf to 0.10363, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 41ms/step - loss: 0.1569 - mean_squared_error: 0.0427 - val_loss: 0.1036 - val_mean_squared_error: 0.0179\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1131 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.10363 to 0.09709, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1131 - mean_squared_error: 0.0209 - val_loss: 0.0971 - val_mean_squared_error: 0.0159\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0185\n",
      "Epoch 3: val_loss did not improve from 0.09709\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1062 - mean_squared_error: 0.0185 - val_loss: 0.0975 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0176\n",
      "Epoch 4: val_loss did not improve from 0.09709\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1032 - mean_squared_error: 0.0175 - val_loss: 0.0996 - val_mean_squared_error: 0.0162\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0174\n",
      "Epoch 5: val_loss improved from 0.09709 to 0.09545, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1030 - mean_squared_error: 0.0174 - val_loss: 0.0955 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.0167\n",
      "Epoch 6: val_loss improved from 0.09545 to 0.09537, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1017 - mean_squared_error: 0.0167 - val_loss: 0.0954 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0165\n",
      "Epoch 7: val_loss did not improve from 0.09537\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1003 - mean_squared_error: 0.0165 - val_loss: 0.0954 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0165\n",
      "Epoch 8: val_loss improved from 0.09537 to 0.09458, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1008 - mean_squared_error: 0.0165 - val_loss: 0.0946 - val_mean_squared_error: 0.0150\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0999 - mean_squared_error: 0.0163\n",
      "Epoch 9: val_loss did not improve from 0.09458\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0999 - mean_squared_error: 0.0163 - val_loss: 0.0960 - val_mean_squared_error: 0.0150\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0999 - mean_squared_error: 0.0163\n",
      "Epoch 10: val_loss did not improve from 0.09458\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0999 - mean_squared_error: 0.0163 - val_loss: 0.0962 - val_mean_squared_error: 0.0152\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.0163\n",
      "Epoch 11: val_loss did not improve from 0.09458\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1001 - mean_squared_error: 0.0163 - val_loss: 0.0961 - val_mean_squared_error: 0.0159\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.3838 - mean_squared_error: 0.1736\n",
      "Epoch 1: val_loss improved from inf to 0.37824, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.3837 - mean_squared_error: 0.1736 - val_loss: 0.3782 - val_mean_squared_error: 0.1692\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3653 - mean_squared_error: 0.1603\n",
      "Epoch 2: val_loss improved from 0.37824 to 0.30677, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.3653 - mean_squared_error: 0.1603 - val_loss: 0.3068 - val_mean_squared_error: 0.1217\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1374 - mean_squared_error: 0.0316\n",
      "Epoch 3: val_loss improved from 0.30677 to 0.11252, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1374 - mean_squared_error: 0.0316 - val_loss: 0.1125 - val_mean_squared_error: 0.0197\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1107 - mean_squared_error: 0.0201\n",
      "Epoch 4: val_loss did not improve from 0.11252\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1107 - mean_squared_error: 0.0201 - val_loss: 0.1139 - val_mean_squared_error: 0.0201\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0183\n",
      "Epoch 5: val_loss improved from 0.11252 to 0.10010, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1055 - mean_squared_error: 0.0183 - val_loss: 0.1001 - val_mean_squared_error: 0.0164\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0173\n",
      "Epoch 6: val_loss did not improve from 0.10010\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1026 - mean_squared_error: 0.0173 - val_loss: 0.1003 - val_mean_squared_error: 0.0161\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0172\n",
      "Epoch 7: val_loss improved from 0.10010 to 0.09820, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1021 - mean_squared_error: 0.0172 - val_loss: 0.0982 - val_mean_squared_error: 0.0160\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0166\n",
      "Epoch 8: val_loss improved from 0.09820 to 0.09784, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1005 - mean_squared_error: 0.0166 - val_loss: 0.0978 - val_mean_squared_error: 0.0159\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0994 - mean_squared_error: 0.0163\n",
      "Epoch 9: val_loss did not improve from 0.09784\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0994 - mean_squared_error: 0.0163 - val_loss: 0.0986 - val_mean_squared_error: 0.0162\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0161\n",
      "Epoch 10: val_loss improved from 0.09784 to 0.09751, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0992 - mean_squared_error: 0.0161 - val_loss: 0.0975 - val_mean_squared_error: 0.0155\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0985 - mean_squared_error: 0.0161\n",
      "Epoch 11: val_loss improved from 0.09751 to 0.09728, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0985 - mean_squared_error: 0.0161 - val_loss: 0.0973 - val_mean_squared_error: 0.0154\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0162\n",
      "Epoch 12: val_loss did not improve from 0.09728\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0992 - mean_squared_error: 0.0162 - val_loss: 0.0974 - val_mean_squared_error: 0.0153\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0161\n",
      "Epoch 13: val_loss improved from 0.09728 to 0.09715, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size9_pool5_do0.1_tra4_head8_kdim128_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0984 - mean_squared_error: 0.0161 - val_loss: 0.0971 - val_mean_squared_error: 0.0154\n",
      "Epoch 14/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0985 - mean_squared_error: 0.0159\n",
      "Epoch 14: val_loss did not improve from 0.09715\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0986 - mean_squared_error: 0.0159 - val_loss: 0.0979 - val_mean_squared_error: 0.0156\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0160\n",
      "Epoch 15: val_loss did not improve from 0.09715\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0987 - mean_squared_error: 0.0160 - val_loss: 0.0988 - val_mean_squared_error: 0.0155\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0988 - mean_squared_error: 0.0161\n",
      "Epoch 16: val_loss did not improve from 0.09715\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0988 - mean_squared_error: 0.0161 - val_loss: 0.0974 - val_mean_squared_error: 0.0155\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae16.81+-12.32\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3255 - mean_squared_error: 0.1393\n",
      "Epoch 1: val_loss improved from inf to 0.46248, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 102ms/step - loss: 0.3255 - mean_squared_error: 0.1393 - val_loss: 0.4625 - val_mean_squared_error: 0.2398\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2761 - mean_squared_error: 0.1051\n",
      "Epoch 2: val_loss improved from 0.46248 to 0.27461, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.2761 - mean_squared_error: 0.1050 - val_loss: 0.2746 - val_mean_squared_error: 0.0984\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2334 - mean_squared_error: 0.0802\n",
      "Epoch 3: val_loss improved from 0.27461 to 0.14935, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.2333 - mean_squared_error: 0.0801 - val_loss: 0.1493 - val_mean_squared_error: 0.0336\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1970 - mean_squared_error: 0.0595\n",
      "Epoch 4: val_loss improved from 0.14935 to 0.11447, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1969 - mean_squared_error: 0.0594 - val_loss: 0.1145 - val_mean_squared_error: 0.0203\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1650 - mean_squared_error: 0.0434\n",
      "Epoch 5: val_loss improved from 0.11447 to 0.10410, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.1649 - mean_squared_error: 0.0433 - val_loss: 0.1041 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1435 - mean_squared_error: 0.0330\n",
      "Epoch 6: val_loss did not improve from 0.10410\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1434 - mean_squared_error: 0.0330 - val_loss: 0.1055 - val_mean_squared_error: 0.0170\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1300 - mean_squared_error: 0.0276\n",
      "Epoch 7: val_loss improved from 0.10410 to 0.10158, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1299 - mean_squared_error: 0.0276 - val_loss: 0.1016 - val_mean_squared_error: 0.0170\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1249 - mean_squared_error: 0.0254\n",
      "Epoch 8: val_loss improved from 0.10158 to 0.10145, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1248 - mean_squared_error: 0.0253 - val_loss: 0.1014 - val_mean_squared_error: 0.0165\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1178 - mean_squared_error: 0.0228\n",
      "Epoch 9: val_loss did not improve from 0.10145\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1178 - mean_squared_error: 0.0228 - val_loss: 0.1025 - val_mean_squared_error: 0.0173\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1154 - mean_squared_error: 0.0216\n",
      "Epoch 10: val_loss did not improve from 0.10145\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1153 - mean_squared_error: 0.0216 - val_loss: 0.1020 - val_mean_squared_error: 0.0169\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1132 - mean_squared_error: 0.0209\n",
      "Epoch 11: val_loss did not improve from 0.10145\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1132 - mean_squared_error: 0.0209 - val_loss: 0.1028 - val_mean_squared_error: 0.0166\n",
      "14/14 [==============================] - 2s 32ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3263 - mean_squared_error: 0.1410\n",
      "Epoch 1: val_loss improved from inf to 0.33029, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 6s 95ms/step - loss: 0.3262 - mean_squared_error: 0.1409 - val_loss: 0.3303 - val_mean_squared_error: 0.1369\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2528 - mean_squared_error: 0.0918\n",
      "Epoch 2: val_loss improved from 0.33029 to 0.13893, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.2526 - mean_squared_error: 0.0918 - val_loss: 0.1389 - val_mean_squared_error: 0.0307\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2032 - mean_squared_error: 0.0630\n",
      "Epoch 3: val_loss improved from 0.13893 to 0.10148, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.2032 - mean_squared_error: 0.0630 - val_loss: 0.1015 - val_mean_squared_error: 0.0171\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1705 - mean_squared_error: 0.0465\n",
      "Epoch 4: val_loss did not improve from 0.10148\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1705 - mean_squared_error: 0.0465 - val_loss: 0.1378 - val_mean_squared_error: 0.0305\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1486 - mean_squared_error: 0.0359\n",
      "Epoch 5: val_loss did not improve from 0.10148\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1485 - mean_squared_error: 0.0359 - val_loss: 0.1362 - val_mean_squared_error: 0.0300\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1361 - mean_squared_error: 0.0301\n",
      "Epoch 6: val_loss did not improve from 0.10148\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1361 - mean_squared_error: 0.0301 - val_loss: 0.1232 - val_mean_squared_error: 0.0252\n",
      "14/14 [==============================] - 1s 30ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3181 - mean_squared_error: 0.1348\n",
      "Epoch 1: val_loss improved from inf to 0.24362, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 6s 95ms/step - loss: 0.3181 - mean_squared_error: 0.1348 - val_loss: 0.2436 - val_mean_squared_error: 0.0830\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2451 - mean_squared_error: 0.0867\n",
      "Epoch 2: val_loss improved from 0.24362 to 0.19476, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.2450 - mean_squared_error: 0.0866 - val_loss: 0.1948 - val_mean_squared_error: 0.0520\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1945 - mean_squared_error: 0.0578\n",
      "Epoch 3: val_loss improved from 0.19476 to 0.12697, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1944 - mean_squared_error: 0.0578 - val_loss: 0.1270 - val_mean_squared_error: 0.0243\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1661 - mean_squared_error: 0.0437\n",
      "Epoch 4: val_loss improved from 0.12697 to 0.10036, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1660 - mean_squared_error: 0.0437 - val_loss: 0.1004 - val_mean_squared_error: 0.0173\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1454 - mean_squared_error: 0.0343\n",
      "Epoch 5: val_loss did not improve from 0.10036\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.1453 - mean_squared_error: 0.0343 - val_loss: 0.1035 - val_mean_squared_error: 0.0164\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1335 - mean_squared_error: 0.0288\n",
      "Epoch 6: val_loss improved from 0.10036 to 0.09995, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1335 - mean_squared_error: 0.0288 - val_loss: 0.0999 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1261 - mean_squared_error: 0.0258\n",
      "Epoch 7: val_loss improved from 0.09995 to 0.09924, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1261 - mean_squared_error: 0.0258 - val_loss: 0.0992 - val_mean_squared_error: 0.0161\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1211 - mean_squared_error: 0.0235\n",
      "Epoch 8: val_loss did not improve from 0.09924\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.1210 - mean_squared_error: 0.0235 - val_loss: 0.1006 - val_mean_squared_error: 0.0162\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1164 - mean_squared_error: 0.0221\n",
      "Epoch 9: val_loss did not improve from 0.09924\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.1163 - mean_squared_error: 0.0220 - val_loss: 0.1003 - val_mean_squared_error: 0.0162\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1147 - mean_squared_error: 0.0211\n",
      "Epoch 10: val_loss did not improve from 0.09924\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.1148 - mean_squared_error: 0.0211 - val_loss: 0.1008 - val_mean_squared_error: 0.0162\n",
      "14/14 [==============================] - 1s 30ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3465 - mean_squared_error: 0.1537\n",
      "Epoch 1: val_loss improved from inf to 0.61629, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 100ms/step - loss: 0.3464 - mean_squared_error: 0.1536 - val_loss: 0.6163 - val_mean_squared_error: 0.4056\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2706 - mean_squared_error: 0.1026\n",
      "Epoch 2: val_loss improved from 0.61629 to 0.55894, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.2706 - mean_squared_error: 0.1025 - val_loss: 0.5589 - val_mean_squared_error: 0.3342\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2101 - mean_squared_error: 0.0670\n",
      "Epoch 3: val_loss improved from 0.55894 to 0.32533, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.2100 - mean_squared_error: 0.0669 - val_loss: 0.3253 - val_mean_squared_error: 0.1231\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1700 - mean_squared_error: 0.0459\n",
      "Epoch 4: val_loss improved from 0.32533 to 0.13437, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1700 - mean_squared_error: 0.0459 - val_loss: 0.1344 - val_mean_squared_error: 0.0262\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1473 - mean_squared_error: 0.0351\n",
      "Epoch 5: val_loss improved from 0.13437 to 0.10141, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1474 - mean_squared_error: 0.0351 - val_loss: 0.1014 - val_mean_squared_error: 0.0172\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1332 - mean_squared_error: 0.0288\n",
      "Epoch 6: val_loss improved from 0.10141 to 0.10077, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt64_stride5_size15_pool2_do0.5_tra5_head8_kdim256_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.1332 - mean_squared_error: 0.0288 - val_loss: 0.1008 - val_mean_squared_error: 0.0164\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1243 - mean_squared_error: 0.0254\n",
      "Epoch 7: val_loss did not improve from 0.10077\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.1243 - mean_squared_error: 0.0254 - val_loss: 0.1066 - val_mean_squared_error: 0.0173\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1185 - mean_squared_error: 0.0229\n",
      "Epoch 8: val_loss did not improve from 0.10077\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.1186 - mean_squared_error: 0.0229 - val_loss: 0.1057 - val_mean_squared_error: 0.0171\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1157 - mean_squared_error: 0.0219\n",
      "Epoch 9: val_loss did not improve from 0.10077\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.1157 - mean_squared_error: 0.0219 - val_loss: 0.1059 - val_mean_squared_error: 0.0172\n",
      "14/14 [==============================] - 1s 30ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae10.13+-0.09\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1541 - mean_squared_error: 0.0392\n",
      "Epoch 1: val_loss improved from inf to 0.12142, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 17s 58ms/step - loss: 0.1541 - mean_squared_error: 0.0392 - val_loss: 0.1214 - val_mean_squared_error: 0.0222\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1176 - mean_squared_error: 0.0230\n",
      "Epoch 2: val_loss improved from 0.12142 to 0.10856, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1176 - mean_squared_error: 0.0230 - val_loss: 0.1086 - val_mean_squared_error: 0.0181\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1111 - mean_squared_error: 0.0206\n",
      "Epoch 3: val_loss improved from 0.10856 to 0.09937, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1111 - mean_squared_error: 0.0206 - val_loss: 0.0994 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0195\n",
      "Epoch 4: val_loss did not improve from 0.09937\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1083 - mean_squared_error: 0.0195 - val_loss: 0.1007 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0179\n",
      "Epoch 5: val_loss improved from 0.09937 to 0.09282, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1037 - mean_squared_error: 0.0179 - val_loss: 0.0928 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.0168\n",
      "Epoch 6: val_loss did not improve from 0.09282\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1001 - mean_squared_error: 0.0168 - val_loss: 0.0940 - val_mean_squared_error: 0.0148\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0956 - mean_squared_error: 0.0152\n",
      "Epoch 7: val_loss did not improve from 0.09282\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0956 - mean_squared_error: 0.0152 - val_loss: 0.0946 - val_mean_squared_error: 0.0151\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0919 - mean_squared_error: 0.0141\n",
      "Epoch 8: val_loss improved from 0.09282 to 0.08509, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0919 - mean_squared_error: 0.0141 - val_loss: 0.0851 - val_mean_squared_error: 0.0122\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0896 - mean_squared_error: 0.0134\n",
      "Epoch 9: val_loss did not improve from 0.08509\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.0896 - mean_squared_error: 0.0134 - val_loss: 0.0867 - val_mean_squared_error: 0.0127\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.0128\n",
      "Epoch 10: val_loss did not improve from 0.08509\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0871 - mean_squared_error: 0.0128 - val_loss: 0.0858 - val_mean_squared_error: 0.0125\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.0128\n",
      "Epoch 11: val_loss did not improve from 0.08509\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.0876 - mean_squared_error: 0.0128 - val_loss: 0.0919 - val_mean_squared_error: 0.0143\n",
      "27/27 [==============================] - 2s 17ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1474 - mean_squared_error: 0.0374\n",
      "Epoch 1: val_loss improved from inf to 0.10424, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 6s 53ms/step - loss: 0.1474 - mean_squared_error: 0.0374 - val_loss: 0.1042 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1129 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.10424 to 0.09701, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1129 - mean_squared_error: 0.0211 - val_loss: 0.0970 - val_mean_squared_error: 0.0153\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0198\n",
      "Epoch 3: val_loss improved from 0.09701 to 0.09677, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1090 - mean_squared_error: 0.0198 - val_loss: 0.0968 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0190\n",
      "Epoch 4: val_loss did not improve from 0.09677\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1068 - mean_squared_error: 0.0190 - val_loss: 0.0976 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0182\n",
      "Epoch 5: val_loss improved from 0.09677 to 0.09644, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1049 - mean_squared_error: 0.0182 - val_loss: 0.0964 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0177\n",
      "Epoch 6: val_loss improved from 0.09644 to 0.09626, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1033 - mean_squared_error: 0.0177 - val_loss: 0.0963 - val_mean_squared_error: 0.0151\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0175\n",
      "Epoch 7: val_loss improved from 0.09626 to 0.09579, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1030 - mean_squared_error: 0.0175 - val_loss: 0.0958 - val_mean_squared_error: 0.0148\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.0170\n",
      "Epoch 8: val_loss did not improve from 0.09579\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1016 - mean_squared_error: 0.0170 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.0169\n",
      "Epoch 9: val_loss improved from 0.09579 to 0.09568, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1017 - mean_squared_error: 0.0169 - val_loss: 0.0957 - val_mean_squared_error: 0.0150\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0166\n",
      "Epoch 10: val_loss did not improve from 0.09568\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1002 - mean_squared_error: 0.0166 - val_loss: 0.0968 - val_mean_squared_error: 0.0152\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.0169\n",
      "Epoch 11: val_loss did not improve from 0.09568\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1010 - mean_squared_error: 0.0169 - val_loss: 0.0972 - val_mean_squared_error: 0.0156\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0167\n",
      "Epoch 12: val_loss did not improve from 0.09568\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1005 - mean_squared_error: 0.0167 - val_loss: 0.0968 - val_mean_squared_error: 0.0156\n",
      "27/27 [==============================] - 1s 16ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1489 - mean_squared_error: 0.0376\n",
      "Epoch 1: val_loss improved from inf to 0.11815, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 7s 57ms/step - loss: 0.1489 - mean_squared_error: 0.0376 - val_loss: 0.1181 - val_mean_squared_error: 0.0212\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1143 - mean_squared_error: 0.0216\n",
      "Epoch 2: val_loss improved from 0.11815 to 0.09844, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1143 - mean_squared_error: 0.0216 - val_loss: 0.0984 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1080 - mean_squared_error: 0.0191\n",
      "Epoch 3: val_loss improved from 0.09844 to 0.09798, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1080 - mean_squared_error: 0.0191 - val_loss: 0.0980 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0183\n",
      "Epoch 4: val_loss improved from 0.09798 to 0.09455, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1055 - mean_squared_error: 0.0183 - val_loss: 0.0946 - val_mean_squared_error: 0.0149\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1052 - mean_squared_error: 0.0181\n",
      "Epoch 5: val_loss did not improve from 0.09455\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1052 - mean_squared_error: 0.0181 - val_loss: 0.0969 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0177\n",
      "Epoch 6: val_loss did not improve from 0.09455\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1043 - mean_squared_error: 0.0177 - val_loss: 0.0957 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0174\n",
      "Epoch 7: val_loss did not improve from 0.09455\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1028 - mean_squared_error: 0.0174 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1510 - mean_squared_error: 0.0388\n",
      "Epoch 1: val_loss improved from inf to 0.10921, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 6s 55ms/step - loss: 0.1510 - mean_squared_error: 0.0388 - val_loss: 0.1092 - val_mean_squared_error: 0.0184\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0217\n",
      "Epoch 2: val_loss improved from 0.10921 to 0.10672, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1145 - mean_squared_error: 0.0217 - val_loss: 0.1067 - val_mean_squared_error: 0.0179\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0195\n",
      "Epoch 3: val_loss improved from 0.10672 to 0.09856, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1082 - mean_squared_error: 0.0195 - val_loss: 0.0986 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0186\n",
      "Epoch 4: val_loss did not improve from 0.09856\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1059 - mean_squared_error: 0.0186 - val_loss: 0.0995 - val_mean_squared_error: 0.0165\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0178\n",
      "Epoch 5: val_loss improved from 0.09856 to 0.09753, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1040 - mean_squared_error: 0.0178 - val_loss: 0.0975 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0173\n",
      "Epoch 6: val_loss did not improve from 0.09753\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1027 - mean_squared_error: 0.0173 - val_loss: 0.0983 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.0171\n",
      "Epoch 7: val_loss did not improve from 0.09753\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1018 - mean_squared_error: 0.0171 - val_loss: 0.0984 - val_mean_squared_error: 0.0157\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0170\n",
      "Epoch 8: val_loss did not improve from 0.09753\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1015 - mean_squared_error: 0.0170 - val_loss: 0.0977 - val_mean_squared_error: 0.0153\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.34+-0.58\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3051 - mean_squared_error: 0.1258\n",
      "Epoch 1: val_loss improved from inf to 0.22191, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 17s 39ms/step - loss: 0.3051 - mean_squared_error: 0.1258 - val_loss: 0.2219 - val_mean_squared_error: 0.0643\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2324 - mean_squared_error: 0.0791\n",
      "Epoch 2: val_loss improved from 0.22191 to 0.16996, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.2324 - mean_squared_error: 0.0791 - val_loss: 0.1700 - val_mean_squared_error: 0.0418\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1558 - mean_squared_error: 0.0391\n",
      "Epoch 3: val_loss improved from 0.16996 to 0.10767, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1558 - mean_squared_error: 0.0391 - val_loss: 0.1077 - val_mean_squared_error: 0.0198\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1200 - mean_squared_error: 0.0234\n",
      "Epoch 4: val_loss improved from 0.10767 to 0.10675, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1200 - mean_squared_error: 0.0234 - val_loss: 0.1067 - val_mean_squared_error: 0.0194\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.0210\n",
      "Epoch 5: val_loss did not improve from 0.10675\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1137 - mean_squared_error: 0.0210 - val_loss: 0.1070 - val_mean_squared_error: 0.0195\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1118 - mean_squared_error: 0.0204\n",
      "Epoch 6: val_loss improved from 0.10675 to 0.10554, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1119 - mean_squared_error: 0.0204 - val_loss: 0.1055 - val_mean_squared_error: 0.0188\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1095 - mean_squared_error: 0.0197\n",
      "Epoch 7: val_loss improved from 0.10554 to 0.10413, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1094 - mean_squared_error: 0.0197 - val_loss: 0.1041 - val_mean_squared_error: 0.0181\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1100 - mean_squared_error: 0.0197\n",
      "Epoch 8: val_loss did not improve from 0.10413\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1099 - mean_squared_error: 0.0197 - val_loss: 0.1048 - val_mean_squared_error: 0.0186\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0192\n",
      "Epoch 9: val_loss improved from 0.10413 to 0.10236, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1085 - mean_squared_error: 0.0193 - val_loss: 0.1024 - val_mean_squared_error: 0.0168\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0185\n",
      "Epoch 10: val_loss did not improve from 0.10236\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1064 - mean_squared_error: 0.0185 - val_loss: 0.1189 - val_mean_squared_error: 0.0241\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0174\n",
      "Epoch 11: val_loss did not improve from 0.10236\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1028 - mean_squared_error: 0.0174 - val_loss: 0.1103 - val_mean_squared_error: 0.0203\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0163\n",
      "Epoch 12: val_loss improved from 0.10236 to 0.09359, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0995 - mean_squared_error: 0.0163 - val_loss: 0.0936 - val_mean_squared_error: 0.0147\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0954 - mean_squared_error: 0.0150\n",
      "Epoch 13: val_loss did not improve from 0.09359\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0954 - mean_squared_error: 0.0150 - val_loss: 0.1017 - val_mean_squared_error: 0.0178\n",
      "Epoch 14/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0939 - mean_squared_error: 0.0145\n",
      "Epoch 14: val_loss did not improve from 0.09359\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0939 - mean_squared_error: 0.0145 - val_loss: 0.0947 - val_mean_squared_error: 0.0154\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.0143\n",
      "Epoch 15: val_loss did not improve from 0.09359\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0928 - mean_squared_error: 0.0143 - val_loss: 0.0968 - val_mean_squared_error: 0.0157\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.3254 - mean_squared_error: 0.1378\n",
      "Epoch 1: val_loss improved from inf to 0.24066, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 38ms/step - loss: 0.3254 - mean_squared_error: 0.1377 - val_loss: 0.2407 - val_mean_squared_error: 0.0745\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2738 - mean_squared_error: 0.1039\n",
      "Epoch 2: val_loss did not improve from 0.24066\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.2737 - mean_squared_error: 0.1037 - val_loss: 0.3359 - val_mean_squared_error: 0.1311\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2067 - mean_squared_error: 0.0649\n",
      "Epoch 3: val_loss improved from 0.24066 to 0.12499, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.2067 - mean_squared_error: 0.0649 - val_loss: 0.1250 - val_mean_squared_error: 0.0251\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1471 - mean_squared_error: 0.0347\n",
      "Epoch 4: val_loss improved from 0.12499 to 0.10575, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1470 - mean_squared_error: 0.0347 - val_loss: 0.1058 - val_mean_squared_error: 0.0191\n",
      "Epoch 5/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1209 - mean_squared_error: 0.0237\n",
      "Epoch 5: val_loss improved from 0.10575 to 0.10355, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1210 - mean_squared_error: 0.0238 - val_loss: 0.1036 - val_mean_squared_error: 0.0184\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0212\n",
      "Epoch 6: val_loss did not improve from 0.10355\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1146 - mean_squared_error: 0.0212 - val_loss: 0.1040 - val_mean_squared_error: 0.0185\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.0205\n",
      "Epoch 7: val_loss improved from 0.10355 to 0.10148, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1124 - mean_squared_error: 0.0205 - val_loss: 0.1015 - val_mean_squared_error: 0.0174\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1107 - mean_squared_error: 0.0198\n",
      "Epoch 8: val_loss did not improve from 0.10148\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1106 - mean_squared_error: 0.0198 - val_loss: 0.1016 - val_mean_squared_error: 0.0175\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0198\n",
      "Epoch 9: val_loss improved from 0.10148 to 0.10130, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1099 - mean_squared_error: 0.0198 - val_loss: 0.1013 - val_mean_squared_error: 0.0173\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0194\n",
      "Epoch 10: val_loss improved from 0.10130 to 0.10105, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1090 - mean_squared_error: 0.0194 - val_loss: 0.1010 - val_mean_squared_error: 0.0172\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1097 - mean_squared_error: 0.0194\n",
      "Epoch 11: val_loss improved from 0.10105 to 0.10065, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1097 - mean_squared_error: 0.0194 - val_loss: 0.1007 - val_mean_squared_error: 0.0171\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0192\n",
      "Epoch 12: val_loss improved from 0.10065 to 0.10037, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1087 - mean_squared_error: 0.0193 - val_loss: 0.1004 - val_mean_squared_error: 0.0167\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0192\n",
      "Epoch 13: val_loss did not improve from 0.10037\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1083 - mean_squared_error: 0.0192 - val_loss: 0.1021 - val_mean_squared_error: 0.0177\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0191\n",
      "Epoch 14: val_loss did not improve from 0.10037\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1078 - mean_squared_error: 0.0191 - val_loss: 0.1016 - val_mean_squared_error: 0.0175\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0190\n",
      "Epoch 15: val_loss improved from 0.10037 to 0.09999, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1078 - mean_squared_error: 0.0190 - val_loss: 0.1000 - val_mean_squared_error: 0.0168\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0190\n",
      "Epoch 16: val_loss improved from 0.09999 to 0.09897, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1078 - mean_squared_error: 0.0190 - val_loss: 0.0990 - val_mean_squared_error: 0.0164\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0191\n",
      "Epoch 17: val_loss did not improve from 0.09897\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1077 - mean_squared_error: 0.0191 - val_loss: 0.0993 - val_mean_squared_error: 0.0166\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0190\n",
      "Epoch 18: val_loss did not improve from 0.09897\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1076 - mean_squared_error: 0.0190 - val_loss: 0.1003 - val_mean_squared_error: 0.0167\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0190\n",
      "Epoch 19: val_loss did not improve from 0.09897\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1077 - mean_squared_error: 0.0190 - val_loss: 0.0996 - val_mean_squared_error: 0.0166\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3262 - mean_squared_error: 0.1379\n",
      "Epoch 1: val_loss improved from inf to 0.34077, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 38ms/step - loss: 0.3262 - mean_squared_error: 0.1379 - val_loss: 0.3408 - val_mean_squared_error: 0.1350\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2518 - mean_squared_error: 0.0899\n",
      "Epoch 2: val_loss improved from 0.34077 to 0.11302, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.2518 - mean_squared_error: 0.0899 - val_loss: 0.1130 - val_mean_squared_error: 0.0207\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1552 - mean_squared_error: 0.0385\n",
      "Epoch 3: val_loss improved from 0.11302 to 0.10437, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1552 - mean_squared_error: 0.0385 - val_loss: 0.1044 - val_mean_squared_error: 0.0189\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1186 - mean_squared_error: 0.0225\n",
      "Epoch 4: val_loss did not improve from 0.10437\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1186 - mean_squared_error: 0.0226 - val_loss: 0.1064 - val_mean_squared_error: 0.0200\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1128 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss improved from 0.10437 to 0.10333, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1128 - mean_squared_error: 0.0206 - val_loss: 0.1033 - val_mean_squared_error: 0.0185\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0200\n",
      "Epoch 6: val_loss did not improve from 0.10333\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1109 - mean_squared_error: 0.0200 - val_loss: 0.1034 - val_mean_squared_error: 0.0187\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1097 - mean_squared_error: 0.0194\n",
      "Epoch 7: val_loss did not improve from 0.10333\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1097 - mean_squared_error: 0.0194 - val_loss: 0.1035 - val_mean_squared_error: 0.0187\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.0195\n",
      "Epoch 8: val_loss improved from 0.10333 to 0.10249, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1093 - mean_squared_error: 0.0195 - val_loss: 0.1025 - val_mean_squared_error: 0.0179\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1097 - mean_squared_error: 0.0195\n",
      "Epoch 9: val_loss did not improve from 0.10249\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1097 - mean_squared_error: 0.0195 - val_loss: 0.1033 - val_mean_squared_error: 0.0188\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1091 - mean_squared_error: 0.0193\n",
      "Epoch 10: val_loss improved from 0.10249 to 0.10100, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1090 - mean_squared_error: 0.0193 - val_loss: 0.1010 - val_mean_squared_error: 0.0175\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0189\n",
      "Epoch 11: val_loss did not improve from 0.10100\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1078 - mean_squared_error: 0.0189 - val_loss: 0.1023 - val_mean_squared_error: 0.0183\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0194\n",
      "Epoch 12: val_loss improved from 0.10100 to 0.10084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1084 - mean_squared_error: 0.0194 - val_loss: 0.1008 - val_mean_squared_error: 0.0174\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0189\n",
      "Epoch 13: val_loss did not improve from 0.10084\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1076 - mean_squared_error: 0.0189 - val_loss: 0.1014 - val_mean_squared_error: 0.0179\n",
      "Epoch 14/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0190\n",
      "Epoch 14: val_loss did not improve from 0.10084\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1081 - mean_squared_error: 0.0190 - val_loss: 0.1017 - val_mean_squared_error: 0.0177\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 15: val_loss improved from 0.10084 to 0.09968, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1072 - mean_squared_error: 0.0189 - val_loss: 0.0997 - val_mean_squared_error: 0.0169\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0192\n",
      "Epoch 16: val_loss improved from 0.09968 to 0.09877, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1078 - mean_squared_error: 0.0192 - val_loss: 0.0988 - val_mean_squared_error: 0.0163\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0194\n",
      "Epoch 17: val_loss did not improve from 0.09877\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1081 - mean_squared_error: 0.0194 - val_loss: 0.1013 - val_mean_squared_error: 0.0172\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0191\n",
      "Epoch 18: val_loss did not improve from 0.09877\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1077 - mean_squared_error: 0.0191 - val_loss: 0.1003 - val_mean_squared_error: 0.0169\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0188\n",
      "Epoch 19: val_loss did not improve from 0.09877\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1073 - mean_squared_error: 0.0188 - val_loss: 0.0989 - val_mean_squared_error: 0.0165\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3427 - mean_squared_error: 0.1482\n",
      "Epoch 1: val_loss improved from inf to 0.22481, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.3427 - mean_squared_error: 0.1482 - val_loss: 0.2248 - val_mean_squared_error: 0.0677\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2822 - mean_squared_error: 0.1078\n",
      "Epoch 2: val_loss improved from 0.22481 to 0.21196, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.2821 - mean_squared_error: 0.1078 - val_loss: 0.2120 - val_mean_squared_error: 0.0595\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1919 - mean_squared_error: 0.0568\n",
      "Epoch 3: val_loss improved from 0.21196 to 0.11329, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1916 - mean_squared_error: 0.0567 - val_loss: 0.1133 - val_mean_squared_error: 0.0222\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1246 - mean_squared_error: 0.0251\n",
      "Epoch 4: val_loss improved from 0.11329 to 0.10668, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1246 - mean_squared_error: 0.0251 - val_loss: 0.1067 - val_mean_squared_error: 0.0198\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss did not improve from 0.10668\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1135 - mean_squared_error: 0.0210 - val_loss: 0.1100 - val_mean_squared_error: 0.0213\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1112 - mean_squared_error: 0.0200\n",
      "Epoch 6: val_loss improved from 0.10668 to 0.10609, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1112 - mean_squared_error: 0.0200 - val_loss: 0.1061 - val_mean_squared_error: 0.0195\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1102 - mean_squared_error: 0.0197\n",
      "Epoch 7: val_loss improved from 0.10609 to 0.10491, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1102 - mean_squared_error: 0.0197 - val_loss: 0.1049 - val_mean_squared_error: 0.0190\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1085 - mean_squared_error: 0.0192\n",
      "Epoch 8: val_loss did not improve from 0.10491\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1086 - mean_squared_error: 0.0192 - val_loss: 0.1051 - val_mean_squared_error: 0.0191\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0194\n",
      "Epoch 9: val_loss improved from 0.10491 to 0.10322, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1086 - mean_squared_error: 0.0194 - val_loss: 0.1032 - val_mean_squared_error: 0.0181\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0193\n",
      "Epoch 10: val_loss did not improve from 0.10322\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1092 - mean_squared_error: 0.0193 - val_loss: 0.1046 - val_mean_squared_error: 0.0188\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1087 - mean_squared_error: 0.0193\n",
      "Epoch 11: val_loss improved from 0.10322 to 0.10282, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1087 - mean_squared_error: 0.0193 - val_loss: 0.1028 - val_mean_squared_error: 0.0177\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0191\n",
      "Epoch 12: val_loss did not improve from 0.10282\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1083 - mean_squared_error: 0.0191 - val_loss: 0.1031 - val_mean_squared_error: 0.0179\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0191\n",
      "Epoch 13: val_loss improved from 0.10282 to 0.10266, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1080 - mean_squared_error: 0.0190 - val_loss: 0.1027 - val_mean_squared_error: 0.0178\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0187\n",
      "Epoch 14: val_loss improved from 0.10266 to 0.10145, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1068 - mean_squared_error: 0.0187 - val_loss: 0.1014 - val_mean_squared_error: 0.0169\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0191\n",
      "Epoch 15: val_loss improved from 0.10145 to 0.10124, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1076 - mean_squared_error: 0.0191 - val_loss: 0.1012 - val_mean_squared_error: 0.0170\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0188\n",
      "Epoch 16: val_loss did not improve from 0.10124\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1073 - mean_squared_error: 0.0188 - val_loss: 0.1021 - val_mean_squared_error: 0.0173\n",
      "Epoch 17/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0190\n",
      "Epoch 17: val_loss did not improve from 0.10124\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1074 - mean_squared_error: 0.0189 - val_loss: 0.1025 - val_mean_squared_error: 0.0176\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0188\n",
      "Epoch 18: val_loss improved from 0.10124 to 0.10120, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1074 - mean_squared_error: 0.0188 - val_loss: 0.1012 - val_mean_squared_error: 0.0168\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0188\n",
      "Epoch 19: val_loss did not improve from 0.10120\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1071 - mean_squared_error: 0.0188 - val_loss: 0.1017 - val_mean_squared_error: 0.0171\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0192\n",
      "Epoch 20: val_loss did not improve from 0.10120\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1074 - mean_squared_error: 0.0192 - val_loss: 0.1028 - val_mean_squared_error: 0.0174\n",
      "Epoch 21/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0184\n",
      "Epoch 21: val_loss improved from 0.10120 to 0.10086, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1062 - mean_squared_error: 0.0184 - val_loss: 0.1009 - val_mean_squared_error: 0.0165\n",
      "Epoch 22/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0187\n",
      "Epoch 22: val_loss did not improve from 0.10086\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1067 - mean_squared_error: 0.0187 - val_loss: 0.1030 - val_mean_squared_error: 0.0177\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0189\n",
      "Epoch 23: val_loss did not improve from 0.10086\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1068 - mean_squared_error: 0.0189 - val_loss: 0.1014 - val_mean_squared_error: 0.0171\n",
      "Epoch 24/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0189\n",
      "Epoch 24: val_loss improved from 0.10086 to 0.10075, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1063 - mean_squared_error: 0.0189 - val_loss: 0.1008 - val_mean_squared_error: 0.0169\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0186\n",
      "Epoch 25: val_loss did not improve from 0.10075\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1063 - mean_squared_error: 0.0186 - val_loss: 0.1013 - val_mean_squared_error: 0.0172\n",
      "Epoch 26/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0186\n",
      "Epoch 26: val_loss improved from 0.10075 to 0.09989, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size15_pool5_do0.5_tra3_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1065 - mean_squared_error: 0.0186 - val_loss: 0.0999 - val_mean_squared_error: 0.0163\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0187\n",
      "Epoch 27: val_loss did not improve from 0.09989\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1063 - mean_squared_error: 0.0187 - val_loss: 0.1037 - val_mean_squared_error: 0.0177\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0189\n",
      "Epoch 28: val_loss did not improve from 0.09989\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1070 - mean_squared_error: 0.0189 - val_loss: 0.1028 - val_mean_squared_error: 0.0176\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0188\n",
      "Epoch 29: val_loss did not improve from 0.09989\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1070 - mean_squared_error: 0.0188 - val_loss: 0.1027 - val_mean_squared_error: 0.0175\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.81+-0.35\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1425 - mean_squared_error: 0.0347\n",
      "Epoch 1: val_loss improved from inf to 0.11497, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 18s 42ms/step - loss: 0.1424 - mean_squared_error: 0.0347 - val_loss: 0.1150 - val_mean_squared_error: 0.0216\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.0208\n",
      "Epoch 2: val_loss improved from 0.11497 to 0.09829, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1124 - mean_squared_error: 0.0208 - val_loss: 0.0983 - val_mean_squared_error: 0.0156\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0193\n",
      "Epoch 3: val_loss did not improve from 0.09829\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1079 - mean_squared_error: 0.0193 - val_loss: 0.1014 - val_mean_squared_error: 0.0169\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1052 - mean_squared_error: 0.0184\n",
      "Epoch 4: val_loss did not improve from 0.09829\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1052 - mean_squared_error: 0.0184 - val_loss: 0.0993 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0177\n",
      "Epoch 5: val_loss did not improve from 0.09829\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1033 - mean_squared_error: 0.0177 - val_loss: 0.1000 - val_mean_squared_error: 0.0160\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1576 - mean_squared_error: 0.0441\n",
      "Epoch 1: val_loss improved from inf to 0.11226, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 39ms/step - loss: 0.1576 - mean_squared_error: 0.0441 - val_loss: 0.1123 - val_mean_squared_error: 0.0203\n",
      "Epoch 2/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0201\n",
      "Epoch 2: val_loss improved from 0.11226 to 0.09645, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1100 - mean_squared_error: 0.0201 - val_loss: 0.0965 - val_mean_squared_error: 0.0156\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0189\n",
      "Epoch 3: val_loss did not improve from 0.09645\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1069 - mean_squared_error: 0.0189 - val_loss: 0.1328 - val_mean_squared_error: 0.0263\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1058 - mean_squared_error: 0.0186\n",
      "Epoch 4: val_loss did not improve from 0.09645\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1058 - mean_squared_error: 0.0186 - val_loss: 0.0967 - val_mean_squared_error: 0.0152\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0172\n",
      "Epoch 5: val_loss did not improve from 0.09645\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1024 - mean_squared_error: 0.0172 - val_loss: 0.0965 - val_mean_squared_error: 0.0152\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1434 - mean_squared_error: 0.0356\n",
      "Epoch 1: val_loss improved from inf to 0.09897, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 39ms/step - loss: 0.1432 - mean_squared_error: 0.0355 - val_loss: 0.0990 - val_mean_squared_error: 0.0167\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0211\n",
      "Epoch 2: val_loss improved from 0.09897 to 0.09714, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1134 - mean_squared_error: 0.0211 - val_loss: 0.0971 - val_mean_squared_error: 0.0157\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0186\n",
      "Epoch 3: val_loss did not improve from 0.09714\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1065 - mean_squared_error: 0.0186 - val_loss: 0.0976 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1053 - mean_squared_error: 0.0179\n",
      "Epoch 4: val_loss improved from 0.09714 to 0.09558, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1053 - mean_squared_error: 0.0179 - val_loss: 0.0956 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0172\n",
      "Epoch 5: val_loss improved from 0.09558 to 0.09558, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1026 - mean_squared_error: 0.0172 - val_loss: 0.0956 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.0168\n",
      "Epoch 6: val_loss did not improve from 0.09558\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1016 - mean_squared_error: 0.0168 - val_loss: 0.0975 - val_mean_squared_error: 0.0153\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0166\n",
      "Epoch 7: val_loss did not improve from 0.09558\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1006 - mean_squared_error: 0.0166 - val_loss: 0.0960 - val_mean_squared_error: 0.0153\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0166\n",
      "Epoch 8: val_loss improved from 0.09558 to 0.09479, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1009 - mean_squared_error: 0.0166 - val_loss: 0.0948 - val_mean_squared_error: 0.0151\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0164\n",
      "Epoch 9: val_loss did not improve from 0.09479\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1004 - mean_squared_error: 0.0164 - val_loss: 0.0955 - val_mean_squared_error: 0.0151\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.0164\n",
      "Epoch 10: val_loss did not improve from 0.09479\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1001 - mean_squared_error: 0.0164 - val_loss: 0.0950 - val_mean_squared_error: 0.0149\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0161\n",
      "Epoch 11: val_loss did not improve from 0.09479\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0995 - mean_squared_error: 0.0161 - val_loss: 0.0961 - val_mean_squared_error: 0.0151\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2233 - mean_squared_error: 0.0825\n",
      "Epoch 1: val_loss improved from inf to 0.13008, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.2233 - mean_squared_error: 0.0825 - val_loss: 0.1301 - val_mean_squared_error: 0.0258\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0205\n",
      "Epoch 2: val_loss improved from 0.13008 to 0.10058, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1118 - mean_squared_error: 0.0204 - val_loss: 0.1006 - val_mean_squared_error: 0.0171\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0185\n",
      "Epoch 3: val_loss did not improve from 0.10058\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1059 - mean_squared_error: 0.0185 - val_loss: 0.1016 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0175\n",
      "Epoch 4: val_loss improved from 0.10058 to 0.09798, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1026 - mean_squared_error: 0.0175 - val_loss: 0.0980 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.0170\n",
      "Epoch 5: val_loss did not improve from 0.09798\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1016 - mean_squared_error: 0.0170 - val_loss: 0.0986 - val_mean_squared_error: 0.0158\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0168\n",
      "Epoch 6: val_loss did not improve from 0.09798\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1007 - mean_squared_error: 0.0168 - val_loss: 0.1045 - val_mean_squared_error: 0.0170\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0999 - mean_squared_error: 0.0164\n",
      "Epoch 7: val_loss improved from 0.09798 to 0.09764, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0999 - mean_squared_error: 0.0164 - val_loss: 0.0976 - val_mean_squared_error: 0.0154\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0998 - mean_squared_error: 0.0164\n",
      "Epoch 8: val_loss did not improve from 0.09764\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0998 - mean_squared_error: 0.0164 - val_loss: 0.0978 - val_mean_squared_error: 0.0158\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0163\n",
      "Epoch 9: val_loss did not improve from 0.09764\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0996 - mean_squared_error: 0.0163 - val_loss: 0.0983 - val_mean_squared_error: 0.0159\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0161\n",
      "Epoch 10: val_loss improved from 0.09764 to 0.09753, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0988 - mean_squared_error: 0.0161 - val_loss: 0.0975 - val_mean_squared_error: 0.0154\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0161\n",
      "Epoch 11: val_loss did not improve from 0.09753\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0984 - mean_squared_error: 0.0160 - val_loss: 0.0981 - val_mean_squared_error: 0.0153\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0160\n",
      "Epoch 12: val_loss did not improve from 0.09753\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0987 - mean_squared_error: 0.0160 - val_loss: 0.0981 - val_mean_squared_error: 0.0154\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.0159\n",
      "Epoch 13: val_loss improved from 0.09753 to 0.09740, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0983 - mean_squared_error: 0.0159 - val_loss: 0.0974 - val_mean_squared_error: 0.0153\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0159\n",
      "Epoch 14: val_loss did not improve from 0.09740\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0987 - mean_squared_error: 0.0159 - val_loss: 0.0983 - val_mean_squared_error: 0.0155\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0989 - mean_squared_error: 0.0161\n",
      "Epoch 15: val_loss improved from 0.09740 to 0.09726, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0989 - mean_squared_error: 0.0161 - val_loss: 0.0973 - val_mean_squared_error: 0.0154\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0161\n",
      "Epoch 16: val_loss did not improve from 0.09726\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0987 - mean_squared_error: 0.0161 - val_loss: 0.0998 - val_mean_squared_error: 0.0157\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.0159\n",
      "Epoch 17: val_loss did not improve from 0.09726\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0982 - mean_squared_error: 0.0159 - val_loss: 0.0973 - val_mean_squared_error: 0.0156\n",
      "Epoch 18/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0160\n",
      "Epoch 18: val_loss improved from 0.09726 to 0.09687, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0986 - mean_squared_error: 0.0160 - val_loss: 0.0969 - val_mean_squared_error: 0.0154\n",
      "Epoch 19/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.0159\n",
      "Epoch 19: val_loss did not improve from 0.09687\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0982 - mean_squared_error: 0.0159 - val_loss: 0.0977 - val_mean_squared_error: 0.0153\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0979 - mean_squared_error: 0.0157\n",
      "Epoch 20: val_loss did not improve from 0.09687\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0979 - mean_squared_error: 0.0157 - val_loss: 0.0970 - val_mean_squared_error: 0.0154\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0981 - mean_squared_error: 0.0159\n",
      "Epoch 21: val_loss did not improve from 0.09687\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0981 - mean_squared_error: 0.0159 - val_loss: 0.0985 - val_mean_squared_error: 0.0155\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.76+-0.11\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3766 - mean_squared_error: 0.1679\n",
      "Epoch 1: val_loss improved from inf to 0.38420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 20s 113ms/step - loss: 0.3766 - mean_squared_error: 0.1680 - val_loss: 0.3842 - val_mean_squared_error: 0.1728\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3796 - mean_squared_error: 0.1695\n",
      "Epoch 2: val_loss improved from 0.38420 to 0.38348, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.3790 - mean_squared_error: 0.1692 - val_loss: 0.3835 - val_mean_squared_error: 0.1722\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3792 - mean_squared_error: 0.1692\n",
      "Epoch 3: val_loss improved from 0.38348 to 0.22595, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.3790 - mean_squared_error: 0.1690 - val_loss: 0.2259 - val_mean_squared_error: 0.0690\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1841 - mean_squared_error: 0.0532\n",
      "Epoch 4: val_loss improved from 0.22595 to 0.10690, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1839 - mean_squared_error: 0.0531 - val_loss: 0.1069 - val_mean_squared_error: 0.0185\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1215 - mean_squared_error: 0.0243\n",
      "Epoch 5: val_loss improved from 0.10690 to 0.10014, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1215 - mean_squared_error: 0.0243 - val_loss: 0.1001 - val_mean_squared_error: 0.0166\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1157 - mean_squared_error: 0.0221\n",
      "Epoch 6: val_loss improved from 0.10014 to 0.09803, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1157 - mean_squared_error: 0.0221 - val_loss: 0.0980 - val_mean_squared_error: 0.0159\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1120 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.09803\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1119 - mean_squared_error: 0.0209 - val_loss: 0.0992 - val_mean_squared_error: 0.0158\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1100 - mean_squared_error: 0.0200\n",
      "Epoch 8: val_loss did not improve from 0.09803\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1100 - mean_squared_error: 0.0200 - val_loss: 0.1005 - val_mean_squared_error: 0.0167\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0190\n",
      "Epoch 9: val_loss improved from 0.09803 to 0.09779, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 86ms/step - loss: 0.1079 - mean_squared_error: 0.0190 - val_loss: 0.0978 - val_mean_squared_error: 0.0158\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0186\n",
      "Epoch 10: val_loss did not improve from 0.09779\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1065 - mean_squared_error: 0.0186 - val_loss: 0.0980 - val_mean_squared_error: 0.0153\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1052 - mean_squared_error: 0.0182\n",
      "Epoch 11: val_loss improved from 0.09779 to 0.09745, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1052 - mean_squared_error: 0.0183 - val_loss: 0.0975 - val_mean_squared_error: 0.0157\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1051 - mean_squared_error: 0.0183\n",
      "Epoch 12: val_loss improved from 0.09745 to 0.09726, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1052 - mean_squared_error: 0.0183 - val_loss: 0.0973 - val_mean_squared_error: 0.0154\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0180\n",
      "Epoch 13: val_loss did not improve from 0.09726\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1045 - mean_squared_error: 0.0180 - val_loss: 0.0973 - val_mean_squared_error: 0.0155\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0179\n",
      "Epoch 14: val_loss improved from 0.09726 to 0.09725, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1038 - mean_squared_error: 0.0179 - val_loss: 0.0973 - val_mean_squared_error: 0.0153\n",
      "Epoch 15/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0179\n",
      "Epoch 15: val_loss did not improve from 0.09725\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1037 - mean_squared_error: 0.0179 - val_loss: 0.0973 - val_mean_squared_error: 0.0154\n",
      "Epoch 16/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0173\n",
      "Epoch 16: val_loss did not improve from 0.09725\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1022 - mean_squared_error: 0.0173 - val_loss: 0.0976 - val_mean_squared_error: 0.0157\n",
      "Epoch 17/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0172\n",
      "Epoch 17: val_loss did not improve from 0.09725\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1022 - mean_squared_error: 0.0172 - val_loss: 0.0974 - val_mean_squared_error: 0.0155\n",
      "14/14 [==============================] - 2s 34ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3782 - mean_squared_error: 0.1692\n",
      "Epoch 1: val_loss improved from inf to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 7s 108ms/step - loss: 0.3782 - mean_squared_error: 0.1692 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3837 - mean_squared_error: 0.1746\n",
      "Epoch 2: val_loss did not improve from 0.38084\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.3846 - mean_squared_error: 0.1755 - val_loss: 0.6187 - val_mean_squared_error: 0.4075\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3922 - mean_squared_error: 0.2121\n",
      "Epoch 3: val_loss improved from 0.38084 to 0.13934, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 86ms/step - loss: 0.3914 - mean_squared_error: 0.2116 - val_loss: 0.1393 - val_mean_squared_error: 0.0326\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1346 - mean_squared_error: 0.0297\n",
      "Epoch 4: val_loss improved from 0.13934 to 0.09833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.1346 - mean_squared_error: 0.0297 - val_loss: 0.0983 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1170 - mean_squared_error: 0.0226\n",
      "Epoch 5: val_loss improved from 0.09833 to 0.09681, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1171 - mean_squared_error: 0.0226 - val_loss: 0.0968 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0208\n",
      "Epoch 6: val_loss improved from 0.09681 to 0.09666, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 86ms/step - loss: 0.1125 - mean_squared_error: 0.0208 - val_loss: 0.0967 - val_mean_squared_error: 0.0155\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0202\n",
      "Epoch 7: val_loss did not improve from 0.09666\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1103 - mean_squared_error: 0.0202 - val_loss: 0.0974 - val_mean_squared_error: 0.0153\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1085 - mean_squared_error: 0.0196\n",
      "Epoch 8: val_loss improved from 0.09666 to 0.09618, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1085 - mean_squared_error: 0.0195 - val_loss: 0.0962 - val_mean_squared_error: 0.0152\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0187\n",
      "Epoch 9: val_loss did not improve from 0.09618\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1066 - mean_squared_error: 0.0187 - val_loss: 0.0963 - val_mean_squared_error: 0.0152\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0185\n",
      "Epoch 10: val_loss did not improve from 0.09618\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.1062 - mean_squared_error: 0.0185 - val_loss: 0.0977 - val_mean_squared_error: 0.0155\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1053 - mean_squared_error: 0.0184\n",
      "Epoch 11: val_loss did not improve from 0.09618\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1054 - mean_squared_error: 0.0184 - val_loss: 0.0976 - val_mean_squared_error: 0.0152\n",
      "14/14 [==============================] - 1s 32ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3774 - mean_squared_error: 0.1684\n",
      "Epoch 1: val_loss improved from inf to 0.38053, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 6s 103ms/step - loss: 0.3773 - mean_squared_error: 0.1683 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1705\n",
      "Epoch 2: val_loss improved from 0.38053 to 0.38050, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.3811 - mean_squared_error: 0.1705 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3479 - mean_squared_error: 0.1513\n",
      "Epoch 3: val_loss improved from 0.38050 to 0.20401, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 87ms/step - loss: 0.3473 - mean_squared_error: 0.1509 - val_loss: 0.2040 - val_mean_squared_error: 0.0631\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1509 - mean_squared_error: 0.0366\n",
      "Epoch 4: val_loss improved from 0.20401 to 0.10674, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1507 - mean_squared_error: 0.0366 - val_loss: 0.1067 - val_mean_squared_error: 0.0198\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1180 - mean_squared_error: 0.0229\n",
      "Epoch 5: val_loss improved from 0.10674 to 0.09862, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 86ms/step - loss: 0.1179 - mean_squared_error: 0.0229 - val_loss: 0.0986 - val_mean_squared_error: 0.0164\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1146 - mean_squared_error: 0.0214\n",
      "Epoch 6: val_loss improved from 0.09862 to 0.09590, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 86ms/step - loss: 0.1146 - mean_squared_error: 0.0214 - val_loss: 0.0959 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0206\n",
      "Epoch 7: val_loss did not improve from 0.09590\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.1116 - mean_squared_error: 0.0206 - val_loss: 0.0972 - val_mean_squared_error: 0.0156\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1088 - mean_squared_error: 0.0195\n",
      "Epoch 8: val_loss did not improve from 0.09590\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1087 - mean_squared_error: 0.0195 - val_loss: 0.0969 - val_mean_squared_error: 0.0160\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0191\n",
      "Epoch 9: val_loss improved from 0.09590 to 0.09515, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1085 - mean_squared_error: 0.0191 - val_loss: 0.0952 - val_mean_squared_error: 0.0151\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0182\n",
      "Epoch 10: val_loss did not improve from 0.09515\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1054 - mean_squared_error: 0.0181 - val_loss: 0.0959 - val_mean_squared_error: 0.0158\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0181\n",
      "Epoch 11: val_loss improved from 0.09515 to 0.09492, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.1056 - mean_squared_error: 0.0182 - val_loss: 0.0949 - val_mean_squared_error: 0.0152\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.0179\n",
      "Epoch 12: val_loss did not improve from 0.09492\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1045 - mean_squared_error: 0.0179 - val_loss: 0.0956 - val_mean_squared_error: 0.0151\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0182\n",
      "Epoch 13: val_loss did not improve from 0.09492\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.1055 - mean_squared_error: 0.0182 - val_loss: 0.0964 - val_mean_squared_error: 0.0153\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0179\n",
      "Epoch 14: val_loss improved from 0.09492 to 0.09472, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.1040 - mean_squared_error: 0.0179 - val_loss: 0.0947 - val_mean_squared_error: 0.0150\n",
      "Epoch 15/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0174\n",
      "Epoch 15: val_loss did not improve from 0.09472\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1032 - mean_squared_error: 0.0174 - val_loss: 0.0976 - val_mean_squared_error: 0.0166\n",
      "Epoch 16/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0173\n",
      "Epoch 16: val_loss did not improve from 0.09472\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1029 - mean_squared_error: 0.0173 - val_loss: 0.0951 - val_mean_squared_error: 0.0151\n",
      "Epoch 17/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0171\n",
      "Epoch 17: val_loss did not improve from 0.09472\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1025 - mean_squared_error: 0.0171 - val_loss: 0.0949 - val_mean_squared_error: 0.0153\n",
      "14/14 [==============================] - 1s 33ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3791 - mean_squared_error: 0.1695\n",
      "Epoch 1: val_loss improved from inf to 0.37837, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 7s 118ms/step - loss: 0.3790 - mean_squared_error: 0.1694 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1711\n",
      "Epoch 2: val_loss improved from 0.37837 to 0.37837, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.3818 - mean_squared_error: 0.1710 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3818 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss improved from 0.37837 to 0.37836, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3854 - mean_squared_error: 0.1752\n",
      "Epoch 4: val_loss improved from 0.37836 to 0.37823, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt128_stride4_size7_pool2_do0.1_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.3862 - mean_squared_error: 0.1760 - val_loss: 0.3782 - val_mean_squared_error: 0.1691\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.4766 - mean_squared_error: 0.2690\n",
      "Epoch 5: val_loss did not improve from 0.37823\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.4762 - mean_squared_error: 0.2687 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3864 - mean_squared_error: 0.1757\n",
      "Epoch 6: val_loss did not improve from 0.37823\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.3865 - mean_squared_error: 0.1757 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3817 - mean_squared_error: 0.1709\n",
      "Epoch 7: val_loss did not improve from 0.37823\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.3818 - mean_squared_error: 0.1709 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "14/14 [==============================] - 1s 30ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae16.78+-12.33\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2465 - mean_squared_error: 0.0906\n",
      "Epoch 1: val_loss improved from inf to 0.11017, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 14s 83ms/step - loss: 0.2464 - mean_squared_error: 0.0905 - val_loss: 0.1102 - val_mean_squared_error: 0.0202\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1978 - mean_squared_error: 0.0613\n",
      "Epoch 2: val_loss did not improve from 0.11017\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1977 - mean_squared_error: 0.0613 - val_loss: 0.1165 - val_mean_squared_error: 0.0221\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1758 - mean_squared_error: 0.0500\n",
      "Epoch 3: val_loss improved from 0.11017 to 0.10289, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1757 - mean_squared_error: 0.0499 - val_loss: 0.1029 - val_mean_squared_error: 0.0176\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1575 - mean_squared_error: 0.0403\n",
      "Epoch 4: val_loss improved from 0.10289 to 0.10048, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1574 - mean_squared_error: 0.0402 - val_loss: 0.1005 - val_mean_squared_error: 0.0163\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1416 - mean_squared_error: 0.0331\n",
      "Epoch 5: val_loss improved from 0.10048 to 0.10010, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1417 - mean_squared_error: 0.0331 - val_loss: 0.1001 - val_mean_squared_error: 0.0163\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1316 - mean_squared_error: 0.0288\n",
      "Epoch 6: val_loss did not improve from 0.10010\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1317 - mean_squared_error: 0.0288 - val_loss: 0.1007 - val_mean_squared_error: 0.0166\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1214 - mean_squared_error: 0.0242\n",
      "Epoch 7: val_loss did not improve from 0.10010\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1213 - mean_squared_error: 0.0242 - val_loss: 0.1012 - val_mean_squared_error: 0.0164\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1180 - mean_squared_error: 0.0228\n",
      "Epoch 8: val_loss did not improve from 0.10010\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1179 - mean_squared_error: 0.0228 - val_loss: 0.1012 - val_mean_squared_error: 0.0165\n",
      "14/14 [==============================] - 1s 21ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2478 - mean_squared_error: 0.0922\n",
      "Epoch 1: val_loss improved from inf to 0.12889, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 4s 68ms/step - loss: 0.2478 - mean_squared_error: 0.0922 - val_loss: 0.1289 - val_mean_squared_error: 0.0261\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1937 - mean_squared_error: 0.0586\n",
      "Epoch 2: val_loss improved from 0.12889 to 0.10996, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1936 - mean_squared_error: 0.0585 - val_loss: 0.1100 - val_mean_squared_error: 0.0193\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1744 - mean_squared_error: 0.0492\n",
      "Epoch 3: val_loss improved from 0.10996 to 0.10439, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1743 - mean_squared_error: 0.0491 - val_loss: 0.1044 - val_mean_squared_error: 0.0172\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1544 - mean_squared_error: 0.0393\n",
      "Epoch 4: val_loss improved from 0.10439 to 0.10101, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1544 - mean_squared_error: 0.0393 - val_loss: 0.1010 - val_mean_squared_error: 0.0163\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1397 - mean_squared_error: 0.0322\n",
      "Epoch 5: val_loss did not improve from 0.10101\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1397 - mean_squared_error: 0.0322 - val_loss: 0.1017 - val_mean_squared_error: 0.0164\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1296 - mean_squared_error: 0.0275\n",
      "Epoch 6: val_loss did not improve from 0.10101\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1297 - mean_squared_error: 0.0275 - val_loss: 0.1047 - val_mean_squared_error: 0.0168\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1222 - mean_squared_error: 0.0245\n",
      "Epoch 7: val_loss did not improve from 0.10101\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1223 - mean_squared_error: 0.0245 - val_loss: 0.1033 - val_mean_squared_error: 0.0166\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2485 - mean_squared_error: 0.0923\n",
      "Epoch 1: val_loss improved from inf to 0.14465, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 4s 75ms/step - loss: 0.2485 - mean_squared_error: 0.0923 - val_loss: 0.1446 - val_mean_squared_error: 0.0313\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1938 - mean_squared_error: 0.0592\n",
      "Epoch 2: val_loss improved from 0.14465 to 0.13289, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1939 - mean_squared_error: 0.0592 - val_loss: 0.1329 - val_mean_squared_error: 0.0265\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1715 - mean_squared_error: 0.0476\n",
      "Epoch 3: val_loss improved from 0.13289 to 0.10133, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1715 - mean_squared_error: 0.0476 - val_loss: 0.1013 - val_mean_squared_error: 0.0164\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1515 - mean_squared_error: 0.0374\n",
      "Epoch 4: val_loss improved from 0.10133 to 0.09981, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1516 - mean_squared_error: 0.0375 - val_loss: 0.0998 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1404 - mean_squared_error: 0.0324\n",
      "Epoch 5: val_loss did not improve from 0.09981\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1405 - mean_squared_error: 0.0324 - val_loss: 0.1010 - val_mean_squared_error: 0.0161\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1278 - mean_squared_error: 0.0268\n",
      "Epoch 6: val_loss did not improve from 0.09981\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1277 - mean_squared_error: 0.0268 - val_loss: 0.1051 - val_mean_squared_error: 0.0168\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1211 - mean_squared_error: 0.0239\n",
      "Epoch 7: val_loss did not improve from 0.09981\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1211 - mean_squared_error: 0.0238 - val_loss: 0.1066 - val_mean_squared_error: 0.0170\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2473 - mean_squared_error: 0.0914\n",
      "Epoch 1: val_loss improved from inf to 0.15441, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 5s 84ms/step - loss: 0.2472 - mean_squared_error: 0.0913 - val_loss: 0.1544 - val_mean_squared_error: 0.0359\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1925 - mean_squared_error: 0.0583\n",
      "Epoch 2: val_loss did not improve from 0.15441\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1924 - mean_squared_error: 0.0583 - val_loss: 0.1639 - val_mean_squared_error: 0.0383\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1709 - mean_squared_error: 0.0470\n",
      "Epoch 3: val_loss improved from 0.15441 to 0.13227, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1709 - mean_squared_error: 0.0470 - val_loss: 0.1323 - val_mean_squared_error: 0.0253\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1520 - mean_squared_error: 0.0376\n",
      "Epoch 4: val_loss improved from 0.13227 to 0.12349, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1520 - mean_squared_error: 0.0376 - val_loss: 0.1235 - val_mean_squared_error: 0.0223\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1373 - mean_squared_error: 0.0310\n",
      "Epoch 5: val_loss did not improve from 0.12349\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1372 - mean_squared_error: 0.0309 - val_loss: 0.1264 - val_mean_squared_error: 0.0228\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1256 - mean_squared_error: 0.0263\n",
      "Epoch 6: val_loss improved from 0.12349 to 0.11736, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride5_size15_pool5_do0.5_tra4_head4_kdim16_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.1256 - mean_squared_error: 0.0263 - val_loss: 0.1174 - val_mean_squared_error: 0.0201\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1193 - mean_squared_error: 0.0234\n",
      "Epoch 7: val_loss did not improve from 0.11736\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.1193 - mean_squared_error: 0.0234 - val_loss: 0.1263 - val_mean_squared_error: 0.0226\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1152 - mean_squared_error: 0.0218\n",
      "Epoch 8: val_loss did not improve from 0.11736\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1152 - mean_squared_error: 0.0217 - val_loss: 0.1242 - val_mean_squared_error: 0.0218\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1126 - mean_squared_error: 0.0206\n",
      "Epoch 9: val_loss did not improve from 0.11736\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1127 - mean_squared_error: 0.0206 - val_loss: 0.1212 - val_mean_squared_error: 0.0210\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###3 fold : val mae 0.12###\n",
      "mae10.56+-0.66\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1749 - mean_squared_error: 0.0504\n",
      "Epoch 1: val_loss improved from inf to 0.19920, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 18s 46ms/step - loss: 0.1749 - mean_squared_error: 0.0504 - val_loss: 0.1992 - val_mean_squared_error: 0.0526\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1209 - mean_squared_error: 0.0242\n",
      "Epoch 2: val_loss improved from 0.19920 to 0.10389, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.1209 - mean_squared_error: 0.0242 - val_loss: 0.1039 - val_mean_squared_error: 0.0167\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1129 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10389\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1129 - mean_squared_error: 0.0211 - val_loss: 0.1410 - val_mean_squared_error: 0.0282\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0194\n",
      "Epoch 4: val_loss did not improve from 0.10389\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1082 - mean_squared_error: 0.0194 - val_loss: 0.1502 - val_mean_squared_error: 0.0317\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0182\n",
      "Epoch 5: val_loss did not improve from 0.10389\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1054 - mean_squared_error: 0.0182 - val_loss: 0.1410 - val_mean_squared_error: 0.0281\n",
      "53/53 [==============================] - 3s 17ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1673 - mean_squared_error: 0.0474\n",
      "Epoch 1: val_loss improved from inf to 0.32109, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 10s 44ms/step - loss: 0.1673 - mean_squared_error: 0.0474 - val_loss: 0.3211 - val_mean_squared_error: 0.1188\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1193 - mean_squared_error: 0.0234\n",
      "Epoch 2: val_loss improved from 0.32109 to 0.17886, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1193 - mean_squared_error: 0.0234 - val_loss: 0.1789 - val_mean_squared_error: 0.0432\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0199\n",
      "Epoch 3: val_loss improved from 0.17886 to 0.14229, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1101 - mean_squared_error: 0.0199 - val_loss: 0.1423 - val_mean_squared_error: 0.0293\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss did not improve from 0.14229\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1071 - mean_squared_error: 0.0188 - val_loss: 0.1525 - val_mean_squared_error: 0.0324\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0178\n",
      "Epoch 5: val_loss did not improve from 0.14229\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1037 - mean_squared_error: 0.0178 - val_loss: 0.1617 - val_mean_squared_error: 0.0360\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0175\n",
      "Epoch 6: val_loss did not improve from 0.14229\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1033 - mean_squared_error: 0.0175 - val_loss: 0.1534 - val_mean_squared_error: 0.0329\n",
      "53/53 [==============================] - 2s 16ms/step\n",
      " ###1 fold : val mae 0.15###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3804 - mean_squared_error: 0.1704\n",
      "Epoch 1: val_loss improved from inf to 0.38051, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 10s 48ms/step - loss: 0.3804 - mean_squared_error: 0.1704 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 2: val_loss improved from 0.38051 to 0.38050, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss did not improve from 0.38050\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 4: val_loss did not improve from 0.38050\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 5: val_loss did not improve from 0.38050\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "53/53 [==============================] - 2s 16ms/step\n",
      " ###2 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2819 - mean_squared_error: 0.1121\n",
      "Epoch 1: val_loss improved from inf to 0.60618, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 10s 46ms/step - loss: 0.2819 - mean_squared_error: 0.1121 - val_loss: 0.6062 - val_mean_squared_error: 0.3924\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1214 - mean_squared_error: 0.0243\n",
      "Epoch 2: val_loss improved from 0.60618 to 0.44413, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1214 - mean_squared_error: 0.0243 - val_loss: 0.4441 - val_mean_squared_error: 0.2157\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1094 - mean_squared_error: 0.0197\n",
      "Epoch 3: val_loss improved from 0.44413 to 0.31559, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1094 - mean_squared_error: 0.0197 - val_loss: 0.3156 - val_mean_squared_error: 0.1162\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1053 - mean_squared_error: 0.0181\n",
      "Epoch 4: val_loss improved from 0.31559 to 0.24936, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1053 - mean_squared_error: 0.0181 - val_loss: 0.2494 - val_mean_squared_error: 0.0765\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0174\n",
      "Epoch 5: val_loss improved from 0.24936 to 0.22088, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1026 - mean_squared_error: 0.0174 - val_loss: 0.2209 - val_mean_squared_error: 0.0619\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0174\n",
      "Epoch 6: val_loss improved from 0.22088 to 0.20438, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1030 - mean_squared_error: 0.0174 - val_loss: 0.2044 - val_mean_squared_error: 0.0541\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0168\n",
      "Epoch 7: val_loss improved from 0.20438 to 0.19395, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1013 - mean_squared_error: 0.0168 - val_loss: 0.1939 - val_mean_squared_error: 0.0496\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0168\n",
      "Epoch 8: val_loss improved from 0.19395 to 0.18180, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1011 - mean_squared_error: 0.0168 - val_loss: 0.1818 - val_mean_squared_error: 0.0440\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0168\n",
      "Epoch 9: val_loss did not improve from 0.18180\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1011 - mean_squared_error: 0.0168 - val_loss: 0.1856 - val_mean_squared_error: 0.0458\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.0168\n",
      "Epoch 10: val_loss improved from 0.18180 to 0.17440, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1010 - mean_squared_error: 0.0168 - val_loss: 0.1744 - val_mean_squared_error: 0.0411\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0169\n",
      "Epoch 11: val_loss improved from 0.17440 to 0.15938, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1011 - mean_squared_error: 0.0169 - val_loss: 0.1594 - val_mean_squared_error: 0.0348\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0164\n",
      "Epoch 12: val_loss improved from 0.15938 to 0.14753, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride4_size15_pool2_do0.2_tra4_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.1002 - mean_squared_error: 0.0164 - val_loss: 0.1475 - val_mean_squared_error: 0.0302\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0167\n",
      "Epoch 13: val_loss did not improve from 0.14753\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1008 - mean_squared_error: 0.0167 - val_loss: 0.1543 - val_mean_squared_error: 0.0331\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0165\n",
      "Epoch 14: val_loss did not improve from 0.14753\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1003 - mean_squared_error: 0.0165 - val_loss: 0.1692 - val_mean_squared_error: 0.0389\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0167\n",
      "Epoch 15: val_loss did not improve from 0.14753\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1008 - mean_squared_error: 0.0167 - val_loss: 0.1640 - val_mean_squared_error: 0.0369\n",
      "53/53 [==============================] - 2s 17ms/step\n",
      " ###3 fold : val mae 0.15###\n",
      "mae19.43+-10.94\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1573 - mean_squared_error: 0.0417\n",
      "Epoch 1: val_loss improved from inf to 0.10169, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 18s 41ms/step - loss: 0.1573 - mean_squared_error: 0.0417 - val_loss: 0.1017 - val_mean_squared_error: 0.0167\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1154 - mean_squared_error: 0.0222\n",
      "Epoch 2: val_loss improved from 0.10169 to 0.10013, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1154 - mean_squared_error: 0.0222 - val_loss: 0.1001 - val_mean_squared_error: 0.0164\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1089 - mean_squared_error: 0.0197\n",
      "Epoch 3: val_loss improved from 0.10013 to 0.09666, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1088 - mean_squared_error: 0.0196 - val_loss: 0.0967 - val_mean_squared_error: 0.0151\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0174\n",
      "Epoch 4: val_loss improved from 0.09666 to 0.09435, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1029 - mean_squared_error: 0.0173 - val_loss: 0.0944 - val_mean_squared_error: 0.0149\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.0160\n",
      "Epoch 5: val_loss improved from 0.09435 to 0.09107, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0982 - mean_squared_error: 0.0160 - val_loss: 0.0911 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0943 - mean_squared_error: 0.0148\n",
      "Epoch 6: val_loss improved from 0.09107 to 0.09103, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0943 - mean_squared_error: 0.0149 - val_loss: 0.0910 - val_mean_squared_error: 0.0136\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0906 - mean_squared_error: 0.0139\n",
      "Epoch 7: val_loss improved from 0.09103 to 0.08840, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0906 - mean_squared_error: 0.0139 - val_loss: 0.0884 - val_mean_squared_error: 0.0133\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0892 - mean_squared_error: 0.0134\n",
      "Epoch 8: val_loss improved from 0.08840 to 0.08716, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0892 - mean_squared_error: 0.0134 - val_loss: 0.0872 - val_mean_squared_error: 0.0127\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0870 - mean_squared_error: 0.0128\n",
      "Epoch 9: val_loss did not improve from 0.08716\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0870 - mean_squared_error: 0.0128 - val_loss: 0.0873 - val_mean_squared_error: 0.0129\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0863 - mean_squared_error: 0.0126\n",
      "Epoch 10: val_loss did not improve from 0.08716\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0862 - mean_squared_error: 0.0126 - val_loss: 0.0946 - val_mean_squared_error: 0.0150\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0855 - mean_squared_error: 0.0124\n",
      "Epoch 11: val_loss did not improve from 0.08716\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0855 - mean_squared_error: 0.0124 - val_loss: 0.0904 - val_mean_squared_error: 0.0134\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1497 - mean_squared_error: 0.0390\n",
      "Epoch 1: val_loss improved from inf to 0.10449, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.1497 - mean_squared_error: 0.0390 - val_loss: 0.1045 - val_mean_squared_error: 0.0184\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1131 - mean_squared_error: 0.0210\n",
      "Epoch 2: val_loss improved from 0.10449 to 0.09712, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1131 - mean_squared_error: 0.0210 - val_loss: 0.0971 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0192\n",
      "Epoch 3: val_loss did not improve from 0.09712\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1079 - mean_squared_error: 0.0192 - val_loss: 0.0987 - val_mean_squared_error: 0.0162\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0182\n",
      "Epoch 4: val_loss improved from 0.09712 to 0.09557, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1050 - mean_squared_error: 0.0182 - val_loss: 0.0956 - val_mean_squared_error: 0.0151\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss did not improve from 0.09557\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1031 - mean_squared_error: 0.0176 - val_loss: 0.0965 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0174\n",
      "Epoch 6: val_loss did not improve from 0.09557\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1029 - mean_squared_error: 0.0173 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.0170\n",
      "Epoch 7: val_loss did not improve from 0.09557\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1017 - mean_squared_error: 0.0170 - val_loss: 0.0971 - val_mean_squared_error: 0.0156\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1492 - mean_squared_error: 0.0377\n",
      "Epoch 1: val_loss improved from inf to 0.10081, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 39ms/step - loss: 0.1492 - mean_squared_error: 0.0377 - val_loss: 0.1008 - val_mean_squared_error: 0.0169\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1138 - mean_squared_error: 0.0214\n",
      "Epoch 2: val_loss improved from 0.10081 to 0.09566, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1138 - mean_squared_error: 0.0214 - val_loss: 0.0957 - val_mean_squared_error: 0.0152\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0190\n",
      "Epoch 3: val_loss improved from 0.09566 to 0.09539, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1072 - mean_squared_error: 0.0190 - val_loss: 0.0954 - val_mean_squared_error: 0.0155\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0181\n",
      "Epoch 4: val_loss did not improve from 0.09539\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1046 - mean_squared_error: 0.0181 - val_loss: 0.0970 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0173\n",
      "Epoch 5: val_loss improved from 0.09539 to 0.09506, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1034 - mean_squared_error: 0.0173 - val_loss: 0.0951 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0170\n",
      "Epoch 6: val_loss did not improve from 0.09506\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1025 - mean_squared_error: 0.0170 - val_loss: 0.0961 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.0170\n",
      "Epoch 7: val_loss did not improve from 0.09506\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1018 - mean_squared_error: 0.0170 - val_loss: 0.0960 - val_mean_squared_error: 0.0159\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0166\n",
      "Epoch 8: val_loss did not improve from 0.09506\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1007 - mean_squared_error: 0.0166 - val_loss: 0.0952 - val_mean_squared_error: 0.0152\n",
      "53/53 [==============================] - 2s 11ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1442 - mean_squared_error: 0.0358\n",
      "Epoch 1: val_loss improved from inf to 0.09922, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.1442 - mean_squared_error: 0.0358 - val_loss: 0.0992 - val_mean_squared_error: 0.0162\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1130 - mean_squared_error: 0.0213\n",
      "Epoch 2: val_loss improved from 0.09922 to 0.09870, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1130 - mean_squared_error: 0.0213 - val_loss: 0.0987 - val_mean_squared_error: 0.0164\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 3: val_loss improved from 0.09870 to 0.09792, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1072 - mean_squared_error: 0.0189 - val_loss: 0.0979 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0180\n",
      "Epoch 4: val_loss did not improve from 0.09792\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1039 - mean_squared_error: 0.0180 - val_loss: 0.0980 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0175\n",
      "Epoch 5: val_loss improved from 0.09792 to 0.09688, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride4_size7_pool5_do0.1_tra4_head4_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1035 - mean_squared_error: 0.0175 - val_loss: 0.0969 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0171\n",
      "Epoch 6: val_loss did not improve from 0.09688\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1013 - mean_squared_error: 0.0171 - val_loss: 0.0980 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0168\n",
      "Epoch 7: val_loss did not improve from 0.09688\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1009 - mean_squared_error: 0.0168 - val_loss: 0.0973 - val_mean_squared_error: 0.0154\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0164\n",
      "Epoch 8: val_loss did not improve from 0.09688\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0997 - mean_squared_error: 0.0164 - val_loss: 0.0976 - val_mean_squared_error: 0.0155\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.43+-0.48\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2957 - mean_squared_error: 0.1212\n",
      "Epoch 1: val_loss improved from inf to 0.37571, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 17s 43ms/step - loss: 0.2957 - mean_squared_error: 0.1212 - val_loss: 0.3757 - val_mean_squared_error: 0.1592\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1179 - mean_squared_error: 0.0229\n",
      "Epoch 2: val_loss improved from 0.37571 to 0.12590, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1179 - mean_squared_error: 0.0229 - val_loss: 0.1259 - val_mean_squared_error: 0.0237\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1087 - mean_squared_error: 0.0198\n",
      "Epoch 3: val_loss improved from 0.12590 to 0.09904, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1087 - mean_squared_error: 0.0198 - val_loss: 0.0990 - val_mean_squared_error: 0.0164\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 4: val_loss did not improve from 0.09904\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1072 - mean_squared_error: 0.0189 - val_loss: 0.1017 - val_mean_squared_error: 0.0173\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0180\n",
      "Epoch 5: val_loss did not improve from 0.09904\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1045 - mean_squared_error: 0.0180 - val_loss: 0.1030 - val_mean_squared_error: 0.0166\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0175\n",
      "Epoch 6: val_loss did not improve from 0.09904\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1031 - mean_squared_error: 0.0175 - val_loss: 0.0994 - val_mean_squared_error: 0.0155\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3809 - mean_squared_error: 0.1709\n",
      "Epoch 1: val_loss improved from inf to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.3809 - mean_squared_error: 0.1709 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 2: val_loss improved from 0.38084 to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 3: val_loss improved from 0.38084 to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 4: val_loss improved from 0.38084 to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 5: val_loss improved from 0.38084 to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 6: val_loss improved from 0.38084 to 0.38084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3810 - mean_squared_error: 0.1708\n",
      "Epoch 7: val_loss improved from 0.38084 to 0.38083, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3810 - mean_squared_error: 0.1708 - val_loss: 0.3808 - val_mean_squared_error: 0.1697\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3518 - mean_squared_error: 0.1532\n",
      "Epoch 8: val_loss did not improve from 0.38083\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.3518 - mean_squared_error: 0.1532 - val_loss: 0.5833 - val_mean_squared_error: 0.3626\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1218 - mean_squared_error: 0.0247\n",
      "Epoch 9: val_loss improved from 0.38083 to 0.23827, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1218 - mean_squared_error: 0.0247 - val_loss: 0.2383 - val_mean_squared_error: 0.0713\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0192\n",
      "Epoch 10: val_loss improved from 0.23827 to 0.13364, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1076 - mean_squared_error: 0.0192 - val_loss: 0.1336 - val_mean_squared_error: 0.0260\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1043 - mean_squared_error: 0.0181\n",
      "Epoch 11: val_loss improved from 0.13364 to 0.12380, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1043 - mean_squared_error: 0.0181 - val_loss: 0.1238 - val_mean_squared_error: 0.0231\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0173\n",
      "Epoch 12: val_loss improved from 0.12380 to 0.11019, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1023 - mean_squared_error: 0.0173 - val_loss: 0.1102 - val_mean_squared_error: 0.0188\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0172\n",
      "Epoch 13: val_loss improved from 0.11019 to 0.10130, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1023 - mean_squared_error: 0.0172 - val_loss: 0.1013 - val_mean_squared_error: 0.0163\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0164\n",
      "Epoch 14: val_loss improved from 0.10130 to 0.09874, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1002 - mean_squared_error: 0.0164 - val_loss: 0.0987 - val_mean_squared_error: 0.0158\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0998 - mean_squared_error: 0.0164\n",
      "Epoch 15: val_loss improved from 0.09874 to 0.09554, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.0998 - mean_squared_error: 0.0164 - val_loss: 0.0955 - val_mean_squared_error: 0.0150\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0994 - mean_squared_error: 0.0163\n",
      "Epoch 16: val_loss did not improve from 0.09554\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0994 - mean_squared_error: 0.0163 - val_loss: 0.1143 - val_mean_squared_error: 0.0197\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0993 - mean_squared_error: 0.0162\n",
      "Epoch 17: val_loss did not improve from 0.09554\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0993 - mean_squared_error: 0.0162 - val_loss: 0.1068 - val_mean_squared_error: 0.0176\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0162\n",
      "Epoch 18: val_loss did not improve from 0.09554\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0992 - mean_squared_error: 0.0162 - val_loss: 0.0994 - val_mean_squared_error: 0.0157\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3812 - mean_squared_error: 0.1708\n",
      "Epoch 1: val_loss improved from inf to 0.38054, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 9s 43ms/step - loss: 0.3812 - mean_squared_error: 0.1708 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 2: val_loss did not improve from 0.38054\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss did not improve from 0.38054\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 4: val_loss did not improve from 0.38054\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1705\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###2 fold : val mae 0.38###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3821 - mean_squared_error: 0.1713\n",
      "Epoch 1: val_loss improved from inf to 0.37833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.3821 - mean_squared_error: 0.1713 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss improved from 0.37833 to 0.37833, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt64_stride2_size15_pool5_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss did not improve from 0.37833\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 4: val_loss did not improve from 0.37833\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 5: val_loss did not improve from 0.37833\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae23.99+-14.16\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1543 - mean_squared_error: 0.0414\n",
      "Epoch 1: val_loss improved from inf to 0.11169, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 17s 42ms/step - loss: 0.1543 - mean_squared_error: 0.0414 - val_loss: 0.1117 - val_mean_squared_error: 0.0208\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1168 - mean_squared_error: 0.0225\n",
      "Epoch 2: val_loss improved from 0.11169 to 0.09806, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1168 - mean_squared_error: 0.0225 - val_loss: 0.0981 - val_mean_squared_error: 0.0159\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0200\n",
      "Epoch 3: val_loss improved from 0.09806 to 0.09779, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1102 - mean_squared_error: 0.0200 - val_loss: 0.0978 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0190\n",
      "Epoch 4: val_loss did not improve from 0.09779\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1070 - mean_squared_error: 0.0190 - val_loss: 0.0985 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0179\n",
      "Epoch 5: val_loss improved from 0.09779 to 0.09462, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1039 - mean_squared_error: 0.0179 - val_loss: 0.0946 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0999 - mean_squared_error: 0.0166\n",
      "Epoch 6: val_loss improved from 0.09462 to 0.08919, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0999 - mean_squared_error: 0.0166 - val_loss: 0.0892 - val_mean_squared_error: 0.0135\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0150\n",
      "Epoch 7: val_loss did not improve from 0.08919\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0953 - mean_squared_error: 0.0150 - val_loss: 0.0973 - val_mean_squared_error: 0.0160\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0922 - mean_squared_error: 0.0141\n",
      "Epoch 8: val_loss did not improve from 0.08919\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0922 - mean_squared_error: 0.0141 - val_loss: 0.0908 - val_mean_squared_error: 0.0135\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.0136\n",
      "Epoch 9: val_loss did not improve from 0.08919\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.0898 - mean_squared_error: 0.0136 - val_loss: 0.0926 - val_mean_squared_error: 0.0146\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1563 - mean_squared_error: 0.0429\n",
      "Epoch 1: val_loss improved from inf to 0.10403, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.1562 - mean_squared_error: 0.0428 - val_loss: 0.1040 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1143 - mean_squared_error: 0.0216\n",
      "Epoch 2: val_loss improved from 0.10403 to 0.09849, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1143 - mean_squared_error: 0.0215 - val_loss: 0.0985 - val_mean_squared_error: 0.0159\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0193\n",
      "Epoch 3: val_loss improved from 0.09849 to 0.09823, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1083 - mean_squared_error: 0.0193 - val_loss: 0.0982 - val_mean_squared_error: 0.0163\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1058 - mean_squared_error: 0.0184\n",
      "Epoch 4: val_loss improved from 0.09823 to 0.09593, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1058 - mean_squared_error: 0.0184 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss did not improve from 0.09593\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1038 - mean_squared_error: 0.0176 - val_loss: 0.0974 - val_mean_squared_error: 0.0152\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0176\n",
      "Epoch 6: val_loss did not improve from 0.09593\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1035 - mean_squared_error: 0.0176 - val_loss: 0.0985 - val_mean_squared_error: 0.0161\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0172\n",
      "Epoch 7: val_loss improved from 0.09593 to 0.09592, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1023 - mean_squared_error: 0.0172 - val_loss: 0.0959 - val_mean_squared_error: 0.0150\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0170\n",
      "Epoch 8: val_loss improved from 0.09592 to 0.09565, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1015 - mean_squared_error: 0.0170 - val_loss: 0.0956 - val_mean_squared_error: 0.0150\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0163\n",
      "Epoch 9: val_loss improved from 0.09565 to 0.09558, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0995 - mean_squared_error: 0.0163 - val_loss: 0.0956 - val_mean_squared_error: 0.0148\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0163\n",
      "Epoch 10: val_loss did not improve from 0.09558\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0996 - mean_squared_error: 0.0163 - val_loss: 0.0957 - val_mean_squared_error: 0.0149\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.0165\n",
      "Epoch 11: val_loss did not improve from 0.09558\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1001 - mean_squared_error: 0.0165 - val_loss: 0.0961 - val_mean_squared_error: 0.0151\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0163\n",
      "Epoch 12: val_loss did not improve from 0.09558\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0995 - mean_squared_error: 0.0163 - val_loss: 0.0960 - val_mean_squared_error: 0.0151\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1448 - mean_squared_error: 0.0364\n",
      "Epoch 1: val_loss improved from inf to 0.11625, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.1448 - mean_squared_error: 0.0364 - val_loss: 0.1162 - val_mean_squared_error: 0.0229\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1140 - mean_squared_error: 0.0214\n",
      "Epoch 2: val_loss improved from 0.11625 to 0.09685, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1140 - mean_squared_error: 0.0214 - val_loss: 0.0969 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0190\n",
      "Epoch 3: val_loss improved from 0.09685 to 0.09584, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1078 - mean_squared_error: 0.0190 - val_loss: 0.0958 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0179\n",
      "Epoch 4: val_loss improved from 0.09584 to 0.09579, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1046 - mean_squared_error: 0.0179 - val_loss: 0.0958 - val_mean_squared_error: 0.0153\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0174\n",
      "Epoch 5: val_loss improved from 0.09579 to 0.09547, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1034 - mean_squared_error: 0.0174 - val_loss: 0.0955 - val_mean_squared_error: 0.0150\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0172\n",
      "Epoch 6: val_loss did not improve from 0.09547\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1021 - mean_squared_error: 0.0172 - val_loss: 0.0956 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.0169\n",
      "Epoch 7: val_loss improved from 0.09547 to 0.09510, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1018 - mean_squared_error: 0.0169 - val_loss: 0.0951 - val_mean_squared_error: 0.0154\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0167\n",
      "Epoch 8: val_loss did not improve from 0.09510\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1011 - mean_squared_error: 0.0167 - val_loss: 0.0966 - val_mean_squared_error: 0.0161\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0165\n",
      "Epoch 9: val_loss did not improve from 0.09510\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1004 - mean_squared_error: 0.0165 - val_loss: 0.0979 - val_mean_squared_error: 0.0164\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1000 - mean_squared_error: 0.0163\n",
      "Epoch 10: val_loss did not improve from 0.09510\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1000 - mean_squared_error: 0.0163 - val_loss: 0.0953 - val_mean_squared_error: 0.0150\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1557 - mean_squared_error: 0.0426\n",
      "Epoch 1: val_loss improved from inf to 0.10768, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.1557 - mean_squared_error: 0.0426 - val_loss: 0.1077 - val_mean_squared_error: 0.0182\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1132 - mean_squared_error: 0.0212\n",
      "Epoch 2: val_loss improved from 0.10768 to 0.09796, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size11_pool5_do0.1_tra4_head8_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1132 - mean_squared_error: 0.0212 - val_loss: 0.0980 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0193\n",
      "Epoch 3: val_loss did not improve from 0.09796\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1086 - mean_squared_error: 0.0193 - val_loss: 0.1027 - val_mean_squared_error: 0.0166\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0178\n",
      "Epoch 4: val_loss did not improve from 0.09796\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1042 - mean_squared_error: 0.0178 - val_loss: 0.0989 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0172\n",
      "Epoch 5: val_loss did not improve from 0.09796\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1028 - mean_squared_error: 0.0172 - val_loss: 0.0991 - val_mean_squared_error: 0.0157\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.51+-0.33\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1467 - mean_squared_error: 0.0372\n",
      "Epoch 1: val_loss improved from inf to 0.09634, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 22s 49ms/step - loss: 0.1467 - mean_squared_error: 0.0372 - val_loss: 0.0963 - val_mean_squared_error: 0.0152\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0196\n",
      "Epoch 2: val_loss improved from 0.09634 to 0.08904, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.1079 - mean_squared_error: 0.0196 - val_loss: 0.0890 - val_mean_squared_error: 0.0131\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.0168\n",
      "Epoch 3: val_loss did not improve from 0.08904\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1001 - mean_squared_error: 0.0168 - val_loss: 0.0912 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0944 - mean_squared_error: 0.0148\n",
      "Epoch 4: val_loss improved from 0.08904 to 0.08597, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0944 - mean_squared_error: 0.0148 - val_loss: 0.0860 - val_mean_squared_error: 0.0126\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.0136\n",
      "Epoch 5: val_loss improved from 0.08597 to 0.08456, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0898 - mean_squared_error: 0.0136 - val_loss: 0.0846 - val_mean_squared_error: 0.0121\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.0130\n",
      "Epoch 6: val_loss did not improve from 0.08456\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0876 - mean_squared_error: 0.0130 - val_loss: 0.0851 - val_mean_squared_error: 0.0120\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.0124\n",
      "Epoch 7: val_loss did not improve from 0.08456\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0861 - mean_squared_error: 0.0124 - val_loss: 0.0879 - val_mean_squared_error: 0.0132\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0835 - mean_squared_error: 0.0118\n",
      "Epoch 8: val_loss improved from 0.08456 to 0.08323, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0835 - mean_squared_error: 0.0118 - val_loss: 0.0832 - val_mean_squared_error: 0.0119\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0817 - mean_squared_error: 0.0113\n",
      "Epoch 9: val_loss did not improve from 0.08323\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0817 - mean_squared_error: 0.0113 - val_loss: 0.0836 - val_mean_squared_error: 0.0122\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0813 - mean_squared_error: 0.0112\n",
      "Epoch 10: val_loss did not improve from 0.08323\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0813 - mean_squared_error: 0.0112 - val_loss: 0.0843 - val_mean_squared_error: 0.0122\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0796 - mean_squared_error: 0.0108\n",
      "Epoch 11: val_loss did not improve from 0.08323\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0796 - mean_squared_error: 0.0108 - val_loss: 0.0899 - val_mean_squared_error: 0.0140\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1428 - mean_squared_error: 0.0358\n",
      "Epoch 1: val_loss improved from inf to 0.10054, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 10s 47ms/step - loss: 0.1428 - mean_squared_error: 0.0358 - val_loss: 0.1005 - val_mean_squared_error: 0.0166\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0204\n",
      "Epoch 2: val_loss improved from 0.10054 to 0.09698, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1109 - mean_squared_error: 0.0204 - val_loss: 0.0970 - val_mean_squared_error: 0.0154\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0183\n",
      "Epoch 3: val_loss improved from 0.09698 to 0.09454, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1046 - mean_squared_error: 0.0183 - val_loss: 0.0945 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0985 - mean_squared_error: 0.0162\n",
      "Epoch 4: val_loss improved from 0.09454 to 0.09225, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.0985 - mean_squared_error: 0.0162 - val_loss: 0.0923 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.0146\n",
      "Epoch 5: val_loss improved from 0.09225 to 0.09133, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0936 - mean_squared_error: 0.0146 - val_loss: 0.0913 - val_mean_squared_error: 0.0132\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0903 - mean_squared_error: 0.0137\n",
      "Epoch 6: val_loss did not improve from 0.09133\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0903 - mean_squared_error: 0.0137 - val_loss: 0.0921 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.0128\n",
      "Epoch 7: val_loss improved from 0.09133 to 0.08439, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.0876 - mean_squared_error: 0.0128 - val_loss: 0.0844 - val_mean_squared_error: 0.0113\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0850 - mean_squared_error: 0.0122\n",
      "Epoch 8: val_loss did not improve from 0.08439\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0850 - mean_squared_error: 0.0122 - val_loss: 0.0849 - val_mean_squared_error: 0.0120\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0845 - mean_squared_error: 0.0120\n",
      "Epoch 9: val_loss improved from 0.08439 to 0.08325, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0845 - mean_squared_error: 0.0120 - val_loss: 0.0832 - val_mean_squared_error: 0.0114\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.0113\n",
      "Epoch 10: val_loss did not improve from 0.08325\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0819 - mean_squared_error: 0.0113 - val_loss: 0.1071 - val_mean_squared_error: 0.0188\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0806 - mean_squared_error: 0.0111\n",
      "Epoch 11: val_loss did not improve from 0.08325\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0806 - mean_squared_error: 0.0111 - val_loss: 0.0896 - val_mean_squared_error: 0.0134\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.0109\n",
      "Epoch 12: val_loss did not improve from 0.08325\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0800 - mean_squared_error: 0.0109 - val_loss: 0.0877 - val_mean_squared_error: 0.0129\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###1 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1390 - mean_squared_error: 0.0341\n",
      "Epoch 1: val_loss improved from inf to 0.09694, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 10s 47ms/step - loss: 0.1390 - mean_squared_error: 0.0341 - val_loss: 0.0969 - val_mean_squared_error: 0.0158\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.09694\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1116 - mean_squared_error: 0.0207 - val_loss: 0.0970 - val_mean_squared_error: 0.0161\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0185\n",
      "Epoch 3: val_loss improved from 0.09694 to 0.09660, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1062 - mean_squared_error: 0.0185 - val_loss: 0.0966 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0179\n",
      "Epoch 4: val_loss improved from 0.09660 to 0.09562, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1045 - mean_squared_error: 0.0179 - val_loss: 0.0956 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0172\n",
      "Epoch 5: val_loss improved from 0.09562 to 0.09545, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.1027 - mean_squared_error: 0.0172 - val_loss: 0.0954 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0170\n",
      "Epoch 6: val_loss did not improve from 0.09545\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1020 - mean_squared_error: 0.0170 - val_loss: 0.0965 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0165\n",
      "Epoch 7: val_loss improved from 0.09545 to 0.09296, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.1002 - mean_squared_error: 0.0165 - val_loss: 0.0930 - val_mean_squared_error: 0.0147\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0950 - mean_squared_error: 0.0149\n",
      "Epoch 8: val_loss did not improve from 0.09296\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0950 - mean_squared_error: 0.0149 - val_loss: 0.0937 - val_mean_squared_error: 0.0155\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0941 - mean_squared_error: 0.0145\n",
      "Epoch 9: val_loss improved from 0.09296 to 0.08662, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 41ms/step - loss: 0.0941 - mean_squared_error: 0.0145 - val_loss: 0.0866 - val_mean_squared_error: 0.0128\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0905 - mean_squared_error: 0.0135\n",
      "Epoch 10: val_loss did not improve from 0.08662\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0905 - mean_squared_error: 0.0135 - val_loss: 0.0874 - val_mean_squared_error: 0.0131\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0878 - mean_squared_error: 0.0129\n",
      "Epoch 11: val_loss improved from 0.08662 to 0.08323, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0878 - mean_squared_error: 0.0129 - val_loss: 0.0832 - val_mean_squared_error: 0.0119\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.0123\n",
      "Epoch 12: val_loss did not improve from 0.08323\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0859 - mean_squared_error: 0.0123 - val_loss: 0.0943 - val_mean_squared_error: 0.0141\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.0117\n",
      "Epoch 13: val_loss did not improve from 0.08323\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0839 - mean_squared_error: 0.0117 - val_loss: 0.0839 - val_mean_squared_error: 0.0118\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.0116\n",
      "Epoch 14: val_loss did not improve from 0.08323\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0831 - mean_squared_error: 0.0116 - val_loss: 0.0876 - val_mean_squared_error: 0.0133\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###2 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1384 - mean_squared_error: 0.0341\n",
      "Epoch 1: val_loss improved from inf to 0.10280, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 10s 47ms/step - loss: 0.1384 - mean_squared_error: 0.0341 - val_loss: 0.1028 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1094 - mean_squared_error: 0.0199\n",
      "Epoch 2: val_loss improved from 0.10280 to 0.09800, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1094 - mean_squared_error: 0.0199 - val_loss: 0.0980 - val_mean_squared_error: 0.0161\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0187\n",
      "Epoch 3: val_loss improved from 0.09800 to 0.09771, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1065 - mean_squared_error: 0.0187 - val_loss: 0.0977 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0177\n",
      "Epoch 4: val_loss improved from 0.09771 to 0.09724, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt32_stride4_size19_pool5_do0.1_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1032 - mean_squared_error: 0.0177 - val_loss: 0.0972 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0173\n",
      "Epoch 5: val_loss did not improve from 0.09724\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1025 - mean_squared_error: 0.0173 - val_loss: 0.0977 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0167\n",
      "Epoch 6: val_loss did not improve from 0.09724\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1005 - mean_squared_error: 0.0167 - val_loss: 0.0977 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0166\n",
      "Epoch 7: val_loss did not improve from 0.09724\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1002 - mean_squared_error: 0.0166 - val_loss: 0.0980 - val_mean_squared_error: 0.0157\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae8.71+-0.58\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1672 - mean_squared_error: 0.0451\n",
      "Epoch 1: val_loss improved from inf to 0.09995, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 22s 46ms/step - loss: 0.1672 - mean_squared_error: 0.0451 - val_loss: 0.0999 - val_mean_squared_error: 0.0160\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1263 - mean_squared_error: 0.0262\n",
      "Epoch 2: val_loss did not improve from 0.09995\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1263 - mean_squared_error: 0.0262 - val_loss: 0.1028 - val_mean_squared_error: 0.0177\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0214\n",
      "Epoch 3: val_loss did not improve from 0.09995\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1134 - mean_squared_error: 0.0214 - val_loss: 0.1004 - val_mean_squared_error: 0.0168\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0191\n",
      "Epoch 4: val_loss improved from 0.09995 to 0.09764, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1074 - mean_squared_error: 0.0191 - val_loss: 0.0976 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss improved from 0.09764 to 0.09571, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1034 - mean_squared_error: 0.0176 - val_loss: 0.0957 - val_mean_squared_error: 0.0145\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0164\n",
      "Epoch 6: val_loss did not improve from 0.09571\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0996 - mean_squared_error: 0.0164 - val_loss: 0.1020 - val_mean_squared_error: 0.0159\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0964 - mean_squared_error: 0.0153\n",
      "Epoch 7: val_loss improved from 0.09571 to 0.09405, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.0964 - mean_squared_error: 0.0153 - val_loss: 0.0940 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0939 - mean_squared_error: 0.0145\n",
      "Epoch 8: val_loss improved from 0.09405 to 0.09005, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0939 - mean_squared_error: 0.0145 - val_loss: 0.0900 - val_mean_squared_error: 0.0132\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0140\n",
      "Epoch 9: val_loss improved from 0.09005 to 0.08807, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0917 - mean_squared_error: 0.0140 - val_loss: 0.0881 - val_mean_squared_error: 0.0128\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.0133\n",
      "Epoch 10: val_loss did not improve from 0.08807\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0893 - mean_squared_error: 0.0133 - val_loss: 0.0901 - val_mean_squared_error: 0.0135\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0883 - mean_squared_error: 0.0129\n",
      "Epoch 11: val_loss did not improve from 0.08807\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0883 - mean_squared_error: 0.0129 - val_loss: 0.0884 - val_mean_squared_error: 0.0130\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0879 - mean_squared_error: 0.0129\n",
      "Epoch 12: val_loss did not improve from 0.08807\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0879 - mean_squared_error: 0.0129 - val_loss: 0.1097 - val_mean_squared_error: 0.0189\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1589 - mean_squared_error: 0.0419\n",
      "Epoch 1: val_loss improved from inf to 0.12184, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 9s 45ms/step - loss: 0.1589 - mean_squared_error: 0.0419 - val_loss: 0.1218 - val_mean_squared_error: 0.0243\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1223 - mean_squared_error: 0.0248\n",
      "Epoch 2: val_loss improved from 0.12184 to 0.09776, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1223 - mean_squared_error: 0.0248 - val_loss: 0.0978 - val_mean_squared_error: 0.0157\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0205\n",
      "Epoch 3: val_loss did not improve from 0.09776\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1125 - mean_squared_error: 0.0205 - val_loss: 0.0978 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0190\n",
      "Epoch 4: val_loss improved from 0.09776 to 0.09665, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1076 - mean_squared_error: 0.0190 - val_loss: 0.0966 - val_mean_squared_error: 0.0153\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0183\n",
      "Epoch 5: val_loss did not improve from 0.09665\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1055 - mean_squared_error: 0.0183 - val_loss: 0.0990 - val_mean_squared_error: 0.0164\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0177\n",
      "Epoch 6: val_loss did not improve from 0.09665\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1036 - mean_squared_error: 0.0177 - val_loss: 0.0975 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0178\n",
      "Epoch 7: val_loss did not improve from 0.09665\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1038 - mean_squared_error: 0.0178 - val_loss: 0.0968 - val_mean_squared_error: 0.0154\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1605 - mean_squared_error: 0.0429\n",
      "Epoch 1: val_loss improved from inf to 0.09764, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 9s 46ms/step - loss: 0.1605 - mean_squared_error: 0.0429 - val_loss: 0.0976 - val_mean_squared_error: 0.0165\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1197 - mean_squared_error: 0.0236\n",
      "Epoch 2: val_loss improved from 0.09764 to 0.09590, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1197 - mean_squared_error: 0.0236 - val_loss: 0.0959 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0200\n",
      "Epoch 3: val_loss did not improve from 0.09590\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1103 - mean_squared_error: 0.0200 - val_loss: 0.0959 - val_mean_squared_error: 0.0154\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 4: val_loss did not improve from 0.09590\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1072 - mean_squared_error: 0.0189 - val_loss: 0.0960 - val_mean_squared_error: 0.0154\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0181\n",
      "Epoch 5: val_loss did not improve from 0.09590\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1056 - mean_squared_error: 0.0181 - val_loss: 0.0960 - val_mean_squared_error: 0.0152\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1613 - mean_squared_error: 0.0425\n",
      "Epoch 1: val_loss improved from inf to 0.10214, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 10s 48ms/step - loss: 0.1613 - mean_squared_error: 0.0425 - val_loss: 0.1021 - val_mean_squared_error: 0.0174\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1185 - mean_squared_error: 0.0231\n",
      "Epoch 2: val_loss improved from 0.10214 to 0.09912, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1185 - mean_squared_error: 0.0231 - val_loss: 0.0991 - val_mean_squared_error: 0.0167\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0198\n",
      "Epoch 3: val_loss did not improve from 0.09912\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1098 - mean_squared_error: 0.0198 - val_loss: 0.1009 - val_mean_squared_error: 0.0160\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0177\n",
      "Epoch 4: val_loss improved from 0.09912 to 0.09862, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1037 - mean_squared_error: 0.0177 - val_loss: 0.0986 - val_mean_squared_error: 0.0153\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0998 - mean_squared_error: 0.0162\n",
      "Epoch 5: val_loss did not improve from 0.09862\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0998 - mean_squared_error: 0.0162 - val_loss: 0.1004 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0960 - mean_squared_error: 0.0150\n",
      "Epoch 6: val_loss did not improve from 0.09862\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.0960 - mean_squared_error: 0.0150 - val_loss: 0.1059 - val_mean_squared_error: 0.0182\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.0140\n",
      "Epoch 7: val_loss improved from 0.09862 to 0.09092, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0928 - mean_squared_error: 0.0140 - val_loss: 0.0909 - val_mean_squared_error: 0.0132\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0924 - mean_squared_error: 0.0140\n",
      "Epoch 8: val_loss did not improve from 0.09092\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0924 - mean_squared_error: 0.0140 - val_loss: 0.0925 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0910 - mean_squared_error: 0.0137\n",
      "Epoch 9: val_loss did not improve from 0.09092\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0910 - mean_squared_error: 0.0137 - val_loss: 0.0969 - val_mean_squared_error: 0.0156\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0886 - mean_squared_error: 0.0131\n",
      "Epoch 10: val_loss improved from 0.09092 to 0.08740, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn4_filt16_stride5_size19_pool4_do0.2_tra5_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0886 - mean_squared_error: 0.0131 - val_loss: 0.0874 - val_mean_squared_error: 0.0128\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0880 - mean_squared_error: 0.0131\n",
      "Epoch 11: val_loss did not improve from 0.08740\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0880 - mean_squared_error: 0.0131 - val_loss: 0.0897 - val_mean_squared_error: 0.0139\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.0124\n",
      "Epoch 12: val_loss did not improve from 0.08740\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.0859 - mean_squared_error: 0.0124 - val_loss: 0.0879 - val_mean_squared_error: 0.0131\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0850 - mean_squared_error: 0.0122\n",
      "Epoch 13: val_loss did not improve from 0.08740\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.0850 - mean_squared_error: 0.0122 - val_loss: 0.0904 - val_mean_squared_error: 0.0139\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.09###\n",
      "mae9.25+-0.54\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1368 - mean_squared_error: 0.0316\n",
      "Epoch 1: val_loss improved from inf to 0.10390, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 15s 37ms/step - loss: 0.1368 - mean_squared_error: 0.0316 - val_loss: 0.1039 - val_mean_squared_error: 0.0180\n",
      "Epoch 2/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1140 - mean_squared_error: 0.0217\n",
      "Epoch 2: val_loss improved from 0.10390 to 0.09487, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1139 - mean_squared_error: 0.0217 - val_loss: 0.0949 - val_mean_squared_error: 0.0143\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0171\n",
      "Epoch 3: val_loss improved from 0.09487 to 0.08921, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1013 - mean_squared_error: 0.0172 - val_loss: 0.0892 - val_mean_squared_error: 0.0134\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0963 - mean_squared_error: 0.0155\n",
      "Epoch 4: val_loss improved from 0.08921 to 0.08612, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0964 - mean_squared_error: 0.0155 - val_loss: 0.0861 - val_mean_squared_error: 0.0124\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.0145\n",
      "Epoch 5: val_loss did not improve from 0.08612\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0936 - mean_squared_error: 0.0145 - val_loss: 0.0874 - val_mean_squared_error: 0.0125\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.0133\n",
      "Epoch 6: val_loss did not improve from 0.08612\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0893 - mean_squared_error: 0.0133 - val_loss: 0.0926 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0872 - mean_squared_error: 0.0127\n",
      "Epoch 7: val_loss improved from 0.08612 to 0.08458, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0872 - mean_squared_error: 0.0127 - val_loss: 0.0846 - val_mean_squared_error: 0.0123\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0857 - mean_squared_error: 0.0124\n",
      "Epoch 8: val_loss did not improve from 0.08458\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0857 - mean_squared_error: 0.0124 - val_loss: 0.0903 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0833 - mean_squared_error: 0.0117\n",
      "Epoch 9: val_loss did not improve from 0.08458\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0833 - mean_squared_error: 0.0117 - val_loss: 0.1000 - val_mean_squared_error: 0.0168\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.0115\n",
      "Epoch 10: val_loss improved from 0.08458 to 0.08314, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0823 - mean_squared_error: 0.0115 - val_loss: 0.0831 - val_mean_squared_error: 0.0117\n",
      "Epoch 11/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.0111\n",
      "Epoch 11: val_loss improved from 0.08314 to 0.08190, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0809 - mean_squared_error: 0.0111 - val_loss: 0.0819 - val_mean_squared_error: 0.0112\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0803 - mean_squared_error: 0.0109\n",
      "Epoch 12: val_loss improved from 0.08190 to 0.08159, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0803 - mean_squared_error: 0.0109 - val_loss: 0.0816 - val_mean_squared_error: 0.0108\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.0108\n",
      "Epoch 13: val_loss did not improve from 0.08159\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0794 - mean_squared_error: 0.0108 - val_loss: 0.0851 - val_mean_squared_error: 0.0123\n",
      "Epoch 14/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0779 - mean_squared_error: 0.0103\n",
      "Epoch 14: val_loss did not improve from 0.08159\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0779 - mean_squared_error: 0.0103 - val_loss: 0.0852 - val_mean_squared_error: 0.0125\n",
      "Epoch 15/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0773 - mean_squared_error: 0.0102\n",
      "Epoch 15: val_loss did not improve from 0.08159\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0773 - mean_squared_error: 0.0102 - val_loss: 0.0828 - val_mean_squared_error: 0.0117\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1328 - mean_squared_error: 0.0296\n",
      "Epoch 1: val_loss improved from inf to 0.11654, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 35ms/step - loss: 0.1327 - mean_squared_error: 0.0295 - val_loss: 0.1165 - val_mean_squared_error: 0.0226\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1142 - mean_squared_error: 0.0219\n",
      "Epoch 2: val_loss improved from 0.11654 to 0.10166, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1142 - mean_squared_error: 0.0219 - val_loss: 0.1017 - val_mean_squared_error: 0.0173\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1084 - mean_squared_error: 0.0195\n",
      "Epoch 3: val_loss improved from 0.10166 to 0.09866, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1084 - mean_squared_error: 0.0195 - val_loss: 0.0987 - val_mean_squared_error: 0.0164\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1058 - mean_squared_error: 0.0187\n",
      "Epoch 4: val_loss improved from 0.09866 to 0.09759, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1058 - mean_squared_error: 0.0187 - val_loss: 0.0976 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0182\n",
      "Epoch 5: val_loss improved from 0.09759 to 0.09679, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1047 - mean_squared_error: 0.0182 - val_loss: 0.0968 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0177\n",
      "Epoch 6: val_loss did not improve from 0.09679\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1032 - mean_squared_error: 0.0177 - val_loss: 0.0976 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0171\n",
      "Epoch 7: val_loss did not improve from 0.09679\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1014 - mean_squared_error: 0.0171 - val_loss: 0.1034 - val_mean_squared_error: 0.0177\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0962 - mean_squared_error: 0.0154\n",
      "Epoch 8: val_loss improved from 0.09679 to 0.08738, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0963 - mean_squared_error: 0.0154 - val_loss: 0.0874 - val_mean_squared_error: 0.0124\n",
      "Epoch 9/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0899 - mean_squared_error: 0.0134\n",
      "Epoch 9: val_loss improved from 0.08738 to 0.08436, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0900 - mean_squared_error: 0.0135 - val_loss: 0.0844 - val_mean_squared_error: 0.0115\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.0129\n",
      "Epoch 10: val_loss did not improve from 0.08436\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0877 - mean_squared_error: 0.0129 - val_loss: 0.0863 - val_mean_squared_error: 0.0127\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0855 - mean_squared_error: 0.0123\n",
      "Epoch 11: val_loss improved from 0.08436 to 0.08220, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0855 - mean_squared_error: 0.0123 - val_loss: 0.0822 - val_mean_squared_error: 0.0112\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.0120\n",
      "Epoch 12: val_loss did not improve from 0.08220\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0841 - mean_squared_error: 0.0120 - val_loss: 0.0859 - val_mean_squared_error: 0.0123\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0840 - mean_squared_error: 0.0119\n",
      "Epoch 13: val_loss did not improve from 0.08220\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0840 - mean_squared_error: 0.0119 - val_loss: 0.0918 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0823 - mean_squared_error: 0.0115\n",
      "Epoch 14: val_loss did not improve from 0.08220\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0823 - mean_squared_error: 0.0115 - val_loss: 0.0850 - val_mean_squared_error: 0.0115\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1348 - mean_squared_error: 0.0306\n",
      "Epoch 1: val_loss improved from inf to 0.10678, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 39ms/step - loss: 0.1348 - mean_squared_error: 0.0306 - val_loss: 0.1068 - val_mean_squared_error: 0.0195\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.0212\n",
      "Epoch 2: val_loss improved from 0.10678 to 0.09965, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1137 - mean_squared_error: 0.0212 - val_loss: 0.0996 - val_mean_squared_error: 0.0174\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0195\n",
      "Epoch 3: val_loss improved from 0.09965 to 0.09629, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1092 - mean_squared_error: 0.0195 - val_loss: 0.0963 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0178\n",
      "Epoch 4: val_loss improved from 0.09629 to 0.09115, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1042 - mean_squared_error: 0.0178 - val_loss: 0.0912 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0975 - mean_squared_error: 0.0156\n",
      "Epoch 5: val_loss did not improve from 0.09115\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0976 - mean_squared_error: 0.0156 - val_loss: 0.0915 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0933 - mean_squared_error: 0.0144\n",
      "Epoch 6: val_loss did not improve from 0.09115\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0933 - mean_squared_error: 0.0144 - val_loss: 0.1111 - val_mean_squared_error: 0.0211\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.0134\n",
      "Epoch 7: val_loss improved from 0.09115 to 0.08496, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0898 - mean_squared_error: 0.0134 - val_loss: 0.0850 - val_mean_squared_error: 0.0127\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0867 - mean_squared_error: 0.0126\n",
      "Epoch 8: val_loss did not improve from 0.08496\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0867 - mean_squared_error: 0.0126 - val_loss: 0.0915 - val_mean_squared_error: 0.0146\n",
      "Epoch 9/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0858 - mean_squared_error: 0.0123\n",
      "Epoch 9: val_loss improved from 0.08496 to 0.08267, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0858 - mean_squared_error: 0.0123 - val_loss: 0.0827 - val_mean_squared_error: 0.0119\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0843 - mean_squared_error: 0.0119\n",
      "Epoch 10: val_loss improved from 0.08267 to 0.08249, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0843 - mean_squared_error: 0.0119 - val_loss: 0.0825 - val_mean_squared_error: 0.0120\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0833 - mean_squared_error: 0.0116\n",
      "Epoch 11: val_loss did not improve from 0.08249\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0833 - mean_squared_error: 0.0116 - val_loss: 0.0902 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0825 - mean_squared_error: 0.0113\n",
      "Epoch 12: val_loss improved from 0.08249 to 0.08168, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0825 - mean_squared_error: 0.0113 - val_loss: 0.0817 - val_mean_squared_error: 0.0118\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0816 - mean_squared_error: 0.0112\n",
      "Epoch 13: val_loss did not improve from 0.08168\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0816 - mean_squared_error: 0.0112 - val_loss: 0.0833 - val_mean_squared_error: 0.0122\n",
      "Epoch 14/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.0110\n",
      "Epoch 14: val_loss did not improve from 0.08168\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0810 - mean_squared_error: 0.0110 - val_loss: 0.0831 - val_mean_squared_error: 0.0122\n",
      "Epoch 15/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0811 - mean_squared_error: 0.0110\n",
      "Epoch 15: val_loss did not improve from 0.08168\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0812 - mean_squared_error: 0.0110 - val_loss: 0.0935 - val_mean_squared_error: 0.0149\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###2 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1343 - mean_squared_error: 0.0305\n",
      "Epoch 1: val_loss improved from inf to 0.10225, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 7s 36ms/step - loss: 0.1343 - mean_squared_error: 0.0305 - val_loss: 0.1022 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1117 - mean_squared_error: 0.0207\n",
      "Epoch 2: val_loss did not improve from 0.10225\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1116 - mean_squared_error: 0.0207 - val_loss: 0.1039 - val_mean_squared_error: 0.0175\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0189\n",
      "Epoch 3: val_loss improved from 0.10225 to 0.09414, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size19_pool5_do0.1_tra3_head4_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.1070 - mean_squared_error: 0.0189 - val_loss: 0.0941 - val_mean_squared_error: 0.0148\n",
      "Epoch 4/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0160\n",
      "Epoch 4: val_loss did not improve from 0.09414\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0985 - mean_squared_error: 0.0160 - val_loss: 0.0944 - val_mean_squared_error: 0.0152\n",
      "Epoch 5/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.0149\n",
      "Epoch 5: val_loss did not improve from 0.09414\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0948 - mean_squared_error: 0.0149 - val_loss: 0.0991 - val_mean_squared_error: 0.0168\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0896 - mean_squared_error: 0.0134\n",
      "Epoch 6: val_loss did not improve from 0.09414\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0897 - mean_squared_error: 0.0134 - val_loss: 0.1152 - val_mean_squared_error: 0.0222\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###3 fold : val mae 0.09###\n",
      "mae8.44+-0.58\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1705 - mean_squared_error: 0.0481\n",
      "Epoch 1: val_loss improved from inf to 0.09952, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 19s 143ms/step - loss: 0.1705 - mean_squared_error: 0.0481 - val_loss: 0.0995 - val_mean_squared_error: 0.0163\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1297 - mean_squared_error: 0.0280\n",
      "Epoch 2: val_loss did not improve from 0.09952\n",
      "40/40 [==============================] - 4s 94ms/step - loss: 0.1296 - mean_squared_error: 0.0279 - val_loss: 0.1089 - val_mean_squared_error: 0.0187\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1212 - mean_squared_error: 0.0241\n",
      "Epoch 3: val_loss did not improve from 0.09952\n",
      "40/40 [==============================] - 4s 93ms/step - loss: 0.1212 - mean_squared_error: 0.0241 - val_loss: 0.1023 - val_mean_squared_error: 0.0166\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1164 - mean_squared_error: 0.0225\n",
      "Epoch 4: val_loss improved from 0.09952 to 0.09904, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.1163 - mean_squared_error: 0.0225 - val_loss: 0.0990 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1136 - mean_squared_error: 0.0215\n",
      "Epoch 5: val_loss improved from 0.09904 to 0.09783, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 4s 99ms/step - loss: 0.1137 - mean_squared_error: 0.0215 - val_loss: 0.0978 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1112 - mean_squared_error: 0.0204\n",
      "Epoch 6: val_loss did not improve from 0.09783\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.1112 - mean_squared_error: 0.0204 - val_loss: 0.1080 - val_mean_squared_error: 0.0179\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.0197\n",
      "Epoch 7: val_loss did not improve from 0.09783\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.1094 - mean_squared_error: 0.0197 - val_loss: 0.1124 - val_mean_squared_error: 0.0192\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0192\n",
      "Epoch 8: val_loss did not improve from 0.09783\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.1078 - mean_squared_error: 0.0192 - val_loss: 0.1085 - val_mean_squared_error: 0.0181\n",
      "14/14 [==============================] - 2s 41ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1711 - mean_squared_error: 0.0479\n",
      "Epoch 1: val_loss improved from inf to 0.10146, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 7s 120ms/step - loss: 0.1709 - mean_squared_error: 0.0478 - val_loss: 0.1015 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1257 - mean_squared_error: 0.0261\n",
      "Epoch 2: val_loss improved from 0.10146 to 0.09785, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.1256 - mean_squared_error: 0.0260 - val_loss: 0.0978 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1210 - mean_squared_error: 0.0240\n",
      "Epoch 3: val_loss did not improve from 0.09785\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.1209 - mean_squared_error: 0.0240 - val_loss: 0.1059 - val_mean_squared_error: 0.0176\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1165 - mean_squared_error: 0.0226\n",
      "Epoch 4: val_loss did not improve from 0.09785\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.1165 - mean_squared_error: 0.0226 - val_loss: 0.1119 - val_mean_squared_error: 0.0193\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0206\n",
      "Epoch 5: val_loss did not improve from 0.09785\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.1114 - mean_squared_error: 0.0206 - val_loss: 0.1006 - val_mean_squared_error: 0.0160\n",
      "14/14 [==============================] - 2s 40ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1652 - mean_squared_error: 0.0452\n",
      "Epoch 1: val_loss improved from inf to 0.11642, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 7s 121ms/step - loss: 0.1652 - mean_squared_error: 0.0452 - val_loss: 0.1164 - val_mean_squared_error: 0.0203\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1253 - mean_squared_error: 0.0260\n",
      "Epoch 2: val_loss improved from 0.11642 to 0.10555, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 4s 100ms/step - loss: 0.1252 - mean_squared_error: 0.0259 - val_loss: 0.1056 - val_mean_squared_error: 0.0174\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1196 - mean_squared_error: 0.0235\n",
      "Epoch 3: val_loss improved from 0.10555 to 0.10400, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 4s 101ms/step - loss: 0.1196 - mean_squared_error: 0.0235 - val_loss: 0.1040 - val_mean_squared_error: 0.0173\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1159 - mean_squared_error: 0.0220\n",
      "Epoch 4: val_loss did not improve from 0.10400\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.1159 - mean_squared_error: 0.0220 - val_loss: 0.1134 - val_mean_squared_error: 0.0196\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1127 - mean_squared_error: 0.0209\n",
      "Epoch 5: val_loss did not improve from 0.10400\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.1127 - mean_squared_error: 0.0209 - val_loss: 0.1436 - val_mean_squared_error: 0.0290\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1100 - mean_squared_error: 0.0201\n",
      "Epoch 6: val_loss did not improve from 0.10400\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.1101 - mean_squared_error: 0.0201 - val_loss: 0.1296 - val_mean_squared_error: 0.0242\n",
      "14/14 [==============================] - 1s 41ms/step\n",
      " ###2 fold : val mae 0.11###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1689 - mean_squared_error: 0.0464\n",
      "Epoch 1: val_loss improved from inf to 0.10352, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 7s 121ms/step - loss: 0.1687 - mean_squared_error: 0.0463 - val_loss: 0.1035 - val_mean_squared_error: 0.0173\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1258 - mean_squared_error: 0.0261\n",
      "Epoch 2: val_loss improved from 0.10352 to 0.10021, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride2_size11_pool2_do0.2_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 4s 98ms/step - loss: 0.1257 - mean_squared_error: 0.0261 - val_loss: 0.1002 - val_mean_squared_error: 0.0163\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1173 - mean_squared_error: 0.0229\n",
      "Epoch 3: val_loss did not improve from 0.10021\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.1173 - mean_squared_error: 0.0229 - val_loss: 0.1105 - val_mean_squared_error: 0.0189\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1136 - mean_squared_error: 0.0212\n",
      "Epoch 4: val_loss did not improve from 0.10021\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.1135 - mean_squared_error: 0.0212 - val_loss: 0.1090 - val_mean_squared_error: 0.0184\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1118 - mean_squared_error: 0.0205\n",
      "Epoch 5: val_loss did not improve from 0.10021\n",
      "40/40 [==============================] - 4s 94ms/step - loss: 0.1118 - mean_squared_error: 0.0205 - val_loss: 0.1158 - val_mean_squared_error: 0.0199\n",
      "14/14 [==============================] - 2s 40ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae10.09+-0.31\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2216 - mean_squared_error: 0.0783\n",
      "Epoch 1: val_loss improved from inf to 0.27750, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 15s 59ms/step - loss: 0.2216 - mean_squared_error: 0.0783 - val_loss: 0.2775 - val_mean_squared_error: 0.0929\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1171 - mean_squared_error: 0.0225\n",
      "Epoch 2: val_loss improved from 0.27750 to 0.11632, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1171 - mean_squared_error: 0.0225 - val_loss: 0.1163 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0197\n",
      "Epoch 3: val_loss improved from 0.11632 to 0.11132, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1090 - mean_squared_error: 0.0197 - val_loss: 0.1113 - val_mean_squared_error: 0.0191\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss improved from 0.11132 to 0.10389, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1067 - mean_squared_error: 0.0188 - val_loss: 0.1039 - val_mean_squared_error: 0.0170\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0189\n",
      "Epoch 5: val_loss improved from 0.10389 to 0.09775, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1071 - mean_squared_error: 0.0189 - val_loss: 0.0977 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0177\n",
      "Epoch 6: val_loss did not improve from 0.09775\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1033 - mean_squared_error: 0.0177 - val_loss: 0.1022 - val_mean_squared_error: 0.0164\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0177\n",
      "Epoch 7: val_loss did not improve from 0.09775\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1035 - mean_squared_error: 0.0177 - val_loss: 0.0979 - val_mean_squared_error: 0.0156\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0171\n",
      "Epoch 8: val_loss did not improve from 0.09775\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1023 - mean_squared_error: 0.0171 - val_loss: 0.0981 - val_mean_squared_error: 0.0154\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2107 - mean_squared_error: 0.0743\n",
      "Epoch 1: val_loss improved from inf to 0.21434, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 6s 55ms/step - loss: 0.2107 - mean_squared_error: 0.0743 - val_loss: 0.2143 - val_mean_squared_error: 0.0590\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1129 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss improved from 0.21434 to 0.10918, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1129 - mean_squared_error: 0.0209 - val_loss: 0.1092 - val_mean_squared_error: 0.0184\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0193\n",
      "Epoch 3: val_loss improved from 0.10918 to 0.09791, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1082 - mean_squared_error: 0.0193 - val_loss: 0.0979 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0187\n",
      "Epoch 4: val_loss did not improve from 0.09791\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1059 - mean_squared_error: 0.0187 - val_loss: 0.1058 - val_mean_squared_error: 0.0177\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1051 - mean_squared_error: 0.0181\n",
      "Epoch 5: val_loss did not improve from 0.09791\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1051 - mean_squared_error: 0.0181 - val_loss: 0.0979 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0178\n",
      "Epoch 6: val_loss improved from 0.09791 to 0.09734, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1041 - mean_squared_error: 0.0178 - val_loss: 0.0973 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0176\n",
      "Epoch 7: val_loss did not improve from 0.09734\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1036 - mean_squared_error: 0.0176 - val_loss: 0.0979 - val_mean_squared_error: 0.0153\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0173\n",
      "Epoch 8: val_loss improved from 0.09734 to 0.09707, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1026 - mean_squared_error: 0.0173 - val_loss: 0.0971 - val_mean_squared_error: 0.0155\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0168\n",
      "Epoch 9: val_loss did not improve from 0.09707\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1009 - mean_squared_error: 0.0168 - val_loss: 0.0979 - val_mean_squared_error: 0.0159\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0167\n",
      "Epoch 10: val_loss improved from 0.09707 to 0.09672, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1008 - mean_squared_error: 0.0167 - val_loss: 0.0967 - val_mean_squared_error: 0.0151\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0167\n",
      "Epoch 11: val_loss did not improve from 0.09672\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1004 - mean_squared_error: 0.0167 - val_loss: 0.0971 - val_mean_squared_error: 0.0151\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0165\n",
      "Epoch 12: val_loss did not improve from 0.09672\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1002 - mean_squared_error: 0.0165 - val_loss: 0.0971 - val_mean_squared_error: 0.0152\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1000 - mean_squared_error: 0.0165\n",
      "Epoch 13: val_loss improved from 0.09672 to 0.09613, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1000 - mean_squared_error: 0.0165 - val_loss: 0.0961 - val_mean_squared_error: 0.0149\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0166\n",
      "Epoch 14: val_loss did not improve from 0.09613\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1004 - mean_squared_error: 0.0166 - val_loss: 0.0972 - val_mean_squared_error: 0.0153\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0993 - mean_squared_error: 0.0162\n",
      "Epoch 15: val_loss did not improve from 0.09613\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.0993 - mean_squared_error: 0.0162 - val_loss: 0.0975 - val_mean_squared_error: 0.0152\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0987 - mean_squared_error: 0.0161\n",
      "Epoch 16: val_loss improved from 0.09613 to 0.09546, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.0987 - mean_squared_error: 0.0161 - val_loss: 0.0955 - val_mean_squared_error: 0.0149\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0993 - mean_squared_error: 0.0162\n",
      "Epoch 17: val_loss did not improve from 0.09546\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0993 - mean_squared_error: 0.0162 - val_loss: 0.0960 - val_mean_squared_error: 0.0152\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0994 - mean_squared_error: 0.0162\n",
      "Epoch 18: val_loss did not improve from 0.09546\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0994 - mean_squared_error: 0.0162 - val_loss: 0.0961 - val_mean_squared_error: 0.0150\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0989 - mean_squared_error: 0.0162\n",
      "Epoch 19: val_loss did not improve from 0.09546\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0989 - mean_squared_error: 0.0162 - val_loss: 0.0955 - val_mean_squared_error: 0.0150\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3807 - mean_squared_error: 0.1705\n",
      "Epoch 1: val_loss improved from inf to 0.38051, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 6s 54ms/step - loss: 0.3807 - mean_squared_error: 0.1705 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 2: val_loss improved from 0.38051 to 0.38050, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 3: val_loss improved from 0.38050 to 0.38048, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3805 - val_mean_squared_error: 0.1704\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.3811 - mean_squared_error: 0.1706\n",
      "Epoch 4: val_loss improved from 0.38048 to 0.37940, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.3811 - mean_squared_error: 0.1706 - val_loss: 0.3794 - val_mean_squared_error: 0.1697\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1920 - mean_squared_error: 0.0622\n",
      "Epoch 5: val_loss improved from 0.37940 to 0.25401, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1920 - mean_squared_error: 0.0622 - val_loss: 0.2540 - val_mean_squared_error: 0.0792\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0203\n",
      "Epoch 6: val_loss improved from 0.25401 to 0.13429, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1110 - mean_squared_error: 0.0203 - val_loss: 0.1343 - val_mean_squared_error: 0.0260\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0189\n",
      "Epoch 7: val_loss improved from 0.13429 to 0.09585, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1071 - mean_squared_error: 0.0189 - val_loss: 0.0959 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0178\n",
      "Epoch 8: val_loss did not improve from 0.09585\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1040 - mean_squared_error: 0.0178 - val_loss: 0.1065 - val_mean_squared_error: 0.0174\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0173\n",
      "Epoch 9: val_loss improved from 0.09585 to 0.09574, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1031 - mean_squared_error: 0.0173 - val_loss: 0.0957 - val_mean_squared_error: 0.0156\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0169\n",
      "Epoch 10: val_loss did not improve from 0.09574\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1022 - mean_squared_error: 0.0169 - val_loss: 0.0971 - val_mean_squared_error: 0.0163\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0170\n",
      "Epoch 11: val_loss improved from 0.09574 to 0.09467, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1020 - mean_squared_error: 0.0170 - val_loss: 0.0947 - val_mean_squared_error: 0.0151\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0164\n",
      "Epoch 12: val_loss did not improve from 0.09467\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1003 - mean_squared_error: 0.0164 - val_loss: 0.0977 - val_mean_squared_error: 0.0165\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0164\n",
      "Epoch 13: val_loss did not improve from 0.09467\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1008 - mean_squared_error: 0.0164 - val_loss: 0.0987 - val_mean_squared_error: 0.0169\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0164\n",
      "Epoch 14: val_loss did not improve from 0.09467\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1005 - mean_squared_error: 0.0164 - val_loss: 0.0950 - val_mean_squared_error: 0.0154\n",
      "27/27 [==============================] - 2s 16ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1997 - mean_squared_error: 0.0674\n",
      "Epoch 1: val_loss improved from inf to 0.10253, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 6s 53ms/step - loss: 0.1997 - mean_squared_error: 0.0674 - val_loss: 0.1025 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1102 - mean_squared_error: 0.0201\n",
      "Epoch 2: val_loss did not improve from 0.10253\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1102 - mean_squared_error: 0.0201 - val_loss: 0.1114 - val_mean_squared_error: 0.0193\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0189\n",
      "Epoch 3: val_loss improved from 0.10253 to 0.10110, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1071 - mean_squared_error: 0.0189 - val_loss: 0.1011 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.0179\n",
      "Epoch 4: val_loss improved from 0.10110 to 0.09933, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1044 - mean_squared_error: 0.0179 - val_loss: 0.0993 - val_mean_squared_error: 0.0168\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0177\n",
      "Epoch 5: val_loss did not improve from 0.09933\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1035 - mean_squared_error: 0.0177 - val_loss: 0.1036 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0173\n",
      "Epoch 6: val_loss improved from 0.09933 to 0.09736, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1023 - mean_squared_error: 0.0173 - val_loss: 0.0974 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0170\n",
      "Epoch 7: val_loss did not improve from 0.09736\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1011 - mean_squared_error: 0.0170 - val_loss: 0.0997 - val_mean_squared_error: 0.0158\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1001 - mean_squared_error: 0.0165\n",
      "Epoch 8: val_loss improved from 0.09736 to 0.09715, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn2_filt64_stride4_size7_pool4_do0.1_tra4_head4_kdim128_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1001 - mean_squared_error: 0.0165 - val_loss: 0.0971 - val_mean_squared_error: 0.0154\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0165\n",
      "Epoch 9: val_loss did not improve from 0.09715\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1005 - mean_squared_error: 0.0165 - val_loss: 0.0994 - val_mean_squared_error: 0.0165\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0163\n",
      "Epoch 10: val_loss did not improve from 0.09715\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0995 - mean_squared_error: 0.0163 - val_loss: 0.0996 - val_mean_squared_error: 0.0157\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.0163\n",
      "Epoch 11: val_loss did not improve from 0.09715\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.0991 - mean_squared_error: 0.0163 - val_loss: 0.0988 - val_mean_squared_error: 0.0155\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.70+-0.06\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1789 - mean_squared_error: 0.0526\n",
      "Epoch 1: val_loss improved from inf to 0.12567, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 20s 108ms/step - loss: 0.1787 - mean_squared_error: 0.0525 - val_loss: 0.1257 - val_mean_squared_error: 0.0247\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1244 - mean_squared_error: 0.0257\n",
      "Epoch 2: val_loss improved from 0.12567 to 0.09545, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.1244 - mean_squared_error: 0.0257 - val_loss: 0.0955 - val_mean_squared_error: 0.0147\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1127 - mean_squared_error: 0.0214\n",
      "Epoch 3: val_loss improved from 0.09545 to 0.09256, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1128 - mean_squared_error: 0.0214 - val_loss: 0.0926 - val_mean_squared_error: 0.0142\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0191\n",
      "Epoch 4: val_loss improved from 0.09256 to 0.09199, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1062 - mean_squared_error: 0.0190 - val_loss: 0.0920 - val_mean_squared_error: 0.0141\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.0175\n",
      "Epoch 5: val_loss improved from 0.09199 to 0.09084, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1018 - mean_squared_error: 0.0175 - val_loss: 0.0908 - val_mean_squared_error: 0.0138\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.0163\n",
      "Epoch 6: val_loss improved from 0.09084 to 0.08746, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0985 - mean_squared_error: 0.0163 - val_loss: 0.0875 - val_mean_squared_error: 0.0126\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0951 - mean_squared_error: 0.0152\n",
      "Epoch 7: val_loss improved from 0.08746 to 0.08420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0950 - mean_squared_error: 0.0152 - val_loss: 0.0842 - val_mean_squared_error: 0.0119\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0913 - mean_squared_error: 0.0142\n",
      "Epoch 8: val_loss improved from 0.08420 to 0.08398, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.0913 - mean_squared_error: 0.0142 - val_loss: 0.0840 - val_mean_squared_error: 0.0118\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0888 - mean_squared_error: 0.0133\n",
      "Epoch 9: val_loss did not improve from 0.08398\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.0888 - mean_squared_error: 0.0134 - val_loss: 0.0916 - val_mean_squared_error: 0.0147\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0880 - mean_squared_error: 0.0131\n",
      "Epoch 10: val_loss did not improve from 0.08398\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.0880 - mean_squared_error: 0.0131 - val_loss: 0.0892 - val_mean_squared_error: 0.0136\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.0121\n",
      "Epoch 11: val_loss did not improve from 0.08398\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0842 - mean_squared_error: 0.0121 - val_loss: 0.0904 - val_mean_squared_error: 0.0143\n",
      "14/14 [==============================] - 2s 29ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1790 - mean_squared_error: 0.0525\n",
      "Epoch 1: val_loss improved from inf to 0.10408, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 6s 98ms/step - loss: 0.1788 - mean_squared_error: 0.0524 - val_loss: 0.1041 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1220 - mean_squared_error: 0.0246\n",
      "Epoch 2: val_loss improved from 0.10408 to 0.09462, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1220 - mean_squared_error: 0.0246 - val_loss: 0.0946 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1128 - mean_squared_error: 0.0212\n",
      "Epoch 3: val_loss improved from 0.09462 to 0.09118, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1128 - mean_squared_error: 0.0212 - val_loss: 0.0912 - val_mean_squared_error: 0.0137\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1048 - mean_squared_error: 0.0185\n",
      "Epoch 4: val_loss improved from 0.09118 to 0.08949, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1048 - mean_squared_error: 0.0185 - val_loss: 0.0895 - val_mean_squared_error: 0.0133\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0171\n",
      "Epoch 5: val_loss improved from 0.08949 to 0.08697, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1012 - mean_squared_error: 0.0171 - val_loss: 0.0870 - val_mean_squared_error: 0.0125\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0958 - mean_squared_error: 0.0155\n",
      "Epoch 6: val_loss improved from 0.08697 to 0.08508, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.0958 - mean_squared_error: 0.0155 - val_loss: 0.0851 - val_mean_squared_error: 0.0119\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0934 - mean_squared_error: 0.0147\n",
      "Epoch 7: val_loss did not improve from 0.08508\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0934 - mean_squared_error: 0.0147 - val_loss: 0.0989 - val_mean_squared_error: 0.0162\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0903 - mean_squared_error: 0.0139\n",
      "Epoch 8: val_loss did not improve from 0.08508\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.0904 - mean_squared_error: 0.0139 - val_loss: 0.0897 - val_mean_squared_error: 0.0137\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0879 - mean_squared_error: 0.0131\n",
      "Epoch 9: val_loss improved from 0.08508 to 0.08382, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0879 - mean_squared_error: 0.0131 - val_loss: 0.0838 - val_mean_squared_error: 0.0118\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0866 - mean_squared_error: 0.0128\n",
      "Epoch 10: val_loss improved from 0.08382 to 0.08338, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0865 - mean_squared_error: 0.0128 - val_loss: 0.0834 - val_mean_squared_error: 0.0115\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.0125\n",
      "Epoch 11: val_loss did not improve from 0.08338\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0851 - mean_squared_error: 0.0124 - val_loss: 0.0999 - val_mean_squared_error: 0.0165\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0837 - mean_squared_error: 0.0119\n",
      "Epoch 12: val_loss did not improve from 0.08338\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.0838 - mean_squared_error: 0.0119 - val_loss: 0.0834 - val_mean_squared_error: 0.0116\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0806 - mean_squared_error: 0.0112\n",
      "Epoch 13: val_loss did not improve from 0.08338\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.0806 - mean_squared_error: 0.0112 - val_loss: 0.0908 - val_mean_squared_error: 0.0139\n",
      "14/14 [==============================] - 1s 31ms/step\n",
      " ###1 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1817 - mean_squared_error: 0.0539\n",
      "Epoch 1: val_loss improved from inf to 0.10819, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 6s 99ms/step - loss: 0.1816 - mean_squared_error: 0.0538 - val_loss: 0.1082 - val_mean_squared_error: 0.0197\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1219 - mean_squared_error: 0.0243\n",
      "Epoch 2: val_loss improved from 0.10819 to 0.09629, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1218 - mean_squared_error: 0.0243 - val_loss: 0.0963 - val_mean_squared_error: 0.0151\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.09629 to 0.08975, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1125 - mean_squared_error: 0.0210 - val_loss: 0.0898 - val_mean_squared_error: 0.0136\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0186\n",
      "Epoch 4: val_loss improved from 0.08975 to 0.08649, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.1050 - mean_squared_error: 0.0186 - val_loss: 0.0865 - val_mean_squared_error: 0.0128\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0170\n",
      "Epoch 5: val_loss did not improve from 0.08649\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1002 - mean_squared_error: 0.0170 - val_loss: 0.0889 - val_mean_squared_error: 0.0134\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0989 - mean_squared_error: 0.0163\n",
      "Epoch 6: val_loss did not improve from 0.08649\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0989 - mean_squared_error: 0.0163 - val_loss: 0.0869 - val_mean_squared_error: 0.0130\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0943 - mean_squared_error: 0.0149\n",
      "Epoch 7: val_loss improved from 0.08649 to 0.08603, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.0943 - mean_squared_error: 0.0149 - val_loss: 0.0860 - val_mean_squared_error: 0.0126\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.0142\n",
      "Epoch 8: val_loss improved from 0.08603 to 0.08478, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.0914 - mean_squared_error: 0.0142 - val_loss: 0.0848 - val_mean_squared_error: 0.0123\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0904 - mean_squared_error: 0.0137\n",
      "Epoch 9: val_loss did not improve from 0.08478\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0904 - mean_squared_error: 0.0137 - val_loss: 0.0872 - val_mean_squared_error: 0.0134\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0874 - mean_squared_error: 0.0130\n",
      "Epoch 10: val_loss did not improve from 0.08478\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0874 - mean_squared_error: 0.0130 - val_loss: 0.0872 - val_mean_squared_error: 0.0132\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.0123\n",
      "Epoch 11: val_loss did not improve from 0.08478\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.0852 - mean_squared_error: 0.0123 - val_loss: 0.1166 - val_mean_squared_error: 0.0233\n",
      "14/14 [==============================] - 1s 29ms/step\n",
      " ###2 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1767 - mean_squared_error: 0.0519\n",
      "Epoch 1: val_loss improved from inf to 0.10709, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 7s 103ms/step - loss: 0.1765 - mean_squared_error: 0.0518 - val_loss: 0.1071 - val_mean_squared_error: 0.0186\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1234 - mean_squared_error: 0.0253\n",
      "Epoch 2: val_loss improved from 0.10709 to 0.10265, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1233 - mean_squared_error: 0.0253 - val_loss: 0.1027 - val_mean_squared_error: 0.0168\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1133 - mean_squared_error: 0.0215\n",
      "Epoch 3: val_loss improved from 0.10265 to 0.09472, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1133 - mean_squared_error: 0.0215 - val_loss: 0.0947 - val_mean_squared_error: 0.0150\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0192\n",
      "Epoch 4: val_loss improved from 0.09472 to 0.09245, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.1070 - mean_squared_error: 0.0192 - val_loss: 0.0924 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss improved from 0.09245 to 0.08882, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.1023 - mean_squared_error: 0.0176 - val_loss: 0.0888 - val_mean_squared_error: 0.0133\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0977 - mean_squared_error: 0.0161\n",
      "Epoch 6: val_loss improved from 0.08882 to 0.08765, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.0978 - mean_squared_error: 0.0161 - val_loss: 0.0876 - val_mean_squared_error: 0.0126\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.0152\n",
      "Epoch 7: val_loss did not improve from 0.08765\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0948 - mean_squared_error: 0.0152 - val_loss: 0.0971 - val_mean_squared_error: 0.0160\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0142\n",
      "Epoch 8: val_loss did not improve from 0.08765\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0917 - mean_squared_error: 0.0142 - val_loss: 0.0891 - val_mean_squared_error: 0.0136\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0900 - mean_squared_error: 0.0135\n",
      "Epoch 9: val_loss improved from 0.08765 to 0.08592, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.0901 - mean_squared_error: 0.0135 - val_loss: 0.0859 - val_mean_squared_error: 0.0125\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0891 - mean_squared_error: 0.0135\n",
      "Epoch 10: val_loss improved from 0.08592 to 0.08455, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt64_stride2_size7_pool5_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.0891 - mean_squared_error: 0.0135 - val_loss: 0.0846 - val_mean_squared_error: 0.0119\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0857 - mean_squared_error: 0.0124\n",
      "Epoch 11: val_loss did not improve from 0.08455\n",
      "40/40 [==============================] - 3s 72ms/step - loss: 0.0856 - mean_squared_error: 0.0124 - val_loss: 0.0872 - val_mean_squared_error: 0.0128\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.0119\n",
      "Epoch 12: val_loss did not improve from 0.08455\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0838 - mean_squared_error: 0.0119 - val_loss: 0.0850 - val_mean_squared_error: 0.0120\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0818 - mean_squared_error: 0.0114\n",
      "Epoch 13: val_loss did not improve from 0.08455\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0818 - mean_squared_error: 0.0114 - val_loss: 0.1021 - val_mean_squared_error: 0.0178\n",
      "14/14 [==============================] - 1s 32ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae8.34+-0.10\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1548 - mean_squared_error: 0.0400\n",
      "Epoch 1: val_loss improved from inf to 0.10062, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 16s 46ms/step - loss: 0.1547 - mean_squared_error: 0.0399 - val_loss: 0.1006 - val_mean_squared_error: 0.0167\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1176 - mean_squared_error: 0.0228\n",
      "Epoch 2: val_loss improved from 0.10062 to 0.09871, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1176 - mean_squared_error: 0.0228 - val_loss: 0.0987 - val_mean_squared_error: 0.0156\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0192\n",
      "Epoch 3: val_loss improved from 0.09871 to 0.09127, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1077 - mean_squared_error: 0.0192 - val_loss: 0.0913 - val_mean_squared_error: 0.0138\n",
      "Epoch 4/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0166\n",
      "Epoch 4: val_loss improved from 0.09127 to 0.09081, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1006 - mean_squared_error: 0.0166 - val_loss: 0.0908 - val_mean_squared_error: 0.0137\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.0153\n",
      "Epoch 5: val_loss improved from 0.09081 to 0.08859, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0959 - mean_squared_error: 0.0153 - val_loss: 0.0886 - val_mean_squared_error: 0.0132\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.0142\n",
      "Epoch 6: val_loss did not improve from 0.08859\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0927 - mean_squared_error: 0.0142 - val_loss: 0.1009 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.0133\n",
      "Epoch 7: val_loss did not improve from 0.08859\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0894 - mean_squared_error: 0.0134 - val_loss: 0.0919 - val_mean_squared_error: 0.0143\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0880 - mean_squared_error: 0.0129\n",
      "Epoch 8: val_loss improved from 0.08859 to 0.08654, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0880 - mean_squared_error: 0.0129 - val_loss: 0.0865 - val_mean_squared_error: 0.0123\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0855 - mean_squared_error: 0.0123\n",
      "Epoch 9: val_loss did not improve from 0.08654\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0855 - mean_squared_error: 0.0123 - val_loss: 0.0967 - val_mean_squared_error: 0.0159\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0848 - mean_squared_error: 0.0122\n",
      "Epoch 10: val_loss did not improve from 0.08654\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0849 - mean_squared_error: 0.0122 - val_loss: 0.1053 - val_mean_squared_error: 0.0184\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0848 - mean_squared_error: 0.0121\n",
      "Epoch 11: val_loss improved from 0.08654 to 0.08503, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.0849 - mean_squared_error: 0.0121 - val_loss: 0.0850 - val_mean_squared_error: 0.0121\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0835 - mean_squared_error: 0.0118\n",
      "Epoch 12: val_loss did not improve from 0.08503\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0835 - mean_squared_error: 0.0118 - val_loss: 0.0899 - val_mean_squared_error: 0.0139\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.0117\n",
      "Epoch 13: val_loss did not improve from 0.08503\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0832 - mean_squared_error: 0.0117 - val_loss: 0.0862 - val_mean_squared_error: 0.0123\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0828 - mean_squared_error: 0.0115\n",
      "Epoch 14: val_loss did not improve from 0.08503\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0828 - mean_squared_error: 0.0115 - val_loss: 0.1009 - val_mean_squared_error: 0.0175\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1641 - mean_squared_error: 0.0478\n",
      "Epoch 1: val_loss improved from inf to 0.12885, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 38ms/step - loss: 0.1640 - mean_squared_error: 0.0477 - val_loss: 0.1288 - val_mean_squared_error: 0.0255\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1144 - mean_squared_error: 0.0216\n",
      "Epoch 2: val_loss improved from 0.12885 to 0.10909, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1144 - mean_squared_error: 0.0216 - val_loss: 0.1091 - val_mean_squared_error: 0.0200\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1091 - mean_squared_error: 0.0196\n",
      "Epoch 3: val_loss improved from 0.10909 to 0.10150, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1091 - mean_squared_error: 0.0196 - val_loss: 0.1015 - val_mean_squared_error: 0.0170\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss improved from 0.10150 to 0.09801, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1068 - mean_squared_error: 0.0188 - val_loss: 0.0980 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1042 - mean_squared_error: 0.0178\n",
      "Epoch 5: val_loss did not improve from 0.09801\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1043 - mean_squared_error: 0.0178 - val_loss: 0.1036 - val_mean_squared_error: 0.0179\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1024 - mean_squared_error: 0.0173\n",
      "Epoch 6: val_loss improved from 0.09801 to 0.09665, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1024 - mean_squared_error: 0.0173 - val_loss: 0.0967 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0168\n",
      "Epoch 7: val_loss did not improve from 0.09665\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1014 - mean_squared_error: 0.0168 - val_loss: 0.0984 - val_mean_squared_error: 0.0162\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0167\n",
      "Epoch 8: val_loss improved from 0.09665 to 0.09604, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1011 - mean_squared_error: 0.0167 - val_loss: 0.0960 - val_mean_squared_error: 0.0152\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0166\n",
      "Epoch 9: val_loss did not improve from 0.09604\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1002 - mean_squared_error: 0.0166 - val_loss: 0.0961 - val_mean_squared_error: 0.0150\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0166\n",
      "Epoch 10: val_loss did not improve from 0.09604\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1003 - mean_squared_error: 0.0166 - val_loss: 0.0963 - val_mean_squared_error: 0.0153\n",
      "Epoch 11/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0998 - mean_squared_error: 0.0164\n",
      "Epoch 11: val_loss improved from 0.09604 to 0.09589, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0998 - mean_squared_error: 0.0164 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0163\n",
      "Epoch 12: val_loss improved from 0.09589 to 0.09553, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0995 - mean_squared_error: 0.0163 - val_loss: 0.0955 - val_mean_squared_error: 0.0149\n",
      "Epoch 13/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0163\n",
      "Epoch 13: val_loss did not improve from 0.09553\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0995 - mean_squared_error: 0.0163 - val_loss: 0.0957 - val_mean_squared_error: 0.0151\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0162\n",
      "Epoch 14: val_loss did not improve from 0.09553\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0992 - mean_squared_error: 0.0162 - val_loss: 0.0956 - val_mean_squared_error: 0.0150\n",
      "Epoch 15/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.0162\n",
      "Epoch 15: val_loss did not improve from 0.09553\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.0991 - mean_squared_error: 0.0162 - val_loss: 0.0976 - val_mean_squared_error: 0.0159\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1573 - mean_squared_error: 0.0425\n",
      "Epoch 1: val_loss improved from inf to 0.09995, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 39ms/step - loss: 0.1573 - mean_squared_error: 0.0425 - val_loss: 0.1000 - val_mean_squared_error: 0.0166\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1128 - mean_squared_error: 0.0209\n",
      "Epoch 2: val_loss did not improve from 0.09995\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1128 - mean_squared_error: 0.0209 - val_loss: 0.1084 - val_mean_squared_error: 0.0180\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0191\n",
      "Epoch 3: val_loss improved from 0.09995 to 0.09651, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1082 - mean_squared_error: 0.0190 - val_loss: 0.0965 - val_mean_squared_error: 0.0160\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0185\n",
      "Epoch 4: val_loss did not improve from 0.09651\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1063 - mean_squared_error: 0.0185 - val_loss: 0.0971 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0174\n",
      "Epoch 5: val_loss improved from 0.09651 to 0.09529, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1036 - mean_squared_error: 0.0174 - val_loss: 0.0953 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.0169\n",
      "Epoch 6: val_loss did not improve from 0.09529\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1017 - mean_squared_error: 0.0169 - val_loss: 0.0963 - val_mean_squared_error: 0.0159\n",
      "Epoch 7/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0167\n",
      "Epoch 7: val_loss did not improve from 0.09529\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1012 - mean_squared_error: 0.0167 - val_loss: 0.0965 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0165\n",
      "Epoch 8: val_loss did not improve from 0.09529\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1006 - mean_squared_error: 0.0165 - val_loss: 0.0953 - val_mean_squared_error: 0.0150\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.2292 - mean_squared_error: 0.0967\n",
      "Epoch 1: val_loss improved from inf to 0.11006, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 39ms/step - loss: 0.2282 - mean_squared_error: 0.0960 - val_loss: 0.1101 - val_mean_squared_error: 0.0191\n",
      "Epoch 2/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1174 - mean_squared_error: 0.0225\n",
      "Epoch 2: val_loss improved from 0.11006 to 0.10125, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1174 - mean_squared_error: 0.0225 - val_loss: 0.1012 - val_mean_squared_error: 0.0174\n",
      "Epoch 3/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1088 - mean_squared_error: 0.0194\n",
      "Epoch 3: val_loss improved from 0.10125 to 0.09990, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1088 - mean_squared_error: 0.0194 - val_loss: 0.0999 - val_mean_squared_error: 0.0169\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0182\n",
      "Epoch 4: val_loss improved from 0.09990 to 0.09907, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1046 - mean_squared_error: 0.0182 - val_loss: 0.0991 - val_mean_squared_error: 0.0163\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1024 - mean_squared_error: 0.0173\n",
      "Epoch 5: val_loss improved from 0.09907 to 0.09758, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt128_stride5_size11_pool2_do0.1_tra3_head4_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1024 - mean_squared_error: 0.0173 - val_loss: 0.0976 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1012 - mean_squared_error: 0.0169\n",
      "Epoch 6: val_loss did not improve from 0.09758\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1012 - mean_squared_error: 0.0170 - val_loss: 0.0982 - val_mean_squared_error: 0.0156\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0166\n",
      "Epoch 7: val_loss did not improve from 0.09758\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1007 - mean_squared_error: 0.0166 - val_loss: 0.0991 - val_mean_squared_error: 0.0165\n",
      "Epoch 8/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0167\n",
      "Epoch 8: val_loss did not improve from 0.09758\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.1008 - mean_squared_error: 0.0167 - val_loss: 0.0991 - val_mean_squared_error: 0.0166\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.35+-0.59\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1408 - mean_squared_error: 0.0334\n",
      "Epoch 1: val_loss improved from inf to 0.09931, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 19s 44ms/step - loss: 0.1408 - mean_squared_error: 0.0334 - val_loss: 0.0993 - val_mean_squared_error: 0.0160\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0212\n",
      "Epoch 2: val_loss improved from 0.09931 to 0.09915, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1134 - mean_squared_error: 0.0212 - val_loss: 0.0992 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.0199\n",
      "Epoch 3: val_loss improved from 0.09915 to 0.09812, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1093 - mean_squared_error: 0.0199 - val_loss: 0.0981 - val_mean_squared_error: 0.0155\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0189\n",
      "Epoch 4: val_loss did not improve from 0.09812\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1059 - mean_squared_error: 0.0188 - val_loss: 0.0987 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0178\n",
      "Epoch 5: val_loss did not improve from 0.09812\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1036 - mean_squared_error: 0.0178 - val_loss: 0.0990 - val_mean_squared_error: 0.0161\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0176\n",
      "Epoch 6: val_loss did not improve from 0.09812\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1028 - mean_squared_error: 0.0176 - val_loss: 0.0988 - val_mean_squared_error: 0.0160\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1360 - mean_squared_error: 0.0319\n",
      "Epoch 1: val_loss improved from inf to 0.10023, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 9s 43ms/step - loss: 0.1360 - mean_squared_error: 0.0319 - val_loss: 0.1002 - val_mean_squared_error: 0.0165\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1111 - mean_squared_error: 0.0204\n",
      "Epoch 2: val_loss did not improve from 0.10023\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1111 - mean_squared_error: 0.0204 - val_loss: 0.1056 - val_mean_squared_error: 0.0178\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0192\n",
      "Epoch 3: val_loss improved from 0.10023 to 0.09889, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1079 - mean_squared_error: 0.0192 - val_loss: 0.0989 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0184\n",
      "Epoch 4: val_loss improved from 0.09889 to 0.09870, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1056 - mean_squared_error: 0.0184 - val_loss: 0.0987 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1036 - mean_squared_error: 0.0177\n",
      "Epoch 5: val_loss improved from 0.09870 to 0.09727, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1036 - mean_squared_error: 0.0177 - val_loss: 0.0973 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0172\n",
      "Epoch 6: val_loss did not improve from 0.09727\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1020 - mean_squared_error: 0.0172 - val_loss: 0.0985 - val_mean_squared_error: 0.0162\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0170\n",
      "Epoch 7: val_loss improved from 0.09727 to 0.09658, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1021 - mean_squared_error: 0.0170 - val_loss: 0.0966 - val_mean_squared_error: 0.0155\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.0168\n",
      "Epoch 8: val_loss did not improve from 0.09658\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1010 - mean_squared_error: 0.0168 - val_loss: 0.0970 - val_mean_squared_error: 0.0156\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1002 - mean_squared_error: 0.0165\n",
      "Epoch 9: val_loss improved from 0.09658 to 0.09592, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1002 - mean_squared_error: 0.0165 - val_loss: 0.0959 - val_mean_squared_error: 0.0151\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0167\n",
      "Epoch 10: val_loss did not improve from 0.09592\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1003 - mean_squared_error: 0.0167 - val_loss: 0.0964 - val_mean_squared_error: 0.0152\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0997 - mean_squared_error: 0.0164\n",
      "Epoch 11: val_loss did not improve from 0.09592\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.0997 - mean_squared_error: 0.0164 - val_loss: 0.0971 - val_mean_squared_error: 0.0153\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.0161\n",
      "Epoch 12: val_loss improved from 0.09592 to 0.09580, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.0992 - mean_squared_error: 0.0161 - val_loss: 0.0958 - val_mean_squared_error: 0.0150\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.0161\n",
      "Epoch 13: val_loss improved from 0.09580 to 0.09552, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.0990 - mean_squared_error: 0.0161 - val_loss: 0.0955 - val_mean_squared_error: 0.0149\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0994 - mean_squared_error: 0.0163\n",
      "Epoch 14: val_loss did not improve from 0.09552\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.0994 - mean_squared_error: 0.0163 - val_loss: 0.0958 - val_mean_squared_error: 0.0151\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0162\n",
      "Epoch 15: val_loss did not improve from 0.09552\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0995 - mean_squared_error: 0.0162 - val_loss: 0.0958 - val_mean_squared_error: 0.0152\n",
      "Epoch 16/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.0163\n",
      "Epoch 16: val_loss did not improve from 0.09552\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0996 - mean_squared_error: 0.0163 - val_loss: 0.0956 - val_mean_squared_error: 0.0150\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1392 - mean_squared_error: 0.0324\n",
      "Epoch 1: val_loss improved from inf to 0.10006, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 9s 45ms/step - loss: 0.1392 - mean_squared_error: 0.0324 - val_loss: 0.1001 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.0206\n",
      "Epoch 2: val_loss did not improve from 0.10006\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1124 - mean_squared_error: 0.0206 - val_loss: 0.1026 - val_mean_squared_error: 0.0170\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0186\n",
      "Epoch 3: val_loss improved from 0.10006 to 0.09491, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1064 - mean_squared_error: 0.0186 - val_loss: 0.0949 - val_mean_squared_error: 0.0154\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0175\n",
      "Epoch 4: val_loss did not improve from 0.09491\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1034 - mean_squared_error: 0.0175 - val_loss: 0.0996 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0173\n",
      "Epoch 5: val_loss did not improve from 0.09491\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1026 - mean_squared_error: 0.0173 - val_loss: 0.0965 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0168\n",
      "Epoch 6: val_loss did not improve from 0.09491\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1014 - mean_squared_error: 0.0168 - val_loss: 0.0992 - val_mean_squared_error: 0.0158\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1368 - mean_squared_error: 0.0320\n",
      "Epoch 1: val_loss improved from inf to 0.11574, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 9s 47ms/step - loss: 0.1368 - mean_squared_error: 0.0320 - val_loss: 0.1157 - val_mean_squared_error: 0.0206\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0201\n",
      "Epoch 2: val_loss improved from 0.11574 to 0.09964, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1101 - mean_squared_error: 0.0201 - val_loss: 0.0996 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0187\n",
      "Epoch 3: val_loss did not improve from 0.09964\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1064 - mean_squared_error: 0.0187 - val_loss: 0.1082 - val_mean_squared_error: 0.0184\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0177\n",
      "Epoch 4: val_loss did not improve from 0.09964\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1040 - mean_squared_error: 0.0177 - val_loss: 0.1046 - val_mean_squared_error: 0.0172\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0172\n",
      "Epoch 5: val_loss improved from 0.09964 to 0.09896, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1022 - mean_squared_error: 0.0172 - val_loss: 0.0990 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0169\n",
      "Epoch 6: val_loss did not improve from 0.09896\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1015 - mean_squared_error: 0.0169 - val_loss: 0.1009 - val_mean_squared_error: 0.0162\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0167\n",
      "Epoch 7: val_loss did not improve from 0.09896\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1009 - mean_squared_error: 0.0167 - val_loss: 0.0999 - val_mean_squared_error: 0.0160\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0165\n",
      "Epoch 8: val_loss improved from 0.09896 to 0.09893, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1004 - mean_squared_error: 0.0165 - val_loss: 0.0989 - val_mean_squared_error: 0.0156\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0998 - mean_squared_error: 0.0163\n",
      "Epoch 9: val_loss improved from 0.09893 to 0.09702, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.0998 - mean_squared_error: 0.0163 - val_loss: 0.0970 - val_mean_squared_error: 0.0153\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0988 - mean_squared_error: 0.0161\n",
      "Epoch 10: val_loss did not improve from 0.09702\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0988 - mean_squared_error: 0.0161 - val_loss: 0.0972 - val_mean_squared_error: 0.0155\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.0163\n",
      "Epoch 11: val_loss did not improve from 0.09702\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0991 - mean_squared_error: 0.0163 - val_loss: 0.0973 - val_mean_squared_error: 0.0153\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0986 - mean_squared_error: 0.0159\n",
      "Epoch 12: val_loss did not improve from 0.09702\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.0986 - mean_squared_error: 0.0159 - val_loss: 0.0980 - val_mean_squared_error: 0.0154\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.71+-0.09\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride2_size7_pool4_do0.5_tra5_head8_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3313 - mean_squared_error: 0.1445\n",
      "Epoch 1: val_loss improved from inf to 0.19376, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride2_size7_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 20s 157ms/step - loss: 0.3313 - mean_squared_error: 0.1445 - val_loss: 0.1938 - val_mean_squared_error: 0.0584\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2726 - mean_squared_error: 0.1045\n",
      "Epoch 2: val_loss did not improve from 0.19376\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2727 - mean_squared_error: 0.1046 - val_loss: 0.2055 - val_mean_squared_error: 0.0604\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2281 - mean_squared_error: 0.0768\n",
      "Epoch 3: val_loss did not improve from 0.19376\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2279 - mean_squared_error: 0.0767 - val_loss: 0.2837 - val_mean_squared_error: 0.0977\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1878 - mean_squared_error: 0.0550\n",
      "Epoch 4: val_loss did not improve from 0.19376\n",
      "40/40 [==============================] - 5s 126ms/step - loss: 0.1876 - mean_squared_error: 0.0550 - val_loss: 0.3259 - val_mean_squared_error: 0.1229\n",
      "14/14 [==============================] - 2s 52ms/step\n",
      " ###0 fold : val mae 0.19###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3320 - mean_squared_error: 0.1464\n",
      "Epoch 1: val_loss improved from inf to 0.20386, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride2_size7_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 8s 149ms/step - loss: 0.3317 - mean_squared_error: 0.1462 - val_loss: 0.2039 - val_mean_squared_error: 0.0617\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2693 - mean_squared_error: 0.1026\n",
      "Epoch 2: val_loss did not improve from 0.20386\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2693 - mean_squared_error: 0.1026 - val_loss: 0.2714 - val_mean_squared_error: 0.0935\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2161 - mean_squared_error: 0.0701\n",
      "Epoch 3: val_loss did not improve from 0.20386\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2161 - mean_squared_error: 0.0701 - val_loss: 0.2993 - val_mean_squared_error: 0.1057\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1806 - mean_squared_error: 0.0516\n",
      "Epoch 4: val_loss did not improve from 0.20386\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.1805 - mean_squared_error: 0.0515 - val_loss: 0.2459 - val_mean_squared_error: 0.0748\n",
      "14/14 [==============================] - 2s 50ms/step\n",
      " ###1 fold : val mae 0.21###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3344 - mean_squared_error: 0.1477\n",
      "Epoch 1: val_loss improved from inf to 0.19073, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride2_size7_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 8s 152ms/step - loss: 0.3344 - mean_squared_error: 0.1477 - val_loss: 0.1907 - val_mean_squared_error: 0.0562\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2673 - mean_squared_error: 0.1020\n",
      "Epoch 2: val_loss did not improve from 0.19073\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2672 - mean_squared_error: 0.1020 - val_loss: 0.3098 - val_mean_squared_error: 0.1180\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2171 - mean_squared_error: 0.0712\n",
      "Epoch 3: val_loss did not improve from 0.19073\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.2170 - mean_squared_error: 0.0711 - val_loss: 0.3030 - val_mean_squared_error: 0.1085\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1812 - mean_squared_error: 0.0518\n",
      "Epoch 4: val_loss did not improve from 0.19073\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.1810 - mean_squared_error: 0.0518 - val_loss: 0.2974 - val_mean_squared_error: 0.1040\n",
      "14/14 [==============================] - 1s 51ms/step\n",
      " ###2 fold : val mae 0.19###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.3368 - mean_squared_error: 0.1472\n",
      "Epoch 1: val_loss improved from inf to 0.20768, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride2_size7_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 8s 151ms/step - loss: 0.3367 - mean_squared_error: 0.1472 - val_loss: 0.2077 - val_mean_squared_error: 0.0654\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2637 - mean_squared_error: 0.0996\n",
      "Epoch 2: val_loss improved from 0.20768 to 0.17455, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride2_size7_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 5s 130ms/step - loss: 0.2636 - mean_squared_error: 0.0995 - val_loss: 0.1745 - val_mean_squared_error: 0.0463\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2163 - mean_squared_error: 0.0707\n",
      "Epoch 3: val_loss did not improve from 0.17455\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.2162 - mean_squared_error: 0.0706 - val_loss: 0.1866 - val_mean_squared_error: 0.0480\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1810 - mean_squared_error: 0.0514\n",
      "Epoch 4: val_loss improved from 0.17455 to 0.17274, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn2_filt16_stride2_size7_pool4_do0.5_tra5_head8_kdim128_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 5s 129ms/step - loss: 0.1809 - mean_squared_error: 0.0514 - val_loss: 0.1727 - val_mean_squared_error: 0.0410\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1570 - mean_squared_error: 0.0397\n",
      "Epoch 5: val_loss did not improve from 0.17274\n",
      "40/40 [==============================] - 5s 125ms/step - loss: 0.1571 - mean_squared_error: 0.0398 - val_loss: 0.1785 - val_mean_squared_error: 0.0429\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1402 - mean_squared_error: 0.0322\n",
      "Epoch 6: val_loss did not improve from 0.17274\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1401 - mean_squared_error: 0.0322 - val_loss: 0.1730 - val_mean_squared_error: 0.0402\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1314 - mean_squared_error: 0.0281\n",
      "Epoch 7: val_loss did not improve from 0.17274\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.1315 - mean_squared_error: 0.0281 - val_loss: 0.1784 - val_mean_squared_error: 0.0424\n",
      "14/14 [==============================] - 1s 49ms/step\n",
      " ###3 fold : val mae 0.17###\n",
      "mae19.19+-1.23\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1696 - mean_squared_error: 0.0471\n",
      "Epoch 1: val_loss improved from inf to 0.11194, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 111ms/step - loss: 0.1696 - mean_squared_error: 0.0471 - val_loss: 0.1119 - val_mean_squared_error: 0.0209\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1314 - mean_squared_error: 0.0287\n",
      "Epoch 2: val_loss improved from 0.11194 to 0.10026, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1314 - mean_squared_error: 0.0287 - val_loss: 0.1003 - val_mean_squared_error: 0.0170\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1176 - mean_squared_error: 0.0230\n",
      "Epoch 3: val_loss did not improve from 0.10026\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1176 - mean_squared_error: 0.0230 - val_loss: 0.1059 - val_mean_squared_error: 0.0186\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0205\n",
      "Epoch 4: val_loss improved from 0.10026 to 0.09593, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1103 - mean_squared_error: 0.0204 - val_loss: 0.0959 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0184\n",
      "Epoch 5: val_loss did not improve from 0.09593\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1040 - mean_squared_error: 0.0184 - val_loss: 0.1016 - val_mean_squared_error: 0.0173\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1007 - mean_squared_error: 0.0171\n",
      "Epoch 6: val_loss improved from 0.09593 to 0.09085, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1007 - mean_squared_error: 0.0171 - val_loss: 0.0909 - val_mean_squared_error: 0.0134\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0967 - mean_squared_error: 0.0156\n",
      "Epoch 7: val_loss improved from 0.09085 to 0.08663, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0968 - mean_squared_error: 0.0156 - val_loss: 0.0866 - val_mean_squared_error: 0.0123\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0931 - mean_squared_error: 0.0146\n",
      "Epoch 8: val_loss did not improve from 0.08663\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0931 - mean_squared_error: 0.0146 - val_loss: 0.0884 - val_mean_squared_error: 0.0132\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.0136\n",
      "Epoch 9: val_loss improved from 0.08663 to 0.08525, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0893 - mean_squared_error: 0.0136 - val_loss: 0.0853 - val_mean_squared_error: 0.0121\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0891 - mean_squared_error: 0.0134\n",
      "Epoch 10: val_loss did not improve from 0.08525\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0891 - mean_squared_error: 0.0134 - val_loss: 0.0967 - val_mean_squared_error: 0.0157\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0850 - mean_squared_error: 0.0125\n",
      "Epoch 11: val_loss did not improve from 0.08525\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0850 - mean_squared_error: 0.0125 - val_loss: 0.0934 - val_mean_squared_error: 0.0150\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.0118\n",
      "Epoch 12: val_loss did not improve from 0.08525\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0832 - mean_squared_error: 0.0118 - val_loss: 0.0969 - val_mean_squared_error: 0.0162\n",
      "14/14 [==============================] - 1s 30ms/step\n",
      " ###0 fold : val mae 0.08###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1702 - mean_squared_error: 0.0475\n",
      "Epoch 1: val_loss improved from inf to 0.10762, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 6s 100ms/step - loss: 0.1701 - mean_squared_error: 0.0474 - val_loss: 0.1076 - val_mean_squared_error: 0.0190\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1255 - mean_squared_error: 0.0263\n",
      "Epoch 2: val_loss improved from 0.10762 to 0.10014, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1253 - mean_squared_error: 0.0263 - val_loss: 0.1001 - val_mean_squared_error: 0.0167\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1176 - mean_squared_error: 0.0231\n",
      "Epoch 3: val_loss improved from 0.10014 to 0.09807, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1176 - mean_squared_error: 0.0231 - val_loss: 0.0981 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1094 - mean_squared_error: 0.0202\n",
      "Epoch 4: val_loss did not improve from 0.09807\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.1094 - mean_squared_error: 0.0202 - val_loss: 0.1199 - val_mean_squared_error: 0.0217\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1034 - mean_squared_error: 0.0182\n",
      "Epoch 5: val_loss improved from 0.09807 to 0.09275, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1033 - mean_squared_error: 0.0182 - val_loss: 0.0928 - val_mean_squared_error: 0.0143\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.0163\n",
      "Epoch 6: val_loss did not improve from 0.09275\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0983 - mean_squared_error: 0.0163 - val_loss: 0.0997 - val_mean_squared_error: 0.0165\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0949 - mean_squared_error: 0.0151\n",
      "Epoch 7: val_loss improved from 0.09275 to 0.09255, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.0949 - mean_squared_error: 0.0151 - val_loss: 0.0925 - val_mean_squared_error: 0.0142\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0934 - mean_squared_error: 0.0148\n",
      "Epoch 8: val_loss improved from 0.09255 to 0.08517, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.0933 - mean_squared_error: 0.0148 - val_loss: 0.0852 - val_mean_squared_error: 0.0117\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0892 - mean_squared_error: 0.0135\n",
      "Epoch 9: val_loss did not improve from 0.08517\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0892 - mean_squared_error: 0.0135 - val_loss: 0.0901 - val_mean_squared_error: 0.0133\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0867 - mean_squared_error: 0.0128\n",
      "Epoch 10: val_loss did not improve from 0.08517\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0868 - mean_squared_error: 0.0128 - val_loss: 0.0940 - val_mean_squared_error: 0.0137\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0836 - mean_squared_error: 0.0120\n",
      "Epoch 11: val_loss did not improve from 0.08517\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0837 - mean_squared_error: 0.0120 - val_loss: 0.0924 - val_mean_squared_error: 0.0143\n",
      "14/14 [==============================] - 2s 29ms/step\n",
      " ###1 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1676 - mean_squared_error: 0.0460\n",
      "Epoch 1: val_loss improved from inf to 0.10258, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 6s 98ms/step - loss: 0.1676 - mean_squared_error: 0.0460 - val_loss: 0.1026 - val_mean_squared_error: 0.0183\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1262 - mean_squared_error: 0.0261\n",
      "Epoch 2: val_loss improved from 0.10258 to 0.09597, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1263 - mean_squared_error: 0.0261 - val_loss: 0.0960 - val_mean_squared_error: 0.0159\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1174 - mean_squared_error: 0.0228\n",
      "Epoch 3: val_loss improved from 0.09597 to 0.09187, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1173 - mean_squared_error: 0.0228 - val_loss: 0.0919 - val_mean_squared_error: 0.0147\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0193\n",
      "Epoch 4: val_loss did not improve from 0.09187\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1082 - mean_squared_error: 0.0193 - val_loss: 0.0959 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0177\n",
      "Epoch 5: val_loss improved from 0.09187 to 0.08461, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.1028 - mean_squared_error: 0.0177 - val_loss: 0.0846 - val_mean_squared_error: 0.0123\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0958 - mean_squared_error: 0.0154\n",
      "Epoch 6: val_loss did not improve from 0.08461\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0958 - mean_squared_error: 0.0154 - val_loss: 0.0869 - val_mean_squared_error: 0.0125\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0949 - mean_squared_error: 0.0151\n",
      "Epoch 7: val_loss did not improve from 0.08461\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0949 - mean_squared_error: 0.0151 - val_loss: 0.0869 - val_mean_squared_error: 0.0127\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.0144\n",
      "Epoch 8: val_loss did not improve from 0.08461\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0921 - mean_squared_error: 0.0144 - val_loss: 0.0879 - val_mean_squared_error: 0.0128\n",
      "14/14 [==============================] - 1s 27ms/step\n",
      " ###2 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1657 - mean_squared_error: 0.0453\n",
      "Epoch 1: val_loss improved from inf to 0.11669, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 95ms/step - loss: 0.1656 - mean_squared_error: 0.0452 - val_loss: 0.1167 - val_mean_squared_error: 0.0222\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1240 - mean_squared_error: 0.0255\n",
      "Epoch 2: val_loss improved from 0.11669 to 0.10890, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1241 - mean_squared_error: 0.0256 - val_loss: 0.1089 - val_mean_squared_error: 0.0200\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1118 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss improved from 0.10890 to 0.10343, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.1118 - mean_squared_error: 0.0211 - val_loss: 0.1034 - val_mean_squared_error: 0.0182\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.0190\n",
      "Epoch 4: val_loss did not improve from 0.10343\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.1062 - mean_squared_error: 0.0190 - val_loss: 0.1125 - val_mean_squared_error: 0.0217\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1011 - mean_squared_error: 0.0174\n",
      "Epoch 5: val_loss improved from 0.10343 to 0.09268, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.1012 - mean_squared_error: 0.0174 - val_loss: 0.0927 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0970 - mean_squared_error: 0.0158\n",
      "Epoch 6: val_loss improved from 0.09268 to 0.09054, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0969 - mean_squared_error: 0.0158 - val_loss: 0.0905 - val_mean_squared_error: 0.0138\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0155\n",
      "Epoch 7: val_loss improved from 0.09054 to 0.08727, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0954 - mean_squared_error: 0.0155 - val_loss: 0.0873 - val_mean_squared_error: 0.0124\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0909 - mean_squared_error: 0.0142\n",
      "Epoch 8: val_loss did not improve from 0.08727\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0909 - mean_squared_error: 0.0142 - val_loss: 0.1049 - val_mean_squared_error: 0.0187\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0882 - mean_squared_error: 0.0133\n",
      "Epoch 9: val_loss improved from 0.08727 to 0.08413, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt128_stride5_size19_pool2_do0.1_tra5_head4_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.0882 - mean_squared_error: 0.0133 - val_loss: 0.0841 - val_mean_squared_error: 0.0118\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0845 - mean_squared_error: 0.0122\n",
      "Epoch 10: val_loss did not improve from 0.08413\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.0845 - mean_squared_error: 0.0122 - val_loss: 0.0869 - val_mean_squared_error: 0.0127\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0830 - mean_squared_error: 0.0118\n",
      "Epoch 11: val_loss did not improve from 0.08413\n",
      "40/40 [==============================] - 3s 69ms/step - loss: 0.0830 - mean_squared_error: 0.0118 - val_loss: 0.0856 - val_mean_squared_error: 0.0127\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0810 - mean_squared_error: 0.0112\n",
      "Epoch 12: val_loss did not improve from 0.08413\n",
      "40/40 [==============================] - 3s 70ms/step - loss: 0.0809 - mean_squared_error: 0.0112 - val_loss: 0.0864 - val_mean_squared_error: 0.0130\n",
      "14/14 [==============================] - 2s 28ms/step\n",
      " ###3 fold : val mae 0.08###\n",
      "mae8.47+-0.13\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1700 - mean_squared_error: 0.0481\n",
      "Epoch 1: val_loss improved from inf to 0.09938, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 109ms/step - loss: 0.1700 - mean_squared_error: 0.0481 - val_loss: 0.0994 - val_mean_squared_error: 0.0159\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1185 - mean_squared_error: 0.0231\n",
      "Epoch 2: val_loss did not improve from 0.09938\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1185 - mean_squared_error: 0.0231 - val_loss: 0.1032 - val_mean_squared_error: 0.0179\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1141 - mean_squared_error: 0.0215\n",
      "Epoch 3: val_loss improved from 0.09938 to 0.09924, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1141 - mean_squared_error: 0.0215 - val_loss: 0.0992 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1104 - mean_squared_error: 0.0201\n",
      "Epoch 4: val_loss improved from 0.09924 to 0.09873, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1105 - mean_squared_error: 0.0201 - val_loss: 0.0987 - val_mean_squared_error: 0.0164\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0195\n",
      "Epoch 5: val_loss improved from 0.09873 to 0.09847, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1083 - mean_squared_error: 0.0195 - val_loss: 0.0985 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0191\n",
      "Epoch 6: val_loss did not improve from 0.09847\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1077 - mean_squared_error: 0.0191 - val_loss: 0.0988 - val_mean_squared_error: 0.0161\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0187\n",
      "Epoch 7: val_loss improved from 0.09847 to 0.09757, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1066 - mean_squared_error: 0.0187 - val_loss: 0.0976 - val_mean_squared_error: 0.0158\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0182\n",
      "Epoch 8: val_loss did not improve from 0.09757\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1047 - mean_squared_error: 0.0182 - val_loss: 0.1001 - val_mean_squared_error: 0.0161\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0192\n",
      "Epoch 9: val_loss did not improve from 0.09757\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1074 - mean_squared_error: 0.0192 - val_loss: 0.0985 - val_mean_squared_error: 0.0161\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0181\n",
      "Epoch 10: val_loss did not improve from 0.09757\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1047 - mean_squared_error: 0.0181 - val_loss: 0.0994 - val_mean_squared_error: 0.0161\n",
      "14/14 [==============================] - 2s 23ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1594 - mean_squared_error: 0.0424\n",
      "Epoch 1: val_loss improved from inf to 0.09849, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_1.hdf5\n",
      "40/40 [==============================] - 7s 82ms/step - loss: 0.1594 - mean_squared_error: 0.0424 - val_loss: 0.0985 - val_mean_squared_error: 0.0159\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1158 - mean_squared_error: 0.0224\n",
      "Epoch 2: val_loss did not improve from 0.09849\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1157 - mean_squared_error: 0.0224 - val_loss: 0.1014 - val_mean_squared_error: 0.0171\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1112 - mean_squared_error: 0.0206\n",
      "Epoch 3: val_loss did not improve from 0.09849\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1112 - mean_squared_error: 0.0206 - val_loss: 0.0996 - val_mean_squared_error: 0.0164\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0199\n",
      "Epoch 4: val_loss did not improve from 0.09849\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1099 - mean_squared_error: 0.0199 - val_loss: 0.0988 - val_mean_squared_error: 0.0158\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1673 - mean_squared_error: 0.0467\n",
      "Epoch 1: val_loss improved from inf to 0.10022, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 7s 81ms/step - loss: 0.1673 - mean_squared_error: 0.0467 - val_loss: 0.1002 - val_mean_squared_error: 0.0166\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1164 - mean_squared_error: 0.0224\n",
      "Epoch 2: val_loss improved from 0.10022 to 0.09696, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1164 - mean_squared_error: 0.0223 - val_loss: 0.0970 - val_mean_squared_error: 0.0157\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1111 - mean_squared_error: 0.0201\n",
      "Epoch 3: val_loss did not improve from 0.09696\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1112 - mean_squared_error: 0.0201 - val_loss: 0.0973 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1100 - mean_squared_error: 0.0197\n",
      "Epoch 4: val_loss did not improve from 0.09696\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1101 - mean_squared_error: 0.0197 - val_loss: 0.1001 - val_mean_squared_error: 0.0172\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0199\n",
      "Epoch 5: val_loss did not improve from 0.09696\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1099 - mean_squared_error: 0.0199 - val_loss: 0.1089 - val_mean_squared_error: 0.0204\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1576 - mean_squared_error: 0.0408\n",
      "Epoch 1: val_loss improved from inf to 0.10087, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 7s 92ms/step - loss: 0.1576 - mean_squared_error: 0.0408 - val_loss: 0.1009 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1165 - mean_squared_error: 0.0223\n",
      "Epoch 2: val_loss did not improve from 0.10087\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1165 - mean_squared_error: 0.0223 - val_loss: 0.1080 - val_mean_squared_error: 0.0179\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1120 - mean_squared_error: 0.0206\n",
      "Epoch 3: val_loss improved from 0.10087 to 0.09800, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1120 - mean_squared_error: 0.0206 - val_loss: 0.0980 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1102 - mean_squared_error: 0.0200\n",
      "Epoch 4: val_loss did not improve from 0.09800\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1102 - mean_squared_error: 0.0200 - val_loss: 0.1011 - val_mean_squared_error: 0.0173\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0192\n",
      "Epoch 5: val_loss improved from 0.09800 to 0.09754, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride4_size7_pool5_do0.1_tra5_head4_kdim64_fnn128/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1078 - mean_squared_error: 0.0192 - val_loss: 0.0975 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0188\n",
      "Epoch 6: val_loss did not improve from 0.09754\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1069 - mean_squared_error: 0.0189 - val_loss: 0.0997 - val_mean_squared_error: 0.0160\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0182\n",
      "Epoch 7: val_loss did not improve from 0.09754\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1046 - mean_squared_error: 0.0182 - val_loss: 0.0993 - val_mean_squared_error: 0.0159\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1057 - mean_squared_error: 0.0185\n",
      "Epoch 8: val_loss did not improve from 0.09754\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1056 - mean_squared_error: 0.0185 - val_loss: 0.1003 - val_mean_squared_error: 0.0160\n",
      "14/14 [==============================] - 1s 24ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.86+-0.16\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1810 - mean_squared_error: 0.0532\n",
      "Epoch 1: val_loss improved from inf to 0.10586, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 89ms/step - loss: 0.1810 - mean_squared_error: 0.0532 - val_loss: 0.1059 - val_mean_squared_error: 0.0187\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1276 - mean_squared_error: 0.0267\n",
      "Epoch 2: val_loss did not improve from 0.10586\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1276 - mean_squared_error: 0.0267 - val_loss: 0.1059 - val_mean_squared_error: 0.0190\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1203 - mean_squared_error: 0.0237\n",
      "Epoch 3: val_loss improved from 0.10586 to 0.09705, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1203 - mean_squared_error: 0.0237 - val_loss: 0.0971 - val_mean_squared_error: 0.0154\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1144 - mean_squared_error: 0.0219\n",
      "Epoch 4: val_loss did not improve from 0.09705\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1144 - mean_squared_error: 0.0219 - val_loss: 0.1028 - val_mean_squared_error: 0.0176\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0196\n",
      "Epoch 5: val_loss did not improve from 0.09705\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1081 - mean_squared_error: 0.0196 - val_loss: 0.1039 - val_mean_squared_error: 0.0181\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1042 - mean_squared_error: 0.0182\n",
      "Epoch 6: val_loss did not improve from 0.09705\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1041 - mean_squared_error: 0.0182 - val_loss: 0.1092 - val_mean_squared_error: 0.0201\n",
      "14/14 [==============================] - 1s 26ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1771 - mean_squared_error: 0.0516\n",
      "Epoch 1: val_loss improved from inf to 0.10832, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 5s 79ms/step - loss: 0.1771 - mean_squared_error: 0.0516 - val_loss: 0.1083 - val_mean_squared_error: 0.0196\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1253 - mean_squared_error: 0.0262\n",
      "Epoch 2: val_loss improved from 0.10832 to 0.09752, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1253 - mean_squared_error: 0.0262 - val_loss: 0.0975 - val_mean_squared_error: 0.0154\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1162 - mean_squared_error: 0.0223\n",
      "Epoch 3: val_loss did not improve from 0.09752\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1162 - mean_squared_error: 0.0223 - val_loss: 0.1023 - val_mean_squared_error: 0.0165\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0198\n",
      "Epoch 4: val_loss improved from 0.09752 to 0.09242, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1092 - mean_squared_error: 0.0198 - val_loss: 0.0924 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1047 - mean_squared_error: 0.0186\n",
      "Epoch 5: val_loss did not improve from 0.09242\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1047 - mean_squared_error: 0.0186 - val_loss: 0.0947 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.0175\n",
      "Epoch 6: val_loss did not improve from 0.09242\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1018 - mean_squared_error: 0.0175 - val_loss: 0.0956 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0164\n",
      "Epoch 7: val_loss improved from 0.09242 to 0.09052, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0983 - mean_squared_error: 0.0164 - val_loss: 0.0905 - val_mean_squared_error: 0.0136\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0961 - mean_squared_error: 0.0155\n",
      "Epoch 8: val_loss did not improve from 0.09052\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.0961 - mean_squared_error: 0.0155 - val_loss: 0.0927 - val_mean_squared_error: 0.0135\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0931 - mean_squared_error: 0.0146\n",
      "Epoch 9: val_loss improved from 0.09052 to 0.08850, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0931 - mean_squared_error: 0.0146 - val_loss: 0.0885 - val_mean_squared_error: 0.0131\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0902 - mean_squared_error: 0.0138\n",
      "Epoch 10: val_loss improved from 0.08850 to 0.08752, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0902 - mean_squared_error: 0.0138 - val_loss: 0.0875 - val_mean_squared_error: 0.0125\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.0135\n",
      "Epoch 11: val_loss did not improve from 0.08752\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0890 - mean_squared_error: 0.0135 - val_loss: 0.1024 - val_mean_squared_error: 0.0174\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0879 - mean_squared_error: 0.0132\n",
      "Epoch 12: val_loss improved from 0.08752 to 0.08671, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0879 - mean_squared_error: 0.0132 - val_loss: 0.0867 - val_mean_squared_error: 0.0124\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.0126\n",
      "Epoch 13: val_loss did not improve from 0.08671\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0859 - mean_squared_error: 0.0126 - val_loss: 0.0912 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.0122\n",
      "Epoch 14: val_loss did not improve from 0.08671\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.0839 - mean_squared_error: 0.0122 - val_loss: 0.0877 - val_mean_squared_error: 0.0128\n",
      "Epoch 15/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.0117\n",
      "Epoch 15: val_loss did not improve from 0.08671\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0824 - mean_squared_error: 0.0116 - val_loss: 0.0869 - val_mean_squared_error: 0.0129\n",
      "14/14 [==============================] - 1s 26ms/step\n",
      " ###1 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1774 - mean_squared_error: 0.0520\n",
      "Epoch 1: val_loss improved from inf to 0.11018, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 5s 89ms/step - loss: 0.1774 - mean_squared_error: 0.0520 - val_loss: 0.1102 - val_mean_squared_error: 0.0193\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1233 - mean_squared_error: 0.0248\n",
      "Epoch 2: val_loss improved from 0.11018 to 0.09723, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1233 - mean_squared_error: 0.0248 - val_loss: 0.0972 - val_mean_squared_error: 0.0155\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1158 - mean_squared_error: 0.0219\n",
      "Epoch 3: val_loss improved from 0.09723 to 0.09492, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1158 - mean_squared_error: 0.0219 - val_loss: 0.0949 - val_mean_squared_error: 0.0149\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1088 - mean_squared_error: 0.0197\n",
      "Epoch 4: val_loss did not improve from 0.09492\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1089 - mean_squared_error: 0.0197 - val_loss: 0.0979 - val_mean_squared_error: 0.0164\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0186\n",
      "Epoch 5: val_loss improved from 0.09492 to 0.09309, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1056 - mean_squared_error: 0.0186 - val_loss: 0.0931 - val_mean_squared_error: 0.0147\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0171\n",
      "Epoch 6: val_loss did not improve from 0.09309\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1013 - mean_squared_error: 0.0171 - val_loss: 0.0947 - val_mean_squared_error: 0.0157\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0964 - mean_squared_error: 0.0155\n",
      "Epoch 7: val_loss improved from 0.09309 to 0.08863, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.0964 - mean_squared_error: 0.0155 - val_loss: 0.0886 - val_mean_squared_error: 0.0135\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0947 - mean_squared_error: 0.0150\n",
      "Epoch 8: val_loss did not improve from 0.08863\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0947 - mean_squared_error: 0.0150 - val_loss: 0.0898 - val_mean_squared_error: 0.0135\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.0142\n",
      "Epoch 9: val_loss did not improve from 0.08863\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.0917 - mean_squared_error: 0.0142 - val_loss: 0.1008 - val_mean_squared_error: 0.0180\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0901 - mean_squared_error: 0.0136\n",
      "Epoch 10: val_loss did not improve from 0.08863\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.0902 - mean_squared_error: 0.0136 - val_loss: 0.0914 - val_mean_squared_error: 0.0146\n",
      "14/14 [==============================] - 2s 25ms/step\n",
      " ###2 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1780 - mean_squared_error: 0.0518\n",
      "Epoch 1: val_loss improved from inf to 0.10271, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 5s 82ms/step - loss: 0.1780 - mean_squared_error: 0.0518 - val_loss: 0.1027 - val_mean_squared_error: 0.0173\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1237 - mean_squared_error: 0.0255\n",
      "Epoch 2: val_loss improved from 0.10271 to 0.09914, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1236 - mean_squared_error: 0.0255 - val_loss: 0.0991 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1163 - mean_squared_error: 0.0224\n",
      "Epoch 3: val_loss improved from 0.09914 to 0.09767, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1163 - mean_squared_error: 0.0224 - val_loss: 0.0977 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0212\n",
      "Epoch 4: val_loss did not improve from 0.09767\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1125 - mean_squared_error: 0.0212 - val_loss: 0.0978 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0201\n",
      "Epoch 5: val_loss improved from 0.09767 to 0.09705, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1099 - mean_squared_error: 0.0201 - val_loss: 0.0970 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0188\n",
      "Epoch 6: val_loss improved from 0.09705 to 0.09545, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1068 - mean_squared_error: 0.0188 - val_loss: 0.0955 - val_mean_squared_error: 0.0150\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1042 - mean_squared_error: 0.0180\n",
      "Epoch 7: val_loss did not improve from 0.09545\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1042 - mean_squared_error: 0.0180 - val_loss: 0.1000 - val_mean_squared_error: 0.0168\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0169\n",
      "Epoch 8: val_loss improved from 0.09545 to 0.09261, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.1005 - mean_squared_error: 0.0169 - val_loss: 0.0926 - val_mean_squared_error: 0.0142\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0985 - mean_squared_error: 0.0163\n",
      "Epoch 9: val_loss did not improve from 0.09261\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0985 - mean_squared_error: 0.0163 - val_loss: 0.0991 - val_mean_squared_error: 0.0165\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0977 - mean_squared_error: 0.0159\n",
      "Epoch 10: val_loss did not improve from 0.09261\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.0976 - mean_squared_error: 0.0159 - val_loss: 0.1074 - val_mean_squared_error: 0.0197\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0946 - mean_squared_error: 0.0150\n",
      "Epoch 11: val_loss improved from 0.09261 to 0.08896, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt32_stride5_size15_pool5_do0.1_tra5_head4_kdim64_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0946 - mean_squared_error: 0.0150 - val_loss: 0.0890 - val_mean_squared_error: 0.0130\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0930 - mean_squared_error: 0.0145\n",
      "Epoch 12: val_loss did not improve from 0.08896\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0930 - mean_squared_error: 0.0145 - val_loss: 0.0928 - val_mean_squared_error: 0.0147\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.0134\n",
      "Epoch 13: val_loss did not improve from 0.08896\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.0893 - mean_squared_error: 0.0134 - val_loss: 0.0898 - val_mean_squared_error: 0.0136\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0868 - mean_squared_error: 0.0128\n",
      "Epoch 14: val_loss did not improve from 0.08896\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.0868 - mean_squared_error: 0.0128 - val_loss: 0.0935 - val_mean_squared_error: 0.0140\n",
      "14/14 [==============================] - 1s 26ms/step\n",
      " ###3 fold : val mae 0.09###\n",
      "mae9.03+-0.33\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1870 - mean_squared_error: 0.0577\n",
      "Epoch 1: val_loss improved from inf to 0.15639, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 20s 46ms/step - loss: 0.1870 - mean_squared_error: 0.0577 - val_loss: 0.1564 - val_mean_squared_error: 0.0342\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1279 - mean_squared_error: 0.0267\n",
      "Epoch 2: val_loss improved from 0.15639 to 0.10202, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.1279 - mean_squared_error: 0.0267 - val_loss: 0.1020 - val_mean_squared_error: 0.0164\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1158 - mean_squared_error: 0.0224\n",
      "Epoch 3: val_loss did not improve from 0.10202\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1158 - mean_squared_error: 0.0224 - val_loss: 0.1023 - val_mean_squared_error: 0.0162\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0204\n",
      "Epoch 4: val_loss did not improve from 0.10202\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1119 - mean_squared_error: 0.0204 - val_loss: 0.1032 - val_mean_squared_error: 0.0177\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0187\n",
      "Epoch 5: val_loss improved from 0.10202 to 0.09955, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1071 - mean_squared_error: 0.0187 - val_loss: 0.0995 - val_mean_squared_error: 0.0156\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1055 - mean_squared_error: 0.0184\n",
      "Epoch 6: val_loss did not improve from 0.09955\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1055 - mean_squared_error: 0.0184 - val_loss: 0.1036 - val_mean_squared_error: 0.0163\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.0177\n",
      "Epoch 7: val_loss improved from 0.09955 to 0.09821, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1038 - mean_squared_error: 0.0177 - val_loss: 0.0982 - val_mean_squared_error: 0.0156\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0176\n",
      "Epoch 8: val_loss did not improve from 0.09821\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1037 - mean_squared_error: 0.0176 - val_loss: 0.1015 - val_mean_squared_error: 0.0159\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1024 - mean_squared_error: 0.0173\n",
      "Epoch 9: val_loss improved from 0.09821 to 0.09810, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1024 - mean_squared_error: 0.0173 - val_loss: 0.0981 - val_mean_squared_error: 0.0157\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1017 - mean_squared_error: 0.0170\n",
      "Epoch 10: val_loss did not improve from 0.09810\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1017 - mean_squared_error: 0.0170 - val_loss: 0.0985 - val_mean_squared_error: 0.0158\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0168\n",
      "Epoch 11: val_loss did not improve from 0.09810\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1013 - mean_squared_error: 0.0168 - val_loss: 0.1006 - val_mean_squared_error: 0.0157\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.0167\n",
      "Epoch 12: val_loss did not improve from 0.09810\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1010 - mean_squared_error: 0.0167 - val_loss: 0.1009 - val_mean_squared_error: 0.0170\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1723 - mean_squared_error: 0.0507\n",
      "Epoch 1: val_loss improved from inf to 0.10994, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 9s 47ms/step - loss: 0.1723 - mean_squared_error: 0.0507 - val_loss: 0.1099 - val_mean_squared_error: 0.0193\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1171 - mean_squared_error: 0.0226\n",
      "Epoch 2: val_loss improved from 0.10994 to 0.10870, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1171 - mean_squared_error: 0.0226 - val_loss: 0.1087 - val_mean_squared_error: 0.0183\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0203\n",
      "Epoch 3: val_loss did not improve from 0.10870\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1110 - mean_squared_error: 0.0203 - val_loss: 0.1162 - val_mean_squared_error: 0.0202\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0184\n",
      "Epoch 4: val_loss improved from 0.10870 to 0.09611, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1056 - mean_squared_error: 0.0184 - val_loss: 0.0961 - val_mean_squared_error: 0.0152\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1052 - mean_squared_error: 0.0181\n",
      "Epoch 5: val_loss did not improve from 0.09611\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1052 - mean_squared_error: 0.0181 - val_loss: 0.1074 - val_mean_squared_error: 0.0194\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0175\n",
      "Epoch 6: val_loss did not improve from 0.09611\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1033 - mean_squared_error: 0.0175 - val_loss: 0.0962 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0173\n",
      "Epoch 7: val_loss did not improve from 0.09611\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1030 - mean_squared_error: 0.0173 - val_loss: 0.0971 - val_mean_squared_error: 0.0155\n",
      "53/53 [==============================] - 1s 14ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2242 - mean_squared_error: 0.0862\n",
      "Epoch 1: val_loss improved from inf to 0.10009, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 10s 51ms/step - loss: 0.2238 - mean_squared_error: 0.0859 - val_loss: 0.1001 - val_mean_squared_error: 0.0165\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1195 - mean_squared_error: 0.0233\n",
      "Epoch 2: val_loss improved from 0.10009 to 0.09803, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.1195 - mean_squared_error: 0.0233 - val_loss: 0.0980 - val_mean_squared_error: 0.0163\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1110 - mean_squared_error: 0.0202\n",
      "Epoch 3: val_loss did not improve from 0.09803\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1110 - mean_squared_error: 0.0202 - val_loss: 0.0988 - val_mean_squared_error: 0.0167\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1065 - mean_squared_error: 0.0187\n",
      "Epoch 4: val_loss improved from 0.09803 to 0.09533, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1065 - mean_squared_error: 0.0187 - val_loss: 0.0953 - val_mean_squared_error: 0.0153\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.0178\n",
      "Epoch 5: val_loss did not improve from 0.09533\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1044 - mean_squared_error: 0.0178 - val_loss: 0.0967 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.0176\n",
      "Epoch 6: val_loss did not improve from 0.09533\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1044 - mean_squared_error: 0.0176 - val_loss: 0.0962 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0172\n",
      "Epoch 7: val_loss did not improve from 0.09533\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.1025 - mean_squared_error: 0.0172 - val_loss: 0.0957 - val_mean_squared_error: 0.0154\n",
      "53/53 [==============================] - 2s 15ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3821 - mean_squared_error: 0.1715\n",
      "Epoch 1: val_loss improved from inf to 0.37834, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 9s 45ms/step - loss: 0.3821 - mean_squared_error: 0.1715 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss improved from 0.37834 to 0.37827, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 3: val_loss improved from 0.37827 to 0.37827, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 4: val_loss improved from 0.37827 to 0.37827, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 5: val_loss improved from 0.37827 to 0.37826, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 6: val_loss improved from 0.37826 to 0.37826, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 7: val_loss improved from 0.37826 to 0.37825, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 8: val_loss improved from 0.37825 to 0.37825, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 9: val_loss improved from 0.37825 to 0.37824, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3782 - val_mean_squared_error: 0.1692\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 10: val_loss improved from 0.37824 to 0.37822, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3782 - val_mean_squared_error: 0.1692\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 11: val_loss improved from 0.37822 to 0.37821, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt128_stride5_size9_pool4_do0.2_tra5_head2_kdim256_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3782 - val_mean_squared_error: 0.1692\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 12: val_loss did not improve from 0.37821\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3782 - val_mean_squared_error: 0.1692\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 13: val_loss did not improve from 0.37821\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3783 - val_mean_squared_error: 0.1692\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3819 - mean_squared_error: 0.1710\n",
      "Epoch 14: val_loss did not improve from 0.37821\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3819 - mean_squared_error: 0.1710 - val_loss: 0.3784 - val_mean_squared_error: 0.1693\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###3 fold : val mae 0.38###\n",
      "mae16.82+-12.32\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1742 - mean_squared_error: 0.0490\n",
      "Epoch 1: val_loss improved from inf to 0.13300, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 18s 44ms/step - loss: 0.1742 - mean_squared_error: 0.0490 - val_loss: 0.1330 - val_mean_squared_error: 0.0269\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1300 - mean_squared_error: 0.0279\n",
      "Epoch 2: val_loss did not improve from 0.13300\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1300 - mean_squared_error: 0.0279 - val_loss: 0.1499 - val_mean_squared_error: 0.0330\n",
      "Epoch 3/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1172 - mean_squared_error: 0.0229\n",
      "Epoch 3: val_loss improved from 0.13300 to 0.12705, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1172 - mean_squared_error: 0.0229 - val_loss: 0.1270 - val_mean_squared_error: 0.0238\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0191\n",
      "Epoch 4: val_loss improved from 0.12705 to 0.10115, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1073 - mean_squared_error: 0.0191 - val_loss: 0.1012 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0173\n",
      "Epoch 5: val_loss did not improve from 0.10115\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1021 - mean_squared_error: 0.0173 - val_loss: 0.1189 - val_mean_squared_error: 0.0213\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0955 - mean_squared_error: 0.0151\n",
      "Epoch 6: val_loss improved from 0.10115 to 0.09420, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0955 - mean_squared_error: 0.0151 - val_loss: 0.0942 - val_mean_squared_error: 0.0140\n",
      "Epoch 7/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.0149\n",
      "Epoch 7: val_loss improved from 0.09420 to 0.08668, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0948 - mean_squared_error: 0.0148 - val_loss: 0.0867 - val_mean_squared_error: 0.0124\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0899 - mean_squared_error: 0.0135\n",
      "Epoch 8: val_loss did not improve from 0.08668\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0899 - mean_squared_error: 0.0135 - val_loss: 0.0879 - val_mean_squared_error: 0.0125\n",
      "Epoch 9/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.0879 - mean_squared_error: 0.0128\n",
      "Epoch 9: val_loss did not improve from 0.08668\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.0881 - mean_squared_error: 0.0129 - val_loss: 0.1029 - val_mean_squared_error: 0.0166\n",
      "Epoch 10/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.0126\n",
      "Epoch 10: val_loss did not improve from 0.08668\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.0871 - mean_squared_error: 0.0126 - val_loss: 0.1026 - val_mean_squared_error: 0.0156\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1664 - mean_squared_error: 0.0459\n",
      "Epoch 1: val_loss improved from inf to 0.17411, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 9s 42ms/step - loss: 0.1664 - mean_squared_error: 0.0459 - val_loss: 0.1741 - val_mean_squared_error: 0.0416\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1255 - mean_squared_error: 0.0257\n",
      "Epoch 2: val_loss improved from 0.17411 to 0.11154, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1255 - mean_squared_error: 0.0257 - val_loss: 0.1115 - val_mean_squared_error: 0.0195\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1139 - mean_squared_error: 0.0213\n",
      "Epoch 3: val_loss improved from 0.11154 to 0.11128, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1139 - mean_squared_error: 0.0213 - val_loss: 0.1113 - val_mean_squared_error: 0.0189\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0195\n",
      "Epoch 4: val_loss did not improve from 0.11128\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1086 - mean_squared_error: 0.0195 - val_loss: 0.1220 - val_mean_squared_error: 0.0220\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1056 - mean_squared_error: 0.0184\n",
      "Epoch 5: val_loss did not improve from 0.11128\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1056 - mean_squared_error: 0.0184 - val_loss: 0.1303 - val_mean_squared_error: 0.0247\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0179\n",
      "Epoch 6: val_loss did not improve from 0.11128\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1040 - mean_squared_error: 0.0179 - val_loss: 0.1290 - val_mean_squared_error: 0.0246\n",
      "53/53 [==============================] - 1s 11ms/step\n",
      " ###1 fold : val mae 0.11###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1626 - mean_squared_error: 0.0436\n",
      "Epoch 1: val_loss improved from inf to 0.10109, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 40ms/step - loss: 0.1626 - mean_squared_error: 0.0436 - val_loss: 0.1011 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1228 - mean_squared_error: 0.0247\n",
      "Epoch 2: val_loss did not improve from 0.10109\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1228 - mean_squared_error: 0.0247 - val_loss: 0.1312 - val_mean_squared_error: 0.0251\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0211\n",
      "Epoch 3: val_loss did not improve from 0.10109\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1134 - mean_squared_error: 0.0211 - val_loss: 0.1273 - val_mean_squared_error: 0.0235\n",
      "Epoch 4/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1089 - mean_squared_error: 0.0192\n",
      "Epoch 4: val_loss did not improve from 0.10109\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1089 - mean_squared_error: 0.0192 - val_loss: 0.1270 - val_mean_squared_error: 0.0235\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1642 - mean_squared_error: 0.0443\n",
      "Epoch 1: val_loss improved from inf to 0.21600, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 38ms/step - loss: 0.1637 - mean_squared_error: 0.0441 - val_loss: 0.2160 - val_mean_squared_error: 0.0617\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1241 - mean_squared_error: 0.0256\n",
      "Epoch 2: val_loss improved from 0.21600 to 0.15191, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1241 - mean_squared_error: 0.0256 - val_loss: 0.1519 - val_mean_squared_error: 0.0329\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.0216\n",
      "Epoch 3: val_loss improved from 0.15191 to 0.12547, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1137 - mean_squared_error: 0.0216 - val_loss: 0.1255 - val_mean_squared_error: 0.0227\n",
      "Epoch 4/100\n",
      "155/157 [============================>.] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss improved from 0.12547 to 0.12371, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1069 - mean_squared_error: 0.0189 - val_loss: 0.1237 - val_mean_squared_error: 0.0226\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1054 - mean_squared_error: 0.0183\n",
      "Epoch 5: val_loss improved from 0.12371 to 0.11450, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1054 - mean_squared_error: 0.0183 - val_loss: 0.1145 - val_mean_squared_error: 0.0195\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.0176\n",
      "Epoch 6: val_loss improved from 0.11450 to 0.11194, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size15_pool4_do0.2_tra4_head2_kdim64_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1035 - mean_squared_error: 0.0176 - val_loss: 0.1119 - val_mean_squared_error: 0.0188\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1025 - mean_squared_error: 0.0171\n",
      "Epoch 7: val_loss did not improve from 0.11194\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1025 - mean_squared_error: 0.0171 - val_loss: 0.1196 - val_mean_squared_error: 0.0210\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.0169\n",
      "Epoch 8: val_loss did not improve from 0.11194\n",
      "157/157 [==============================] - 5s 32ms/step - loss: 0.1017 - mean_squared_error: 0.0169 - val_loss: 0.1180 - val_mean_squared_error: 0.0203\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.0169\n",
      "Epoch 9: val_loss did not improve from 0.11194\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.1016 - mean_squared_error: 0.0169 - val_loss: 0.1136 - val_mean_squared_error: 0.0191\n",
      "53/53 [==============================] - 2s 12ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae10.39+-1.10\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1738 - mean_squared_error: 0.0498\n",
      "Epoch 1: val_loss improved from inf to 0.10430, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 19s 43ms/step - loss: 0.1738 - mean_squared_error: 0.0498 - val_loss: 0.1043 - val_mean_squared_error: 0.0172\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1246 - mean_squared_error: 0.0259\n",
      "Epoch 2: val_loss did not improve from 0.10430\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1246 - mean_squared_error: 0.0259 - val_loss: 0.1315 - val_mean_squared_error: 0.0278\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1155 - mean_squared_error: 0.0222\n",
      "Epoch 3: val_loss improved from 0.10430 to 0.09863, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1155 - mean_squared_error: 0.0222 - val_loss: 0.0986 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1102 - mean_squared_error: 0.0200\n",
      "Epoch 4: val_loss did not improve from 0.09863\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1102 - mean_squared_error: 0.0200 - val_loss: 0.0987 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0185\n",
      "Epoch 5: val_loss improved from 0.09863 to 0.09840, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1060 - mean_squared_error: 0.0185 - val_loss: 0.0984 - val_mean_squared_error: 0.0154\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1042 - mean_squared_error: 0.0180\n",
      "Epoch 6: val_loss did not improve from 0.09840\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1042 - mean_squared_error: 0.0180 - val_loss: 0.1010 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0173\n",
      "Epoch 7: val_loss did not improve from 0.09840\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1029 - mean_squared_error: 0.0173 - val_loss: 0.1048 - val_mean_squared_error: 0.0167\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1023 - mean_squared_error: 0.0173\n",
      "Epoch 8: val_loss improved from 0.09840 to 0.09826, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1023 - mean_squared_error: 0.0173 - val_loss: 0.0983 - val_mean_squared_error: 0.0153\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.0170\n",
      "Epoch 9: val_loss did not improve from 0.09826\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1018 - mean_squared_error: 0.0170 - val_loss: 0.0984 - val_mean_squared_error: 0.0157\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0168\n",
      "Epoch 10: val_loss did not improve from 0.09826\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1014 - mean_squared_error: 0.0168 - val_loss: 0.1064 - val_mean_squared_error: 0.0171\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0169\n",
      "Epoch 11: val_loss did not improve from 0.09826\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1015 - mean_squared_error: 0.0169 - val_loss: 0.1121 - val_mean_squared_error: 0.0187\n",
      "53/53 [==============================] - 2s 13ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3816 - mean_squared_error: 0.1715\n",
      "Epoch 1: val_loss improved from inf to 0.38082, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.3816 - mean_squared_error: 0.1715 - val_loss: 0.3808 - val_mean_squared_error: 0.1696\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3473 - mean_squared_error: 0.1508\n",
      "Epoch 2: val_loss did not improve from 0.38082\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.3473 - mean_squared_error: 0.1508 - val_loss: 0.4951 - val_mean_squared_error: 0.2663\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1355 - mean_squared_error: 0.0302\n",
      "Epoch 3: val_loss improved from 0.38082 to 0.10542, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1355 - mean_squared_error: 0.0302 - val_loss: 0.1054 - val_mean_squared_error: 0.0184\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1142 - mean_squared_error: 0.0216\n",
      "Epoch 4: val_loss improved from 0.10542 to 0.09698, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1142 - mean_squared_error: 0.0216 - val_loss: 0.0970 - val_mean_squared_error: 0.0153\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0188\n",
      "Epoch 5: val_loss did not improve from 0.09698\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1071 - mean_squared_error: 0.0188 - val_loss: 0.1137 - val_mean_squared_error: 0.0197\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1048 - mean_squared_error: 0.0179\n",
      "Epoch 6: val_loss improved from 0.09698 to 0.09683, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1048 - mean_squared_error: 0.0179 - val_loss: 0.0968 - val_mean_squared_error: 0.0151\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0174\n",
      "Epoch 7: val_loss improved from 0.09683 to 0.09613, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1026 - mean_squared_error: 0.0174 - val_loss: 0.0961 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0172\n",
      "Epoch 8: val_loss did not improve from 0.09613\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1027 - mean_squared_error: 0.0172 - val_loss: 0.0995 - val_mean_squared_error: 0.0157\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0171\n",
      "Epoch 9: val_loss did not improve from 0.09613\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1022 - mean_squared_error: 0.0171 - val_loss: 0.1039 - val_mean_squared_error: 0.0168\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0171\n",
      "Epoch 10: val_loss did not improve from 0.09613\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1020 - mean_squared_error: 0.0171 - val_loss: 0.0969 - val_mean_squared_error: 0.0151\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1860 - mean_squared_error: 0.0580\n",
      "Epoch 1: val_loss improved from inf to 0.15060, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 43ms/step - loss: 0.1860 - mean_squared_error: 0.0580 - val_loss: 0.1506 - val_mean_squared_error: 0.0316\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1198 - mean_squared_error: 0.0235\n",
      "Epoch 2: val_loss improved from 0.15060 to 0.11444, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1198 - mean_squared_error: 0.0235 - val_loss: 0.1144 - val_mean_squared_error: 0.0197\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0197\n",
      "Epoch 3: val_loss improved from 0.11444 to 0.11274, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1099 - mean_squared_error: 0.0197 - val_loss: 0.1127 - val_mean_squared_error: 0.0188\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0186\n",
      "Epoch 4: val_loss improved from 0.11274 to 0.10310, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1066 - mean_squared_error: 0.0186 - val_loss: 0.1031 - val_mean_squared_error: 0.0164\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0176\n",
      "Epoch 5: val_loss did not improve from 0.10310\n",
      "157/157 [==============================] - 5s 35ms/step - loss: 0.1040 - mean_squared_error: 0.0176 - val_loss: 0.1119 - val_mean_squared_error: 0.0187\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0175\n",
      "Epoch 6: val_loss improved from 0.10310 to 0.09742, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1031 - mean_squared_error: 0.0175 - val_loss: 0.0974 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0173\n",
      "Epoch 7: val_loss improved from 0.09742 to 0.09649, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1032 - mean_squared_error: 0.0173 - val_loss: 0.0965 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1020 - mean_squared_error: 0.0171\n",
      "Epoch 8: val_loss improved from 0.09649 to 0.09559, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1020 - mean_squared_error: 0.0171 - val_loss: 0.0956 - val_mean_squared_error: 0.0153\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1018 - mean_squared_error: 0.0169\n",
      "Epoch 9: val_loss did not improve from 0.09559\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1018 - mean_squared_error: 0.0169 - val_loss: 0.0969 - val_mean_squared_error: 0.0152\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0169\n",
      "Epoch 10: val_loss did not improve from 0.09559\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1022 - mean_squared_error: 0.0169 - val_loss: 0.1006 - val_mean_squared_error: 0.0157\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0168\n",
      "Epoch 11: val_loss did not improve from 0.09559\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1013 - mean_squared_error: 0.0168 - val_loss: 0.0971 - val_mean_squared_error: 0.0152\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2764 - mean_squared_error: 0.1087\n",
      "Epoch 1: val_loss improved from inf to 0.31737, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 42ms/step - loss: 0.2764 - mean_squared_error: 0.1087 - val_loss: 0.3174 - val_mean_squared_error: 0.1176\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1249 - mean_squared_error: 0.0258\n",
      "Epoch 2: val_loss improved from 0.31737 to 0.11017, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1249 - mean_squared_error: 0.0258 - val_loss: 0.1102 - val_mean_squared_error: 0.0187\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1127 - mean_squared_error: 0.0210\n",
      "Epoch 3: val_loss improved from 0.11017 to 0.10764, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1127 - mean_squared_error: 0.0210 - val_loss: 0.1076 - val_mean_squared_error: 0.0176\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0188\n",
      "Epoch 4: val_loss improved from 0.10764 to 0.10068, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1070 - mean_squared_error: 0.0188 - val_loss: 0.1007 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1051 - mean_squared_error: 0.0182\n",
      "Epoch 5: val_loss improved from 0.10068 to 0.10035, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1051 - mean_squared_error: 0.0182 - val_loss: 0.1003 - val_mean_squared_error: 0.0171\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.0175\n",
      "Epoch 6: val_loss did not improve from 0.10035\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.1033 - mean_squared_error: 0.0175 - val_loss: 0.1032 - val_mean_squared_error: 0.0164\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0172\n",
      "Epoch 7: val_loss improved from 0.10035 to 0.09813, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1026 - mean_squared_error: 0.0172 - val_loss: 0.0981 - val_mean_squared_error: 0.0156\n",
      "Epoch 8/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0169\n",
      "Epoch 8: val_loss improved from 0.09813 to 0.09776, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride4_size9_pool4_do0.2_tra5_head2_kdim128_fnn32/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1014 - mean_squared_error: 0.0169 - val_loss: 0.0978 - val_mean_squared_error: 0.0154\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0168\n",
      "Epoch 9: val_loss did not improve from 0.09776\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1015 - mean_squared_error: 0.0168 - val_loss: 0.0990 - val_mean_squared_error: 0.0156\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1004 - mean_squared_error: 0.0166\n",
      "Epoch 10: val_loss did not improve from 0.09776\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1004 - mean_squared_error: 0.0166 - val_loss: 0.1000 - val_mean_squared_error: 0.0157\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1013 - mean_squared_error: 0.0167\n",
      "Epoch 11: val_loss did not improve from 0.09776\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1013 - mean_squared_error: 0.0167 - val_loss: 0.1043 - val_mean_squared_error: 0.0167\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.73+-0.05\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1932 - mean_squared_error: 0.0591\n",
      "Epoch 1: val_loss improved from inf to 0.10891, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 13s 77ms/step - loss: 0.1932 - mean_squared_error: 0.0591 - val_loss: 0.1089 - val_mean_squared_error: 0.0200\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1517 - mean_squared_error: 0.0373\n",
      "Epoch 2: val_loss improved from 0.10891 to 0.09914, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1518 - mean_squared_error: 0.0374 - val_loss: 0.0991 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1374 - mean_squared_error: 0.0314\n",
      "Epoch 3: val_loss improved from 0.09914 to 0.09850, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1374 - mean_squared_error: 0.0314 - val_loss: 0.0985 - val_mean_squared_error: 0.0160\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1279 - mean_squared_error: 0.0271\n",
      "Epoch 4: val_loss improved from 0.09850 to 0.09789, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1278 - mean_squared_error: 0.0271 - val_loss: 0.0979 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1219 - mean_squared_error: 0.0249\n",
      "Epoch 5: val_loss did not improve from 0.09789\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1219 - mean_squared_error: 0.0249 - val_loss: 0.0986 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1192 - mean_squared_error: 0.0235\n",
      "Epoch 6: val_loss improved from 0.09789 to 0.09766, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1192 - mean_squared_error: 0.0235 - val_loss: 0.0977 - val_mean_squared_error: 0.0153\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1156 - mean_squared_error: 0.0222\n",
      "Epoch 7: val_loss improved from 0.09766 to 0.09707, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1156 - mean_squared_error: 0.0222 - val_loss: 0.0971 - val_mean_squared_error: 0.0152\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1122 - mean_squared_error: 0.0209\n",
      "Epoch 8: val_loss did not improve from 0.09707\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1121 - mean_squared_error: 0.0209 - val_loss: 0.0972 - val_mean_squared_error: 0.0153\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0199\n",
      "Epoch 9: val_loss improved from 0.09707 to 0.09664, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1099 - mean_squared_error: 0.0199 - val_loss: 0.0966 - val_mean_squared_error: 0.0152\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0187\n",
      "Epoch 10: val_loss improved from 0.09664 to 0.09443, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1060 - mean_squared_error: 0.0187 - val_loss: 0.0944 - val_mean_squared_error: 0.0144\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1019 - mean_squared_error: 0.0173\n",
      "Epoch 11: val_loss improved from 0.09443 to 0.09182, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1019 - mean_squared_error: 0.0173 - val_loss: 0.0918 - val_mean_squared_error: 0.0138\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0165\n",
      "Epoch 12: val_loss did not improve from 0.09182\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0996 - mean_squared_error: 0.0165 - val_loss: 0.0942 - val_mean_squared_error: 0.0149\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0965 - mean_squared_error: 0.0155\n",
      "Epoch 13: val_loss did not improve from 0.09182\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.0965 - mean_squared_error: 0.0155 - val_loss: 0.0986 - val_mean_squared_error: 0.0164\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0947 - mean_squared_error: 0.0150\n",
      "Epoch 14: val_loss did not improve from 0.09182\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0948 - mean_squared_error: 0.0150 - val_loss: 0.0969 - val_mean_squared_error: 0.0158\n",
      "14/14 [==============================] - 1s 22ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1885 - mean_squared_error: 0.0574\n",
      "Epoch 1: val_loss improved from inf to 0.10015, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 4s 65ms/step - loss: 0.1884 - mean_squared_error: 0.0573 - val_loss: 0.1001 - val_mean_squared_error: 0.0168\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1435 - mean_squared_error: 0.0342\n",
      "Epoch 2: val_loss did not improve from 0.10015\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1436 - mean_squared_error: 0.0342 - val_loss: 0.1005 - val_mean_squared_error: 0.0168\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1306 - mean_squared_error: 0.0283\n",
      "Epoch 3: val_loss improved from 0.10015 to 0.09636, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1305 - mean_squared_error: 0.0283 - val_loss: 0.0964 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1233 - mean_squared_error: 0.0251\n",
      "Epoch 4: val_loss did not improve from 0.09636\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1234 - mean_squared_error: 0.0252 - val_loss: 0.0971 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1194 - mean_squared_error: 0.0235\n",
      "Epoch 5: val_loss did not improve from 0.09636\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1196 - mean_squared_error: 0.0235 - val_loss: 0.0966 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1152 - mean_squared_error: 0.0221\n",
      "Epoch 6: val_loss did not improve from 0.09636\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1152 - mean_squared_error: 0.0220 - val_loss: 0.0972 - val_mean_squared_error: 0.0157\n",
      "14/14 [==============================] - 1s 21ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1896 - mean_squared_error: 0.0581\n",
      "Epoch 1: val_loss improved from inf to 0.10252, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 4s 69ms/step - loss: 0.1893 - mean_squared_error: 0.0580 - val_loss: 0.1025 - val_mean_squared_error: 0.0179\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1453 - mean_squared_error: 0.0344\n",
      "Epoch 2: val_loss improved from 0.10252 to 0.09808, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1454 - mean_squared_error: 0.0344 - val_loss: 0.0981 - val_mean_squared_error: 0.0164\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1324 - mean_squared_error: 0.0287\n",
      "Epoch 3: val_loss improved from 0.09808 to 0.09641, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1324 - mean_squared_error: 0.0287 - val_loss: 0.0964 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1247 - mean_squared_error: 0.0255\n",
      "Epoch 4: val_loss did not improve from 0.09641\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1248 - mean_squared_error: 0.0255 - val_loss: 0.0972 - val_mean_squared_error: 0.0161\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1200 - mean_squared_error: 0.0238\n",
      "Epoch 5: val_loss improved from 0.09641 to 0.09581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1199 - mean_squared_error: 0.0237 - val_loss: 0.0958 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0215\n",
      "Epoch 6: val_loss improved from 0.09581 to 0.09548, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1145 - mean_squared_error: 0.0215 - val_loss: 0.0955 - val_mean_squared_error: 0.0151\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1120 - mean_squared_error: 0.0206\n",
      "Epoch 7: val_loss improved from 0.09548 to 0.09493, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1119 - mean_squared_error: 0.0206 - val_loss: 0.0949 - val_mean_squared_error: 0.0151\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1101 - mean_squared_error: 0.0197\n",
      "Epoch 8: val_loss did not improve from 0.09493\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1100 - mean_squared_error: 0.0197 - val_loss: 0.0953 - val_mean_squared_error: 0.0151\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0191\n",
      "Epoch 9: val_loss did not improve from 0.09493\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1076 - mean_squared_error: 0.0191 - val_loss: 0.0950 - val_mean_squared_error: 0.0148\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0181\n",
      "Epoch 10: val_loss improved from 0.09493 to 0.09363, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1050 - mean_squared_error: 0.0181 - val_loss: 0.0936 - val_mean_squared_error: 0.0145\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.0171\n",
      "Epoch 11: val_loss improved from 0.09363 to 0.09180, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1021 - mean_squared_error: 0.0171 - val_loss: 0.0918 - val_mean_squared_error: 0.0142\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0991 - mean_squared_error: 0.0161\n",
      "Epoch 12: val_loss improved from 0.09180 to 0.09170, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0991 - mean_squared_error: 0.0161 - val_loss: 0.0917 - val_mean_squared_error: 0.0144\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0984 - mean_squared_error: 0.0160\n",
      "Epoch 13: val_loss did not improve from 0.09170\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0984 - mean_squared_error: 0.0160 - val_loss: 0.0922 - val_mean_squared_error: 0.0145\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0949 - mean_squared_error: 0.0148\n",
      "Epoch 14: val_loss did not improve from 0.09170\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0949 - mean_squared_error: 0.0148 - val_loss: 0.0929 - val_mean_squared_error: 0.0151\n",
      "Epoch 15/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0929 - mean_squared_error: 0.0144\n",
      "Epoch 15: val_loss did not improve from 0.09170\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0930 - mean_squared_error: 0.0144 - val_loss: 0.0936 - val_mean_squared_error: 0.0154\n",
      "14/14 [==============================] - 1s 22ms/step\n",
      " ###2 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1889 - mean_squared_error: 0.0573\n",
      "Epoch 1: val_loss improved from inf to 0.10337, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 4s 68ms/step - loss: 0.1887 - mean_squared_error: 0.0572 - val_loss: 0.1034 - val_mean_squared_error: 0.0178\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1434 - mean_squared_error: 0.0336\n",
      "Epoch 2: val_loss improved from 0.10337 to 0.09934, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1434 - mean_squared_error: 0.0336 - val_loss: 0.0993 - val_mean_squared_error: 0.0162\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1298 - mean_squared_error: 0.0278\n",
      "Epoch 3: val_loss improved from 0.09934 to 0.09856, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1298 - mean_squared_error: 0.0278 - val_loss: 0.0986 - val_mean_squared_error: 0.0163\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1227 - mean_squared_error: 0.0252\n",
      "Epoch 4: val_loss did not improve from 0.09856\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1226 - mean_squared_error: 0.0252 - val_loss: 0.0986 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1177 - mean_squared_error: 0.0229\n",
      "Epoch 5: val_loss improved from 0.09856 to 0.09778, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1177 - mean_squared_error: 0.0229 - val_loss: 0.0978 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1135 - mean_squared_error: 0.0214\n",
      "Epoch 6: val_loss improved from 0.09778 to 0.09695, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1136 - mean_squared_error: 0.0214 - val_loss: 0.0969 - val_mean_squared_error: 0.0153\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0200\n",
      "Epoch 7: val_loss improved from 0.09695 to 0.09685, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1105 - mean_squared_error: 0.0201 - val_loss: 0.0969 - val_mean_squared_error: 0.0157\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1063 - mean_squared_error: 0.0188\n",
      "Epoch 8: val_loss improved from 0.09685 to 0.09590, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1064 - mean_squared_error: 0.0189 - val_loss: 0.0959 - val_mean_squared_error: 0.0155\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0176\n",
      "Epoch 9: val_loss improved from 0.09590 to 0.09312, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1031 - mean_squared_error: 0.0176 - val_loss: 0.0931 - val_mean_squared_error: 0.0145\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0990 - mean_squared_error: 0.0163\n",
      "Epoch 10: val_loss improved from 0.09312 to 0.09267, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.0990 - mean_squared_error: 0.0163 - val_loss: 0.0927 - val_mean_squared_error: 0.0138\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.0154\n",
      "Epoch 11: val_loss improved from 0.09267 to 0.08963, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0959 - mean_squared_error: 0.0154 - val_loss: 0.0896 - val_mean_squared_error: 0.0134\n",
      "Epoch 12/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.0146\n",
      "Epoch 12: val_loss did not improve from 0.08963\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0936 - mean_squared_error: 0.0146 - val_loss: 0.0906 - val_mean_squared_error: 0.0134\n",
      "Epoch 13/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0923 - mean_squared_error: 0.0142\n",
      "Epoch 13: val_loss did not improve from 0.08963\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0923 - mean_squared_error: 0.0142 - val_loss: 0.0939 - val_mean_squared_error: 0.0141\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0887 - mean_squared_error: 0.0133\n",
      "Epoch 14: val_loss improved from 0.08963 to 0.08800, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn3_filt16_stride5_size9_pool4_do0.2_tra3_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.0886 - mean_squared_error: 0.0132 - val_loss: 0.0880 - val_mean_squared_error: 0.0129\n",
      "Epoch 15/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0888 - mean_squared_error: 0.0133\n",
      "Epoch 15: val_loss did not improve from 0.08800\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.0888 - mean_squared_error: 0.0133 - val_loss: 0.0910 - val_mean_squared_error: 0.0141\n",
      "Epoch 16/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0875 - mean_squared_error: 0.0129\n",
      "Epoch 16: val_loss did not improve from 0.08800\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0876 - mean_squared_error: 0.0129 - val_loss: 0.0883 - val_mean_squared_error: 0.0128\n",
      "Epoch 17/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0864 - mean_squared_error: 0.0125\n",
      "Epoch 17: val_loss did not improve from 0.08800\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0864 - mean_squared_error: 0.0125 - val_loss: 0.0882 - val_mean_squared_error: 0.0129\n",
      "14/14 [==============================] - 1s 21ms/step\n",
      " ###3 fold : val mae 0.09###\n",
      "mae9.22+-0.36\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2041 - mean_squared_error: 0.0658\n",
      "Epoch 1: val_loss improved from inf to 0.11010, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 18s 90ms/step - loss: 0.2041 - mean_squared_error: 0.0658 - val_loss: 0.1101 - val_mean_squared_error: 0.0205\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1514 - mean_squared_error: 0.0374\n",
      "Epoch 2: val_loss improved from 0.11010 to 0.09912, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1514 - mean_squared_error: 0.0374 - val_loss: 0.0991 - val_mean_squared_error: 0.0163\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1375 - mean_squared_error: 0.0312\n",
      "Epoch 3: val_loss did not improve from 0.09912\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1375 - mean_squared_error: 0.0312 - val_loss: 0.0993 - val_mean_squared_error: 0.0163\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1296 - mean_squared_error: 0.0279\n",
      "Epoch 4: val_loss improved from 0.09912 to 0.09791, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1296 - mean_squared_error: 0.0279 - val_loss: 0.0979 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1224 - mean_squared_error: 0.0248\n",
      "Epoch 5: val_loss improved from 0.09791 to 0.09692, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1224 - mean_squared_error: 0.0248 - val_loss: 0.0969 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1174 - mean_squared_error: 0.0226\n",
      "Epoch 6: val_loss improved from 0.09692 to 0.09558, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_0.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1174 - mean_squared_error: 0.0226 - val_loss: 0.0956 - val_mean_squared_error: 0.0152\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1122 - mean_squared_error: 0.0209\n",
      "Epoch 7: val_loss did not improve from 0.09558\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1122 - mean_squared_error: 0.0209 - val_loss: 0.0998 - val_mean_squared_error: 0.0167\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.0190\n",
      "Epoch 8: val_loss did not improve from 0.09558\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1063 - mean_squared_error: 0.0189 - val_loss: 0.0962 - val_mean_squared_error: 0.0155\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1029 - mean_squared_error: 0.0176\n",
      "Epoch 9: val_loss did not improve from 0.09558\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1029 - mean_squared_error: 0.0177 - val_loss: 0.0975 - val_mean_squared_error: 0.0160\n",
      "14/14 [==============================] - 1s 25ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.2012 - mean_squared_error: 0.0647\n",
      "Epoch 1: val_loss improved from inf to 0.10742, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 5s 77ms/step - loss: 0.2011 - mean_squared_error: 0.0646 - val_loss: 0.1074 - val_mean_squared_error: 0.0200\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1485 - mean_squared_error: 0.0360\n",
      "Epoch 2: val_loss improved from 0.10742 to 0.09847, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1485 - mean_squared_error: 0.0360 - val_loss: 0.0985 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1332 - mean_squared_error: 0.0292\n",
      "Epoch 3: val_loss improved from 0.09847 to 0.09764, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1332 - mean_squared_error: 0.0292 - val_loss: 0.0976 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1256 - mean_squared_error: 0.0261\n",
      "Epoch 4: val_loss improved from 0.09764 to 0.09665, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1256 - mean_squared_error: 0.0261 - val_loss: 0.0966 - val_mean_squared_error: 0.0154\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1209 - mean_squared_error: 0.0241\n",
      "Epoch 5: val_loss improved from 0.09665 to 0.09593, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1208 - mean_squared_error: 0.0241 - val_loss: 0.0959 - val_mean_squared_error: 0.0152\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1160 - mean_squared_error: 0.0223\n",
      "Epoch 6: val_loss improved from 0.09593 to 0.09505, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1160 - mean_squared_error: 0.0223 - val_loss: 0.0951 - val_mean_squared_error: 0.0150\n",
      "Epoch 7/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.0207\n",
      "Epoch 7: val_loss improved from 0.09505 to 0.09376, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1113 - mean_squared_error: 0.0207 - val_loss: 0.0938 - val_mean_squared_error: 0.0144\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0192\n",
      "Epoch 8: val_loss improved from 0.09376 to 0.09309, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1079 - mean_squared_error: 0.0192 - val_loss: 0.0931 - val_mean_squared_error: 0.0143\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1037 - mean_squared_error: 0.0180\n",
      "Epoch 9: val_loss improved from 0.09309 to 0.09193, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 0.1038 - mean_squared_error: 0.0180 - val_loss: 0.0919 - val_mean_squared_error: 0.0138\n",
      "Epoch 10/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.0170\n",
      "Epoch 10: val_loss did not improve from 0.09193\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1008 - mean_squared_error: 0.0170 - val_loss: 0.0943 - val_mean_squared_error: 0.0148\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0977 - mean_squared_error: 0.0159\n",
      "Epoch 11: val_loss did not improve from 0.09193\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0977 - mean_squared_error: 0.0159 - val_loss: 0.0951 - val_mean_squared_error: 0.0143\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0945 - mean_squared_error: 0.0150\n",
      "Epoch 12: val_loss improved from 0.09193 to 0.08929, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0945 - mean_squared_error: 0.0150 - val_loss: 0.0893 - val_mean_squared_error: 0.0133\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0920 - mean_squared_error: 0.0141\n",
      "Epoch 13: val_loss improved from 0.08929 to 0.08897, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0920 - mean_squared_error: 0.0141 - val_loss: 0.0890 - val_mean_squared_error: 0.0130\n",
      "Epoch 14/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0903 - mean_squared_error: 0.0137\n",
      "Epoch 14: val_loss improved from 0.08897 to 0.08842, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0903 - mean_squared_error: 0.0137 - val_loss: 0.0884 - val_mean_squared_error: 0.0128\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0888 - mean_squared_error: 0.0133\n",
      "Epoch 15: val_loss improved from 0.08842 to 0.08823, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0888 - mean_squared_error: 0.0133 - val_loss: 0.0882 - val_mean_squared_error: 0.0129\n",
      "Epoch 16/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.0125\n",
      "Epoch 16: val_loss did not improve from 0.08823\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0858 - mean_squared_error: 0.0124 - val_loss: 0.0964 - val_mean_squared_error: 0.0149\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0863 - mean_squared_error: 0.0128\n",
      "Epoch 17: val_loss improved from 0.08823 to 0.08671, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_1.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.0863 - mean_squared_error: 0.0128 - val_loss: 0.0867 - val_mean_squared_error: 0.0124\n",
      "Epoch 18/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0844 - mean_squared_error: 0.0121\n",
      "Epoch 18: val_loss did not improve from 0.08671\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.0845 - mean_squared_error: 0.0121 - val_loss: 0.0893 - val_mean_squared_error: 0.0132\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.0120\n",
      "Epoch 19: val_loss did not improve from 0.08671\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.0838 - mean_squared_error: 0.0120 - val_loss: 0.0897 - val_mean_squared_error: 0.0135\n",
      "Epoch 20/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.0112\n",
      "Epoch 20: val_loss did not improve from 0.08671\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.0807 - mean_squared_error: 0.0112 - val_loss: 0.0907 - val_mean_squared_error: 0.0138\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###1 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1987 - mean_squared_error: 0.0636\n",
      "Epoch 1: val_loss improved from inf to 0.10119, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 6s 86ms/step - loss: 0.1987 - mean_squared_error: 0.0636 - val_loss: 0.1012 - val_mean_squared_error: 0.0180\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1409 - mean_squared_error: 0.0328\n",
      "Epoch 2: val_loss improved from 0.10119 to 0.09955, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.1409 - mean_squared_error: 0.0328 - val_loss: 0.0996 - val_mean_squared_error: 0.0170\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1298 - mean_squared_error: 0.0280\n",
      "Epoch 3: val_loss improved from 0.09955 to 0.09567, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1298 - mean_squared_error: 0.0280 - val_loss: 0.0957 - val_mean_squared_error: 0.0155\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1211 - mean_squared_error: 0.0242\n",
      "Epoch 4: val_loss did not improve from 0.09567\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.1211 - mean_squared_error: 0.0242 - val_loss: 0.0960 - val_mean_squared_error: 0.0155\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1162 - mean_squared_error: 0.0224\n",
      "Epoch 5: val_loss improved from 0.09567 to 0.09485, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_2.hdf5\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1163 - mean_squared_error: 0.0224 - val_loss: 0.0948 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0216\n",
      "Epoch 6: val_loss did not improve from 0.09485\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1145 - mean_squared_error: 0.0216 - val_loss: 0.0959 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0204\n",
      "Epoch 7: val_loss did not improve from 0.09485\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1119 - mean_squared_error: 0.0204 - val_loss: 0.0953 - val_mean_squared_error: 0.0153\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1095 - mean_squared_error: 0.0196\n",
      "Epoch 8: val_loss did not improve from 0.09485\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.1094 - mean_squared_error: 0.0196 - val_loss: 0.0953 - val_mean_squared_error: 0.0150\n",
      "14/14 [==============================] - 2s 23ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1987 - mean_squared_error: 0.0635\n",
      "Epoch 1: val_loss improved from inf to 0.10653, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 6s 93ms/step - loss: 0.1985 - mean_squared_error: 0.0634 - val_loss: 0.1065 - val_mean_squared_error: 0.0191\n",
      "Epoch 2/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1444 - mean_squared_error: 0.0345\n",
      "Epoch 2: val_loss improved from 0.10653 to 0.10001, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1444 - mean_squared_error: 0.0345 - val_loss: 0.1000 - val_mean_squared_error: 0.0166\n",
      "Epoch 3/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1288 - mean_squared_error: 0.0276\n",
      "Epoch 3: val_loss improved from 0.10001 to 0.09816, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1288 - mean_squared_error: 0.0276 - val_loss: 0.0982 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1233 - mean_squared_error: 0.0253\n",
      "Epoch 4: val_loss improved from 0.09816 to 0.09744, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1233 - mean_squared_error: 0.0253 - val_loss: 0.0974 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1156 - mean_squared_error: 0.0221\n",
      "Epoch 5: val_loss did not improve from 0.09744\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.1156 - mean_squared_error: 0.0221 - val_loss: 0.0978 - val_mean_squared_error: 0.0153\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1119 - mean_squared_error: 0.0208\n",
      "Epoch 6: val_loss improved from 0.09744 to 0.09734, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1119 - mean_squared_error: 0.0208 - val_loss: 0.0973 - val_mean_squared_error: 0.0154\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0190\n",
      "Epoch 7: val_loss improved from 0.09734 to 0.09285, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1071 - mean_squared_error: 0.0190 - val_loss: 0.0928 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.1031 - mean_squared_error: 0.0175\n",
      "Epoch 8: val_loss improved from 0.09285 to 0.09005, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch256_cnn4_filt16_stride4_size11_pool2_do0.2_tra5_head8_kdim16_fnn32/weights_3.hdf5\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1031 - mean_squared_error: 0.0175 - val_loss: 0.0901 - val_mean_squared_error: 0.0138\n",
      "Epoch 9/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.0161\n",
      "Epoch 9: val_loss did not improve from 0.09005\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0981 - mean_squared_error: 0.0161 - val_loss: 0.0952 - val_mean_squared_error: 0.0154\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0966 - mean_squared_error: 0.0156\n",
      "Epoch 10: val_loss did not improve from 0.09005\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.0966 - mean_squared_error: 0.0156 - val_loss: 0.1005 - val_mean_squared_error: 0.0174\n",
      "Epoch 11/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0953 - mean_squared_error: 0.0152\n",
      "Epoch 11: val_loss did not improve from 0.09005\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0953 - mean_squared_error: 0.0151 - val_loss: 0.1015 - val_mean_squared_error: 0.0159\n",
      "14/14 [==============================] - 1s 23ms/step\n",
      " ###3 fold : val mae 0.09###\n",
      "mae9.19+-0.43\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2616 - mean_squared_error: 0.0986\n",
      "Epoch 1: val_loss improved from inf to 0.19664, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 17s 58ms/step - loss: 0.2616 - mean_squared_error: 0.0986 - val_loss: 0.1966 - val_mean_squared_error: 0.0534\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1824 - mean_squared_error: 0.0528\n",
      "Epoch 2: val_loss did not improve from 0.19664\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1824 - mean_squared_error: 0.0528 - val_loss: 0.1991 - val_mean_squared_error: 0.0526\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1502 - mean_squared_error: 0.0370\n",
      "Epoch 3: val_loss improved from 0.19664 to 0.18318, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1502 - mean_squared_error: 0.0370 - val_loss: 0.1832 - val_mean_squared_error: 0.0448\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1325 - mean_squared_error: 0.0288\n",
      "Epoch 4: val_loss improved from 0.18318 to 0.16647, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1325 - mean_squared_error: 0.0288 - val_loss: 0.1665 - val_mean_squared_error: 0.0378\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1186 - mean_squared_error: 0.0231\n",
      "Epoch 5: val_loss improved from 0.16647 to 0.15822, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1186 - mean_squared_error: 0.0231 - val_loss: 0.1582 - val_mean_squared_error: 0.0340\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.0211\n",
      "Epoch 6: val_loss improved from 0.15822 to 0.14666, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1137 - mean_squared_error: 0.0211 - val_loss: 0.1467 - val_mean_squared_error: 0.0295\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.0196\n",
      "Epoch 7: val_loss improved from 0.14666 to 0.14584, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1093 - mean_squared_error: 0.0196 - val_loss: 0.1458 - val_mean_squared_error: 0.0295\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.0197\n",
      "Epoch 8: val_loss improved from 0.14584 to 0.13572, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1093 - mean_squared_error: 0.0197 - val_loss: 0.1357 - val_mean_squared_error: 0.0256\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.0194\n",
      "Epoch 9: val_loss did not improve from 0.13572\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1086 - mean_squared_error: 0.0194 - val_loss: 0.1414 - val_mean_squared_error: 0.0275\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1085 - mean_squared_error: 0.0194\n",
      "Epoch 10: val_loss improved from 0.13572 to 0.13465, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1085 - mean_squared_error: 0.0194 - val_loss: 0.1347 - val_mean_squared_error: 0.0251\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0192\n",
      "Epoch 11: val_loss improved from 0.13465 to 0.13265, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1082 - mean_squared_error: 0.0192 - val_loss: 0.1327 - val_mean_squared_error: 0.0246\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0190\n",
      "Epoch 12: val_loss improved from 0.13265 to 0.13262, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1075 - mean_squared_error: 0.0190 - val_loss: 0.1326 - val_mean_squared_error: 0.0246\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0189\n",
      "Epoch 13: val_loss improved from 0.13262 to 0.12913, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1070 - mean_squared_error: 0.0189 - val_loss: 0.1291 - val_mean_squared_error: 0.0233\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0193\n",
      "Epoch 14: val_loss improved from 0.12913 to 0.12111, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_0.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1079 - mean_squared_error: 0.0193 - val_loss: 0.1211 - val_mean_squared_error: 0.0209\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0189\n",
      "Epoch 15: val_loss did not improve from 0.12111\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1068 - mean_squared_error: 0.0189 - val_loss: 0.1266 - val_mean_squared_error: 0.0226\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0191\n",
      "Epoch 16: val_loss did not improve from 0.12111\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1077 - mean_squared_error: 0.0191 - val_loss: 0.1234 - val_mean_squared_error: 0.0216\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0189\n",
      "Epoch 17: val_loss did not improve from 0.12111\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1072 - mean_squared_error: 0.0189 - val_loss: 0.1251 - val_mean_squared_error: 0.0222\n",
      "27/27 [==============================] - 2s 17ms/step\n",
      " ###0 fold : val mae 0.12###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2365 - mean_squared_error: 0.0840\n",
      "Epoch 1: val_loss improved from inf to 0.18628, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 7s 64ms/step - loss: 0.2365 - mean_squared_error: 0.0840 - val_loss: 0.1863 - val_mean_squared_error: 0.0486\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1699 - mean_squared_error: 0.0464\n",
      "Epoch 2: val_loss did not improve from 0.18628\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1699 - mean_squared_error: 0.0464 - val_loss: 0.2165 - val_mean_squared_error: 0.0610\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1419 - mean_squared_error: 0.0333\n",
      "Epoch 3: val_loss improved from 0.18628 to 0.17543, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1419 - mean_squared_error: 0.0333 - val_loss: 0.1754 - val_mean_squared_error: 0.0416\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1253 - mean_squared_error: 0.0259\n",
      "Epoch 4: val_loss improved from 0.17543 to 0.15341, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1253 - mean_squared_error: 0.0259 - val_loss: 0.1534 - val_mean_squared_error: 0.0325\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1181 - mean_squared_error: 0.0228\n",
      "Epoch 5: val_loss did not improve from 0.15341\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1181 - mean_squared_error: 0.0228 - val_loss: 0.1589 - val_mean_squared_error: 0.0343\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1128 - mean_squared_error: 0.0210\n",
      "Epoch 6: val_loss improved from 0.15341 to 0.14676, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1128 - mean_squared_error: 0.0210 - val_loss: 0.1468 - val_mean_squared_error: 0.0300\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0201\n",
      "Epoch 7: val_loss improved from 0.14676 to 0.12638, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_1.hdf5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1109 - mean_squared_error: 0.0201 - val_loss: 0.1264 - val_mean_squared_error: 0.0228\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1105 - mean_squared_error: 0.0197\n",
      "Epoch 8: val_loss did not improve from 0.12638\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1105 - mean_squared_error: 0.0197 - val_loss: 0.1301 - val_mean_squared_error: 0.0241\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1097 - mean_squared_error: 0.0198\n",
      "Epoch 9: val_loss did not improve from 0.12638\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1097 - mean_squared_error: 0.0198 - val_loss: 0.1353 - val_mean_squared_error: 0.0257\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1098 - mean_squared_error: 0.0195\n",
      "Epoch 10: val_loss did not improve from 0.12638\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1098 - mean_squared_error: 0.0195 - val_loss: 0.1310 - val_mean_squared_error: 0.0243\n",
      "27/27 [==============================] - 2s 17ms/step\n",
      " ###1 fold : val mae 0.13###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2469 - mean_squared_error: 0.0902\n",
      "Epoch 1: val_loss improved from inf to 0.28337, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 7s 58ms/step - loss: 0.2469 - mean_squared_error: 0.0902 - val_loss: 0.2834 - val_mean_squared_error: 0.0975\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1704 - mean_squared_error: 0.0469\n",
      "Epoch 2: val_loss improved from 0.28337 to 0.12291, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_2.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1704 - mean_squared_error: 0.0469 - val_loss: 0.1229 - val_mean_squared_error: 0.0221\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1418 - mean_squared_error: 0.0331\n",
      "Epoch 3: val_loss did not improve from 0.12291\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1418 - mean_squared_error: 0.0331 - val_loss: 0.1313 - val_mean_squared_error: 0.0243\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1242 - mean_squared_error: 0.0252\n",
      "Epoch 4: val_loss did not improve from 0.12291\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1242 - mean_squared_error: 0.0252 - val_loss: 0.1448 - val_mean_squared_error: 0.0288\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1154 - mean_squared_error: 0.0218\n",
      "Epoch 5: val_loss did not improve from 0.12291\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1154 - mean_squared_error: 0.0218 - val_loss: 0.1484 - val_mean_squared_error: 0.0299\n",
      "27/27 [==============================] - 2s 19ms/step\n",
      " ###2 fold : val mae 0.12###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2442 - mean_squared_error: 0.0885\n",
      "Epoch 1: val_loss improved from inf to 0.17287, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 7s 59ms/step - loss: 0.2442 - mean_squared_error: 0.0885 - val_loss: 0.1729 - val_mean_squared_error: 0.0418\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1702 - mean_squared_error: 0.0461\n",
      "Epoch 2: val_loss did not improve from 0.17287\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1702 - mean_squared_error: 0.0461 - val_loss: 0.2019 - val_mean_squared_error: 0.0541\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1409 - mean_squared_error: 0.0325\n",
      "Epoch 3: val_loss improved from 0.17287 to 0.15405, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1409 - mean_squared_error: 0.0325 - val_loss: 0.1540 - val_mean_squared_error: 0.0332\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1238 - mean_squared_error: 0.0252\n",
      "Epoch 4: val_loss did not improve from 0.15405\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1238 - mean_squared_error: 0.0252 - val_loss: 0.1541 - val_mean_squared_error: 0.0328\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0214\n",
      "Epoch 5: val_loss improved from 0.15405 to 0.14924, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1145 - mean_squared_error: 0.0214 - val_loss: 0.1492 - val_mean_squared_error: 0.0306\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0202\n",
      "Epoch 6: val_loss improved from 0.14924 to 0.14907, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.1109 - mean_squared_error: 0.0202 - val_loss: 0.1491 - val_mean_squared_error: 0.0303\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1096 - mean_squared_error: 0.0197\n",
      "Epoch 7: val_loss did not improve from 0.14907\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1096 - mean_squared_error: 0.0197 - val_loss: 0.1558 - val_mean_squared_error: 0.0327\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1085 - mean_squared_error: 0.0192\n",
      "Epoch 8: val_loss improved from 0.14907 to 0.14805, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1085 - mean_squared_error: 0.0192 - val_loss: 0.1480 - val_mean_squared_error: 0.0302\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0191\n",
      "Epoch 9: val_loss improved from 0.14805 to 0.13435, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1081 - mean_squared_error: 0.0191 - val_loss: 0.1343 - val_mean_squared_error: 0.0250\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0192\n",
      "Epoch 10: val_loss improved from 0.13435 to 0.12497, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride2_size9_pool4_do0.5_tra5_head8_kdim64_fnn128/weights_3.hdf5\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.1081 - mean_squared_error: 0.0192 - val_loss: 0.1250 - val_mean_squared_error: 0.0222\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1087 - mean_squared_error: 0.0193\n",
      "Epoch 11: val_loss did not improve from 0.12497\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.1087 - mean_squared_error: 0.0193 - val_loss: 0.1297 - val_mean_squared_error: 0.0236\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.0191\n",
      "Epoch 12: val_loss did not improve from 0.12497\n",
      "79/79 [==============================] - 3s 42ms/step - loss: 0.1079 - mean_squared_error: 0.0191 - val_loss: 0.1360 - val_mean_squared_error: 0.0255\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1074 - mean_squared_error: 0.0188\n",
      "Epoch 13: val_loss did not improve from 0.12497\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1074 - mean_squared_error: 0.0188 - val_loss: 0.1288 - val_mean_squared_error: 0.0233\n",
      "27/27 [==============================] - 1s 18ms/step\n",
      " ###3 fold : val mae 0.12###\n",
      "mae12.53+-0.30\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3136 - mean_squared_error: 0.1305\n",
      "Epoch 1: val_loss improved from inf to 0.16130, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 24s 55ms/step - loss: 0.3136 - mean_squared_error: 0.1305 - val_loss: 0.1613 - val_mean_squared_error: 0.0408\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2068 - mean_squared_error: 0.0657\n",
      "Epoch 2: val_loss improved from 0.16130 to 0.15383, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 8s 49ms/step - loss: 0.2068 - mean_squared_error: 0.0657 - val_loss: 0.1538 - val_mean_squared_error: 0.0341\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1462 - mean_squared_error: 0.0350\n",
      "Epoch 3: val_loss did not improve from 0.15383\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1462 - mean_squared_error: 0.0350 - val_loss: 0.1713 - val_mean_squared_error: 0.0399\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1199 - mean_squared_error: 0.0237\n",
      "Epoch 4: val_loss did not improve from 0.15383\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1199 - mean_squared_error: 0.0237 - val_loss: 0.1767 - val_mean_squared_error: 0.0415\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.0207\n",
      "Epoch 5: val_loss did not improve from 0.15383\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1124 - mean_squared_error: 0.0207 - val_loss: 0.1702 - val_mean_squared_error: 0.0389\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      " ###0 fold : val mae 0.16###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3494 - mean_squared_error: 0.1528\n",
      "Epoch 1: val_loss improved from inf to 0.30011, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 10s 51ms/step - loss: 0.3494 - mean_squared_error: 0.1528 - val_loss: 0.3001 - val_mean_squared_error: 0.1191\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.2172 - mean_squared_error: 0.0712\n",
      "Epoch 2: val_loss improved from 0.30011 to 0.18472, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.2172 - mean_squared_error: 0.0712 - val_loss: 0.1847 - val_mean_squared_error: 0.0468\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1499 - mean_squared_error: 0.0371\n",
      "Epoch 3: val_loss improved from 0.18472 to 0.16011, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1499 - mean_squared_error: 0.0371 - val_loss: 0.1601 - val_mean_squared_error: 0.0352\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1220 - mean_squared_error: 0.0246\n",
      "Epoch 4: val_loss did not improve from 0.16011\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1220 - mean_squared_error: 0.0246 - val_loss: 0.1845 - val_mean_squared_error: 0.0446\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1135 - mean_squared_error: 0.0212\n",
      "Epoch 5: val_loss improved from 0.16011 to 0.15306, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1135 - mean_squared_error: 0.0212 - val_loss: 0.1531 - val_mean_squared_error: 0.0318\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1099 - mean_squared_error: 0.0198\n",
      "Epoch 6: val_loss did not improve from 0.15306\n",
      "157/157 [==============================] - 7s 45ms/step - loss: 0.1099 - mean_squared_error: 0.0198 - val_loss: 0.1575 - val_mean_squared_error: 0.0337\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0197\n",
      "Epoch 7: val_loss did not improve from 0.15306\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1103 - mean_squared_error: 0.0197 - val_loss: 0.1720 - val_mean_squared_error: 0.0392\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1095 - mean_squared_error: 0.0195\n",
      "Epoch 8: val_loss improved from 0.15306 to 0.14794, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1095 - mean_squared_error: 0.0195 - val_loss: 0.1479 - val_mean_squared_error: 0.0300\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0193\n",
      "Epoch 9: val_loss improved from 0.14794 to 0.13594, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 48ms/step - loss: 0.1092 - mean_squared_error: 0.0193 - val_loss: 0.1359 - val_mean_squared_error: 0.0260\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0194\n",
      "Epoch 10: val_loss did not improve from 0.13594\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1090 - mean_squared_error: 0.0194 - val_loss: 0.1374 - val_mean_squared_error: 0.0262\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0196\n",
      "Epoch 11: val_loss did not improve from 0.13594\n",
      "157/157 [==============================] - 7s 45ms/step - loss: 0.1092 - mean_squared_error: 0.0196 - val_loss: 0.1374 - val_mean_squared_error: 0.0266\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1083 - mean_squared_error: 0.0193\n",
      "Epoch 12: val_loss improved from 0.13594 to 0.12978, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1083 - mean_squared_error: 0.0193 - val_loss: 0.1298 - val_mean_squared_error: 0.0237\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1087 - mean_squared_error: 0.0192\n",
      "Epoch 13: val_loss improved from 0.12978 to 0.12917, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1087 - mean_squared_error: 0.0192 - val_loss: 0.1292 - val_mean_squared_error: 0.0235\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0189\n",
      "Epoch 14: val_loss did not improve from 0.12917\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.1078 - mean_squared_error: 0.0189 - val_loss: 0.1326 - val_mean_squared_error: 0.0248\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0190\n",
      "Epoch 15: val_loss improved from 0.12917 to 0.11522, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1075 - mean_squared_error: 0.0190 - val_loss: 0.1152 - val_mean_squared_error: 0.0195\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1088 - mean_squared_error: 0.0193\n",
      "Epoch 16: val_loss did not improve from 0.11522\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1088 - mean_squared_error: 0.0193 - val_loss: 0.1214 - val_mean_squared_error: 0.0212\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0189\n",
      "Epoch 17: val_loss did not improve from 0.11522\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1071 - mean_squared_error: 0.0189 - val_loss: 0.1289 - val_mean_squared_error: 0.0236\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1077 - mean_squared_error: 0.0190\n",
      "Epoch 18: val_loss did not improve from 0.11522\n",
      "157/157 [==============================] - 7s 45ms/step - loss: 0.1077 - mean_squared_error: 0.0190 - val_loss: 0.1207 - val_mean_squared_error: 0.0210\n",
      "53/53 [==============================] - 2s 18ms/step\n",
      " ###1 fold : val mae 0.12###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3152 - mean_squared_error: 0.1319\n",
      "Epoch 1: val_loss improved from inf to 0.54377, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 10s 53ms/step - loss: 0.3152 - mean_squared_error: 0.1319 - val_loss: 0.5438 - val_mean_squared_error: 0.3187\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1886 - mean_squared_error: 0.0560\n",
      "Epoch 2: val_loss improved from 0.54377 to 0.38960, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1886 - mean_squared_error: 0.0560 - val_loss: 0.3896 - val_mean_squared_error: 0.1693\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1361 - mean_squared_error: 0.0308\n",
      "Epoch 3: val_loss improved from 0.38960 to 0.25483, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1361 - mean_squared_error: 0.0308 - val_loss: 0.2548 - val_mean_squared_error: 0.0793\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1175 - mean_squared_error: 0.0225\n",
      "Epoch 4: val_loss improved from 0.25483 to 0.23576, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1175 - mean_squared_error: 0.0225 - val_loss: 0.2358 - val_mean_squared_error: 0.0692\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1115 - mean_squared_error: 0.0202\n",
      "Epoch 5: val_loss improved from 0.23576 to 0.18478, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1115 - mean_squared_error: 0.0202 - val_loss: 0.1848 - val_mean_squared_error: 0.0444\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0198\n",
      "Epoch 6: val_loss improved from 0.18478 to 0.16946, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 48ms/step - loss: 0.1103 - mean_squared_error: 0.0198 - val_loss: 0.1695 - val_mean_squared_error: 0.0380\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1097 - mean_squared_error: 0.0195\n",
      "Epoch 7: val_loss did not improve from 0.16946\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1097 - mean_squared_error: 0.0195 - val_loss: 0.1738 - val_mean_squared_error: 0.0396\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1091 - mean_squared_error: 0.0195\n",
      "Epoch 8: val_loss did not improve from 0.16946\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1091 - mean_squared_error: 0.0195 - val_loss: 0.1827 - val_mean_squared_error: 0.0435\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1089 - mean_squared_error: 0.0192\n",
      "Epoch 9: val_loss improved from 0.16946 to 0.16769, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1089 - mean_squared_error: 0.0192 - val_loss: 0.1677 - val_mean_squared_error: 0.0371\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0188\n",
      "Epoch 10: val_loss improved from 0.16769 to 0.16513, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1076 - mean_squared_error: 0.0188 - val_loss: 0.1651 - val_mean_squared_error: 0.0362\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0191\n",
      "Epoch 11: val_loss improved from 0.16513 to 0.16382, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1082 - mean_squared_error: 0.0191 - val_loss: 0.1638 - val_mean_squared_error: 0.0358\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0189\n",
      "Epoch 12: val_loss improved from 0.16382 to 0.14748, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1078 - mean_squared_error: 0.0189 - val_loss: 0.1475 - val_mean_squared_error: 0.0295\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0191\n",
      "Epoch 13: val_loss improved from 0.14748 to 0.14432, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1081 - mean_squared_error: 0.0191 - val_loss: 0.1443 - val_mean_squared_error: 0.0282\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0190\n",
      "Epoch 14: val_loss improved from 0.14432 to 0.13017, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1076 - mean_squared_error: 0.0190 - val_loss: 0.1302 - val_mean_squared_error: 0.0238\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0192\n",
      "Epoch 15: val_loss did not improve from 0.13017\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1081 - mean_squared_error: 0.0192 - val_loss: 0.1461 - val_mean_squared_error: 0.0290\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0189\n",
      "Epoch 16: val_loss improved from 0.13017 to 0.12890, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1078 - mean_squared_error: 0.0189 - val_loss: 0.1289 - val_mean_squared_error: 0.0231\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1072 - mean_squared_error: 0.0188\n",
      "Epoch 17: val_loss improved from 0.12890 to 0.12787, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1072 - mean_squared_error: 0.0188 - val_loss: 0.1279 - val_mean_squared_error: 0.0227\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1076 - mean_squared_error: 0.0188\n",
      "Epoch 18: val_loss did not improve from 0.12787\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1076 - mean_squared_error: 0.0188 - val_loss: 0.1323 - val_mean_squared_error: 0.0241\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0188\n",
      "Epoch 19: val_loss improved from 0.12787 to 0.12550, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1070 - mean_squared_error: 0.0188 - val_loss: 0.1255 - val_mean_squared_error: 0.0224\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1070 - mean_squared_error: 0.0189\n",
      "Epoch 20: val_loss improved from 0.12550 to 0.12288, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1070 - mean_squared_error: 0.0189 - val_loss: 0.1229 - val_mean_squared_error: 0.0215\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1067 - mean_squared_error: 0.0187\n",
      "Epoch 21: val_loss did not improve from 0.12288\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1067 - mean_squared_error: 0.0187 - val_loss: 0.1239 - val_mean_squared_error: 0.0218\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0189\n",
      "Epoch 22: val_loss improved from 0.12288 to 0.11851, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1073 - mean_squared_error: 0.0189 - val_loss: 0.1185 - val_mean_squared_error: 0.0201\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0188\n",
      "Epoch 23: val_loss did not improve from 0.11851\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1073 - mean_squared_error: 0.0188 - val_loss: 0.1212 - val_mean_squared_error: 0.0207\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1073 - mean_squared_error: 0.0189\n",
      "Epoch 24: val_loss did not improve from 0.11851\n",
      "157/157 [==============================] - 7s 45ms/step - loss: 0.1073 - mean_squared_error: 0.0189 - val_loss: 0.1190 - val_mean_squared_error: 0.0201\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0186\n",
      "Epoch 25: val_loss did not improve from 0.11851\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1066 - mean_squared_error: 0.0186 - val_loss: 0.1246 - val_mean_squared_error: 0.0218\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      " ###2 fold : val mae 0.12###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3820 - mean_squared_error: 0.1717\n",
      "Epoch 1: val_loss improved from inf to 0.37485, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 11s 54ms/step - loss: 0.3820 - mean_squared_error: 0.1717 - val_loss: 0.3749 - val_mean_squared_error: 0.1668\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3818 - mean_squared_error: 0.1710\n",
      "Epoch 2: val_loss did not improve from 0.37485\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.3818 - mean_squared_error: 0.1710 - val_loss: 0.3753 - val_mean_squared_error: 0.1671\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3789 - mean_squared_error: 0.1704\n",
      "Epoch 3: val_loss improved from 0.37485 to 0.21167, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.3789 - mean_squared_error: 0.1704 - val_loss: 0.2117 - val_mean_squared_error: 0.0693\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.3029 - mean_squared_error: 0.1215\n",
      "Epoch 4: val_loss improved from 0.21167 to 0.19774, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.3029 - mean_squared_error: 0.1215 - val_loss: 0.1977 - val_mean_squared_error: 0.0555\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1662 - mean_squared_error: 0.0445\n",
      "Epoch 5: val_loss improved from 0.19774 to 0.16502, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn3_filt16_stride2_size7_pool2_do0.5_tra5_head8_kdim128_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1662 - mean_squared_error: 0.0445 - val_loss: 0.1650 - val_mean_squared_error: 0.0372\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1214 - mean_squared_error: 0.0243\n",
      "Epoch 6: val_loss did not improve from 0.16502\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1214 - mean_squared_error: 0.0243 - val_loss: 0.2021 - val_mean_squared_error: 0.0529\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1122 - mean_squared_error: 0.0205\n",
      "Epoch 7: val_loss did not improve from 0.16502\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1122 - mean_squared_error: 0.0205 - val_loss: 0.2068 - val_mean_squared_error: 0.0552\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1096 - mean_squared_error: 0.0195\n",
      "Epoch 8: val_loss did not improve from 0.16502\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1096 - mean_squared_error: 0.0195 - val_loss: 0.2115 - val_mean_squared_error: 0.0572\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      " ###3 fold : val mae 0.16###\n",
      "mae13.98+-2.03\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2626 - mean_squared_error: 0.1005\n",
      "Epoch 1: val_loss improved from inf to 0.11582, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 16s 55ms/step - loss: 0.2626 - mean_squared_error: 0.1005 - val_loss: 0.1158 - val_mean_squared_error: 0.0221\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2104 - mean_squared_error: 0.0686\n",
      "Epoch 2: val_loss improved from 0.11582 to 0.10623, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.2104 - mean_squared_error: 0.0686 - val_loss: 0.1062 - val_mean_squared_error: 0.0186\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1738 - mean_squared_error: 0.0489\n",
      "Epoch 3: val_loss improved from 0.10623 to 0.09955, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1738 - mean_squared_error: 0.0489 - val_loss: 0.0995 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1443 - mean_squared_error: 0.0344\n",
      "Epoch 4: val_loss did not improve from 0.09955\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1443 - mean_squared_error: 0.0344 - val_loss: 0.1021 - val_mean_squared_error: 0.0162\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1248 - mean_squared_error: 0.0255\n",
      "Epoch 5: val_loss did not improve from 0.09955\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1248 - mean_squared_error: 0.0255 - val_loss: 0.1048 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1165 - mean_squared_error: 0.0222\n",
      "Epoch 6: val_loss did not improve from 0.09955\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1165 - mean_squared_error: 0.0222 - val_loss: 0.1067 - val_mean_squared_error: 0.0172\n",
      "27/27 [==============================] - 1s 17ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2611 - mean_squared_error: 0.1003\n",
      "Epoch 1: val_loss improved from inf to 0.12168, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 6s 53ms/step - loss: 0.2611 - mean_squared_error: 0.1003 - val_loss: 0.1217 - val_mean_squared_error: 0.0244\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2053 - mean_squared_error: 0.0655\n",
      "Epoch 2: val_loss improved from 0.12168 to 0.10565, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.2053 - mean_squared_error: 0.0655 - val_loss: 0.1056 - val_mean_squared_error: 0.0185\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1720 - mean_squared_error: 0.0479\n",
      "Epoch 3: val_loss improved from 0.10565 to 0.09702, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1720 - mean_squared_error: 0.0479 - val_loss: 0.0970 - val_mean_squared_error: 0.0154\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1455 - mean_squared_error: 0.0347\n",
      "Epoch 4: val_loss did not improve from 0.09702\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1455 - mean_squared_error: 0.0347 - val_loss: 0.0987 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1271 - mean_squared_error: 0.0263\n",
      "Epoch 5: val_loss did not improve from 0.09702\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1271 - mean_squared_error: 0.0263 - val_loss: 0.0989 - val_mean_squared_error: 0.0159\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1172 - mean_squared_error: 0.0224\n",
      "Epoch 6: val_loss did not improve from 0.09702\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1172 - mean_squared_error: 0.0224 - val_loss: 0.0997 - val_mean_squared_error: 0.0162\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2605 - mean_squared_error: 0.1000\n",
      "Epoch 1: val_loss improved from inf to 0.11318, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 6s 53ms/step - loss: 0.2605 - mean_squared_error: 0.1000 - val_loss: 0.1132 - val_mean_squared_error: 0.0218\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2037 - mean_squared_error: 0.0640\n",
      "Epoch 2: val_loss improved from 0.11318 to 0.10043, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.2037 - mean_squared_error: 0.0640 - val_loss: 0.1004 - val_mean_squared_error: 0.0164\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1702 - mean_squared_error: 0.0470\n",
      "Epoch 3: val_loss did not improve from 0.10043\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1702 - mean_squared_error: 0.0470 - val_loss: 0.1006 - val_mean_squared_error: 0.0166\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1414 - mean_squared_error: 0.0331\n",
      "Epoch 4: val_loss did not improve from 0.10043\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1414 - mean_squared_error: 0.0331 - val_loss: 0.1012 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1242 - mean_squared_error: 0.0253\n",
      "Epoch 5: val_loss did not improve from 0.10043\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1242 - mean_squared_error: 0.0253 - val_loss: 0.1015 - val_mean_squared_error: 0.0161\n",
      "27/27 [==============================] - 2s 15ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2596 - mean_squared_error: 0.0995\n",
      "Epoch 1: val_loss improved from inf to 0.11581, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 6s 53ms/step - loss: 0.2596 - mean_squared_error: 0.0995 - val_loss: 0.1158 - val_mean_squared_error: 0.0222\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.2045 - mean_squared_error: 0.0644\n",
      "Epoch 2: val_loss improved from 0.11581 to 0.10612, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.2045 - mean_squared_error: 0.0644 - val_loss: 0.1061 - val_mean_squared_error: 0.0183\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1674 - mean_squared_error: 0.0454\n",
      "Epoch 3: val_loss did not improve from 0.10612\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1674 - mean_squared_error: 0.0454 - val_loss: 0.1071 - val_mean_squared_error: 0.0177\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1388 - mean_squared_error: 0.0317\n",
      "Epoch 4: val_loss improved from 0.10612 to 0.10396, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 41ms/step - loss: 0.1388 - mean_squared_error: 0.0317 - val_loss: 0.1040 - val_mean_squared_error: 0.0168\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1227 - mean_squared_error: 0.0244\n",
      "Epoch 5: val_loss did not improve from 0.10396\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1227 - mean_squared_error: 0.0244 - val_loss: 0.1067 - val_mean_squared_error: 0.0174\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1156 - mean_squared_error: 0.0217\n",
      "Epoch 6: val_loss did not improve from 0.10396\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1156 - mean_squared_error: 0.0217 - val_loss: 0.1043 - val_mean_squared_error: 0.0170\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1120 - mean_squared_error: 0.0204\n",
      "Epoch 7: val_loss improved from 0.10396 to 0.10290, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt16_stride5_size7_pool2_do0.5_tra4_head8_kdim16_fnn64/weights_3.hdf5\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1120 - mean_squared_error: 0.0204 - val_loss: 0.1029 - val_mean_squared_error: 0.0167\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1104 - mean_squared_error: 0.0198\n",
      "Epoch 8: val_loss did not improve from 0.10290\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1104 - mean_squared_error: 0.0198 - val_loss: 0.1057 - val_mean_squared_error: 0.0173\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0198\n",
      "Epoch 9: val_loss did not improve from 0.10290\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1103 - mean_squared_error: 0.0198 - val_loss: 0.1079 - val_mean_squared_error: 0.0178\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1080 - mean_squared_error: 0.0193\n",
      "Epoch 10: val_loss did not improve from 0.10290\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1080 - mean_squared_error: 0.0193 - val_loss: 0.1040 - val_mean_squared_error: 0.0170\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae10.11+-0.18\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1320 - mean_squared_error: 0.0296\n",
      "Epoch 1: val_loss improved from inf to 0.10649, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 21s 55ms/step - loss: 0.1320 - mean_squared_error: 0.0296 - val_loss: 0.1065 - val_mean_squared_error: 0.0177\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.0201\n",
      "Epoch 2: val_loss improved from 0.10649 to 0.09931, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_0.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1103 - mean_squared_error: 0.0201 - val_loss: 0.0993 - val_mean_squared_error: 0.0158\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0192\n",
      "Epoch 3: val_loss did not improve from 0.09931\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1075 - mean_squared_error: 0.0192 - val_loss: 0.1053 - val_mean_squared_error: 0.0173\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0182\n",
      "Epoch 4: val_loss did not improve from 0.09931\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1049 - mean_squared_error: 0.0182 - val_loss: 0.1109 - val_mean_squared_error: 0.0189\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0173\n",
      "Epoch 5: val_loss did not improve from 0.09931\n",
      "157/157 [==============================] - 7s 46ms/step - loss: 0.1021 - mean_squared_error: 0.0173 - val_loss: 0.1234 - val_mean_squared_error: 0.0228\n",
      "53/53 [==============================] - 3s 19ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1288 - mean_squared_error: 0.0282\n",
      "Epoch 1: val_loss improved from inf to 0.11673, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 12s 53ms/step - loss: 0.1288 - mean_squared_error: 0.0282 - val_loss: 0.1167 - val_mean_squared_error: 0.0224\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1092 - mean_squared_error: 0.0200\n",
      "Epoch 2: val_loss improved from 0.11673 to 0.10186, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 48ms/step - loss: 0.1092 - mean_squared_error: 0.0200 - val_loss: 0.1019 - val_mean_squared_error: 0.0180\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1068 - mean_squared_error: 0.0190\n",
      "Epoch 3: val_loss improved from 0.10186 to 0.09783, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_1.hdf5\n",
      "157/157 [==============================] - 7s 48ms/step - loss: 0.1068 - mean_squared_error: 0.0190 - val_loss: 0.0978 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1051 - mean_squared_error: 0.0184\n",
      "Epoch 4: val_loss did not improve from 0.09783\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1051 - mean_squared_error: 0.0184 - val_loss: 0.1020 - val_mean_squared_error: 0.0166\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1030 - mean_squared_error: 0.0177\n",
      "Epoch 5: val_loss did not improve from 0.09783\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1030 - mean_squared_error: 0.0177 - val_loss: 0.1018 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.0172\n",
      "Epoch 6: val_loss did not improve from 0.09783\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1015 - mean_squared_error: 0.0172 - val_loss: 0.0993 - val_mean_squared_error: 0.0157\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1290 - mean_squared_error: 0.0282\n",
      "Epoch 1: val_loss improved from inf to 0.10138, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 12s 55ms/step - loss: 0.1290 - mean_squared_error: 0.0282 - val_loss: 0.1014 - val_mean_squared_error: 0.0170\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1113 - mean_squared_error: 0.0204\n",
      "Epoch 2: val_loss improved from 0.10138 to 0.09918, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1113 - mean_squared_error: 0.0204 - val_loss: 0.0992 - val_mean_squared_error: 0.0162\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1078 - mean_squared_error: 0.0191\n",
      "Epoch 3: val_loss improved from 0.09918 to 0.09650, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_2.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1078 - mean_squared_error: 0.0191 - val_loss: 0.0965 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1046 - mean_squared_error: 0.0181\n",
      "Epoch 4: val_loss did not improve from 0.09650\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1046 - mean_squared_error: 0.0181 - val_loss: 0.1088 - val_mean_squared_error: 0.0186\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0174\n",
      "Epoch 5: val_loss did not improve from 0.09650\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1032 - mean_squared_error: 0.0174 - val_loss: 0.1036 - val_mean_squared_error: 0.0167\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1021 - mean_squared_error: 0.0172\n",
      "Epoch 6: val_loss did not improve from 0.09650\n",
      "157/157 [==============================] - 7s 48ms/step - loss: 0.1021 - mean_squared_error: 0.0172 - val_loss: 0.1076 - val_mean_squared_error: 0.0178\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1334 - mean_squared_error: 0.0308\n",
      "Epoch 1: val_loss improved from inf to 0.15055, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 12s 54ms/step - loss: 0.1334 - mean_squared_error: 0.0308 - val_loss: 0.1506 - val_mean_squared_error: 0.0324\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1108 - mean_squared_error: 0.0203\n",
      "Epoch 2: val_loss improved from 0.15055 to 0.11459, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 7s 48ms/step - loss: 0.1108 - mean_squared_error: 0.0203 - val_loss: 0.1146 - val_mean_squared_error: 0.0204\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.0185\n",
      "Epoch 3: val_loss improved from 0.11459 to 0.10847, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 48ms/step - loss: 0.1060 - mean_squared_error: 0.0185 - val_loss: 0.1085 - val_mean_squared_error: 0.0184\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.0173\n",
      "Epoch 4: val_loss did not improve from 0.10847\n",
      "157/157 [==============================] - 7s 48ms/step - loss: 0.1026 - mean_squared_error: 0.0173 - val_loss: 0.1171 - val_mean_squared_error: 0.0206\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0175\n",
      "Epoch 5: val_loss improved from 0.10847 to 0.10785, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt16_stride2_size9_pool2_do0.1_tra5_head2_kdim64_fnn128/weights_3.hdf5\n",
      "157/157 [==============================] - 8s 50ms/step - loss: 0.1028 - mean_squared_error: 0.0175 - val_loss: 0.1078 - val_mean_squared_error: 0.0180\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0167\n",
      "Epoch 6: val_loss did not improve from 0.10785\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.1005 - mean_squared_error: 0.0167 - val_loss: 0.1140 - val_mean_squared_error: 0.0199\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0163\n",
      "Epoch 7: val_loss did not improve from 0.10785\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.0996 - mean_squared_error: 0.0163 - val_loss: 0.1158 - val_mean_squared_error: 0.0201\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.0164\n",
      "Epoch 8: val_loss did not improve from 0.10785\n",
      "157/157 [==============================] - 7s 47ms/step - loss: 0.0996 - mean_squared_error: 0.0164 - val_loss: 0.1120 - val_mean_squared_error: 0.0192\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      " ###3 fold : val mae 0.11###\n",
      "mae10.14+-0.29\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1608 - mean_squared_error: 0.0432\n",
      "Epoch 1: val_loss improved from inf to 0.10230, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 20s 46ms/step - loss: 0.1608 - mean_squared_error: 0.0432 - val_loss: 0.1023 - val_mean_squared_error: 0.0176\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1240 - mean_squared_error: 0.0252\n",
      "Epoch 2: val_loss improved from 0.10230 to 0.09817, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_0.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1240 - mean_squared_error: 0.0252 - val_loss: 0.0982 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1151 - mean_squared_error: 0.0218\n",
      "Epoch 3: val_loss did not improve from 0.09817\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1151 - mean_squared_error: 0.0218 - val_loss: 0.1001 - val_mean_squared_error: 0.0161\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1090 - mean_squared_error: 0.0196\n",
      "Epoch 4: val_loss did not improve from 0.09817\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1090 - mean_squared_error: 0.0196 - val_loss: 0.0993 - val_mean_squared_error: 0.0162\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0188\n",
      "Epoch 5: val_loss did not improve from 0.09817\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1066 - mean_squared_error: 0.0188 - val_loss: 0.0989 - val_mean_squared_error: 0.0160\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      " ###0 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1563 - mean_squared_error: 0.0409\n",
      "Epoch 1: val_loss improved from inf to 0.10241, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 9s 47ms/step - loss: 0.1563 - mean_squared_error: 0.0409 - val_loss: 0.1024 - val_mean_squared_error: 0.0169\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1210 - mean_squared_error: 0.0242\n",
      "Epoch 2: val_loss improved from 0.10241 to 0.09758, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_1.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1210 - mean_squared_error: 0.0242 - val_loss: 0.0976 - val_mean_squared_error: 0.0154\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.0212\n",
      "Epoch 3: val_loss did not improve from 0.09758\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1134 - mean_squared_error: 0.0212 - val_loss: 0.0984 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1075 - mean_squared_error: 0.0192\n",
      "Epoch 4: val_loss did not improve from 0.09758\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.1075 - mean_squared_error: 0.0192 - val_loss: 0.1003 - val_mean_squared_error: 0.0157\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1050 - mean_squared_error: 0.0182\n",
      "Epoch 5: val_loss did not improve from 0.09758\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1050 - mean_squared_error: 0.0182 - val_loss: 0.1018 - val_mean_squared_error: 0.0164\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1553 - mean_squared_error: 0.0407\n",
      "Epoch 1: val_loss improved from inf to 0.10184, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 9s 43ms/step - loss: 0.1553 - mean_squared_error: 0.0407 - val_loss: 0.1018 - val_mean_squared_error: 0.0178\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1211 - mean_squared_error: 0.0241\n",
      "Epoch 2: val_loss improved from 0.10184 to 0.09656, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1211 - mean_squared_error: 0.0241 - val_loss: 0.0966 - val_mean_squared_error: 0.0156\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1125 - mean_squared_error: 0.0208\n",
      "Epoch 3: val_loss did not improve from 0.09656\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1125 - mean_squared_error: 0.0208 - val_loss: 0.0983 - val_mean_squared_error: 0.0156\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1069 - mean_squared_error: 0.0189\n",
      "Epoch 4: val_loss improved from 0.09656 to 0.09575, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_2.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1069 - mean_squared_error: 0.0189 - val_loss: 0.0957 - val_mean_squared_error: 0.0152\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0180\n",
      "Epoch 5: val_loss did not improve from 0.09575\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1049 - mean_squared_error: 0.0180 - val_loss: 0.0972 - val_mean_squared_error: 0.0152\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1039 - mean_squared_error: 0.0176\n",
      "Epoch 6: val_loss did not improve from 0.09575\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1039 - mean_squared_error: 0.0176 - val_loss: 0.0973 - val_mean_squared_error: 0.0155\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.0173\n",
      "Epoch 7: val_loss did not improve from 0.09575\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1027 - mean_squared_error: 0.0173 - val_loss: 0.0975 - val_mean_squared_error: 0.0153\n",
      "53/53 [==============================] - 1s 12ms/step\n",
      " ###2 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1551 - mean_squared_error: 0.0411\n",
      "Epoch 1: val_loss improved from inf to 0.10689, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 9s 45ms/step - loss: 0.1551 - mean_squared_error: 0.0411 - val_loss: 0.1069 - val_mean_squared_error: 0.0197\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1197 - mean_squared_error: 0.0237\n",
      "Epoch 2: val_loss did not improve from 0.10689\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1197 - mean_squared_error: 0.0237 - val_loss: 0.1069 - val_mean_squared_error: 0.0195\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1118 - mean_squared_error: 0.0208\n",
      "Epoch 3: val_loss improved from 0.10689 to 0.10332, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1118 - mean_squared_error: 0.0208 - val_loss: 0.1033 - val_mean_squared_error: 0.0178\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.0187\n",
      "Epoch 4: val_loss improved from 0.10332 to 0.09877, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1071 - mean_squared_error: 0.0187 - val_loss: 0.0988 - val_mean_squared_error: 0.0163\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1045 - mean_squared_error: 0.0178\n",
      "Epoch 5: val_loss did not improve from 0.09877\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1045 - mean_squared_error: 0.0178 - val_loss: 0.0991 - val_mean_squared_error: 0.0162\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.0174\n",
      "Epoch 6: val_loss did not improve from 0.09877\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1032 - mean_squared_error: 0.0174 - val_loss: 0.0996 - val_mean_squared_error: 0.0167\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.0173\n",
      "Epoch 7: val_loss improved from 0.09877 to 0.09829, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1028 - mean_squared_error: 0.0173 - val_loss: 0.0983 - val_mean_squared_error: 0.0161\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.0168\n",
      "Epoch 8: val_loss did not improve from 0.09829\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1014 - mean_squared_error: 0.0168 - val_loss: 0.0992 - val_mean_squared_error: 0.0165\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.0168\n",
      "Epoch 9: val_loss did not improve from 0.09829\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1010 - mean_squared_error: 0.0168 - val_loss: 0.0991 - val_mean_squared_error: 0.0164\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.0169\n",
      "Epoch 10: val_loss improved from 0.09829 to 0.09823, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1009 - mean_squared_error: 0.0169 - val_loss: 0.0982 - val_mean_squared_error: 0.0161\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1000 - mean_squared_error: 0.0164\n",
      "Epoch 11: val_loss did not improve from 0.09823\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.1000 - mean_squared_error: 0.0164 - val_loss: 0.0984 - val_mean_squared_error: 0.0160\n",
      "Epoch 12/100\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0167\n",
      "Epoch 12: val_loss improved from 0.09823 to 0.09759, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch64_cnn2_filt32_stride2_size11_pool5_do0.2_tra5_head8_kdim16_fnn64/weights_3.hdf5\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.1005 - mean_squared_error: 0.0167 - val_loss: 0.0976 - val_mean_squared_error: 0.0158\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1006 - mean_squared_error: 0.0166\n",
      "Epoch 13: val_loss did not improve from 0.09759\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1006 - mean_squared_error: 0.0166 - val_loss: 0.0989 - val_mean_squared_error: 0.0164\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.0165\n",
      "Epoch 14: val_loss did not improve from 0.09759\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1005 - mean_squared_error: 0.0165 - val_loss: 0.0978 - val_mean_squared_error: 0.0158\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - ETA: 0s - loss: 0.1003 - mean_squared_error: 0.0165\n",
      "Epoch 15: val_loss did not improve from 0.09759\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.1003 - mean_squared_error: 0.0165 - val_loss: 0.0976 - val_mean_squared_error: 0.0157\n",
      "53/53 [==============================] - 1s 13ms/step\n",
      " ###3 fold : val mae 0.10###\n",
      "mae9.82+-0.07\n",
      "============================\n",
      "randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1882 - mean_squared_error: 0.0562\n",
      "Epoch 1: val_loss improved from inf to 0.10341, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 13s 50ms/step - loss: 0.1882 - mean_squared_error: 0.0562 - val_loss: 0.1034 - val_mean_squared_error: 0.0177\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1409 - mean_squared_error: 0.0323\n",
      "Epoch 2: val_loss improved from 0.10341 to 0.10257, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.1409 - mean_squared_error: 0.0323 - val_loss: 0.1026 - val_mean_squared_error: 0.0174\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1240 - mean_squared_error: 0.0249\n",
      "Epoch 3: val_loss improved from 0.10257 to 0.09792, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1240 - mean_squared_error: 0.0249 - val_loss: 0.0979 - val_mean_squared_error: 0.0162\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1127 - mean_squared_error: 0.0210\n",
      "Epoch 4: val_loss improved from 0.09792 to 0.09336, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1127 - mean_squared_error: 0.0210 - val_loss: 0.0934 - val_mean_squared_error: 0.0147\n",
      "Epoch 5/100\n",
      "77/79 [============================>.] - ETA: 0s - loss: 0.1040 - mean_squared_error: 0.0179\n",
      "Epoch 5: val_loss improved from 0.09336 to 0.08917, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.1039 - mean_squared_error: 0.0179 - val_loss: 0.0892 - val_mean_squared_error: 0.0134\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0967 - mean_squared_error: 0.0156\n",
      "Epoch 6: val_loss did not improve from 0.08917\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0967 - mean_squared_error: 0.0156 - val_loss: 0.0926 - val_mean_squared_error: 0.0146\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0935 - mean_squared_error: 0.0145\n",
      "Epoch 7: val_loss did not improve from 0.08917\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0935 - mean_squared_error: 0.0145 - val_loss: 0.0896 - val_mean_squared_error: 0.0127\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0885 - mean_squared_error: 0.0131\n",
      "Epoch 8: val_loss improved from 0.08917 to 0.08832, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_0.hdf5\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.0885 - mean_squared_error: 0.0131 - val_loss: 0.0883 - val_mean_squared_error: 0.0133\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0851 - mean_squared_error: 0.0121\n",
      "Epoch 9: val_loss did not improve from 0.08832\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0851 - mean_squared_error: 0.0121 - val_loss: 0.0977 - val_mean_squared_error: 0.0164\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0826 - mean_squared_error: 0.0116\n",
      "Epoch 10: val_loss did not improve from 0.08832\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.0826 - mean_squared_error: 0.0116 - val_loss: 0.0949 - val_mean_squared_error: 0.0139\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0801 - mean_squared_error: 0.0108\n",
      "Epoch 11: val_loss did not improve from 0.08832\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.0801 - mean_squared_error: 0.0108 - val_loss: 0.0951 - val_mean_squared_error: 0.0155\n",
      "27/27 [==============================] - 1s 15ms/step\n",
      " ###0 fold : val mae 0.09###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1808 - mean_squared_error: 0.0531\n",
      "Epoch 1: val_loss improved from inf to 0.10315, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 5s 47ms/step - loss: 0.1808 - mean_squared_error: 0.0531 - val_loss: 0.1031 - val_mean_squared_error: 0.0179\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1333 - mean_squared_error: 0.0292\n",
      "Epoch 2: val_loss improved from 0.10315 to 0.09757, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1333 - mean_squared_error: 0.0292 - val_loss: 0.0976 - val_mean_squared_error: 0.0159\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1221 - mean_squared_error: 0.0245\n",
      "Epoch 3: val_loss improved from 0.09757 to 0.09684, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1221 - mean_squared_error: 0.0245 - val_loss: 0.0968 - val_mean_squared_error: 0.0154\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1155 - mean_squared_error: 0.0221\n",
      "Epoch 4: val_loss did not improve from 0.09684\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1155 - mean_squared_error: 0.0221 - val_loss: 0.0987 - val_mean_squared_error: 0.0162\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.0201\n",
      "Epoch 5: val_loss did not improve from 0.09684\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1109 - mean_squared_error: 0.0201 - val_loss: 0.0981 - val_mean_squared_error: 0.0160\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.0193\n",
      "Epoch 6: val_loss improved from 0.09684 to 0.09600, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_1.hdf5\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1082 - mean_squared_error: 0.0193 - val_loss: 0.0960 - val_mean_squared_error: 0.0151\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.0186\n",
      "Epoch 7: val_loss did not improve from 0.09600\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1066 - mean_squared_error: 0.0186 - val_loss: 0.0962 - val_mean_squared_error: 0.0151\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.0181\n",
      "Epoch 8: val_loss did not improve from 0.09600\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1049 - mean_squared_error: 0.0181 - val_loss: 0.0965 - val_mean_squared_error: 0.0154\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.0177\n",
      "Epoch 9: val_loss did not improve from 0.09600\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1041 - mean_squared_error: 0.0177 - val_loss: 0.0960 - val_mean_squared_error: 0.0153\n",
      "27/27 [==============================] - 1s 16ms/step\n",
      " ###1 fold : val mae 0.10###\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1826 - mean_squared_error: 0.0536\n",
      "Epoch 1: val_loss improved from inf to 0.10026, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 6s 50ms/step - loss: 0.1826 - mean_squared_error: 0.0536 - val_loss: 0.1003 - val_mean_squared_error: 0.0175\n",
      "Epoch 2/100\n",
      "77/79 [============================>.] - ETA: 0s - loss: 0.1311 - mean_squared_error: 0.0282\n",
      "Epoch 2: val_loss improved from 0.10026 to 0.09673, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1307 - mean_squared_error: 0.0280 - val_loss: 0.0967 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1206 - mean_squared_error: 0.0239\n",
      "Epoch 3: val_loss did not improve from 0.09673\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1206 - mean_squared_error: 0.0239 - val_loss: 0.0970 - val_mean_squared_error: 0.0159\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.0216\n",
      "Epoch 4: val_loss improved from 0.09673 to 0.09667, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1145 - mean_squared_error: 0.0216 - val_loss: 0.0967 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1117 - mean_squared_error: 0.0203\n",
      "Epoch 5: val_loss improved from 0.09667 to 0.09601, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 36ms/step - loss: 0.1117 - mean_squared_error: 0.0203 - val_loss: 0.0960 - val_mean_squared_error: 0.0151\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1081 - mean_squared_error: 0.0191\n",
      "Epoch 6: val_loss improved from 0.09601 to 0.09582, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 37ms/step - loss: 0.1081 - mean_squared_error: 0.0191 - val_loss: 0.0958 - val_mean_squared_error: 0.0153\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.1059 - mean_squared_error: 0.0182\n",
      "Epoch 7: val_loss improved from 0.09582 to 0.09531, saving model to randomSearch/SRATE500_ECG-bandpass_z-norm_adult_male_train/CNN+transformer+feats_age%100(sigmoid)_loss(mae)_4fold/batch128_cnn3_filt64_stride4_size9_pool4_do0.2_tra3_head2_kdim64_fnn32/weights_2.hdf5\n",
      "79/79 [==============================] - 3s 38ms/step - loss: 0.1059 - mean_squared_error: 0.0182 - val_loss: 0.0953 - val_mean_squared_error: 0.0151\n",
      "Epoch 8/100\n",
      "13/79 [===>..........................] - ETA: 2s - loss: 0.1025 - mean_squared_error: 0.0174"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Layer, LayerNormalization, Dense, Dropout, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Input, Concatenate, multiply, dot, MultiHeadAttention\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "# learning scheduler\n",
    "def step_decay(epoch):\n",
    "    start = 1e-3\n",
    "    drop = 0.1\n",
    "    epochs_drop = 10\n",
    "    lr = start * (drop ** np.floor((epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "random.seed(98)\n",
    "SRATE = 500  # in hz\n",
    "SEGLEN = 10 * SRATE  # samples\n",
    "#BATCH_SIZE = 256\n",
    "MAX_CASES = 500\n",
    "nfold = 4\n",
    "\n",
    "hyperparameters = {\n",
    "    \"nfilt\" : [16, 32, 64, 128],\n",
    "    \"stride\": [2,4,5],\n",
    "    'nhead' : [2, 4, 8],\n",
    "    'kdim': [16, 64, 128, 256],\n",
    "    \"fnode\" : [32, 64, 128],\n",
    "    \"clayer\" : [2, 3, 4],\n",
    "    \"tlayer\" : [3, 4, 5],\n",
    "    \"droprate\" : [0.1, 0.2, 0.5],\n",
    "    \"filtsize\" : [7, 9, 11, 15, 19],\n",
    "    'poolsize' : [2, 4, 5],\n",
    "    'batch_size': [64, 128, 256]\n",
    "}\n",
    "keys, values = zip(*hyperparameters.items())\n",
    "permutations_dicts = it.product(*values)\n",
    "permutations_dicts = list(permutations_dicts)\n",
    "random.shuffle(permutations_dicts)\n",
    "for nfilt, stride, nhead, kdim, fnode, clayer, tlayer, droprate, filtsize, poolsize, batch_size in permutations_dicts:\n",
    "    test_start = time.time()\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    rootdir = f'randomSearch/{hyper_path}/CNN+transformer+feats_age%{SCALE_Y}(sigmoid)_loss(mae)_{nfold}fold'\n",
    "    odir_f = 'batch{}_cnn{}_filt{}_stride{}_size{}_pool{}_do{}'.format(batch_size, clayer, nfilt, stride, filtsize, poolsize, droprate)\n",
    "    odir_f += '_tra{}_head{}_kdim{}_fnn{}'.format(tlayer, nhead, kdim, fnode)\n",
    "    \n",
    "    if not os.path.exists(rootdir):\n",
    "        os.mkdir(rootdir)\n",
    "    \n",
    "    odir = rootdir+'/'+odir_f\n",
    "    print(\"============================\")\n",
    "    print(odir)\n",
    "    print(\"============================\")\n",
    "\n",
    "    # cnn-transformer\n",
    "    # https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "    #with strategy.scope():\n",
    "    with tf.device(f'/gpu:{GPU}'):\n",
    "        out = inp = Input(shape=(x_train.shape[1], x_train.shape[2]), name='input_1')\n",
    "\n",
    "        # out = Conv1D(filters=kdim, kernel_size=filtsize, padding='same')(out)\n",
    "\n",
    "        # conv 여러층    \n",
    "        for i in range(clayer):\n",
    "            out = Conv1D(filters=nfilt, kernel_size=filtsize, strides=stride, padding='same', activation=None)(out)\n",
    "            out = BatchNormalization()(out)\n",
    "            out = Activation('relu')(out)\n",
    "            out = MaxPooling1D(poolsize, padding='same')(out)\n",
    "        out = Dense(kdim)(out)  # 마지막 차원이 nfilt 인데 kdim 으로 바꿔야 transformer block을 쌓을 수 있다.\n",
    "        for i in range(tlayer):  # transformer\n",
    "            attn_output = MultiHeadAttention(num_heads=nhead, key_dim=kdim, attention_axes=[1,])(out, out)\n",
    "            attn_output = Dropout(droprate)(attn_output)\n",
    "            out1 = LayerNormalization(epsilon=1e-6)(out + attn_output)  # sum and norm\n",
    "            ffn_output = tf.keras.Sequential([Dense(fnode, activation=\"relu\"), Dense(kdim)])(out1)\n",
    "            out2 = Dropout(droprate)(ffn_output)\n",
    "            out = LayerNormalization(epsilon=1e-6)(out1 + out2)  # sum and norm\n",
    "        out = GlobalMaxPooling1D()(out)\n",
    "\n",
    "        # concat with X_feature\n",
    "        inp_feat = Input(shape=(feat_train.shape[1]), name=\"input_2\")\n",
    "        out = Concatenate(axis=1)([out, inp_feat])\n",
    "        \n",
    "        if droprate:\n",
    "            out = Dropout(droprate)(out)\n",
    "        out = Dense(fnode)(out)\n",
    "        if droprate:\n",
    "            out = Dropout(droprate)(out)\n",
    "        out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "        if not os.path.exists(odir):\n",
    "            os.mkdir(odir)\n",
    "\n",
    "        #cache_path = odir + \"/initial_weights.hdf5\"\n",
    "        model = Model(inputs=[inp, inp_feat], outputs=[out])\n",
    "        lr_scheduler = LearningRateScheduler(step_decay, verbose=1)\n",
    "        model.compile(loss='mae', optimizer=Adam(lr=lr_scheduler, weight_decay=None), metrics=['mean_squared_error'])\n",
    "        model.save_weights(f'{odir}/initial_weights.hdf5')\n",
    "    \n",
    "    \n",
    "    # 4-fold cv\n",
    "    kfold = KFold(nfold)\n",
    "    tprs, aucs, prs = [], [], []\n",
    "    test_rmse, test_mae = [], []\n",
    "    f1_scores, thvals = [], []\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    mean_recall = np.linspace(0,1,100)\n",
    "\n",
    "    switch = 0\n",
    "    caseids_train = np.unique(c_train)\n",
    "    for fold, (c_cv_trains_mask, c_cv_test_mask) in enumerate(kfold.split(caseids_train)):\n",
    "        c_cv_trains = caseids_train[c_cv_trains_mask]\n",
    "\n",
    "        cv_train_mask = np.isin(c_train, c_cv_trains)\n",
    "        cv_val_mask = ~cv_train_mask\n",
    "\n",
    "        X_train = x_train[cv_train_mask]\n",
    "        X_val = x_train[cv_val_mask]\n",
    "\n",
    "        Y_train = y_train[cv_train_mask]\n",
    "        Y_val = y_train[cv_val_mask]\n",
    "        \n",
    "        Feat_train = feat_train[cv_train_mask]\n",
    "        Feat_val = feat_train[cv_val_mask]\n",
    "\n",
    "        # model 학습\n",
    "        try:\n",
    "            # loading dataset\n",
    "            with tf.device(\"/CPU:0\"):\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\": X_train, \"input_2\": Feat_train}, Y_train)).shuffle(x_train.shape[0]).batch(batch_size)\n",
    "                val_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\": X_val, \"input_2\": Feat_val}, Y_val)).batch(batch_size)\n",
    "                test_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\": x_test, \"input_2\": feat_test}, y_test)).batch(batch_size)\n",
    "                \n",
    "            weightcache = f\"{odir}/weights_{fold}.hdf5\"\n",
    "            #model = multi_gpu_model(model, gpus=4)\n",
    "            #model.compile(loss='mae', optimizer=Adam(lr=lr_scheduler, weight_decay=None), metrics=['mean_squared_error'])\n",
    "            hist = model.fit(train_dataset, validation_data=val_dataset, epochs=100, batch_size=batch_size, #class_weight={0:1, 1:3}, \n",
    "                                    callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weightcache, verbose=1, save_best_only=True),\n",
    "                                                EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')])\n",
    "\n",
    "            model.load_weights(weightcache)\n",
    "            y_pred = model.predict(test_dataset).flatten()\n",
    "\n",
    "            # MAE 계산\n",
    "            model_err = metrics.MeanAbsoluteError()\n",
    "            model_err.update_state(y_test, y_pred)\n",
    "            mae_val = model_err.result().numpy()\n",
    "            test_mae.append(mae_val)\n",
    "\n",
    "\n",
    "\n",
    "            print(f' ###{fold} fold : val mae {mae_val:.2f}###')\n",
    "            tf.keras.backend.clear_session()\n",
    "            model.load_weights(f'{odir}/initial_weights.hdf5')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            switch = 1\n",
    "            shutil.rmtree(odir)\n",
    "            break\n",
    "    ###\n",
    "    if switch:\n",
    "        switch = 0\n",
    "        tf.keras.backend.clear_session()\n",
    "        continue\n",
    "\n",
    "\n",
    "    mean_mae = np.mean(test_mae)\n",
    "    std_mae = np.std(test_mae)\n",
    "\n",
    "    max_idx = test_mae.index(min(test_mae))\n",
    "\n",
    "\n",
    "    print(f'mae{mean_mae*SCALE_Y:.2f}+-{std_mae*SCALE_Y:.2f}')\n",
    "    open(odir+\"/model.json\", \"wt\").write(model.to_json())\n",
    "\n",
    "    os.rename(odir, rootdir+f'/mae{mean_mae*SCALE_Y:.2f}+-{std_mae*SCALE_Y:.2f}_max{max_idx}__{odir_f}')\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hskim",
   "language": "python",
   "name": "hskim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
